[{"path":"index.html","id":"index","chapter":"ようこそ！","heading":"ようこそ！","text":" オンライン版の R によるメタ分析：ハンズオンへようこそ。本書は、 R でメタ分析を行う方法について、わかりやすく紹介するガイドラインである。メタ分析の基本的な手順として、アウトカム指標のプール、フォレストプロット、異質性診断、サブグループ解析、メタ回帰、出版バイアスの制御方法、バイアスリスク評価、プロットツールなどを網羅している。また、ネットワークメタ分析、マルチレベル (３レベル) メタ分析、ベイズメタ分析アプローチ、SEM メタ分析といった高度でありながら関連性の高いトピックも取り上げる。本書で扱うプログラミングや統計的背景は、専門家でなくても理解できるレベルにとどめている。原著の印刷版は、Chapman & Hall/CRC Press (Taylor & Francis) から出版されている。","code":""},{"path":"index.html","id":"ソースレポジトリ","chapter":"ようこそ！","heading":"ソースレポジトリ","text":"本書は、{rmarkdown} および {bookdown} を使用して構築されている。数式は MathJax を使ってレンダリングしている。このガイドの編集に使用したすべての資料とソースコードは GitHub で見ることができる。フォーク、共有、再利用は自由である。ただし、このリポジトリは主に「読むだけ」を想定しており、基本的に PR は考慮されていない (連絡方法については、以下のセクションと前書きを参照)。","code":""},{"path":"index.html","id":"本書の使い方","chapter":"ようこそ！","heading":"本書の使い方","text":"このチュートリアルは、本書の簡単な紹介とメタ分析を行う際の使い方を教えている。","code":""},{"path":"index.html","id":"contributing","chapter":"ようこそ！","heading":"貢献","text":"このガイドはオープンソースプロジェクトであり、本ガイドのいくつかのセクションで追加コンテンツを提供してくれた専門家の貢献者に特別な感謝を捧げる。Luke . McGuinness, University Bristol: Chapter 15, Risk Bias Plots.本書に貢献したい方は、Mathias (mathias.harrer@fau.de) に、メールで提案事項を伝えていただきたい。","code":""},{"path":"index.html","id":"citing-this-guide","chapter":"ようこそ！","heading":"本書を引用","text":"本書の原著を引用する際には、以下のようにしていただきたい。\nHarrer, M., Cuijpers, P., Furukawa, T.., & Ebert, D.D. (2021).\nMeta-Analysis R: Hands-Guide. Boca Raton, FL\nLondon: Chapman & Hall/CRC Press. ISBN 978-0-367-61007-4.\n引用は BibTeX または .ris でもダウンロード可能。","code":""},{"path":"index.html","id":"パッケージを引用","chapter":"ようこそ！","heading":"パッケージを引用","text":"このガイドでは、様々な R パッケージを紹介し、使用していく。こうしたパッケージが誰でも無料で使えるのは、世界中の専門家が膨大な時間と労力を費やして、通常は無報酬で開発してきたからに他ならない。本書で紹介されているパッケージを使ってメタ分析する場合は、レポートの中で引用することも強く推奨する。このガイドでは、新しいパッケージが紹介されるたびに、それを引用するためのリファレンスも提供していく。また、citation(\"package\") を実行することで、適切な引用方法を取得することが可能である。感謝！","code":""},{"path":"preface.html","id":"preface","chapter":"序章","heading":"序章","text":"“problems solved, giving new information,\narranging known since long.”– Ludwig Wittgenstein, Philosophical Investigationsこ\nの世界を観察していて複雑であると気づくのは、ごく当たり前のことである。科学研究も例外ではなく、多くの研究分野において、一見すると乗り越えられないような先行研究群に直面することがある。また、異なる研究からの証拠は矛盾していることがあり、様々な情報源から意味を見出すことが困難な場合もある。そのため、社会科学、医学、生物学、計量経済学など、多くの分野でエビデンス合成の手法が重要な役割を担っている。メタ分析は、様々な研究や分析の結果を組み合わせるために用いられる統計的手法であり、多くの研究分野において不可欠なツールとなっている。メタ分析は、特に実用的な意思決定や将来の研究努力の指針となる場合、非常に重要な意味を持つことがある。そのため、多くの応用研究者はメタ分析のスキルを「統計のツールボックス」の中に入れているが、一方で、自分の研究分野でメタ分析を行う方法を学びたいと考えている研究者もいる。メタ分析は非常に一般的なものとなっており、多くの大学院生や学部生がすでにカリキュラムの一部としてメタ分析の実行方法を学んでいる (その熱心さは様々であるが)。メタ分析の実行方法は、統計計算全体と同様に、この数十年で大きな変化を遂げた。これは、主に R Statistical Programming Language Environmentという形で、オープンソースで共同開発された統計ソフトウェアの台頭と大いに関係がある。 R のエコシステムにより、世界中の研究者や統計学者が独自のパッケージを構築し、誰でも無料で利用することができるようになった。このため、 R 言語用の統計ソフトは目を見張るほど増えている。これを書いている間にも、CRAN Task View には、メタ分析専用パッケージだけでも130以上リストアップされている。R では、文字通り何でも可能である。完全なプログラミング言語なので、必要な関数が見つからなければ、自分で簡単に書くことも可能である。しかし、メタ分析では、もうほとんどその必要はない。それほど多くない R パッケージのコレクションで、現在の「最先端」のメタ解析プログラムに見られるすべての機能を無料で提供しているのである。さらに言えば、現在 R でしか適用できない新しいメタ分析手法もたくさんある。要するに、 R 環境は研究者に多くのメタ解析ツールを提供している。最良のケースでは、データからより確かな結論を導き出すことができ、その結果、意思決定により良い情報を提供することが可能である。ここで、なぜ誰もがメタ分析に R を使わないのかという疑問が湧いてくる。私たちは、主に2つの理由があると考えている。利便性と不安 (そして時にはその両方が混在している) である。どちらの理由も非常に理解しやすいものである。メタ分析者の多くは応用研究者であり、統計学者やプログラマではない。不明瞭で複雑に見えるプログラミング言語を学ぶことを考えると、それが抑止力として働くことがある。メタ分析の手法も同様で、特別な理論的背景、無数の分析的選択肢、正しく解釈する必要のあるさまざまな統計学がある。このガイドでは、これらの懸念の多くが杞憂であること、そして R でのメタ分析の方法を学ぶことは努力に値することを示したい。このガイドが、 R でのメタ分析プロジェクトをマスターするために必要なスキルの習得の一助となれば幸いである。また、このガイドによって、いつどのようなメタ分析手法を適用するかだけでなく、なぜその手法を適用するかも簡単に理解できるようになることを期待している。最後になるが、このガイドは、メタ分析手法と R プログラミングが単なる不便なものではなく、魅力的なトピックであることを示す試みであると考えている。","code":""},{"path":"preface.html","id":"対象者は普通の人","chapter":"序章","heading":"対象者は普通の人","text":"このガイドは、メタ分析の専門家や統計学者向けに書かれたものではない。また、メタ分析手法に関する特別な背景知識を持っていることを前提としていない。必要なのは、基本的な数学的・統計的概念に関する基礎知識だけである。例えば、「平均」「標準偏差」「相関」「回帰」「\\(p\\)値」「正規分布」などは聞いたことがあるだろう。これらの用語にピンとくるのであればもう大丈夫。本当にゼロから始めるのであれば、まず Robert Stinerock の統計学ビギナーズガイド (Stinerock 2018) を読み、 R での実践例を含む徹底的な紹介を受けると良いだろう – あるいは他の統計学入門書でも構わない。数式や統計表記を使うことがあるが、なるべく最小限にとどめるようにした。しかし、慌てないように。数式やギリシャ文字は一見するとわかりにくいが、メタ分析手法の背後にある考え方を的確に表現するための非常に優れた方法であることが多いのである。これらの数式を見て、それが何を表しているのかを知ることで、この先読みすすめるより高度な文章を理解することも容易になる。もちろん、ある記号や文字が何を表しているのか、特定の数式が何を伝えようとしているのか、常に詳しく説明するように努める。この本の付録には、記号のリストと、それが何を表しているのかが書かれている。この後の章、特に上級者向けの手法の章では、応用技術の背後にある考え方を説明するために、少し専門的になる必要がある。それでも、これらの章で使用される数学的、統計的概念に関する背景情報を常に含めるようにする。R (または一般的なプログラミング) の予備知識は必要ない。このガイドでは、独自のメタ分析をコーディングするために必要な R の基本的なスキルを優しく紹介するように努めている。また、学習を継続するための適切なリソースへの参照も提供する。さらに、PC や Mac で R を便利に使用できる無料のコンピュータプログラムをセットアップする方法を紹介する。タイトルにあるように、本書はメタ分析を「行う」部分に焦点をあてている。本書は、 R を使った分析を始めたいと考えている応用研究者、学生、データサイエンティストのニーズを満たす、アクセス可能なリソースとなることを目的としている。しかし、メタ分析は広大で多面的なトピックであるため、このガイドですべてをカバーできないのは当然である。本書では、特に3つの領域について制限を設けている。各トピックについて簡単な入門を提供するが、研究課題を定義する方法、系統的に研究を検索してメタ分析に含める方法、そして研究の質を評価する方法については詳細には説明しない。トピック一つ一つはそれぞれ独自の書籍に値するものであり、幸いにも多くの有用なリソースが少なくとも英語では既に存在している。そこで、メタ分析用のデータを収集する際の重要な検討事項や落とし穴について概要を説明し、詳細については適切なリソースを紹介する。各トピックについて簡単な入門を提供するが、研究課題を定義する方法、系統的に研究を検索してメタ分析に含める方法、そして研究の質を評価する方法については詳細には説明しない。トピック一つ一つはそれぞれ独自の書籍に値するものであり、幸いにも多くの有用なリソースが少なくとも英語では既に存在している。そこで、メタ分析用のデータを収集する際の重要な検討事項や落とし穴について概要を説明し、詳細については適切なリソースを紹介する。このガイドの第二の限界は、技術的なレベルに関するものである。この本は、明らかに「人間」向けに書かれている。本書の目的は、特定のメタ分析技術をいつ、どのように、そしてなぜ適用するのか、その落とし穴も含めて紹介することである。また、本書で扱う技術について、簡単にアクセスでき、概念的な理解を得られるように努め、このミッションに役立つ場合のみ、より技術的な詳細に言及する。当然ながら、専門家レベルのメタ分析や統計学者が望むような技術的な内容を深く掘り下げることは、このガイドの一部には含まれないことになる。それでも、各章にはより高度なリソースや出版物への参照を設け、関心のある読者のために配慮している。このガイドの第二の限界は、技術的なレベルに関するものである。この本は、明らかに「人間」向けに書かれている。本書の目的は、特定のメタ分析技術をいつ、どのように、そしてなぜ適用するのか、その落とし穴も含めて紹介することである。また、本書で扱う技術について、簡単にアクセスでき、概念的な理解を得られるように努め、このミッションに役立つ場合のみ、より技術的な詳細に言及する。当然ながら、専門家レベルのメタ分析や統計学者が望むような技術的な内容を深く掘り下げることは、このガイドの一部には含まれないことになる。それでも、各章にはより高度なリソースや出版物への参照を設け、関心のある読者のために配慮している。書籍の内容は、常に著者の経歴や経験をある程度反映している。本書で取り上げる手法は、幅広い研究領域や専門分野に適用でき、関連性があると確信している。しかし、本書の著者4名は、主に心理学、精神医学、医学、介入研究の最新の研究に精通している。そのため、本書で取り上げる「実世界」での使用例や事例も、私たちが熟知しているトピックに集中している。メタ分析の手法は、(これから説明するいくつかの前提条件を満たせば) データがどのような研究分野に由来しているかにはほとんど関係なく、さまざまな種類の結果指標に使用できることは良いニュースである。しかし、このガイドをできるだけ多くの応用研究分野に広く適用しようと最善を尽くしているが、本書で取り上げる方法が特定の分野に強く関連する可能性もある。書籍の内容は、常に著者の経歴や経験をある程度反映している。本書で取り上げる手法は、幅広い研究領域や専門分野に適用でき、関連性があると確信している。しかし、本書の著者4名は、主に心理学、精神医学、医学、介入研究の最新の研究に精通している。そのため、本書で取り上げる「実世界」での使用例や事例も、私たちが熟知しているトピックに集中している。メタ分析の手法は、(これから説明するいくつかの前提条件を満たせば) データがどのような研究分野に由来しているかにはほとんど関係なく、さまざまな種類の結果指標に使用できることは良いニュースである。しかし、このガイドをできるだけ多くの応用研究分野に広く適用しようと最善を尽くしているが、本書で取り上げる方法が特定の分野に強く関連する可能性もある。","code":""},{"path":"preface.html","id":"本書で扱うトピック","chapter":"序章","heading":"本書で扱うトピック","text":"このガイドでは、特に以下のトピックについて説明する。メタ分析とは何か、そしてなぜメタ分析が発明されたのか。メタ分析とは何か、そしてなぜメタ分析が発明されたのか。メタ分析の利点と一般的な問題点。メタ分析の利点と一般的な問題点。メタ分析のリサーチクエスチョンをどのように設定し、どのように研究のための検索を行うことができるのか。メタ分析のリサーチクエスチョンをどのように設定し、どのように研究のための検索を行うことができるのか。R の設定方法と、 R を便利に使うためのコンピュータ・プログラムである。R の設定方法と、 R を便利に使うためのコンピュータ・プログラムである。メタ分析のデータを R にインポートする方法と、コードで操作する方法。メタ分析のデータを R にインポートする方法と、コードで操作する方法。効果量とは何か、どのように算出するのか。効果量とは何か、どのように算出するのか。固定効果メタ解析とランダム効果メタ解析における効果量のプール方法。固定効果メタ解析とランダム効果メタ解析における効果量のプール方法。メタ分析における異質性の分析方法、およびサブグループ解析とメタ回帰を用いた探索方法。メタ分析における異質性の分析方法、およびサブグループ解析とメタ回帰を用いた探索方法。選択的成果報告の問題点、およびその取り組み方。選択的成果報告の問題点、およびその取り組み方。マルチレベルメタ解析、メタ解析的構造方程式モデリング、ネットワークメタ解析、ベイズメタ解析などの高度なメタ解析手法の実行方法。マルチレベルメタ解析、メタ解析的構造方程式モデリング、ネットワークメタ解析、ベイズメタ解析などの高度なメタ解析手法の実行方法。メタ分析の結果をどのように報告し、再現性を持たせるか。メタ分析の結果をどのように報告し、再現性を持たせるか。","code":""},{"path":"preface.html","id":"本書の使い方-1","chapter":"序章","heading":"本書の使い方","text":"","code":""},{"path":"preface.html","id":"作業の流れ","chapter":"序章","heading":"作業の流れ","text":"本書は「直線的」に読み進めることを意図している。メタ分析と R の基本に関する最初の章から始めて、1章ずつ読み進めていくことを勧める。すぐに実践的な章に飛びつくのは魅力的かもしれないが、一般的には勧めない。学生や研究者に初めてメタ分析を行う方法を教える場合、この手法や R Studio 環境に関する基本的な知識は、後々挫折しないための必要悪であることがわかるようにする。特に、メタ分析と R プログラミングの経験がない場合には、このことが当てはまる。 R の経験者は、 R と R Studio を紹介する章を読み飛ばしても構わないが、復習のために読んでおいても損はないだろう。すべての章はほぼ自己完結しているが、前の章で扱ったトピックを参照することがある。特に高度なメタ解析手法の章では、以前に扱った理論的な概念に慣れていることを前提としている。本書の最後のセクションで、メタ分析に役立つツールを紹介している。しかし、これらのツールはメタ分析を行う際に考慮すべき最後の事柄であるということではない。主にメタ分析プロジェクトのための参考文献として役立つものとしてこれらの章を最後に置いただけである。本書では、テーマごとに関連するセクションで、これらのツールにリンクしている。","code":""},{"path":"preface.html","id":"コンパニオン-r-パッケージ","chapter":"序章","heading":"コンパニオン R パッケージ","text":"本書には {dmetar} というコンパニオン R パッケージが付属している。このパッケージは主に2つの機能を提供する。まず、快適に R に親しむことを目的としている。 R には、メタ解析のための素晴らしい パッケージがすでにあり、その機能は多岐にわたるが、少なくとも初心者が R で使うのは現状では簡単ではない落とし穴もある。{dmetar} パッケージは、この落とし穴を埋めることを目的として、問題解決を容易にする関数を提供する。さらに、このパッケージには、本書で紹介する実践的な例で使用するすべてのデータセットも含まれている。Chapter 2.3 では、{dmetar} パッケージを詳しく紹介し、パッケージのインストール方法を順を追って説明する。大きな変更はないが、{dmetar} は現在も活発に開発されているので、時々パッケージのサイトを見て、メタ解析に使える新機能や改良がないか確認しておくとよいだろう。{dmetar} パッケージのインストールを推奨するが、必須ではない。本書で {dmetar} を使用する場合、その関数の生のコード、または使用するデータセットのダウンロードリンクも提供する。","code":""},{"path":"preface.html","id":"テキストボックス","chapter":"序章","heading":"テキストボックス","text":"本書全体を通して、テキストボックスのセットを使用している。\n一般的な注意事項\n\n一般的なメモには、関連する背景情報、洞察、逸話、考察、または主題に関連するテイクホームメッセージが含まれている。\n\n重要なお知らせ\n\nこのボックスには、注意点、問題点、欠点、落とし穴などの情報が記載されている。\n\n質問\n\n各章の終わりには、このボックスの中にいくつかの質問があり、あなたの知識を試すことが可能である。これらの質問の答えは、巻末の付録Aに掲載されている。\n\n{dmetar} 注意事項\n\n付属の R\nパッケージに含まれる関数やデータセットが使用された場合、{dmetar}\nのノートボックスが表示される。これらのボックスには、パッケージがインストールされていない読者のために、関数コードやデータセットのダウンロードリンクへのURLも含まれている。\n\nどのように報告すればよいのだろうか？\n\nこのボックスには、論文や研究記事で R\n出力を報告する方法についての推奨事項が記載されている。\n","code":""},{"path":"preface.html","id":"凡例","chapter":"序章","heading":"凡例","text":"この本では、いくつかの表記法を使っている。\\[~\\]{package}すべての R パッケージは太字で書かれ、中括弧 (波括弧) でくくられる。これは R のコミュニティでは一般的なパッケージ名の書き方である。\\[~\\]R codeR のコードや R で定義するオブジェクトは、すべてこの等幅フォントで書かれている。\\[~\\]## R 出力R のコードを実行した後に受け取る出力にも同じ等幅フォントが使用されている。ただし、 R の入力と区別するために2つの番号記号 (シャープ記号) を使っている。\\[~\\]\\(Formula\\)セリフフォントは、数式や統計など、数学的な表記をするときに使う。","code":""},{"path":"preface.html","id":"行き詰まったら","chapter":"序章","heading":"行き詰まったら","text":"R でメタ分析を行うための道は、時に険しい道であることは否めない。これは時に誇張されていると思うこともあるが、 R の学習曲線は険しい。統計学は難しいものである。本書では、 R を使ったメタ分析の実行方法を学ぶ際に、できるだけ苦痛を感じないようにするために最善を尽くす。しかし、それでも、時には挫折することがある。これは当然といえば当然なのである。私たちは皆、どこかでゼロから始めなければならないのである。私たちの経験から、 R やメタ分析のやり方を学べなかった人に会ったことがないと断言できる。必要なのは練習と、いつまでも「学び続ける」ことなのである。私たちはあなたを信じている。このモチベーションメッセージよりももう少し実用的なものとして、このガイドでは答えられないようなことにつまずいたときにできることをいくつか紹介する。","code":""},{"path":"preface.html","id":"パニックにならない","chapter":"序章","heading":"パニックにならない","text":"R の最初の一歩を踏み出すとき、多くの人は最初の赤いエラーメッセージが出始めると恐怖を感じるが、恐れる必要はない。誰でもエラーメッセージは頻繁に出ている。パニックになったり、コンピュータを窓から投げ捨てたりするのではなく、深呼吸をしてエラーメッセージをよく読もう。少し手を加えるだけで、エラーメッセージが消えることはよくある。コードのスペルを間違えていないか？括弧を閉じたり、引用符で囲んだりするのを忘れていないか？また、出力が実際に エラーであることを確認する (訳注:訳者は初心者に R の使い方を教えることがあるが、 R のメッセージは赤字かつ英語であるため、初学者はエラーでないものも「エラーが出た」と勘違いすることが多い。)。 R は「エラー (Error)」、「警告 (Warning)」、「メッセージ」を区別している。エラーは、コードが実行されなかったことを意味する。警告は、コードは実行されたが、何か問題が発生した可能性があることを意味する。メッセージは、コードが完全に実行されたことを意味し、通常、関数が内部で行ったことに注意を向けさせたいときに表示される。このため、これは診断メッセージとも呼ばれている。","code":""},{"path":"preface.html","id":"google","chapter":"序章","heading":"Google","text":"あるソフトウェア開発者の友人が、ソフトウェア開発者についてこんなジョークを言ったことがある。「プログラマとは、一般人よりもグーグル操作がうまい人のことだ」。この言葉は、 R プログラミングにも当てはまる。もし、エラーや警告のメッセージの意味が分からない状況に陥ったら、迷わずコピー＆ペーストして、Googleで検索する。その際、「R」をつけると検索結果が良くなることがある。インターネット上のほとんどのコンテンツは英語で書かれているので、 R のエラーメッセージが他の言語で書かれている場合は、 Sys.setenv(LANGUAGE = \"en\") を実行してから、もう一度コードを実行してみよう。世の中には大きな R コミュニティがあり、以前同じ問題に直面した人がいる可能性は非常に高い。また、データに対して何か特別なことをしたいが、そのためにどのような R コマンドを使用できるかがわからない場合にも、Google は役に立つ。専門家であっても、 R のコードを書くときに Google を数十回使うことはよくある。あなたも困ったときは、迷わず Google を使おう。","code":""},{"path":"preface.html","id":"stackoverflow-と-crossvalidated","chapter":"序章","heading":"StackOverflow と CrossValidated","text":"Google で R 関連の質問を検索すると、最初にヒットするリンクが StackOverflow というサイトが多いことがすぐに分かる。StackOverflow は、プログラミングに関連する一般的な質問のための大規模なコミュニティベースのフォーラムである。StackOverflow では、(あなたを含む) すべての人が質問をしたり回答したりすることが可能である。インターネット上の他の多くのフォーラムとは対照的に、StackOverflow で得られる回答は、通常、目標指向で役に立つものである。Google で検索しても問題が解決しない場合は、そこで対処するのが良い解決策になるかもしれない。ただし、いくつか注意しなければならないことがある。まず、質問をするときは、どのプログラミング言語について話しているのかがわかるように、常に [R] というタグを付けてみよう。また、 R で sessionInfo() を実行し、得られた出力を質問に添付する。これにより、あなたが使っている R とパッケージのバージョンを知ることができ、問題の所在を突き止めるのに役立つこともある。最後に、圧倒的な優しさを期待しないことである。StackOverflow のユーザーの多くは経験豊富なプログラマで、特定の解決策を教えてくれるかもしれないが、誰かがあなたの代わりに問題を解決してくれると思うべきではない。また、誰かがこのトピックはすでに他の場所で扱われていることを伝え、リンクを送り、次に進むこともあり得る。とはいえ、StackOverflow を使用することは、通常、あなたが対処している特定の問題に対する質の高いサポートを得るための最良の方法である。ちなみに StackOverflow は、主にプログラミングに関する質問をするところである。統計学的な背景もある質問であれば、代わりに CrossValidated を利用するとよいだろう。CrossValidated は StackOverflow と同じように機能しているが、主に統計学や機械学習の専門家が使用する。","code":""},{"path":"preface.html","id":"問い合わせ","chapter":"序章","heading":"問い合わせ","text":"もし、疑問がこのガイド自体と関係があるように感じられるのであれば、私たちに連絡することも可能である。特に、このガイドの付属の R パッケージである {dmetar} の問題に関係している場合がそうである。パッケージのインストールや機能の使用に問題がある場合、私たちのウェブサイトで問題を報告する方法を見つけることができる。特定の問題が頻繁に発生する場合、私たちは通常その問題を調査し、解決策を探している。既知の問題は、オンライン版ガイドの「修正・備考」セクションにも表示される (ワークフローセクションを参照)。ご質問に対する回答がない場合や、回答までに時間がかかる場合もあるが、ご容赦いただきたい。メタ分析やパッケージに関する質問は毎日多数寄せられており、ひとつひとつに直接お答えすることができない場合もある。(訳注: 日本語訳に関することは、日本語版の githubに報告していただきたい。)","code":""},{"path":"preface.html","id":"謝辞","chapter":"序章","heading":"謝辞","text":"David Grubbs と Chapmann & Hall/CRC Press には、私たちのオンラインガイドを印刷された書籍にするという素晴らしいアイデアをいただき、また編集面で貴重なご支援をいただいたことに感謝する。2018年末にオンライン版の予備的な執筆を始めて以来、多くの研究者や学生が本書で作業した感想や経験を私たちと共有してくた。このフィードバックは非常に貴重であり、本書を読むもののニーズに合わせてさらに調整するのにかなり役立っている。皆さまに感謝する。このガイドで紹介する R メタ分析基盤の開発に携わったすべての研究者に感謝する。しかし、何よりもまず、{meta} と {metafor} パッケージのメンテナである Guido Schwarzer と Wolfgang Viechtbauer に、それぞれお礼を申し上げる。このガイドは、 R メタ解析コミュニティ全体と同様に、彼らの努力と献身なしには存在し得なかった。さらに、本書のコンパニオンサイトにある バイアスリスクの可視化に関する追加章を執筆してくれた、豪華な {robvis} パッケージの著者である Luke McGuinness に特に感謝を捧げたい。Luke、私たちはこのプロジェクトに対するあなたの継続的なサポートにとても感謝している。最後になるが、本書の作成と編集をサポートしてくれた Lea Schuurmans、Paula Kuper、Antonia Sprenger に感謝する。エアランゲン、アムステルダム、京都、ミュンヘン\nMathias, Pim, Toshi & David\n","code":""},{"path":"about-the-authors.html","id":"about-the-authors","chapter":"著者について","heading":"著者について","text":"Mathias Harrer は、 ミュンヘン工科大学およびフリードリヒ・アレクサンダー大学エアランゲン-ニュルンベルク校の研究者。マティアスの研究は、心理療法研究における統計的・技術的手法、臨床研究統合のための手法、統計ソフトの開発に重点を置いている。\nPim Cuijpers は、アムステルダム自由大学の臨床心理学教授。一般的な精神疾患の予防と治療を中心に、無作為化比較試験とメタアナリシスの実施を専門としている。国際的な査読付き科学雑誌に800以上の論文を発表しており、その多くは臨床試験のメタアナリシスである。Toshi . Furukawa (古川壽亮) は、京都大学公衆衛生大学院健康増進・行動学の教授。研究統合とメタアナリシスの理論的側面と、エビデンスに基づく医療への応用の両方に焦点を当てた精力的な研究を行っている。David D. Ebert は、ミュンヘン工科大学心理学・行動健康工学部教授。インターネットを利用した介入、臨床疫学、およびこの分野における応用研究の統合を中心に研究している。翻訳者: 馬場美彦は、有限会社アウトソー、杏林大学医学部非常勤講師。博士 (医学)。専門は地域包括ケア、まちづくり。高齢者介護の実践と研究を行なっている。","code":""},{"path":"intro.html","id":"intro","chapter":"1 はじめに","heading":"1 はじめに","text":"科\n学は一般に、蓄積されたプロセスであると考えられている。研究者は、何世代も前の科学者が積み上げてきた証拠を基に、科学的な努力を積み重ねている。アイザック・ニュートンの有名な言葉に「巨人の肩の上に立つことで、より遠くを見ることができる」というのがある。多くの人が科学に魅了されるのは、科学が進歩的であり、世界への理解を深めたり、より良い決断を下すのに役立つからである。これは直感的な考えであるが、少なくとも数字上は正当化される。歴史上、今日ほど研究論文の発表という形で多くの証拠にアクセスできる時代はなかった。ペタバイト級の研究成果が、世界中で毎日生み出されているのである。生物医学だけでも、毎年100万件以上の査読付き論文が出版されている (Björk, Roos, Lauri 2008)。発表される研究成果の量は、ほぼ指数関数的に増加している。最大の書誌データベースの一つである PubMed の各年度の索引論文数は、このことを模範的に象徴しているといえるだろう。20世紀の半ばまで、各年度の研究論文は数百件しか掲載されていなかった。それが、その後の数十年で大幅に増え、21世紀に入ってから急増している (Figure 1.1 参照)。\nFigure 1.1: PubMed にインデックスされた論文数 (年別)、1781年～2019年\n原理的には、科学の発展により、科学の将来性が加速されるはずである。科学が蓄積されるものであるならば、より多くの研究が発表されるということは、より多くの証拠が得られることに等しい。そうすれば、より強力な理論を構築し、過去の誤謬を取り除くことができるはずである。しかし、もちろん、そう簡単にはいかない。スタンフォード大学の John Ioannidis は、非常に影響力のある論文の中で、科学は自動的に蓄積され、常に改善されるという考え方を批判した。彼の論文には、「科学は、なぜ必ずしも自己修正しないのか」 (“Science Necessarily Self-Correcting”) という分かりやすいタイトルがつけられている (Ioannidis 2012)。彼は、研究分野では、特定のトピックや理論について膨大な研究成果が生み出される一方、根本的な誤謬に対しては検証されずに永続する状態が存在することもよくあると主張している。1970年代にさかのぼるが、優れた心理学者である Paul Meehl は、ある研究分野において、理論とファッションのトレンドが酷似していることに気づき観察していた。Meehl は、多くの理論は継続的に改良されたり反論されたりするのではなく、人々が興味を失い始めると、単に「消えていく」のだと主張した (Meehl 1978)。科学的なプロセスだけでは、自動的に最善の世界へと導かれることはない。これは、不都合な真実である。日々、前例のない量の研究結果が生み出される中、証拠となるものを全体として捉え、批判的に評価することがより一層重要になっている。メタ分析は、メタ分析自体の限界とバイアスを認識する限り、最善の世界に達するために非常に役立つものである。","code":""},{"path":"intro.html","id":"what-are-mas","chapter":"1 はじめに","heading":"1.1 メタ分析とは？","text":"\nメタ分析の創始者の一人である Gene V. Glass は、メタ分析を「分析の分析」(Glass 1976) と表現した。この単純な定義が、すでに多くのことを物語っている。従来の研究では、分析の単位は、多数の人、標本、国、または物である。メタ分析では、一次研究そのものが分析の要素になるのである。メタ分析の目的は、明確に定義された研究分野や研究課題に関連する利用可能なすべての証拠を組み合わせ、要約し、解釈することである (Lipsey Wilson 2001, chap. 1)。しかし、メタ分析はこれを行うための1つの手法に過ぎない。複数の研究からのエビデンスを合成する方法には、少なくとも3つの異なる方法がある (Pim Cuijpers 2016)。伝統的/ナラティブレビュー: 1980年代に入るまで、研究分野を要約する方法としては、ナラティブレビュー (narrative review) が最も一般的であった。ナラティブ (訳注: 「物語り」の意) レビューは、その分野の専門家や権威によって書かれることが多い。ナラティブレビューに含まれる研究をどのように選択しなければならないか、またレビューの範囲をどのように定義するかについて、厳密なルールはない。また、レビューされたエビデンスからどのように結論を出すかについても、決まったルールはない。全体として、これは著者の意見に有利なバイアスにつながる可能性がある。しかしながら、ナラティブレビューは、バランスの取れた方法で書かれていれば、読者が関連するリサーチクエスチョンや分野のエビデンスベースについて全体的な印象を得るのに役立つ方法となり得る。伝統的/ナラティブレビュー: 1980年代に入るまで、研究分野を要約する方法としては、ナラティブレビュー (narrative review) が最も一般的であった。ナラティブ (訳注: 「物語り」の意) レビューは、その分野の専門家や権威によって書かれることが多い。ナラティブレビューに含まれる研究をどのように選択しなければならないか、またレビューの範囲をどのように定義するかについて、厳密なルールはない。また、レビューされたエビデンスからどのように結論を出すかについても、決まったルールはない。全体として、これは著者の意見に有利なバイアスにつながる可能性がある。しかしながら、ナラティブレビューは、バランスの取れた方法で書かれていれば、読者が関連するリサーチクエスチョンや分野のエビデンスベースについて全体的な印象を得るのに役立つ方法となり得る。システマティックレビュー: システマティックレビューは、明確に定義された透明性の高いルールでエビデンスをまとめようとするものである。システマティックレビューでは、研究課題を事前に決定し、研究を選択し、レビューするための明確で再現可能な方法論が存在する。その目的は、利用可能なすべてのエビデンスを網羅することである。また、あらかじめ定義された基準でエビデンスの妥当性を評価し、結果の統合を系統的に提示する。システマティックレビュー: システマティックレビューは、明確に定義された透明性の高いルールでエビデンスをまとめようとするものである。システマティックレビューでは、研究課題を事前に決定し、研究を選択し、レビューするための明確で再現可能な方法論が存在する。その目的は、利用可能なすべてのエビデンスを網羅することである。また、あらかじめ定義された基準でエビデンスの妥当性を評価し、結果の統合を系統的に提示する。メタ分析: メタ分析の多くは、システマティックレビューの発展型といえるだろう。メタ分析の範囲は事前に明確に定義され、一次研究も体系的かつ再現可能な方法で選択され、エビデンスの妥当性を評価する基準も明確になっている。そのため、「システマティックレビューとメタ分析」と名付けられた研究がよく見られるのである。メタ分析の目的は、先行研究の結果を定量的に組み合わせることで、この点がメタ分析を特別なものにしている。メタ分析の目的は、選択された研究で報告された定量的アウトカムを1つの数値的な推定値に統合することである。そしてこの推定値は、個々の結果をすべて要約したものである。メタ分析は、例えば、薬の効果、病気の流行、2つの性質の相関などを、すべての研究にわたって定量化する1 。したがって、定量的な結果を報告している研究にのみ適用することが可能である。システマティックレビューと比較して、メタ分析は、要約される証拠の種類に関してより限定的でなければならないことが多い。メタ分析を行うには、通常、同じデザイン、同じタイプの測定、同じ介入を行った研究が必要である (Chapter 1.3 参照)。メタ分析: メタ分析の多くは、システマティックレビューの発展型といえるだろう。メタ分析の範囲は事前に明確に定義され、一次研究も体系的かつ再現可能な方法で選択され、エビデンスの妥当性を評価する基準も明確になっている。そのため、「システマティックレビューとメタ分析」と名付けられた研究がよく見られるのである。メタ分析の目的は、先行研究の結果を定量的に組み合わせることで、この点がメタ分析を特別なものにしている。メタ分析の目的は、選択された研究で報告された定量的アウトカムを1つの数値的な推定値に統合することである。そしてこの推定値は、個々の結果をすべて要約したものである。メタ分析は、例えば、薬の効果、病気の流行、2つの性質の相関などを、すべての研究にわたって定量化する1 。したがって、定量的な結果を報告している研究にのみ適用することが可能である。システマティックレビューと比較して、メタ分析は、要約される証拠の種類に関してより限定的でなければならないことが多い。メタ分析を行うには、通常、同じデザイン、同じタイプの測定、同じ介入を行った研究が必要である (Chapter 1.3 参照)。\n個別被験者データメタ分析 (Individual Participant\nData Meta-Analysis)\n\n定義によっては、第4のタイプのエビデンス合成法、いわゆる個別被験者データ\n(Individual Participant Data, IPD) メタ分析も存在する\n(Richard D. Riley, Lambert, Abo-Zaid 2010; Richard D. Riley, Tierney, Stewart 2021)。従来、メタ分析は、発表された文献にある研究の集計された結果\n(例えば、平均と標準偏差、または割合) に基づいている。IPD\nメタ分析では、代わりにすべての研究のオリジナルデータを収集し、1つの大きなデータセットにまとめる。\n\nIPD\nメタ分析にはいくつかの利点がある。例えば、欠損データをインプットしたり、全ての研究に対して全く同じ方法で統計手法を適用することが可能である。さらに、関心のある結果に影響を与える変数の探索を容易にすることが可能である。従来のメタ分析では、いわゆる研究レベルの変数\n(例えば、発表年や研究で使用された集団など)\nのみを使用して、このようなことを行うことができることとする。しかし、結果の重要なモデレータとしての役割を果たすのは、しばしば参加者レベルの情報\n(例えば、個々の人の年齢や性別) である。このような変数は、IPD\nメタ分析を使ってのみ探索することが可能である。\n\nIPD\nメタ解析は比較的新しい手法であり、現在行われているメタ解析の圧倒的多数は「従来の」メタ解析のままである。このことも、本ガイドで\nIPD メタ分析手法を取り上げない理由の一つである。\n\nこれは、従来のメタ分析が優れているということとは全く関係がなく、その逆である。これは単に、すべての研究データがオープンに利用可能であるという事実が、残念ながら最近までほとんどの分野で非常に稀であったためである。発表された研究報告から要約された結果を抽出することは比較的容易であるが、関連するすべての研究のオリジナルデータを入手することは、はるかに困難である。例えば、生物医学研究では、参加者個人のデータは、対象となる研究の約64％からしか得られない\n(Richard D. Riley, Simmonds, Look 2007)。\n","code":""},{"path":"intro.html","id":"history","chapter":"1 はじめに","heading":"1.2 “Exercises in Mega-Silliness” 歴史的な逸話","text":"メタ分析は一人の人間によって発明されたのではなく、多くの創始者と父親によって発明されたのである。別々の、しかし類似した研究の効果を統計的に要約する最初の試みは約100年前にさかのぼり、史上最も重要な統計学者である Karl Pearson と Ronald . Fisher の2人に結びつけることが可能である。Pearson は20世紀初頭に、大英帝国全体での腸チフス接種の効果に関する知見を組み合わせて、プール推定値を計算した (Shannon 2016)。Fisher は、1935年の実験計画法の代表的な著書で、農業研究における複数の研究のデータを分析するアプローチを取り上げ、場所や時間によって研究結果が異なるという問題を既に認めている (R. . Fisher 1935; O’Rourke 2007).\nしかし、「メタ分析」という名称とその隆盛のきっかけは、20世紀半ばに起こったある学問的論争にさかのぼることが可能である。1952年、イギリスの著名な心理学者 Hans Jürgen Eysenck (Figure 1.2) が、心理療法 (当時はフロイトの精神分析を指すことが多かった) は効果がないと主張する論文を発表したのである。もし患者が治療中に良くなったとしても、それは治療とは関係のない要因によるものであって、治療がなくとも状況が改善されたからである。さらに悪いことに、Eysenck は、心理療法は患者の回復を妨げることもよくあると主張した。心理療法は大きな打撃を受け、1970年代後半までその評判は回復しなかった。この間、Gene V. Glass は「メタ分析」と呼ぶ技法を開発し、研究間で標準化平均差 (Standardized Mean Differences)2をプールできるようにした。この手法が初めて広範囲に適用されたのは、Mary L. Smith と Glass 自身 (Smith Glass 1977) が書いた American Psychologist 誌に掲載された論文であった。この大規模な研究では、4000人以上が参加した375の研究の結果がメタ分析で統合された。その結果、心理療法は 0.68 のプール効果を示し、これは非常に大きいと考えられる。Glass の研究は、Eysenck の評決が誤りであることを定量的に証明するものであり、そのインパクトは絶大であった。しかし、Eysenck 自身は納得しておらず、メタ分析を “Exercises Mega-Silliness” と呼んでいる (Eysenck 1978) 。\nFigure 1.2: Hans Jürgen Eysenck (Sirswindon/CC -SA 3.0)\n今日、私たちは、Smith Glass の研究が、対象研究のバイアスを制御しなかったために、心理療法の効果を過大評価した可能性があることを知っている (P. Cuijpers, Karyotaki, et al. 2019)。しかし、いくつかの心理療法が有効であるという主要な発見は、その後の数十年間で、他の無数のメタ分析によって裏付けらた。Eysenck の厳しい反応も、メタ分析がやがて様々な研究分野でよく使われる手法となるということを変えることはできなかった。この時代のことは、“meta-analytic Big Bang” に詳しく書かれている (Shadish Lecy 2015)。Glass がメタ分析の手法を開発したのとほぼ同時期に、Hunter Schmidt は、測定誤差の補正に重点を置いた独自のメタ分析手法を作り始めた (Schmidt Hunter 1977; Hunter Schmidt 2004)。メタ分析が初めて医学の世界に登場したのは、Peter Elwood や Archie Cochrane らがメタ分析を用いた画期的な業績からである。このメタ分析で、アスピリンには、わずかではあるが心臓発作の再発を防ぐ効果が統計的にも臨床的にもあることを示した (Peto Parish 1980; Elwood 2006; O’Rourke 2007)。80年代半ば、Rebecca DerSimonian Nan Laird がランダム効果メタ分析を計算するアプローチを紹介し (Chapter 4.1.2 参照)、今日まで使用されている (DerSimonian Laird 1986)。その他にも数え切れないほどの技術革新があり、過去40年間にメタ分析手法の適用性、頑健性、汎用性を高めることに貢献してきた。\nCochrane と Campbellの共同研究1993 年に設立され、Archie Cochrane にちなんで名付けられた コクラン共同計画 (Cochrane Collaboration, または単に Cochrane) は、応用メタ分析の発展において重要な役割を担っている。コクラン共同計画は、研究者、専門家、患者、その他関係者の国際的なネットワークで、「商業的なスポンサーシップやその他の利益相反のない、信頼性が高くアクセスしやすい健康情報を生み出すために協力し合う」ものである。コクラン共同計画は、生物医学分野におけるエビデンスを統合するために、厳格な基準を用いている。ロンドンに本部を置くほか、世界数カ国に現地支部を置いている。コクラン共同計画では、定期的に更新される Handbook Systematic Reviews Interventions (Julian Higgins et al. 2019) と Cochrane Risk Bias Tool (Sterne et al. 2019) を発行している。どちらもシステマティックレビューやメタ分析に関するあらゆる技術的な詳細について、標準的な参考書として広く知られている (Chapter 1.4 参照)。コクランに似た組織として、オスロに拠点を置くCampbell Collaboration があり、主に社会科学分野の研究に力を入れている。","code":""},{"path":"intro.html","id":"pitfalls","chapter":"1 はじめに","heading":"1.3 りんごとオレンジ: メタ分析の落とし穴のクイックツアー","text":"この数十年で、メタ分析は普遍的に受け入れられる研究ツールとなった。しかし、これにはそれなりのコストがかかる。質の高い一次研究を行うには多くの場合非常にコストがかかり、その結果を最終的に分析できるようになるまで何年もかかることがある。それに比べてメタ分析は、あまり多くのリソースを必要とせず、比較的短期間で作成することが可能である。それにもかかわらず、メタ分析はしばしば高い影響力を持ち、頻繁に引用されている (Patsopoulos, Analatos, Ioannidis 2005)。すなわち、科学雑誌はメタ分析を掲載する傾向が強く、たとえその品質や科学的メリットが限られていたとしても、掲載する傾向があるのである。残念ながら、このことは研究者に多くのメタ分析を作成する動機を与え、科学的動機は時として従属的になっている。Ioannidis (2016) は、毎年膨大な量の冗長で誤解を招くメタ分析が生産されていると批判している。いくつかの「ホット」なトピックでは、最近のメタ分析が20以上ある。また、薬物療法研究などでは、企業の利益に大きく偏ったメタ分析もある(Ebrahim et al. 2016; Kirsch et al. 2002)。前にも述べたように、再現性は優れた科学の特徴である。しかし現実には、重要な情報が報告されないために、多くのメタ分析の再現性が制限されていることがあまりにも多い (Lakens et al. 2017)。また、同じテーマ、あるいは重複するテーマについて、異なるメタ分析で異なる結論に至ることもよくある問題である。例えば、心理療法の研究では、すべてのタイプの心理療法が同等の結果をもたらすかどうかという問題に関連する議論が続いている。数え切れないほどのレビューが、どちらかの結論を支持する形で発表されている (Wampold 2013; Pim Cuijpers, Reijnders, Huibers 2019) 。こうした問題は、科学的プロセスの体系的な問題と関連しているかもしれないし、メタ分析自体の欠陥にさかのぼることが可能である。そこで、メタ分析の落とし穴を簡単に紹介する (Borenstein et al. 2011, chap. 40; Greco et al. 2013; Sharpe 1997)。\n","code":""},{"path":"intro.html","id":"りんごとオレンジ問題","chapter":"1 はじめに","heading":"1.3.1 「りんごとオレンジ」問題","text":"メタ分析とは、りんごとオレンジを混ぜることだ、と主張する人もいる。対象基準を最大限に厳格にしても、メタ分析における研究が完全に同一であることはない。含まれるサンプル、介入の実施方法、研究デザイン、研究で使用された測定の種類などには、常に大小の差が存在する。これは問題になることもある。メタ分析とは、すべての研究の結果を表す数値的な推定値を計算することである。このような推定値は、統計学的な観点からは常に計算することが可能であるが、特定の研究課題に答えるために重要な特性を共有する研究がない場合には、意味がなくなる。明らかにばかげたシナリオとして、仕事のパフォーマンスに対する仕事満足度の効果に関する研究と糖尿病患者の HbA1c 値に対する投薬の効果に関する利用可能なすべてのエビデンスを、1つのメタ分析にプールすることを決定した、と想像してみよう。その結果は、組織心理学者にとっても、糖尿病学者にとっても、無意味なものだろう。さて、この無能なメタ分析者が、過去の失敗から学び過剰な補償をして、1990年から1999年の間に発表された、中程度の抑うつ症状を持つ60代のカナダ人男性に Fluoxetine を1日 40 mg、正確に6週間投与した研究のみを含むメタ分析を実施したとする。メタ分析は、研究の肯定的な結果を誇らしげに精神科医に報告することが可能である。しかし、精神科医は、「私の患者が45歳のフランス人だったらどうすればいいのか」と聞くだけだろう。ここで重要なポイントがある。メタ分析の目的は、組み合わせられるものは何でも無造作に放り込むことではない。メタ分析は、個々の研究の特殊性を超えた、関連する研究課題に答えるために用いることが可能である (Borenstein et al. 2011, chap. 40)。したがって、メタ分析の範囲と特異性は、答えたい研究課題に基づくべきであり、この課題は実用的な関連性を持つものであるべきである (Chapter 1.4 参照)。例えば、ある種のトレーニングプログラムが、様々な年齢層、文化的地域、環境において有効であるかどうかに関心がある場合、研究の対象者や出身国に制限を設けないことは非常に理にかなっている。しかし、その場合、評価する研修プログラムを限定し、一定の長さの研修や類似のトピックを扱った研修のみを対象とすることが望ましいと考えられる。このようなメタ分析の結果は、トレーニングのプール効果を推定するだけでなく、この効果がどの程度変動しているのかを定量化することが可能である。メタ分析は、このような異質性に対応し、意味を持たせることができるのである。Chapter 5 では、この重要な概念について詳しく見ていく。要約すると、「りんごとオレンジ」問題が実際に問題であるかどうかは、メタ分析が答えたい問題に大きく依存するということである。研究間のばらつきは、メタ分析の目的と問題の特定に正しく組み入れられれば、多くの場合問題にはならず、洞察的でさえある。","code":""},{"path":"intro.html","id":"garbage-in-garbage-out問題","chapter":"1 はじめに","heading":"1.3.2 「Garbage In, Garbage Out」問題","text":"メタ分析が生み出すエビデンスの質は、それが要約した研究の質に大きく依存する。もし、含まれる知見で報告された結果が偏っていたり、全く間違っていたりすれば、メタ分析の結果も同様に欠陥があることになる。これが「Garbage , Garbage 」問題の指すところである (訳注: 入力が無意味なら出力も無意味であることを指す。略して GIGO と書くこともある。)。これは、含まれる研究の質やバイアスのリスク (Chapter 1.4 と Chapter 15) 参照) を評価することである程度軽減することが可能である。しかし、結果の多くまたは大部分が最適な品質ではなく、バイアスがある可能性が高い場合、最も厳密なメタ分析でもバランスを取ることはできない。このような場合、導き出される唯一の結論は、レビューしたテーマについて信頼できる証拠は存在せず、今後さらに質の高い研究を実施しなければならないということである。しかし、このような残念な結果であっても、将来の研究の指針として参考になることがある。","code":""},{"path":"intro.html","id":"ファイルの引き出し問題","chapter":"1 はじめに","heading":"1.3.3 「ファイルの引き出し」問題","text":"ファイルの引き出し問題とは、関連する研究結果がすべて発表されているわけではないため、メタ分析に欠落してしまうという問題である。メタ分析ですべてのエビデンスを統合できないことは望ましくないが、少なくとも、研究成果が発表された文献の中でランダムに欠落していると安全に仮定できるのであれば、許容範囲であろう。しかし、残念ながら、そうではない。ポジティブで「革新的」な発見は、失敗した複製やネガティブで結論の出ない研究よりも話題を呼ぶことが多い。これに伴い、ここ数十年、多くの分野、特に社会科学や生物医学の分野で、否定的な知見が発表されることが少なくなっていることが調査で明らかになっている (Fanelli 2012)。否定的な結果や「期待はずれ」の結果を出した研究は、発表された文献の中で体系的に過小評価されており、いわゆる発表バイアスがあると考える十分な根拠がある。このバイアスの正確な性質と程度は、メタ分析ではせいぜい「未知の知」(known unknown) である。しかし、出版バイアスを最小化する方法はいくつかある。一つは、研究の検索・抽出の方法に関連する (Chapter 1.4 参照)。もう1つは、メタ分析において出版バイアスが存在するかどうか、またその影響がどの程度あるのかを推定しようとする統計的な方法である。これらの手法については、Chapter 9 でいくつか紹介する。","code":""},{"path":"intro.html","id":"研究者のアジェンダ問題","chapter":"1 はじめに","heading":"1.3.4 「研究者のアジェンダ」問題","text":"メタ分析の範囲を定義し、研究を検索・選択し、最終的にアウトカム指標をプールする際、研究者は無数の選択を迫られる。メタ分析には多くの「研究者の自由度」(Wicherts et al. 2016) があり、時には恣意的であったり、公表されていない個人の好みの結果などの決定の余地が多く残されている。メタ分析の運用法 (modus operandi) の自由度は、研究者が意識的または無意識的に自身のアジェンダに突き動かされている場合に特に問題となる。メタ分析は通常、応用研究者によって行われるが、レビュートピックに関する広範な主題固有の専門知識を持つことは諸刃の剣である。一方では、特定の分野における有意義なリサーチクエスチョンを導き出し、それに答えるのに役立つこともある。また他方では、そのような専門家は、自分が調査している研究分野に深く関与していることも事実である。つまり、多くのメタ分析者は特定のテーマについて強い意見を持っており、意図的または無意識に自分の信念に合う方向に結果に影響を与える可能性がある。同じデータセットが与えられると、最高の意図を持った経験豊富な分析者間でも、結論が大きく異なることがあるというエビデンスがある (Silberzahn et al. 2018) 。この問題は介入研究においてさらに深刻で、メタ分析者の中には、研究中の介入手法の開発に貢献したことがあるため、堅固な研究者としての忠誠心を持っている人もいる。そのような研究者はもちろん、メタ分析の結果を証拠によって示されるよりも肯定的に解釈する傾向が強いかもしれない。研究者のアジェンダ問題を軽減する一つの方法として、メタ分析のデータ収集を開始する前に、事前登録を行い、詳細な解析計画を公開することが挙げられる (Chapter 1.4 と 16.3.5を参照)。","code":""},{"path":"intro.html","id":"spec-search-coding","chapter":"1 はじめに","heading":"1.4 問題の特定、スタディ検索、コーディング","text":"前章では、メタ分析の一般的な問題や限界について時間をかけて議論した。「りんごとオレンジ」問題、「ファイルの引き出し」問題、「研究者のアジェンダ」問題など、これらの問題の多くは、すべてのメタ分析者が取り組むことができ、また取り組むべきものである。これは、最初の結果を計算し始めるずっと前から始まっている。メタ分析はデータがなければ実施できないため、当然ながらこのデータをどこからか持ってこなければならない。まず、計画中のメタ分析の研究課題と適格基準を特定し、研究を検索して関連するものを選び、計算に必要なデータを抽出し、後で報告したい重要な情報をコーディングする。各ステップにおいて、従うことができる、または従うべき規則、基準、推奨事項がいくつかあり、高品質なメタ分析を作成するのに役立つ。このような高品質のメタ分析には、すべての適切なエビデンスが包括的に選択されており、その対象に関してバイアスがなく公平であり、その結果から有効かつ正当で、実際的に適切な結論が導き出されている。しかし、「すべてのルールに従う」といっても、実際には具体的にどのような判断が最適なのか、必ずしも明らかでない場合もある。あなたが行った方法に対して、人々が反対することもあり得る。これは普通のことで、方法論の決定が透明かつ再現可能である限り、問題はない (Pigott Polanin 2020)。この章では、計算を始めるより前の段階で必要となる重要な構成要素を順番に説明する。この章は長いが、データ取得のプロセスが現実に要する時間を表すものではない。経験上、統計解析はメタ分析に費やす時間の最大15％を占めるに過ぎず、その前に行われるすべての作業と比較するとはるかに少ないものである。しかし、研究課題を特定し、系統的に研究を検索し、抽出されたデータを確実にコーディングすることは不可欠である。これが、優れたメタ分析の基礎となるのである。","code":""},{"path":"intro.html","id":"research-question","chapter":"1 はじめに","heading":"1.4.1 リサーチクエスチョンの定義","text":"研究をデザインするとき、最初にすることはリサーチクエスチョンの定義である。メタ分析も例外ではない。リサーチクエスチョンを問題指定の一形態として捉えると、適切に定義することができる。適切でインパクトのあるメタ分析を行うためには、問題を解決する必要がある。そのような問題を特定するためには、対象分野に特化した知識が必要である。メタ分析のための良いリサーチクエスチョンを見つけるには、ある程度背景知識のある研究分野を選び、まずいくつかの基本的な質問を自分自身に問いかけることが有効だろう。この分野では、現在どのようなことが問題になっているのか？特定のテーマについて、現在の知識には欠如がないか？未解決の議論が残っていないか？また、対象となる読者について考えてみるのもよいだろう。他の研究者に関連する問題は何か？他の人々、例えば医療関係者、国家機関、学校、人事部などが直面しそうな問題は何か。メタ分析は先行研究に依存する。研究課題の大まかな方向性が決まったら、現在の文献を見るのが効果的である。このテーマに関する先行研究は存在し、どのように問題に対処していたのか？どのような方法とアウトカム尺度を使用したのか？論文の背景や考察のセクションで、どのような制限に言及しているか？過去のレビューやメタ分析でこのテーマを扱ったことがあるか、またどのような問題が残されているか？Cummings ら (2013) は、メタ分析の対象となる問題を特定するために使用できるいくつかの基準、FINERフレームワークを提案している。それは、リサーチクエスチョンが、実行可能 (Feasible) で、興味深く (Interesting)、新規性があり (Novel)、倫理的である ( Ethical)、関連性がある (Relevant) べきである。これらの質問を自分に投げかけることで、メタ分析で何を達成したいのかが、少しずつ明らかになってくるはずである。また、メタ分析が自分の問題に適していないことが明らかになる場合もある。例えば、そのテーマを扱った関連する研究がない、あるいは、その問題を十分に扱った質の高いメタ分析が既に文献に残っている、などである。しかし、自分の問題が1つまたは複数のグループの人々に関連し、先行研究がこの問題に関連するデータを提供し、先行するレビューやメタ分析が十分にまたは適切に対処していないと感じた場合、それをリサーチクエスチョンに変えるために進むことが可能である。どのようなことができるのか、例を挙げてみよう。医学研究においてジェンダーバイアスが存在することを示唆する証拠がある (Hamberg 2008; Nielsen et al. 2017)。以前は、多くの臨床試験で男性の参加者のみであるか、または大部分が男性であっタにもかかわらず、単純にアウトカムが女性にも一般化されると仮定されていた。このため、心臓疾患など一部の疾患では、女性の健康状態が悪くなることにつながったと考えられている (Kim Menon 2009; Mosca et al. 2013) 3。あなたが医学研究者であると仮定しよう。よく使われる薬である Chauvicepine には、これまでほとんど認識されていなかった女性への深刻な副作用があるのではないかという噂を耳にしたとする。これは、安全でない可能性のある薬が多くの女性に処方されていることになるので、もし噂が本当であれば非常に重要な問題であると判断した。文献を見ると、Chauvicepine を調査した研究のほとんどが無作為化プラセボ対照試験であることがわかった。初期の試験では、男性のみ、あるいは男性が大半を占める集団で実施された。しかし、最近の試験では、性別の構成がよりバランスの取れたものもいくつか見受けられる。これらの試験の多くは、試験中に発生した否定的な副作用の数を、男女別に報告していた。また医学雑誌の最近の論評で、ある医師が、自分のクリニックでは、この薬で治療したときに多くの女性がネガティブな副作用を経験したと報告しているのも見つかった。この問題をメタ分析で解決するのは面白いかもしれないと考えついた。そこで、今発見した問題をリサーチクエスチョンに変換した。「プラセボと比較して、Chauvicepine が女性における負の副作用を有意に増加させることを示す無作為化プラセボ対照試験からのエビデンスはあるだろうか？」。リサーチクエスチョンの最初の定式化は、最初のステップに過ぎない。次に、それを具体的な適格性基準に変換する必要がある。これらの適格基準は、どの研究がメタ分析に含まれ、どの研究が含まれないかを決定する指針となりうる。したがって、この基準は非常に重要であり、絶対的に透明で再現可能でなければならない。適格基準を指定し始める良い方法は、PICO フレームワークを使用することである (Mattos Ruellas 2015)。このフレームワークは主に介入研究を対象としているが、他のタイプのリサーチクエスチョンにも役に立ちる。PICO の文字は、母集団 (Population)、介入 ( Intervention)、対照群 (Control group) または比較 (Comparison)、アウトカム (Outcome) の頭文字をとったものである (訳注: P は、Patients, Problems とも)。母集団 (P): どのような人々や研究対象者が含まれていれば、研究の対象となるのか。繰り返しになるが、この質問にはできるだけ正確に答え、それぞれの定義が持つ意味を考えることが重要であることを覚えておいてください。若年成人を対象とした研究のみを対象とするのであれば、「若年成人」とは何を意味するのだろうか。18歳から30歳までの人だけが対象なのだろうか？それは発表された論文から簡単に判断できることなのだろうか？それとも、大学や Cardi B のコンサートのような、若者がよく訪れる場所で募集されたことだけが重要なのだろうか？特定の病状を持つ患者に関する研究のみを対象とするのであれば、その病状はどのように診断されたのだろうか？訓練を受けた医療専門家によるものなのか、それとも自己報告式のアンケートで十分なのか？こうした質問は、FINER フレームワークの F と R の部分に頼ることによって答えられることが多い。発表された研究にこのような制限を加えることは可能なのか？また、それは適切な差別化なのだろうか。母集団 (P): どのような人々や研究対象者が含まれていれば、研究の対象となるのか。繰り返しになるが、この質問にはできるだけ正確に答え、それぞれの定義が持つ意味を考えることが重要であることを覚えておいてください。若年成人を対象とした研究のみを対象とするのであれば、「若年成人」とは何を意味するのだろうか。18歳から30歳までの人だけが対象なのだろうか？それは発表された論文から簡単に判断できることなのだろうか？それとも、大学や Cardi B のコンサートのような、若者がよく訪れる場所で募集されたことだけが重要なのだろうか？特定の病状を持つ患者に関する研究のみを対象とするのであれば、その病状はどのように診断されたのだろうか？訓練を受けた医療専門家によるものなのか、それとも自己報告式のアンケートで十分なのか？こうした質問は、FINER フレームワークの F と R の部分に頼ることによって答えられることが多い。発表された研究にこのような制限を加えることは可能なのか？また、それは適切な差別化なのだろうか。介入 (): どのような介入 (または曝露) を研究する必要があるのか。介入の効果を研究したいのであれば、対象となる治療の種類を明確にすることが重要である。介入はどのくらいの期間でなければならないか？誰が介入を行うことが可能であるか？介入はどのような内容を含まなければならないか？介入に焦点を当てない場合、独立変数はどのように運用されなければならないか？変数は特定の測定機器や質問紙によって測定されなければならないか？例えば、仕事に対する満足度を研究する場合、この構成要素は研究においてどのように運用されなければならないか？介入 (): どのような介入 (または曝露) を研究する必要があるのか。介入の効果を研究したいのであれば、対象となる治療の種類を明確にすることが重要である。介入はどのくらいの期間でなければならないか？誰が介入を行うことが可能であるか？介入はどのような内容を含まなければならないか？介入に焦点を当てない場合、独立変数はどのように運用されなければならないか？変数は特定の測定機器や質問紙によって測定されなければならないか？例えば、仕事に対する満足度を研究する場合、この構成要素は研究においてどのように運用されなければならないか？対照群または比較対象 (C): 試験結果は何と比較されたのか？情報提供プラセボ (Attention placebo) か、または錠剤のプラセボを受けた対照群か？待機者？別の治療法？それとも全く何もしないのか？例えば、異なる研究間での病気の有病率推定を研究したい場合や、異なる生息地にどれだけの種の標本があるのかを研究したい場合など、比較群や対照群が全くないこともあり得る。対照群または比較対象 (C): 試験結果は何と比較されたのか？情報提供プラセボ (Attention placebo) か、または錠剤のプラセボを受けた対照群か？待機者？別の治療法？それとも全く何もしないのか？例えば、異なる研究間での病気の有病率推定を研究したい場合や、異なる生息地にどれだけの種の標本があるのかを研究したい場合など、比較群や対照群が全くないこともあり得る。アウトカム (O): 研究では、どのような成果や従属変数を測定しなければならないのだろうか？そして、その変数はどのように測定しなければならないのだろうか？質問票の点数の平均や標準偏差だろうか？それとも、死亡した患者や病気になった患者の数か？結果はいつ測定されなければならないのだろうか？治療期間には関係なく、単純に治療直後でよいのか？それとも1〜2年後か？アウトカム (O): 研究では、どのような成果や従属変数を測定しなければならないのだろうか？そして、その変数はどのように測定しなければならないのだろうか？質問票の点数の平均や標準偏差だろうか？それとも、死亡した患者や病気になった患者の数か？結果はいつ測定されなければならないのだろうか？治療期間には関係なく、単純に治療直後でよいのか？それとも1〜2年後か？\nシステマティックレビューとメタ分析のためのガイドラインメタ分析の質が低いことが多いことから、メタ分析の実施方法について、いくつかのガイドラインや基準が設けられている。生物医学研究または介入の効果に関するエビデンスをメタ分析する場合、Preferred Reporting Items Systematic Reviews Meta-Analyses (PRISMA) (Moher et al. 2009) に従うよう強く推奨する。PRISMA 声明には、メタ分析過程のほぼすべての側面についてどのように報告すべきかという推奨事項が含まれている。また、この声明はオンラインで見ることが可能である4。心理・行動研究のメタ分析については、米国心理学会のメタ分析報告基準 (American Psychological Association’s Meta-Analysis Reporting Standards, MARS) (Appelbaum et al. 2018) に従うことが可能である。これらの基準は、メタ分析がどのように報告されるべきかについて主にコメントしているが、メタ分析を行う際のベストプラクティスにも影響を及ぼしている。PRISMA とMARS はコアな要素を多数共有しており、本章で取り上げる多くの事柄は、両ガイドラインでも言及されている。さらに詳細な資料として、Cochrane Handbook Systematic Reviews Interventions (Chapter 1.2) があり、システマティックレビューとメタ分析のほぼすべての側面に関する正確な推奨事項が記載されている。社会科学におけるメタ分析の方法論的基準の概要は、Pigott Polanin (2020) で見ることが可能である。PICO フレームワークはメタ分析の適格基準を指定する優れた方法であるが、関連する可能性のある情報すべてを網羅しているわけではない。他にも考慮すべき点がいくつかある (Lipsey Wilson 2001)。関連する詳細の1つは、対象となる研究デザインである。エビデンスに基づく医療では、無作為化化比較試験 (参加者が偶然に治療群または対照群に割り付けられた研究を意味する) からのエビデンスのみを含めることが一般的であるが、これは必ずしも必要ではない (Borenstein et al. 2011、Chapter 40)。また、対象となる研究の文化的および言語的範囲を指定することも有用だろう。ほとんどの研究は WEIRD 集団、つまり西洋 (Western)、教育 (Educated)、工業化 (Industrialized)、豊か (Ric)、 民主主義国 (Democratic societies) に基づいている (Henrich, Heine, Norenzayan 2010) 。特に社会科学の分野では、ある効果や現象が他の社会規範を持つ国にはうまく一般化されない可能性が非常に高い。しかし、多くの研究者は、他の言語の論文を翻訳する手間を省くために、英語の論文のみをメタ分析の対象としている。これは、異なる言語圏からのエビデンスが考慮されないことを意味する。英語はほとんどの分野で科学的発表の最も一般的な言語であるが、少なくともこの制限が存在することは適格基準において明らかにされるべきである。しかし、メタ分析の目的の一つが異文化間の差異を調べることであるならば、他のすべての基準を満たす限り、一般的に適格基準を他の言語にも拡大することが望ましい。もう一つの重要な点は、メタ分析に許可される出版物の種類である。メタ分析には、査読付き科学雑誌に掲載された研究論文のみが含まれることがある。これは、その分野の専門家の厳しい目を通過した研究であるため、より高い基準を満たすという主張である。この正当化には欠点がないわけではない。Chapter 1.3 では、「ファイル引き出し」問題がメタ分析結果の妥当性を著しく制限する可能性があることをすでに取り上げた。したがって、出版バイアスのリスクを軽減する方法として、灰色文献も含めることが挙げられる。灰色文献とは、従来の出版形式では入手できなかったあらゆるタイプの研究資料と定義することが可能である。これには、研究報告書、プレプリント、ワーキングペーパー、会議への投稿などが含まれる。学位論文も灰色文献に数えられることが多いが、その多くは今日、電子書誌データベースで索引付けされている (Schöpfel Rasuli 2018)。学位論文については、少なくともメタ分析には含めることが望ましいと思われる。他の種類の未発表資料と比較して、学位論文で提供される情報に大きなバイアスがあったり、明らかに不正であったりすることは、むしろ少ないだろう。さらに、科学雑誌に掲載されたかどうかにかかわらず、特定の方法論的要件を満たす研究のみを含めるよう、他の適格基準を定義することも可能である。適格基準を定義する最後のステップは、適用する包含基準と除外基準のリストとして書き留めることである。大学生における不眠症の介入に関するメタ分析から、このような方法があることを示す例を紹介する (Saruhanjan et al. 2020)。“included: () RCTs [randomized controlled trials; authors’ note] (b) individuals enrolled tertiary education facility (university, college comparable postsecondary higher education facility) time randomization, (c) received sleep-focused psychological intervention, (d) compared passive control condition, defined control condition active manipulation induced part study (wait-list, treatment usual).purposes analysis, “sleep-focused” means (e) effects symptoms sleep disturbances (global measures sleep disturbances, sleep-onset latency […], fatigue daytime functionality, pre-sleep behaviour experiences) assessed (f) target outcome (declaring sleep outcome primary outcome stating intervention primarily aimed outcome) using (g) standardized symptom measures (objective sleep measures, standardized sleep fatigue questionnaires, sleep diaries, items recording sleep quantity, quality hygiene).studies (h) published English German considered inclusion.”","code":""},{"path":"intro.html","id":"analysis-plan","chapter":"1 はじめに","heading":"1.4.2 解析計画・事前登録","text":"\nリサーチクエスチョンと適格基準を設定したら、解析計画 (Pigott Polanin 2020; Tipton, Pustejovsky, Ahmadi 2019) も書くのが賢明だろう。統計学では、priori (先験的) な分析と post hoc (事後) な分析を明確に区別する。priori 分析とは、データを見る前に指定される分析である。post hoc 分析あるいは探索的分析は、データを見た後、あるいはデータから示唆される結果に基づいて行われる。priori 分析の結果は、post hoc 分析よりもはるかに有効で信頼できると見なすことができる。post hoc 分析では、研究者の目標が達成されるまで、分析内容やデータそのものに手を加えることが容易になり得る。そのため、「研究者アジェンダ」の問題が発生しやすい。解析計画では、メタ解析で行いたい重要な計算をすべて priori に指定する。これには2つの目的がある。まず、実行した分析が本当に計画されたものであり、望ましい結果が得られるまでデータを操作しただけの結果ではないことを、他の人が確認することが可能である。つまり、メタ分析の各ステップで何をしたかを理解し、それを再現しようとすることができるのである。R を使う場合は、分析の各ステップを他の人が再実行できるようなドキュメントを書くことができ、これによって解析の再現性を高めることが可能である (「各種ツール」の Chapter 16 参照)。しかし、これは分析が完了した後の話である。解析計画では、データを収集する前に、何をする予定なのかを指定する。\n解析計画には、必ず明記すべきことが何点かある。どのような情報を抽出するのか、含まれる研究ごとにどのような効果量指標を算出するのかを明確にしておく必要がある (Chapter 3)。また、各研究の結果をプールする際に、研究間のばらつきの大きさを考慮して、固定効果モデルとランダム効果モデルのどちらを使用するかをあらかじめ決めておくとよいだろう (Chapter 4参照)。また、メタ分析で統計的に有意な効果を得るために必要な研究数を決定するために、先験的な検出力分析も役に立つ (「ツール」の Chapter 14 参照)。さらに、サブグループ解析 (Chapter 7) やメタ回帰 (Chapter 8) を用いて、いくつかの変数が対象研究の結果の違いを説明しているかどうかを評価したいかを決定することが重要である。例えば、仮説として出版年が研究のアウトカムと関連している可能性があり、この関連をメタ分析で後で調べたい場合、解析計画にその旨を記載する。研究をサブグループに分類し、そのサブグループを別々に調査する予定であれば、特定のサブグループに属すると判断する正確な基準も報告する必要がある (Chapter 1.4.4 参照)。本書の第II部 (「 R でメタ分析」) では、メタ分析の一部として適用すべき様々な統計的技法について取り上げる。ここで学び、メタ分析で適用する予定の技法は、すべて解析計画書に記載する必要がある。\n解析計画を書き終えたら、どこかに埋めてしまうのではなく、公開するようにしよう。研究者が自分の研究文書をオープンにするための優れた選択肢がいくつかある。例えば、オープンサイエンス・フレームワーク (OSF) のウェブサイトに新しいプロジェクトを作成し、そこに解析計画書をアップロードすることができる。また、研究内容によっては、medrxiv.org、biorxiv.org、psyarxiv.comなどのプレプリントサーバーに解析計画をアップロードすることも可能である。研究課題、適格基準、解析計画、検索戦略 (次章参照) が決まったら、メタ分析も登録する必要がある。メタ分析が広く健康に関連するアウトカムである場合、前向きシステマティックレビューとメタ分析の最大級の登録機関である PROSPERO を利用することが望ましい。OSF の事前登録サービスも良い選択肢である。さらに一歩進んで、メタ分析用のプロトコル全体を書くことも可能である (Quintana 2015)。メタ分析プロトコルには、解析計画に加えて、研究の科学的背景の説明、より詳細な方法論、研究の潜在的な影響についての議論を含める。また、PRISMA-P ステートメント (Moher et al. 2015) など、プロトコルの書き方に関するガイドラインも存在する。メタ分析のプロトコルは、多くの査読誌で受け入れられている。Büscher, Torok Sander (2019) や Valstad colleagues (2016) などは良い例である。priori な解析計画と事前登録は、よくできた信頼できるメタ分析には欠かせない特徴である。そして、このことで不安になる必要はない。方法論の決定一つ一つについて、事前に完璧な選択をすることは、不可能ではないにせよ、困難である。最初の計画をある時点で変更するのは、ごく普通のことである。計画したアプローチの変更について正直かつ明確に説明すれば、ほとんどの研究者はこれを失敗の印ではなく、プロ意識と信頼性の証と受け止めてくれることは間違いない。","code":""},{"path":"intro.html","id":"study-search","chapter":"1 はじめに","heading":"1.4.3 研究の検索","text":"適格基準や解析計画を決定した次のステップは、研究の検索である。本章では、ほとんどのメタ分析がシステマティックレビューの発展型であることを説明してきた。偏りのない包括的な事実の見方を得るために、研究課題に関する利用可能なエビデンスすべてを見つけることを目的としている。つまり、研究の検索も可能な限り包括的でなければならない。研究の検索には、1つだけでなく、複数の情報源を使用する必要がある。ここでは、重要かつ一般的に使用されている情報源の概要を説明する。レビュー記事: 同じトピックや類似のトピックに関する過去のレビューを精査し、関連する文献を探すことは非常に役に立つ。ナラティブレビューやシステマティックレビューでは、通常、レビューに含まれるすべての研究の引用が提供される。こうした研究の中には、自分の研究目的にも関連しているものも多くある可能性がある。レビュー記事: 同じトピックや類似のトピックに関する過去のレビューを精査し、関連する文献を探すことは非常に役に立つ。ナラティブレビューやシステマティックレビューでは、通常、レビューに含まれるすべての研究の引用が提供される。こうした研究の中には、自分の研究目的にも関連しているものも多くある可能性がある。研究中の参照文献: メタ分析に関連する研究を見つけた場合、この研究が参照している論文もスクリーニングするのが賢明である。その研究が序論や考察のセクションで同じトピックに関する過去の文献を引用している可能性は非常に高く、これらの研究のいくつかもメタ分析に関連する可能性がある。研究中の参照文献: メタ分析に関連する研究を見つけた場合、この研究が参照している論文もスクリーニングするのが賢明である。その研究が序論や考察のセクションで同じトピックに関する過去の文献を引用している可能性は非常に高く、これらの研究のいくつかもメタ分析に関連する可能性がある。フォワードサーチ: フォワードサーチは、先行する一次研究やレビューの文献をスクリーニングすることの逆と見ることができる。メタ分析に関連する研究をベースとして、その研究が発表されてから引用された他の論文を検索することを意味する。これはインターネット上で非常に簡単に行うことが可能である。通常、その研究が掲載された雑誌のウェブサイトにある、その研究のオンラインエントリーを見つければいいのである。今日、ほとんどの雑誌のウェブサイトには、ある研究を引用した論文を表示する機能がある。また、Google Scholarで検索することもできる (Table 1.1 を参照)。Google Scholar では、引用されている研究を項目ごとに表示することが可能である。フォワードサーチ: フォワードサーチは、先行する一次研究やレビューの文献をスクリーニングすることの逆と見ることができる。メタ分析に関連する研究をベースとして、その研究が発表されてから引用された他の論文を検索することを意味する。これはインターネット上で非常に簡単に行うことが可能である。通常、その研究が掲載された雑誌のウェブサイトにある、その研究のオンラインエントリーを見つければいいのである。今日、ほとんどの雑誌のウェブサイトには、ある研究を引用した論文を表示する機能がある。また、Google Scholarで検索することもできる (Table 1.1 を参照)。Google Scholar では、引用されている研究を項目ごとに表示することが可能である。関連する学術雑誌: 多くの場合、あなたが注目している研究課題の種類に特化した科学雑誌がいくつもある。そのため、それらの雑誌に掲載されている研究を探すとよいだろう。現在では、ほぼすべての学術雑誌が検索機能を備えたウェブ サイトを持っており、それを使って対象となりそうな研究を選別することができ る。また、電子書誌データベースを利用し、1つまたは複数の雑誌からの結果のみが表示されるようにフィルタを使用することも可能である。関連する学術雑誌: 多くの場合、あなたが注目している研究課題の種類に特化した科学雑誌がいくつもある。そのため、それらの雑誌に掲載されている研究を探すとよいだろう。現在では、ほぼすべての学術雑誌が検索機能を備えたウェブ サイトを持っており、それを使って対象となりそうな研究を選別することができ る。また、電子書誌データベースを利用し、1つまたは複数の雑誌からの結果のみが表示されるようにフィルタを使用することも可能である。上で説明した方法は、かなり細かい戦略として見ることができる。この方法は、関連する論文がリストアップされる可能性が非常に高い場所を検索する方法である。欠点としては、本当にそこにあるすべての証拠を発見することができないことである。したがって、検索には電子書誌データベースも使用することが推奨される。重要なデータベースの概要は、Table 1.1 に記載している。1つのデータベースだけでなく、常に複数のデータベースで検索する必要がある。多くの書誌データベースには、膨大な数の項目が含まれている。それでも、データベースの検索結果の重複が予想以上に少ないということはよくあることである。検索するデータベースは、テーマ別の焦点に基づいて選択することができる。例えば、メタ分析が健康に関連する結果に焦点を当てている場合、少なくとも PubMed と CENTRAL を検索する必要がある。書誌データベースを検索する際には、検索文字列を作成することが重要になる。検索文字列には、異なる単語や用語を含め、や などの演算子を使って連結する。検索文字列の作成には、ある程度の時間と実験が必要である。まずは、PICO や適格基準 (Chapter 1.4.1) をベースに、でつなげるのがよいだろう (簡単な例では、“college student” “psychotherapy” “randomized controlled trial” “depression” など)。ほとんどの書誌データベースでは、切り捨てとワイルドカードも使用可能である。切り捨ては、語尾を記号で置き換えて、検索の一部として変化させることである。これは通常、アスタリスクを使用して行われる。たとえば、“sociolog*” を検索用語として使用すると、データベースは “sociology”、“sociological”、“sociologist” を同時に検索する。ワイルドカードは、単語の中の文字が変化してもよいことを意味している。これは、単語の綴りに違いがある場合に便利である (例えば、アメリカ英語とイギリス英語の違いなど)。例えば、“randomized” という検索語を考えてみよう。この場合、アメリカ英語のスペルを使った研究のみが検索される。ワイルドカード (しばしばクエスチョンマークで象徴される) を使用する場合、代わりに “randomi?ed” と書くと、イギリス英語のスペルが使用された結果 (“randomised”) も得られる。検索文字列を作成する際には、ヒット数にも注目する必要がある。検索文字列は、あまり特定しすぎて関連する記事が見落とされるようなことがあってはならない。例えば、検索文字列のヒット数が3000件程度であれば、後のステップで管理しやすく、重要な参考文献がすべて結果にリストアップされる可能性が高くなる。検索文字列が一般的に有効かどうかを確認するには、最初の数百件を検索して、少なくともいくつかの文献が研究課題と関係があるかどうかをチェックすると良いだろう。選択したデータベースで使用する検索文字列の最終版を作成したら、どこかに保存する。検索文字列は、事前登録に含めておくのがベストプラクティスである。メタ分析のプロトコルを公開する場合や、メタ分析の最終結果を公開する場合は、検索文字列の報告 (例えば、付録) が必要である。結論として、書誌データベースの検索はそれ自体が技術であり、この段落では表面をわずかになぞった程度であることを強調しておきたい。このトピックに関しては、Cuijpers (2016) と Bramer colleagues (2018) が より詳細な議論している。\nTable 1.1: 関連する書誌データベースの一部。\n","code":""},{"path":"intro.html","id":"study-selection","chapter":"1 はじめに","heading":"1.4.4 研究の選択","text":"研究調査を終えれば、さまざまな情報源から何千もの参考文献を集めることができるはずである。次のステップは、自分の適格基準を満たすものを選択することである。そのためには、以下のように3つのステップを踏むことを勧める。ステップ 1 では、重複している文献を削除する必要がある。特に、複数の電子書誌データベースで検索した場合、1つの文献が2回以上表示される可能性がある。これを行う簡単な方法は、まず、すべての参考文献を参考文献管理ソフトウェアにインポートして、一箇所に集めることである。優れた参考文献管理ツールはいくつかある。Zotero や Mendeley のようなものは、無料でダウンロードすることが可能である。また、EndNote のようなプログラムは、より多くの機能を提供したが、通常、ライセンスが必要である。文献管理ソフトは、重複する論文を自動的に削除できる機能を備えている。最初に研究検索で見つけた文献の数と、重複を除去した後に残った文献の数を書き留めておくことが重要である。除外の詳細は、後にメタ分析を公開する際に報告する必要がある。重複を除去した後は、タイトルとアブストラクトに基づいて、目的に合わない文献を除外する必要がある。研究検索をすると、研究課題とは全く関係のない結果が何百件も出てくる可能性が非常に高い5 。このような文献は、タイトルと要旨だけを見て、安全に削除することが可能である。このステップでも、文献管理ソフトが役に立つ。各参考文献を一つずつ調べていき、その論文が自分とは関係ないと確信したら、単に削除すればいい6。タイトルとアブストラクトから、ある研究に興味深い情報が含まれているかもしれないと思った場合、たとえその研究が重要でないように思えても、削除しないほうがよい。せっかく時間と労力をかけて総合的な研究を検索したのに、次のステップで誤って関連する文献を削除してしまったら残念なことである。タイトルと抄録に基づく文献のスクリーニングでは、その研究を除外した具体的な理由を説明する必要はない。最終的には、次のステップのために、いくつの研究が残ったかを記録するだけでよいのである。タイトルとアブストラクトのスクリーニングに基づくと、最初の参考文献の90%以上が削除される可能性がある。次のステップでは、各文献の全文を取得する必要がある。論文で報告されたすべての内容に基づいて、その研究が適格基準を満たすかどうかを最終的に判断する。この作業は、メタ分析に研究を含めるかどうかを決定する最終ステップなので、特に念入りに行う必要がある。さらに、単に「目的に合わないから外した」というだけでは不十分である。ここで理由を述べなければならない。削除する各研究について、定義した基準に従って、なぜその研究が適格でなかったのかを文書化する必要がある。適格性の基準以外に、ある研究を含めることができない理由がもう一つある。論文全体に目を通すと、その研究が適格かどうかを判断するのに十分な情報が提供されていないことがわかるかもしれない。研究デザインに関する十分な情報が提供されていないだけということもあり得る。また別のよくあるシナリオは、メタ分析に必要な効果量メトリックを計算できるような形で研究結果が報告されていないことである。このような場合は、少なくとも2回、研究の責任著者に連絡を取り、必要な情報を求めるようにする。著者が応答しない場合、そして発表論文に欠けている情報が不可欠な場合のみ、その研究を除外することが可能である。\n含めるべき研究の最終的な選択に到達したら、含めるプロセスのすべての詳細をフロー図に書き留める。フロー図のテンプレートとしてよく使われるのは、PRISMAガイドラインで提供されている7。このフローチャートは、上記で取り上げた必要な情報をすべて文書化したものである。電子データベースを検索して、いくつの文献を特定できたか。電子データベースを検索して、いくつの文献を特定できたか。他の情報源から見つけた追加の参考資料の数。他の情報源から見つけた追加の参考資料の数。重複排除後に残った参考文献の数。重複排除後に残った参考文献の数。タイトルとアブストラクトに基づいて削除した文献の数。タイトルとアブストラクトに基づいて削除した文献の数。フル論文に基づいて削除した論文の数、特定の理由で除外した論文の数を含む。フル論文に基づいて削除した論文の数、特定の理由で除外した論文の数を含む。定性的統合 (つまりシステマティックレビュー) および定量的統合 (つまりメタ分析) に含めた研究の数。定性的統合 (つまりシステマティックレビュー) および定量的統合 (つまりメタ分析) に含めた研究の数。なお、(5)で除外しなかった論文の数と(6)で含めた研究の数は通常同じであるが、必ずしも同じである必要はない。例えば、1つの論文が2つ以上の独立した研究の結果を報告し、そのすべてがメタ分析に適していることもあり得る。その場合、研究の数は、含まれる論文の数より多くなる。ダブルスクリーニング関連するほぼすべてのガイドラインやコンセンサスステートメントは、研究選択プロセスにおいてダブルスクリーニングを用いるべきであると強調している (Tacconelli 2009; Julian Higgins et al. 2019; Campbell Collaboration 2016)。つまり、誤りを避けるために、少なくとも2人が独立して各研究選択ステップを行う必要がある。タイトルとアブストラクトに基づく文献の削除は、2人以上の研究者が独立して行い、評価者が削除しなかったすべての記録の組み合わせを次のステップに転送する必要がある。2人以上の評価者を使うことは、論文の全文をスクリーニングする最後のステップではさらに重要である。このステップでは、各人が独立して研究が適格であるかどうかを評価し、適格でない場合はその理由を述べなければならない。その後、評価者同士でその結果を比較する必要がある。一部の研究の適格性に関して評価者が意見を異にすることはよくあることで、そのような意見の相違は通常、議論を通じて解決することが可能である。評価者が合意を見いだせない場合、そのような場合に最終決定を下すことができる上級研究者をあらかじめ決めておくと便利である。2人以上の評価者を使用することは、研究の選択プロセスにおいてのみ望ましいわけではない。この方法は、データの抽出やコーディングの際にも有効である (Chapter 1.4.5 参照)。","code":""},{"path":"intro.html","id":"data-extraction","chapter":"1 はじめに","heading":"1.4.5 データ抽出とコーディング","text":"メタ分析に含める研究の選択が確定すると、データを抽出することができる。選択した論文から抽出すべき情報は、大きく分けて3種類ある (Pim Cuijpers 2016)。研究の特徴。効果量を算出するために必要なデータ。研究の質またはバイアスのリスクの特性。質の高いメタ分析では、対象となった研究の特徴を報告する表が用意されるのが通例である。この表で報告される正確な内容は、研究分野や研究課題によって異なる可能性がある。しかし、研究の筆頭著者とその発表時期は必ず抽出して報告する必要がある。また、各研究のサンプルサイズも報告する必要がある。これとは別に、メタ分析の PICO で指定された特性、例えば、対象国、平均年齢または中央値、女性と男性の参加者の割合、介入または曝露の種類、対照群または比較 (該当する場合)、および各研究の評価結果についての情報を含めることが可能である。1つまたは複数の研究で特性の1つが評価されていない場合は、その詳細が表で指定されていないことを示す必要がある。また、プールする予定の効果量や結果指標を計算するために必要なデータを抽出・収集することも必要である。章では、効果量データを表計算ソフトで構成し、 R での計算に利用しやすくする方法について詳しく説明する。また、解析計画 (Chapter 1.4.2 参照) にサブグループ解析やメタ回帰を計画している場合は、これらの分析に必要なデータも論文から抽出する必要がある。\nメタ分析では、一次研究の質も評価して報告することが一般的である。そのために各研究から抽出する必要のある情報は、使用する評価システムの種類に依存する。一次研究の質を評価するツールは、この数十年で数え切れないほど開発されている (Sanderson, Tatt, Higgins 2007)。ランダム化比較試験のみが対象である場合、研究の質をコード化する方法として、コクランが開発した Risk Bias Tool を用いるのが最適な方法の1つである (Julian Higgins et al. 2011; Sterne et al. 2019) 。タイトルにあるように、このツールは研究の質そのものを評価するのではなく、研究のバイアスのリスクを評価するものである。研究の質とバイアスのリスクは関連しているが、同一の概念ではない。「バイアス」 (あるいは「偏り」) とは、研究結果やその解釈における系統的な誤りを指す。バイアスのリスクとは、研究の実施方法やその結果が、そのような系統的な誤りを引き起こす可能性を高めるような側面である。たとえ、ある研究が「最先端」とされる方法のみを適用している場合でも、バイアスが存在する可能性はある。ある研究は、特定の研究分野で重要だと考えられている品質基準をすべて満たすことが可能であるが、時にはこれらのベストプラクティスでさえ、研究を歪みから守るには十分でない場合がある。このように、「バイアスのリスク」の概念は、研究の質の評価とは少し異なる焦点を持っている。それは主に介入研究のアウトプットが信じられるかという問題に関心があり、この目標に資する基準に焦点を当てている (Julian Higgins et al. 2019).いくつかのドメインでは、バイアスリスクツールで研究のバイアスリスクを「高い」「低い」に分類できたり、「何らかの懸念がある」と判断できる。また、バイアスリスクをどのように視覚的にまとめるかについても慣例がある (Chapter 15 で R でどのようにできるかを説明している)。非無作為化研究のバイアスリスクを評価するための同様のリソースとして、Risk Bias Non-randomized Studies Interventions または ROBINS-, tool がある (Sterne et al. 2016)。Cochrane Risk Bias ツールは、(非) 無作為化臨床試験におけるバイアスのリスクを評価するための標準的なアプローチとなっている (Jørgensen et al. 2016)。他の分野では、現在は残念ながらまだむしろ開拓時代である。例えば、心理学研究においては、研究の質の評価は一貫性がなく、不透明であるか、全く実施されていないことが多い (Hohn, Slaney, Tafreshi 2019)。臨床試験以外の研究のメタ分析を計画している場合、できることが2つある。まず、Risk Bias または ROBINS-ツールがまだ適用可能かどうかを確認しよう。例えば、健康に関連しない別の介入方法に焦点を当てている場合である。もう一つは、確かに最適とは言えないかもしれないが、類似のテーマに関する過去の高品質なメタ分析を検索し、これらの研究がどのように主要研究の品質を決定したかを確認することである。これで、メタ分析の歴史、問題点、そしてデータを収集しエンコードする際にそれらをどのように回避するかについての考察を終えることとする。次の章は、このガイドの「ハンズオン」部分の始まりである。この章では、 R の最初のステップを自分で実施してみる。\\[\\tag*{$\\blacksquare$}\\]","code":""},{"path":"intro.html","id":"演習問題","chapter":"1 はじめに","heading":"1.5 演習問題","text":"知識を試そう！メタ分析はどのように定義することができるか？メタ分析と他の文献レビューの違いは何か？メタ分析の生みの親、生みの親を一人挙げることができるか？その人物はどのような功績を残したか？メタ分析のよくある問題点を3つ挙げ、1～2文で説明しなさい。メタ分析のための良いリサーチクエスチョンを定義する資質を挙げなさい。大学生の睡眠介入に関するメタ分析の適格基準をもう一度見てみよう (Chapter 1.4.1章末)。この研究の適格基準、除外基準から PICO を抽出できるか。研究を検索するために使用できるいくつかの重要なソースを挙げなさい。「研究の質」と「バイアスのリスク」の違いを1～2文で説明しなさい。","code":""},{"path":"intro.html","id":"概要","chapter":"1 はじめに","heading":"1.6 概要","text":"毎年、より多くの科学的研究が発表され、利用可能な証拠を追跡することが難しくなっている。しかし、研究成果が多いからといって、自動的に科学が進歩するわけではない。毎年、より多くの科学的研究が発表され、利用可能な証拠を追跡することが難しくなっている。しかし、研究成果が多いからといって、自動的に科学が進歩するわけではない。メタ分析の目的は、過去の研究結果を定量的に組み合わせることである。ある研究課題に関する利用可能なすべての証拠を統合し、意思決定に利用することができる。メタ分析の目的は、過去の研究結果を定量的に組み合わせることである。ある研究課題に関する利用可能なすべての証拠を統合し、意思決定に利用することができる。メタ分析の手法は、20世紀初頭にまで遡る。しかし、現代的なメタ分析手法は20世紀後半に開発され、それ以降、メタ分析は一般的な研究ツールとなった。メタ分析の手法は、20世紀初頭にまで遡る。しかし、現代的なメタ分析手法は20世紀後半に開発され、それ以降、メタ分析は一般的な研究ツールとなった。各メタ分析には、「りんごとオレンジ」問題、「Garbage , Garbage 」問題、「ファイルの引き出し」問題、「研究者のアジェンダ」問題などが関連する。各メタ分析には、「りんごとオレンジ」問題、「Garbage , Garbage 」問題、「ファイルの引き出し」問題、「研究者のアジェンダ」問題などが関連する。これらの問題の多くは、明確な研究課題と適格基準を定義し、解析計画を書き、メタ解析を事前に登録し、研究検索とデータ抽出を系統的かつ再現可能な方法で行うことによって軽減することが可能である。これらの問題の多くは、明確な研究課題と適格基準を定義し、解析計画を書き、メタ解析を事前に登録し、研究検索とデータ抽出を系統的かつ再現可能な方法で行うことによって軽減することが可能である。","code":""},{"path":"discovering-R.html","id":"discovering-R","chapter":"2 R の発見","heading":"2 R の発見","text":"こ\nの章では、 R の世界への旅行を始めよう。初めてプログラミングに触れる読者、少し不安かもしれない。その気持ちはよく分かる。しかし、それほど心配する必要はない。この 20 年間、世界中の何千人もの知的な人々が、 R をより簡単に、より便利に使えるようにするための方法を提供してきた。また、 R のコードの記述と実行をより簡単にするために使用できる、非常に強力なコンピュータプログラムについても紹介する。とはいえ、これまで使ってきた他のデータ解析プログラムと比べると、 R で作業するのはやはり難しいのも事実である。 R コミュニティの最も重要な人物の一人である Hadley Wickham は、かつて R は GUI (Graphical User Interface) ベースの統計用ソフトウェアとは根本的に異なることを強調した (Grolemund 2014, Foreword)。GUI では、いくつかのボタンをクリックするだけでデータ分析を行うことが可能であるが、最終的には開発者が重要と判断した機能に限定されてしまう。一方、 R はこのような制限はない。しかし、より多くの背景知識を必要とする場合がある。他の言語と同様に、 R も学習が必要であり、熟練したユーザーになるためには練習が必要である。この過程では、不満が生じることもあるが、それは当然のことである。序章では、「行き詰まったら」という節で、できることをいくつか紹介している。R には、学ぶ価値があることを保証しよう。 R は、最も汎用性が高く、包括的で、最も頻繁に使用されている統計プログラミング言語である。 R のコミュニティは毎年急速に拡大しており、 R の魅力は非常に大きいので、ニューヨークタイムズでさえもニュースとして報道する価値があると判断した (Vance 2009)。大学や研究機関で働いていようが、一般企業で働いていようが、 R でできることは、他人から見れば超能力に見えることが多いだろう。しかし、多少の時間と努力さえあれば、誰でも習得できる超能力なのである。では、そろそろ始めよう。","code":""},{"path":"discovering-R.html","id":"install-R","chapter":"2 R の発見","heading":"2.1 R と R Studio のインストール","text":"開始する前に、統計解析のために R を便利に使えるコンピュータ・プログラムをダウンロードし、用意しなければならない。現時点での最良の選択肢は、おそらく R Studio だろう。このプログラムは、データ、パッケージ、出力の取り扱いを容易にするユーザー・インタフェースを提供してくれる。R Studio は完全に無料で、インターネットからいつでもダウンロードできるのが最大の魅力である。最近では、R Studio のオンライン版もリリースされ (https://rstudio.cloud/)、ウェブブラウザを通してほぼ同じインターフェースと機能を利用できるようになった。しかし、本書では、コンピュータに直接インストールする R Studio のバージョンに焦点を当てる。\nこの章では、 R と R Studio 各自のコンピュータに\nインストールする方法に焦点を当てている。すでに R Studio\nをコンピュータにインストールしており、 R\nの経験豊富なユーザーであれば、どれも目新しいものではないだろう。その場合は、この章を読み飛ばしてよい。\nR を使ったことがない人は、しばらくお付き合い願いたい。\nそれでは、初めてのコーディングに向けて、 R と R Studio の設定に必要なステップに進んでいこう。R Studio は、 R のコードを書き、それを簡単に実行できるようにするインターフェイスである。しかし、R Studioは R と同一ではなく、 R のソフトウェアがすでにコンピュータにインストールされている必要がある。したがって、まず、 R の最新版をインストールする必要がある。R Studio と同様、 R は完全に無料である。Comprehensive R Archive Network (CRAN)というウェブサイトからダウンロード可能である。Windows PC か Mac かによって、ダウンロードする R の種類は異なる。 R の重要な点は、その バージョン である。 R は定期的に更新され、新しいバージョンが利用できるようになる。 R のバージョンが古くなりすぎると、一部の機能が動作しなくなることがある。そのため、 R を再インストールして、定期的 (だいたい1年ごと) に R のバージョンを更新することが有効である。この本では 、 R のバージョン 4.0.3 を使用している。 R をインストールした時点で、すでに上位のバージョンがある可能性もあるので、常に最新のバージョンをインストールすることを勧める。R Studio は、 R のコードを書き、それを簡単に実行できるようにするインターフェイスである。しかし、R Studioは R と同一ではなく、 R のソフトウェアがすでにコンピュータにインストールされている必要がある。したがって、まず、 R の最新版をインストールする必要がある。R Studio と同様、 R は完全に無料である。Comprehensive R Archive Network (CRAN)というウェブサイトからダウンロード可能である。Windows PC か Mac かによって、ダウンロードする R の種類は異なる。 R の重要な点は、その バージョン である。 R は定期的に更新され、新しいバージョンが利用できるようになる。 R のバージョンが古くなりすぎると、一部の機能が動作しなくなることがある。そのため、 R を再インストールして、定期的 (だいたい1年ごと) に R のバージョンを更新することが有効である。この本では 、 R のバージョン 4.0.3 を使用している。 R をインストールした時点で、すでに上位のバージョンがある可能性もあるので、常に最新のバージョンをインストールすることを勧める。R をダウンロードしてインストールした後、R Studioのウェブサイトから “R Studio Desktop” をダウンロードする。R Studio にはライセンスを購入しなければならないバージョンもあるが、今回の目的では必要ではない。R Studio Desktop の無料版をダウンロードしてインストールするだけである。R をダウンロードしてインストールした後、R Studioのウェブサイトから “R Studio Desktop” をダウンロードする。R Studio にはライセンスを購入しなければならないバージョンもあるが、今回の目的では必要ではない。R Studio Desktop の無料版をダウンロードしてインストールするだけである。R Studio を初めて開くと、Figure 2.1 のような画面になると思われる。R Studio には、3 つのペインがある。右上には Environment ペインがあり、 R で内部的に定義した (＝保存した) オブジェクトが表示される。右下には、Files, Plots, Packages, Help ペインがある。このペインにはいくつかの機能があり、例えば、コンピュータ上のファイルを表示したり、プロットやインストールされたパッケージを表示したり、ヘルプページにアクセスするために使用される。しかし、R Studio の中心は左側の Console である。Console は、 R コードを入力し、実行する場所である。R Studio を初めて開くと、Figure 2.1 のような画面になると思われる。R Studio には、3 つのペインがある。右上には Environment ペインがあり、 R で内部的に定義した (＝保存した) オブジェクトが表示される。右下には、Files, Plots, Packages, Help ペインがある。このペインにはいくつかの機能があり、例えば、コンピュータ上のファイルを表示したり、プロットやインストールされたパッケージを表示したり、ヘルプページにアクセスするために使用される。しかし、R Studio の中心は左側の Console である。Console は、 R コードを入力し、実行する場所である。\nFigure 2.1: R Studio のペイン\nR Studioには、通常はじめに表示されない4番目のペインとして、Source ペインがある。メニューの File > New File > R Script をクリックすると、Source ペインを開くことが可能である。すると、左上に空の R スクリプトを含む新しいペインが開く。 R スクリプトは、コードを1つの場所に集めるのに最適な方法である。また、拡張子が “.R” のファイル (例: myscript.R) として、コンピュータに保存することも可能である。 R スクリプトのコードを実行するには、関連するすべての行にカーソルをドラッグして選択し、右側にある “Run” ボタンをクリックする。これにより、コードがコンソールに送信され、そこで評価される。ショートカットは、Ctrl + R (Windows) または Cmd + R (Mac)である。","code":""},{"path":"discovering-R.html","id":"packages","chapter":"2 R の発見","heading":"2.2 パッケージ","text":"ここでは、 R のコードを使用して、いくつかのパッケージをインストールする。パッケージは R が非常に強力である主な理由の1つである。パッケージによって、世界中の専門家が一連の関数を開発し、他の人がそれをダウンロードして R で使用できるようになる。関数は R の中核的な要素であり、事前に定義された種類の操作を、通常は自分のデータに対して実行できるようにする。関数 \\(f(x)\\) の数学的定式化と R における関数の定義の仕方は並行している。 R では、関数はまずその名前を書き、その後に入力や関数の指定 (いわゆる引数) を括弧で囲んでコーディングされる。例えば、9の平方根が何であるかを知りたいとする。 R では、 sqrt 関数を使用することが可能である。結果を得るためには、関数への入力として 9 を与えるだけでよいのである。自分で試してみてみよう。コンソールの小さな矢印(>)の横に sqrt(9) と書いて、Enter キーを押してみてみよう。何が起こるか見てみよう。これで R から最初の出力が得られた。 R にはこれよりはるかに複雑な関数があるが、すべて同じ原理で支配されている。関数が必要とするパラメータの情報を提供すると、関数はその情報を使って計算を行い、最終的に出力を提供する。\nR では、install.packages という関数を使って、パッケージのインストール を行う。この関数に伝えるべきことは、インストールしたいパッケージの名前だけである。とりあえず、後々役に立つ３つのパッケージをインストールしておこう。{tidyverse}. {tidyverse} (Wickham et al. 2019) は単一のパッケージではなく、実際には R でのデータの操作と視覚化を容易にするパッケージのバンドルである。{tidyverse} パッケージをインストールすると、同時に {ggplot2}, {dplyr}, {tidyr}, {readr}, {purr}, {stringr}, {forcats} パッケージが提供される。tidyverse に含まれる関数は、近年 R コミュニティで非常に人気があり、多くの研究者、プログラマ、データ科学者に利用されている。tidyverse についてもっと知りたい方は、公式ウェブサイトを参照。{tidyverse}. {tidyverse} (Wickham et al. 2019) は単一のパッケージではなく、実際には R でのデータの操作と視覚化を容易にするパッケージのバンドルである。{tidyverse} パッケージをインストールすると、同時に {ggplot2}, {dplyr}, {tidyr}, {readr}, {purr}, {stringr}, {forcats} パッケージが提供される。tidyverse に含まれる関数は、近年 R コミュニティで非常に人気があり、多くの研究者、プログラマ、データ科学者に利用されている。tidyverse についてもっと知りたい方は、公式ウェブサイトを参照。{meta}. このパッケージには、様々なタイプのメタアナリシスを簡単に実行するための関数が含まれている (Balduzzi, Rücker, Schwarzer 2019)。このガイドでは主にこのパッケージに焦点を当てる。なぜなら、このパッケージは使いやすく、よく文書化されており、非常に汎用性が高いからである。{meta} パッケージの詳細については、 ウェブサイトを参照。{meta}. このパッケージには、様々なタイプのメタアナリシスを簡単に実行するための関数が含まれている (Balduzzi, Rücker, Schwarzer 2019)。このガイドでは主にこのパッケージに焦点を当てる。なぜなら、このパッケージは使いやすく、よく文書化されており、非常に汎用性が高いからである。{meta} パッケージの詳細については、 ウェブサイトを参照。{metafor}. {metafor} パッケージ (Viechtbauer 2010) もメタアナリシスの実施に特化したパッケージで、機能面ではまさに強豪と言える。このパッケージは後の章で時々使用するし、{meta} パッケージが多くの応用で {metafor} を使用するため、インストールしておくとよいだろう (訳注: 通常、meta をインストールすると自動的に metafor もインストールされる。)。また、{metafor} パッケージには、メタ分析関連の様々なトピックに関する優れたドキュメントがある。{metafor}. {metafor} パッケージ (Viechtbauer 2010) もメタアナリシスの実施に特化したパッケージで、機能面ではまさに強豪と言える。このパッケージは後の章で時々使用するし、{meta} パッケージが多くの応用で {metafor} を使用するため、インストールしておくとよいだろう (訳注: 通常、meta をインストールすると自動的に metafor もインストールされる。)。また、{metafor} パッケージには、メタ分析関連の様々なトピックに関する優れたドキュメントがある。install.packages 関数は、インストールしたいパッケージの名前のみを入力として要求する。ひとつずつパッケージを追加するコードは次のようになるはずである。コンソールに上記のコードを入力し、Enter キーを押すだけでインストールが開始される (Figure 2.1)。\nFigure 2.2: パッケージをインストールする。\nEnter を押すと、 R はパッケージのインストールを開始し、インストールの進行状況についての情報を表示する。install.packages 関数が終了すると、そのパッケージを使用する準備が整ったことになる (訳注: この際のメッセージが赤字の英語で表示されるため、エラーが出たと勘違いする人が多い。じっくり読んで、successful とあれば成功である。)。インストールされたパッケージは、 R の システム・ライブラリ に追加される。このシステムライブラリは、R Studio の画面左下にあるパッケージペインでアクセス可能である。インストールされたパッケージを使いたいときは、library 関数を使ってライブラリから読み込むことが可能である。試しに、{tidyverse} パッケージをロードしてみよう。","code":"\nsqrt(9)## [1] 3\ninstall.packages(\"tidyverse\")\ninstall.packages(\"meta\")\ninstall.packages(\"metafor\")\nlibrary(tidyverse)"},{"path":"discovering-R.html","id":"dmetar","chapter":"2 R の発見","heading":"2.3 {dmetar} パッケージ","text":"このガイドでは、研究者としてメタアナリシスの実施をできるだけアクセスしやすく、簡単にできるようにしたい。メタ分析には {meta} や {metafor} パッケージのような素晴らしいパッケージがあり、ほとんどの重労働をこなしてくれるが、メタ分析にはまだいくつかの重要な側面があり、現在 R で行うのは簡単ではない。不足している機能を補うため、我々は本書のコンパニオン R パッケージとして、{dmetar} パッケージを開発した。{dmetar} パッケージは独自のドキュメントを持っており、オンラインで見ることが可能である。{dmetar} パッケージの関数は、このガイドで頻繁に使用する {meta} と {metafor} パッケージ (と、より高度な他のいくつかのパッケージ) のための追加機能を提供している。{dmetar} パッケージに含まれる関数がどのようにメタ分析のワークフローを改善するかを、この本を通じて詳細に説明していこう。このガイドで使用するサンプルデータセットのほとんどは、{dmetar} に含まれている。このガイドを読み進めていくためには、{dmetar} パッケージをインストールすることを強く推奨するが、必須ではない。パッケージの各関数について、ソースコード (関数をローカルに保存するために使用可能) と、それらの関数が依存する追加の R パッケージも提供している。また、パッケージに含まれるデータセットの補足的なダウンロードリンクも提供する。{dmetar} パッケージをインストールするには、 R のバージョンが 3.6 以降である必要がある。最近 R を (再) インストールしたのであれば、おそらく大丈夫だろう。 R のバージョンが十分に新しいかどうかを確認するには、次のコード行をコンソールに貼り付けて、Enterキーを押す。これにより、現在の R バージョンが表示される。もし、 R のバージョンが3.6以下であれば、アップデートする必要がある。この方法については、インターネット上に良いブログ記事があり、案内されている。{dmetar} をインストールする場合、先にインストールしなければならないパッケージがある。このパッケージは {devtools} と呼ばれている。{devtools} がまだコンピュータにインストールされていない場合は、先程と同じようにインストールしておこう。そして、この行を使って {dmetar} をインストールすることが可能である。これでインストールが開始される。{dmetar} パッケージが正しく機能するためには、他のパッケージも一緒にインストー ルする必要があるため、インストールに時間がかかる可能性がある。インストール中に、インストールマネージャが以下のように訪ねてくることがあるがこれは、すでにインストール済みの R パッケージを更新するかどうか尋ねている。このメッセージが表示されたら、パッケージ更新をしたくないことをインストールマネージャに伝えるとよい。この例では、コンソールに 3 を貼り付けて Enter キーを押す。同じように、インストールマネージャが、このような質問をした場合、n (いいえ) を選ぶとよいだろう。この方法でインストールに失敗した場合 (つまり Error が表示された場合)、もう一度インストールを実行し、今度はすべてのパッケージをアップデートする。本書を執筆し、パッケージを開発する際には、誰もがエラーなくインストールできるように配慮した。とはいえ、初回でパッケージのインストールがうまくいかない可能性もある。それでもインストールに問題がある場合は、本書のまえがきにある「問い合わせ」の項を参照されたい。","code":"\nR.Version()$version.string\ninstall.packages(\"devtools\")\ndevtools::install_github(\"MathiasHarrer/dmetar\")## These packages have more recent versions available.\n## Which would you like to update?\n## \n## 1: All                          \n## 2: CRAN packages only            \n## 3: None                          \n## 4: ggpubr (0.2.2 -> 0.2.3) [CRAN]\n## 5: zip    (2.0.3 -> 2.0.4) [CRAN]\n## \n## Enter one or more numbers, or an empty line to skip updates:## There are binary versions available but the source versions are later:\n##  \n##  [...]\n##  \n##   Do you want to install from sources the package which needs compilation?\n##   y/n: "},{"path":"discovering-R.html","id":"data-prep-R","chapter":"2 R の発見","heading":"2.4 データ準備とインポート","text":"この章では、R Studio を使用してデータを R にインポートする方法について説明する。データの準備は、面倒で疲れるものではあるが、後のすべてのステップの基礎となる。したがって、先に進む前にデータを正しい形式にすることに細心の注意を払わなければならない。通常、 R に取り込んだデータは、 Microsoft Excel のスプレッドシートに格納されている。インポートを非常に簡単に行うことができるため、データを Excel に保存することを勧める。 Excel でデータを準備する際には、いくつかの「すべきこと」と「してはいけないこと」がある。Excel シートの列にどのように名前を付けるかは非常に重要である。列に正しく名前を付けておけば、 R を使用してデータを変換する必要がないため、後で時間を大幅に節約することが可能である。スプレッドシートの列に「名前を付ける」とは、単に変数の名前を列の最初の行に書き込むことである。(訳注: 日本では２行目以降にも列名を書くことがあるが、あまりよい習慣とは言えない。)Excel シートの列にどのように名前を付けるかは非常に重要である。列に正しく名前を付けておけば、 R を使用してデータを変換する必要がないため、後で時間を大幅に節約することが可能である。スプレッドシートの列に「名前を付ける」とは、単に変数の名前を列の最初の行に書き込むことである。(訳注: 日本では２行目以降にも列名を書くことがあるが、あまりよい習慣とは言えない。)列名にはスペースを含めてはいけない。列名の2つの単語を区切るには、アンダースコアまたはポイントを使用した(例: “column_name”)。列名にはスペースを含めてはいけない。列名の2つの単語を区切るには、アンダースコアまたはポイントを使用した(例: “column_name”)。Excel のスプレッドシートで列をどのように並べるかは重要ではない。ただ、正しくラベル付けされている必要がある。Excel のスプレッドシートで列をどのように並べるかは重要ではない。ただ、正しくラベル付けされている必要がある。また、列の書式設定も必要ない。スプレッドシートの最初の行に列名を入力すると、 R はそれを列名として自動的に検出する。また、列の書式設定も必要ない。スプレッドシートの最初の行に列名を入力すると、 R はそれを列名として自動的に検出する。インポート時に、ä、ü、ö、á、é、ê などの特殊文字が文字化けする可能性があることも知っておくとよいだろう。インポートする前に、これらの文字を「通常の」文字に変換しておくとよいだろう。(訳注: 列名に日本語を使っても問題ないが、英語論文作成を意図している場合は英語にしておく方が良いだろう。)インポート時に、ä、ü、ö、á、é、ê などの特殊文字が文字化けする可能性があることも知っておくとよいだろう。インポートする前に、これらの文字を「通常の」文字に変換しておくとよいだろう。(訳注: 列名に日本語を使っても問題ないが、英語論文作成を意図している場合は英語にしておく方が良いだろう。)Excel ファイルにシートが1つだけ入っていることを確認する。Excel ファイルにシートが1つだけ入っていることを確認する。もし、以前にデータを含んでいて現在空になっている行や列が1つまたはいくつかある場合、それらの列や行を完全に削除することを確認する。もし、以前にデータを含んでいて現在空になっている行や列が1つまたはいくつかある場合、それらの列や行を完全に削除することを確認する。まず、データセットの例から見てみよう。これから、自殺防止プログラムのメタアナリシスを実施する予定だとする。研究で注目したいアウトカムは、質問票によって評価された自殺念慮の重症度 (すなわち、個人がどの程度、自分の人生を終わらせることを考え、検討し、計画するか) である。あなたはすでに研究の検索とデータ抽出を完了し、次に R でメタ分析データをインポートしたいと思っている。したがって、次の作業は、関連するすべてのデータを含む Excel シートを準備することである。Table 2.1 は、インポートするすべてのデータを示している。この表の最初の行には、上で挙げたルールに基づき、 Excel ファイル内の列にどのような名前を付けるかも示されている。スプレッドシートには、各研究が1行にリストされていることがわかる。各研究について、介入群と対照群の両方のサンプルサイズ (\\(n\\))、平均値、標準偏差 (\\(SD\\)) が含まれている。これは効果の大きさを計算するために必要なアウトカムデータで、詳しくは Chapter 3 で説明する。次の3列は、後でメタ分析で分析したい変数である。このデータをまとめた “SuicidePrevention.xlsx”という Excel ファイルを用意した。このファイルは、インターネットからダウンロードすることが可能である。\nTable 2.1: Suicide Prevention データセット\nR Studioで Excel ファイルをインポートするには、まず作業ディレクトリを設定する必要がある。作業ディレクトリとは、 R がデータを使用することができ、出力が保存されるコンピュータ上のフォルダのことである。作業ディレクトリを設定するには、まず、メタアナリシスのデータと結果をすべて保存するフォルダをコンピュータ上に作成する必要がある。また、インポートしたい “SuicidePrevention.xlsx” ファイルもこのフォルダに保存する。R Studio を起動し、左下の Files ペインに新しく作成したフォルダを開く。フォルダを開くと、先ほど保存した Excel ファイルが表示されているはずである。次に、ペイン上部の小さな歯車をクリックし、ポップアップメニューの Set working directory をクリックして、このフォルダを作業ディレクトリとして設定する。これで、現在開いているフォルダが作業ディレクトリになる。\nFigure 2.3: 作業ディレクトリを設定し、R 環境にデータセットを読み込む。\nこれで、 R にデータをインポートできるようになった。Files ペインで、“SuicidePrevention.xlsx” ファイルをクリックしよう。次に、Import Dataset… をクリックする。インポートアシスタントがポップアップ表示され、データのプレビューが読み込まれるはずである。これは時間がかかる場合があるので、このステップをスキップして、そのまま Import をクリックする。すると、右上の Environment ペインに SuicidePrevention という名前でデータセットが表示されるはずである。これは、データが読み込まれ、 R コードで使用できるようになったことを意味している。今回インポートしたような表形式のデータセットは、 R では データフレーム (data.frame) と呼ばれている。データフレームは、先ほどインポートした Excel のシートのように、列と行を持つデータセットである。{openxlsx}また、コードを使用してデータファイルを直接インポートすることも可能である。このために使える良いパッケージは {openxslx} (Schauberger Walker 2020) と呼ばれるものである。他の R パッケージと同様に、最初にこれをインストールする必要がある。それから read.xlsx 関数を使って Excel シートをインポートすることが可能である。ファイルが作業ディレクトリに保存されている場合、関数にファイル名を与え、インポートしたデータを R のオブジェクトに代入するだけでよい。例えば、データセットが R 内で data という名前になるようにしたい場合は、次のようなコードを使用する。","code":""},{"path":"discovering-R.html","id":"data-manip-R","chapter":"2 R の発見","heading":"2.5 データ操作","text":"R Studio を使って最初のデータセットをインポートしたので、いくつかの操作を行ってみよう。データ操作とは、さらなる分析に使えるようにデータを変換することであり、すべてのデータ分析に不可欠な作業である。データサイエンティストのような職業は、生の「整頓されていない」データを「整頓された」(tidy) データセットに変えることに大半の時間を費やしている。{tidyverse} の関数は、データ操作のための優れたツールボックスを提供している。もしまだパッケージをライブラリからロードしていないなら、次の例のために今ロードすべきである。","code":"\nlibrary(tidyverse)"},{"path":"discovering-R.html","id":"class-conversion","chapter":"2 R の発見","heading":"2.5.1 クラス変換","text":"まず、前章でインポートした SuicidePrevention データセットを覗いてみよう。これを行うには、 {tidyverse} が提供する glimpse 関数を使用する。(訳注: あるいは Environment ペイン内の SuicidePrevention の左にある丸印をクリックすれば表示される。)これにより、データセットの各列に格納されているデータの種類の詳細を知ることができる。データの種類を示す略語はさまざまである。 R では、これらはクラスと呼ばれている (訳注: クラスではなく型である)。<num> は numeric の略である。これは、数字として格納されているすべてのデータである (例: 1.02)。(訳注: 実際は  と表示されているはずである。)<num> は numeric の略である。これは、数字として格納されているすべてのデータである (例: 1.02)。(訳注: 実際は  と表示されているはずである。)<chr> は character の略である。これは、単語として格納されているすべてのデータである。<chr> は character の略である。これは、単語として格納されているすべてのデータである。<log> は logical の略で、ある条件が TRUE または FALSE のいずれかであることを示すバイナリ変数である。<log> は logical の略で、ある条件が TRUE または FALSE のいずれかであることを示すバイナリ変数である。<factor> は数値として保存され、各数値は変数の異なる水準を意味する。変数の因子水準は、1 = “low”、2 = “medium”、3 = “high” とすることができる。<factor> は数値として保存され、各数値は変数の異なる水準を意味する。変数の因子水準は、1 = “low”、2 = “medium”、3 = “high” とすることができる。また、 class 関数を使用して、列のクラスを確認することも可能である。データフレームの列の名前に $ 演算子を付けて、列の名前を指定すれば、データフレーム内の列に直接アクセスすることが可能である。これを試してみよう。まず、 R に n.e という列に含まれるデータを提供させる。その後、その列のクラスを確認する。介入グループのサンプルサイズを含む列 n.e は、クラス character を持っていることがわかる。しかし、待ってみよう、これは間違ったクラスである。インポート時に、この列は誤って character 変数として分類されたが、実際には numeric クラスであるべきである。この間違いは、今後の分析段階に影響を与える。例えば、サンプルサイズの平均を計算したい場合、このような警告が表示される。データセットを使えるようにするためには、まず列を正しいクラスに変換しなければならないことがよくある。これを行うには、すべて “.” で始まる一連の関数を使用することが可能である。すなわち、 .numeric, .character, .logical そして .factor である。それでは、いくつかの例を見てみよう。先ほどの glimpse 関数の出力では、いくつかの列が numeric であるべきなのに character クラスに設定されていることがわかる。これは n.e, mean.e, sd.e, mean.c, sd.c という列に関係している。出版年 pubyear は <dbl> というクラスを持っていることがわかる。これは double の略で、列が数値ベクトルであることを意味する。 R では、数値データ型を参照するために double と numeric の両方が使用されるのは歴史的な例外である。しかし、通常、これは実際のところ何の意味もない。しかし、このデータセットでは、いくつかの数値が文字 (character) としてコード化されているため、今後問題が発生することが予想される。したがって、 .numeric 関数を使用してクラスを変更する必要がある。この関数に変更したい列を指定し、代入演算子 (<-) を使って出力を元の場所に保存する。これは次のようなコードになる。また、glimpse の出力では、データのサブグループである age_group と control が文字としてコード化されていることがわかる。しかし、実際には、それぞれ2つの因子水準を持つ因子としてエンコードする方が適切である。クラスを変更するには、 .factor 関数を使用する。levels と nlevels 関数を使用すると、因子のラベルと因子の水準数を確認することも可能である。また、levels 関数を使用して、因子ラベルの名前を変更することが可能である。単に、元のラベルに新しい名前を割り当てるだけである。これを R で行うには、 concatenate または c 関数を使用する必要がある。この関数は2つ以上の単語や数字を結びつけて、1つの要素を作ることが可能である。これを試してみよう。完璧である。これで、新しく作成した new.factor.levels オブジェクトを使用して、age_group 列の因子ラベルに割り当てることができるようになった。リネームがうまくいったかどうか、確認してみよう。また、.logical を使用して論理値を作成することも可能である。例えば、 pubyear 列を再コード化し、2009年以降に発表された研究のみを表示するようにしたいとしよう。これを行うには、コードでイエス/ノーのルールを定義する必要がある。「以上」演算子 >= を使用し、.logical 関数の入力として使用する。これは pubyear の各要素を、出版年が2010年以上かそうでないかによって TRUE または FALSE としてエンコードしていることがわかる。","code":"\nglimpse(SuicidePrevention)## Rows: 9\n## Columns: 10\n## $ author    <chr> \"Berry et al.\", \"DeVries et al.\", \"Fleming et al.\", \"Hunt & …\n## $ n.e       <chr> \"90\", \"77\", \"30\", \"64\", \"50\", \"109\", \"60\", \"40\", \"51\"\n## $ mean.e    <chr> \"14.98\", \"16.21\", \"3.01\", \"19.32\", \"4.54\", \"15.11\", \"3.44\", …\n## $ sd.e      <chr> \"3.29\", \"5.35\", \"0.87\", \"6.41\", \"2.75\", \"4.63\", \"1.26\", \"0.7…\n## $ n.c       <dbl> 95, 69, 30, 65, 50, 111, 60, 40, 56\n## $ mean.c    <chr> \"15.54\", \"20.13\", \"3.13\", \"20.22\", \"5.61\", \"16.46\", \"3.42\", …\n## $ sd.c      <chr> \"4.41\", \"7.43\", \"1.23\", \"7.62\", \"2.66\", \"5.39\", \"1.88\", \"1.4…\n## $ pubyear   <dbl> 2006, 2019, 2006, 2011, 1997, 2000, 2013, 2015, 2014\n## $ age_group <chr> \"general\", \"older adult\", \"general\", \"general\", \"general\", \"…\n## $ control   <chr> \"WLC\", \"no intervention\", \"no intervention\", \"WLC\", \"WLC\", \"…\nSuicidePrevention$n.e## [1] \"90\"  \"77\"  \"30\"  \"64\"  \"50\"  \"109\" \"60\"  \"40\"  \"51\"\nclass(SuicidePrevention$n.e)## [1] \"character\"\nmean(SuicidePrevention$n.e)## Warning in mean.default(SuicidePrevention$n.e): argument is not numeric or\n## logical: returning NA## [1] NA\nSuicidePrevention$n.e <- as.numeric(SuicidePrevention$n.e)\nSuicidePrevention$mean.e <- as.numeric(SuicidePrevention$mean.e)\nSuicidePrevention$sd.e <- as.numeric(SuicidePrevention$sd.e)\nSuicidePrevention$n.c <- as.numeric(SuicidePrevention$n.c)\nSuicidePrevention$mean.c <- as.numeric(SuicidePrevention$mean.c)\nSuicidePrevention$sd.c <- as.numeric(SuicidePrevention$sd.c)\nSuicidePrevention$n.c <- as.numeric(SuicidePrevention$n.c)\nSuicidePrevention$age_group <- as.factor(SuicidePrevention$age_group)\nSuicidePrevention$control <- as.factor(SuicidePrevention$control)\nlevels(SuicidePrevention$age_group)## [1] \"general\"     \"older adult\"\nnlevels(SuicidePrevention$age_group)## [1] 2\nnew.factor.levels <- c(\"gen\", \"older\")\nnew.factor.levels## [1] \"gen\"   \"older\"\nlevels(SuicidePrevention$age_group) <- new.factor.levels\nSuicidePrevention$age_group## [1] gen   older gen   gen   gen   gen   gen   older older\n## Levels: gen older\nSuicidePrevention$pubyear## [1] 2006 2019 2006 2011 1997 2000 2013 2015 2014\nas.logical(SuicidePrevention$pubyear >= 2010)## [1] FALSE  TRUE FALSE  TRUE FALSE FALSE  TRUE  TRUE  TRUE"},{"path":"discovering-R.html","id":"data-slicing","chapter":"2 R の発見","heading":"2.5.2 データのスライス","text":"R では、データフレームの部分集合を抽出する方法がいくつかある。そのうちのひとつである $ 演算子を使って列を抽出する方法についてすでに説明した。データセットからスライスを抽出する、より一般的な方法は、角括弧を使用することである。角括弧を使用する一般的な形式は、 data.frame[rows, columns] である。行と列は、データセットに現れる番号を使って抽出することができる。例えば、データフレームの2行目のデータを取り出すには、以下のようなコードを使用する。さらに具体的に、2行目の1列目の情報だけが欲しいと R に伝えることが可能である。特定のスライスを選択するには、再び concatenate (c) 関数を使用する必要がある。たとえば、2行目と3行目、および4列目と6列目を抽出したい場合は、次のようなコードを使用する。通常、行は番号によってのみ選択することができる。しかし、列の場合は、番号の代わりに列の名前を指定することも可能である。別の方法として、行の値に基づいてデータセットにフィルタを行うこともできる。これを行うには、関数 filter を使用する。この関数では、データセット名とフィルタ条件を指定する必要がある。比較的簡単な例として、n.e が50以下である研究をすべてフィルタしてみよう。名前によるフィルタも可能である。例えば、著者である Meijer と Zaytsev による研究を抽出したいとする。そのためには、%%演算子と concatenate 関数を用いて、フィルタ条件を定義する必要がある。逆に、フィルタの論理式の前に感嘆符 (!) をつけることで、Meijer と Zaytsev による研究を除くすべての研究を抽出することも可能である。","code":"\nSuicidePrevention[2,]##           author n.e mean.e sd.e n.c mean.c sd.c pubyear age_group\n## 2 DeVries et al.  77  16.21 5.35  69  20.13 7.43    2019     older\n##           control\n## 2 no intervention\nSuicidePrevention[2, 1]## [1] \"DeVries et al.\"\nSuicidePrevention[c(2,3), c(4,6)]##   sd.e mean.c\n## 2 5.35  20.13\n## 3 0.87   3.13\nSuicidePrevention[, c(\"author\", \"control\")]##            author         control\n## 1    Berry et al.             WLC\n## 2  DeVries et al. no intervention\n## 3  Fleming et al. no intervention\n## 4    Hunt & Burke             WLC\n## 5 McCarthy et al.             WLC\n## 6   Meijer et al. no intervention\n## 7   Rivera et al. no intervention\n## 8  Watkins et al. no intervention\n## 9  Zaytsev et al. no intervention\nfilter(SuicidePrevention, n.e <= 50)##            author n.e mean.e sd.e n.c mean.c sd.c pubyear age_group\n## 1  Fleming et al.  30   3.01 0.87  30   3.13 1.23    2006       gen\n## 2 McCarthy et al.  50   4.54 2.75  50   5.61 2.66    1997       gen\n## 3  Watkins et al.  40   7.10 0.76  40   7.38 1.41    2015     older\n##           control\n## 1 no intervention\n## 2             WLC\n## 3 no intervention\nfilter(SuicidePrevention, author %in% c(\"Meijer et al.\",\n                                        \"Zaytsev et al.\"))##           author n.e mean.e sd.e n.c mean.c  sd.c pubyear age_group\n## 1  Meijer et al. 109  15.11 4.63 111  16.46  5.39    2000       gen\n## 2 Zaytsev et al.  51  23.74 7.24  56  24.91 10.65    2014     older\n##           control\n## 1 no intervention\n## 2 no intervention\nfilter(SuicidePrevention, !author %in% c(\"Meijer et al.\", \n                                         \"Zaytsev et al.\"))"},{"path":"discovering-R.html","id":"data-transform","chapter":"2 R の発見","heading":"2.5.3 データ変換","text":"もちろん、 R のデータフレーム内の特定の値を変更したり、拡張したりすることも可能である。 R で内部保存したデータを変更するには、代入演算子を使用する必要がある。以前、データスライスについて学んだことを再利用して、データセットの特定の値を変更することにしよう。私たちが間違いを犯し、DeVries et al. による研究の出版年が、2018であるべきところを2019と誤って報告されたとする。データセットを適宜スライスし、新しい値を割り当てることで、値を変更することが可能である。DeVries et al. の結果は、データセットの2行目に報告されていることを忘れないように。また、一度に複数の値を変更することもできる。例えば、データセットのすべての介入グループの平均に5を加えたい場合、次のコードで可能である。また、2つ以上の列を使用して計算を行うこともできる。実用的な例としては、各研究の介入群の平均と対照群の平均の平均差 (mean difference) を計算したいとする。他のプログラミング言語と比較すると、 R では、これは驚くほど簡単である。今見たように、これは各研究の介入群の平均から対照群の平均を引くが、毎回同じ行の値を使用する。この平均差 (mean difference) を後で利用することにしよう。そこで、これを md というオブジェクトとして保存し、 SuicidePrevention データフレームに新しい列として追加したいと思ったとする。どちらも代入演算子を使えば簡単にできる。最後に紹介するのは、パイプ演算子である。 R では、パイプは %>% と表記される (訳注: R 4.2 から、|> というパイプも導入された)。パイプを使うと、関数を呼び出す際にオブジェクト名を直接指定することなく、オブジェクトに関数を適用することが可能である。単に、オブジェクトと関数をパイプ演算子でつなげるだけである。簡単な例を挙げてみよう。対照群のサンプル数の平均を計算したい場合、mean 関数とパイプ演算子を次のように使用する。この例では、パイプの価値を見ることは困難である。パイプの特別な強みは、多くの関数を連結することができる点にある。例えば、2009年以降に発表された研究のみを対象として、対照群サンプルサイズの平均値の平方根を知りたいとする。パイプを使えば、これを1ステップで簡単に行うことが可能である。パイプの中では、これまで取り上げていない関数として、pull 関数を使った。この関数は、パイプで使用できる $ 演算子と同等と見なすことができる。この関数は、関数内で指定した変数を単に「引き出す」だけで、パイプの次の部分に送り込むことが可能である。\nR のドキュメントにアクセス\n\nR\nの多くの関数は複数の引数を必要とし、全ての関数の使い方を正しく記憶することは不可能である。ありがたいことに、各関数の使い方を丸暗記する必要はない。R\nStudio では、 R\nのドキュメントに簡単にアクセスでき、各関数には詳細な説明ページが用意されている。\n\n関数のドキュメントページを検索するには、2つの方法がある。一つは、R\nStudio の左下 (訳注: 「右下」にあることの方が多い。) にある\nHelp\nペインにアクセスし、検索バーを使って特定の関数に関する情報を見つける方法である。もっと便利な方法は、コンソールで\n? の後に関数名をつけて、例えば ?mean\nのように実行することである。これで自動的にこの関数のドキュメントのエントリーが開かれる。\n\n関数の R\nドキュメントには通常、少なくとも使用法\n(Usage)、引数 (Arguments)、例\n(Examples)\nのセクションがある。特に、引数と例のセクションは、関数がどのように使用されるかを理解するのに役立つことが多いだろう。\n","code":"\nSuicidePrevention[2, \"pubyear\"] <- 2018\nSuicidePrevention[2, \"pubyear\"]## [1] 2018\nSuicidePrevention$mean.e + 5## [1] 19.98 21.21  8.01 24.32  9.54 20.11  8.44 12.10 28.74\nSuicidePrevention$mean.e - SuicidePrevention$mean.c## [1] -0.56 -3.92 -0.12 -0.90 -1.07 -1.35  0.02 -0.28 -1.17\nmd <- SuicidePrevention$mean.e - SuicidePrevention$mean.c\n\nSuicidePrevention$md <- SuicidePrevention$mean.e - \n                            SuicidePrevention$mean.c\nSuicidePrevention$n.c %>% mean()## [1] 64\nSuicidePrevention %>% \n  filter(pubyear > 2009) %>% \n  pull(n.c) %>% \n  mean() %>% \n  sqrt()## [1] 7.615773"},{"path":"discovering-R.html","id":"saving-data","chapter":"2 R の発見","heading":"2.5.4 データの保存","text":"データを変換して R に内部保存した後、ある時点でエクスポートする必要がある。 R のデータフレームを保存する際には、2種類のファイル形式を使用することをお勧めする。 .rda と .csv である。ファイルの末尾 .rda は、 R Data の略である。これは R 専用のファイル タイプで、すべての利点と欠点がある。 .rda ファイルの利点は、 R で簡単に再オープンできることと、エクスポート中にデータが歪む心配がないことである。また、汎用性が高く、表計算ソフトの形式に収まらないデータも保存可能である。欠点は、 R でしか開けないことであるが、プロジェクトによっては、これで十分である。オブジェクトを .rda データファイルとして保存するには、 save 関数を使用する。この関数では、(1) オブジェクトの名前、(2) ファイルの末尾を含めた正確なファイル名、を指定する必要がある。この関数を実行すると、ファイルが作業ディレクトリに保存される。ファイルの末尾 .csv は comma-separated values の略である。この形式は、一般的なデータで最もよく使用されるものの1つである。これは、Excel_を含む多くのプログラムで開くことが可能である。データを .csv_ として保存するには、 write.csv 関数を使用する。コードの構成や動作は save とほぼ同じであるが、提供するオブジェクトはデータフレームなどの表形式データオブジェクトである必要がある。そしてもちろん、ファイルタイプは “.csv” を指定する必要がある。ここでは、 R におけるデータ操作の戦略について簡単に説明する。特に、データの操作のように簡単だと思われるものを扱う場合、 R をゼロから学ぶのは疲れることがある。しかし、 R の動作に慣れるには、練習するのが一番である。しばらくすると、 R の一般的なコマンドは自然に使えるようになる。学習を続けるには、Hadley Wickham Garrett Grolemund の著書 R Data Science (2016) に目を通しておくとよいだろう。このガイドと同様に、この本もオンラインで完全に無料で読むことが可能である 。さらに、次のページでいくつかの演習も集めたので、ここで学んだことを実践するために使うことを勧める。\\[\\tag*{$\\blacksquare$}\\]","code":"\nsave(SuicidePrevention, file = \"suicideprevention.rda\")\nwrite.csv(SuicidePrevention, file = \"suicideprevention.csv\")"},{"path":"discovering-R.html","id":"演習問題-1","chapter":"2 R の発見","heading":"2.6 演習問題","text":"\nデータ操作の演習\n\nこの演習では、data\nという新しいデータセットを使用する。このデータセットは、以下のコードを使って\nR で直接作成することが可能である。\n\nこのデータセットの演習を紹介する。\n\n変数 Author を表示しなさい。\n\nsubgroup を因子型 (factor) に変換しなさい。\n\n“Jones” と “Martin” の研究のデータをすべて選択しなさい。\n\n研究名 “Rose” を “Bloom” に変更しなさい。\n\nTE から seTE を引いて、新しい変数\nTE_seTE_diff を作成し、結果を data\nに保存しなさい。\n\nパイプを使用して、(1) subgroup が”one” または “two”\nに属するすべての研究をフィルタし、(2) 変数 TE_seTE_diff\nを選択し、(3) その変数の平均をとり、それに exp\n関数を適用しなさい。 R\nのドキュメントにアクセスして、exp\n関数が何をするのか調べてみなさい。\n\n問題の解答は、本書の巻末 Appendix\nにある。\n","code":"\ndata <- data.frame(\"Author\" = c(\"Jones\", \"Goldman\", \n                                \"Townsend\", \"Martin\", \n                                \"Rose\"),\n                   \"TE\" = c(0.23, 0.56, \n                            0.78, 0.23, \n                            0.33),\n                  \"seTE\" = c(0.324, 0.235, \n                             0.394, 0.275, \n                             0.348),\n                  \"subgroup\" = c(\"one\", \"one\", \n                                 \"two\", \"two\", \n                                 \"three\"))"},{"path":"discovering-R.html","id":"概要-1","chapter":"2 R の発見","heading":"2.7 概要","text":"R は、世界で最も強力かつ頻繁に使用される統計プログラミング言語の1つとなっている。R は、世界で最も強力かつ頻繁に使用される統計プログラミング言語の1つとなっている。R は、グラフィカル・ユーザー・インターフェースとあらかじめ定義された機能を持つコンピュータ・プログラムではない。世界中の人々が自由に利用できるアドオン、いわゆるパッケージを提供できる完全なプログラミング言語である。R は、グラフィカル・ユーザー・インターフェースとあらかじめ定義された機能を持つコンピュータ・プログラムではない。世界中の人々が自由に利用できるアドオン、いわゆるパッケージを提供できる完全なプログラミング言語である。R Studio は、 R を使った統計解析を便利に行うためのコンピュータ・プログラムである。R Studio は、 R を使った統計解析を便利に行うためのコンピュータ・プログラムである。R の基本的な構成要素は関数である。これらの関数の多くは、インターネットからインストールできるパッケージを通じてインポートすることが可能である。R の基本的な構成要素は関数である。これらの関数の多くは、インターネットからインストールできるパッケージを通じてインポートすることが可能である。R を使ったデータの取り込み、操作、解析、保存に関数を使用することが可能である。R を使ったデータの取り込み、操作、解析、保存に関数を使用することが可能である。","code":""},{"path":"effects.html","id":"effects","chapter":"3 効果量","heading":"3 効果量","text":"前\n章では、 R の世界に慣れ親しみ、データのインポートと操作に役立ついくつかのツールを学んだ。本書の第 2 部では、 R の知識を応用して拡張しながら、メタ分析で使用される主要な統計技術について学習していこう。Chapter 1.1 では、メタ分析を「複数の研究から得られた定量的な結果を要約する手法」と定義した。メタ分析では、個人ではなく研究が分析の基本単位となる。これは新たな問題を引き起こす。一次研究において、収集したデータを記述するための要約統計を計算することは、通常、非常に簡単である。例えば一次研究では、連続変数アウトカムの算術平均 (arithmetic mean) \\(\\bar{x}\\) と標準偏差 (standard deviation) \\(s\\) を計算するのは、非常によくある手法である。しかし、これが可能なのは、通常、一次研究において本質的な前提条件の一つが満たされているからである。この条件とは、アウトカム変数がすべての研究対象者において同じ方法で測定されたことである。メタ分析では、この前提は通常満たされていない。中学校 2 年の数学能力をアウトカムとするメタ分析を実施したいと想像してみよう。どんなに厳密な包括基準を適用しても (Chapter 1.4.1 参照)、すべての研究がまったく同じテストを使って数学能力を測定しているとは思われないし、テストの合格・不合格の割合だけを報告している研究もあるかもしれない。このため、アウトカムを直接定量的に統合することは事実上不可能である。メタ分析を行うには、すべての研究にわたって要約される効果量 (effect size) を見つけなければならない。そのような効果量は、論文から直接抽出できることもあるが、多くの場合、研究で報告された他のデータから計算する必要がある。効果量の計量は、メタ分析の結果およびその解釈可能性に大きな影響を与える可能性がある。そのため、重要な基準を満たす必要がある (Lipsey Wilson 2001; Julian Higgins et al. 2019)。特に、メタ分析で選択される効果量指標は、以下のようなものであるべきである。比較できる (Comparable). 効果量の測定は、すべての研究において同じ意味を持つことが重要である。再び数学のスキルを例にとってみよう。異なるテストを使用した研究において、数学のテストで達成した点数における実験群と対照群の差をプールすることは意味がない。例えば、テストは難易度や達成できる最大点数が異なる場合がある。比較できる (Comparable). 効果量の測定は、すべての研究において同じ意味を持つことが重要である。再び数学のスキルを例にとってみよう。異なるテストを使用した研究において、数学のテストで達成した点数における実験群と対照群の差をプールすることは意味がない。例えば、テストは難易度や達成できる最大点数が異なる場合がある。計算できる (Computable). 効果量の指標は、主要な研究からその数値を導き出すことが可能である場合のみ、メタ分析に使用することが可能である。含まれるすべての研究のデータに基づいて、効果量を計算することが可能でなければならない。計算できる (Computable). 効果量の指標は、主要な研究からその数値を導き出すことが可能である場合のみ、メタ分析に使用することが可能である。含まれるすべての研究のデータに基づいて、効果量を計算することが可能でなければならない。信頼できる (Reliable). たとえ含まれるすべての研究の効果量を計算できたとしても、それらを統計的にプールすることもできなければならない。メタ分析で何らかの指標を用いるには、少なくとも標準誤差 (次章参照) を算出できなければならない。また、効果量の形式が、適用したいメタ分析手法に適しており、推定値に誤差やバイアスが生じないことも重要である。信頼できる (Reliable). たとえ含まれるすべての研究の効果量を計算できたとしても、それらを統計的にプールすることもできなければならない。メタ分析で何らかの指標を用いるには、少なくとも標準誤差 (次章参照) を算出できなければならない。また、効果量の形式が、適用したいメタ分析手法に適しており、推定値に誤差やバイアスが生じないことも重要である。解釈できる (Interpretable). 効果量の種類は、リサーチクエスチョンに答えるために適切でなければならない。例えば、2つの連続変数間の関連性の強さに関心がある場合、効果の大きさを表すには相関を用いるのが一般的である。相関の大きさを解釈するのは比較的簡単で、多くの研究者が理解することが可能である。しかし、この後の章では、解釈しやすく、かつ統計計算に最適な結果指標を用いることができない場合があることを学びる。このような場合、効果量をプールする前に、より良い数学的特性を持つ形式に変換する必要がある。解釈できる (Interpretable). 効果量の種類は、リサーチクエスチョンに答えるために適切でなければならない。例えば、2つの連続変数間の関連性の強さに関心がある場合、効果の大きさを表すには相関を用いるのが一般的である。相関の大きさを解釈するのは比較的簡単で、多くの研究者が理解することが可能である。しかし、この後の章では、解釈しやすく、かつ統計計算に最適な結果指標を用いることができない場合があることを学びる。このような場合、効果量をプールする前に、より良い数学的特性を持つ形式に変換する必要がある。「効果量」という言葉は、すでにどこかで目にしたことがあるのではないだろうか。私たちも、この言葉が何を表しているのか、あまり気にせずに使ってきた。そこで、次節では、「効果量」という言葉が実際に何を意味しているのかを探ってみたい。","code":""},{"path":"effects.html","id":"what-is-es","chapter":"3 効果量","heading":"3.1 効果量とは何か？","text":"効果量とは、本書では 2 つの実体の間の関係を定量化する指標と定義する。効果量は、この関係の方向と大きさを捉えたものである。関係性が同じ効果量として表現されていれば、それらを比較することが可能である。\nここで強調したいのは、これは効果量の意味を定義するための1つの方法に過ぎないということである。効果量の定義には幅があり、人によって使い方が異なる (Borenstein et al. 2011, chap. 3)。研究者の中には、介入研究の結果に言及する際にのみ効果量を定義する人もおり、治療群と対照群の差として表現される (Chapter 3.3.1 参照)。この概念では、「効果量」とは、ある治療の効果とその大きさを指す。私たち、これはかなり狭い定義であると考えている。治療が何らかの変数に影響を与えるだけでなく、人間が直接介入しなくても、効果は自然に現れることもある。例えば、親の収入や親の教育などの社会人口統計学的変数が、その子どもの教育達成度に影響を与える可能性がある。相関は、ある変数の値から別の変数の値をどれだけ予測できるかを記述し、効果量の一形態として見ることもできる。逆に、メタ分析としてプールできるものはすべて自動的に効果量になる、というのは行き過ぎかもしれない。これから学ぶように、サンプル平均のような中心傾向 (central tendency) の指標はメタ分析に用いることが可能だが、これだけでは 2 つの現象の関係を定量化することはできず、「効果」は存在しない。とはいえ、本書では、実際の効果の推定値だけでなく、「一変数」や「中心傾向」の指標も表す、全体を代表する部分 (pars pro toto) として、「効果量」という言葉をよく使う。これは正確だからではなく、その方が便利だからである。「効果量」という言葉を全面的に否定する人もいる。その主張は、「効果量」の「効果」という言葉が、因果関係を示唆していると強調しているためである。しかし、私たちは皆、相関は因果関係ではないことを知っており、介入群と対照群の差が自動的に治療そのものを原因とするものであってはならない。最終的にどちらの定義を好むかは使う人次第であるが、効果量について話すとき、人々は異なる概念を持っているかもしれないことを意識する必要がある。数学の表記法では、真の効果量を表す記号としてギリシャ文字のシータ (\\(\\theta\\)) を用いるのが一般的である8。より正確には、 \\(\\theta_k\\) は研究 \\(k\\) の真の効果量を表している。真の効果量は、公表された研究アウトカムに見られる観察された効果量と同一ではないという点は重要である。観測された効果量は、真の効果量の推定値に過ぎない。私たちが言及する実体が推定値に過ぎないことを明確にするために、ハット (^) の記号を使用するのが一般的である。したがって、真の効果量の推定値である \\(k\\) 試験で観測された効果量は、\\(\\hat\\theta_k\\) (「シータ・ハット・k」と読む) と書くことが可能となる。しかし、なぜ \\(\\hat\\theta_k\\) と \\(\\theta_k\\) は異なるのだろうか？それは、サンプル誤差のためで、 \\(\\epsilon_k\\) (「イプシロン・k」と読む) として記号化できる。どのような一次調査でも、研究者は母集団全体から小さなサンプルしか抽出することができない。例えば、プライマリケア患者の心臓血管の健康に対する定期的な運動の効果を調べたい場合、世界中のプライマリケア患者すべてではなく、ごく一部の患者を対象とすることが可能である。無限に大きな母集団から小さなサンプルしか取れないということは、観察された効果が真の母集団効果とは異なることを意味する。つまり、 \\(\\hat\\theta_k\\) は \\(\\theta_k\\) にサンプル誤差 \\(\\epsilon_k\\) を加えたものと同じになる9。\\[\\begin{align}\n\\hat\\theta_k = \\theta_k + \\epsilon_k\n\\tag{3.1}\n\\end{align}\\]研究 \\(k\\) の効果量推定値 \\(\\hat\\theta_k\\) が真の効果量にできるだけ近く、かつ \\(\\epsilon_k\\) が最小であることが望ましいのは明らかである。すべての条件が同じであれば、\\(\\epsilon\\) が小さい研究ほど、真の効果量の正確な推定値を提供すると考えることが可能である。メタ分析の手法では、効果量の推定値の精度を考慮する (Chapter 4 参照)。異なる研究の結果をプールする場合、精度が高い (サンプル誤差が少ない) 効果ほど、真の効果量の推定精度が高いため、高いウェイトを与える (L. Hedges Olkin 2014)。しかし、サンプル誤差の大きさはどのようにして知ることができるのだろうか。当然のことながら、研究の真の効果は \\(\\theta_k\\) なので、\\(\\epsilon_k\\) も不明である。しかし、多くの場合、統計理論を使ってサンプル誤差を近似的に求めることが可能である。一般に、\\(\\epsilon\\) を定量化する方法として、標準誤差 (\\(SE\\)) がある。標準誤差は、サンプル分布の標準偏差として定義される。サンプル分布とは、母集団から同じサンプルサイズ \\(n\\) のサンプルを多数回無作為に抽出したときに得られる指標の分布のことである。R でデータをシミュレートすることによって、これをより具体的に見てみよう。rnorm 関数を使って、より大きな母集団から無作為にサンプルを抽出しているようにしてみたい。この関数名は、正規 (normal) 分布から 無作為 (random) サンプルを作成することからきている。rnorm 関数は、真の母集団で値がどのように分布しているかを知っているという「完璧な世界」をシミュレートし、サンプルを取ることを可能にする。この関数は、以下の3つの引数を取る。すなわち、n: サンプルとして取得したい観測数、 mean: 母集団の真の平均値、 sd: 真の標準偏差である。rnorm 関数は乱数要素を持っているので、結果を再現するために、まず seed を設定する必要がある。これは set.seed 関数で行うことができるが、数値を指定する必要がある。この例では、123 を seed に設定する。さらに、母集団の真の平均は \\(\\mu =\\) 10、真の標準偏差は \\(\\sigma =\\) 2、サンプルは \\(n=\\) 50のランダムに選んだ観測からなり、これを sample という名前で保存するシミュレーションをしたい。このようなコードになる。さて、サンプルの平均を計算することが可能である。平均は \\(\\bar{x} =\\) 10.07 であり、すでに母集団における真の値に非常に近いことがわかる。ここでやったことを繰り返すと、サンプル分布ができあがる。このプロセスをシミュレートするために、先ほどのステップを 1000 回実行する。その結果を Figure 3.1 のヒストグラムに示す。サンプルの平均は、平均が 10 の正規分布に近いことがわかる。さらに多くのサンプルを抽出すれば、平均の分布はさらに正規分布に近くなる。この考え方は、統計学の最も基本的な考え方の1つである「中心極限定理」(central limit theorem) で表現されている (Aronow Miller 2019, chap. 3.2.4)。\nFigure 3.1: 平均値の「サンプル分布」 (1000 件のサンプル)。\n標準誤差はこのサンプル分布の標準偏差と定義される。そこで、標準誤差の近似値を得るために、1000 個の模擬平均の標準偏差を計算しておいた。その結果、\\(SE =\\) 0.267 となる。前にも述べたように、現実世界ではサンプル分布をシミュレーションして標準誤差を計算することはできない。しかし、統計理論に基づいた公式があるので、観測されたサンプルが1つしかない (通常の) 場合でも、標準誤差の推定値を計算することが可能である)。平均値の標準誤差を計算する公式は次のように定義されている。\\[\\begin{align}\nSE = \\frac{s}{\\sqrt{n}}\n\\tag{3.2}\n\\end{align}\\]つまり、サンプル \\(s\\) の標準偏差をサンプルサイズ \\(n\\) の平方根で割ったものを標準誤差と定義している。この式を使って、 R を使う前に作った sample オブジェクトの標準誤差を簡単に計算することが可能である。ランダムサンプルのサイズは \\(n =\\) 50 であったことを思い出す。この値をサンプル分布のシミュレーションで求めた値と比較すると、ほぼ同じであることがわかる。この公式を使えば、手持ちのサンプルだけで、かなり正確に標準誤差を推定することができるのである。式 3.2 から、平均値の標準誤差は研究のサンプルサイズに依存することがわかる。\\(n\\) が大きくなると標準誤差は小さくなり、真の母平均の推定値がより正確になることを意味している。この関係を説明するために、別のシミュレーションを行おう。ここでも、rnorm 関数を使用し、母集団の平均を \\(\\mu =\\) 10、\\(\\sigma =\\) 2 とする。しかし、今回は、\\(n =\\) 2 から \\(n =\\) 500 まで、サンプルサイズを変化させる。各シミュレーションについて、式 3.2 を用いて、平均と標準誤差を計算する。\nFigure 3.2: サンプルサイズの関数としてのサンプル平均とサンプル誤差。\nその結果を Figure 3.2 に示す。サンプルサイズが大きくなるにつれて、平均値の推定値はどんどん正確になっていき、10 に向かって収束していく。この精度の向上は標準誤差で表される。サンプルサイズが大きくなると、標準誤差はどんどん小さくなっていく。ここまで、メタ分析を行うために必要な要素、すなわち、(１) 観察された効果量またはアウトカム指標、および (２) 標準誤差として表されるその精度について探ってきた。発表された研究からこの2つの情報を算出することができれば、通常はメタ分析合成を行うことも可能である (Chapter 4 参照)。このシミュレーションでは、例として変数の平均を使用した。上で見た特性は、よく使われる効果量など、他のアウトカム指標でも見られることを理解することが重要である。もし、平均ではなく、サンプルの平均差を計算したとすると、この平均差は、同じような形のサンプル分布を示し、平均差の標準誤差もサンプルサイズが大きくなると小さくなる (標準偏差が同じであることが条件)。例えば、(Fisher’s \\(z\\) 変換された) 相関関係についても同様である。以下の節では、メタ分析で最も一般的に使用される効果量とアウトカム指標について説明する。これらの効果量測定がよく使われる理由の1つは、本章の最初に定義した2つの基準、すなわち、信頼できる、計算できるを満たしているからである。式 3.2 で平均値の標準誤差を計算する方法を説明したが、この式は平均値にのみ容易に適用することができる。他の効果量やアウトカム指標では、標準誤差を計算するための公式が異なる。ここで取り上げる効果量の測定基準については、幸いにも公式が存在するので、それらをすべて紹介していこう。公式のコレクションは、Appendixでも見ることが可能である。公式の中にはやや複雑なものもあるが、標準誤差を手動で計算する必要はほとんどない。 R は、この大変な計算を代行してくれる様々な関数がある。以下の節では、様々な効果量の測定基準についての理論的な議論を提供するだけではない。後で使用する R メタ分析関数が効果量を簡単に計算できるように、データセットにどのような情報を用意しなければならないかも紹介する。研究デザインの種類ごとに、通常現れる効果量をグループ分けしよう。すなわち、単群デザイン (例: 自然主義研究、調査、非対照試験)、対照群デザイン (例: 実験研究、対照臨床試験) である。これはあくまで大まかな分類であり、厳密なルールではないことに注意したい。ここで提示する効果量の多くは、アウトカムデータの種類が適切であれば、技術的にはどのようなタイプの研究デザインにも適用可能である。","code":"\nset.seed(123)\nsample <- rnorm(n = 50, mean = 10, sd = 2)\nmean(sample)## [1] 10.06881\nsd(sample)/sqrt(50)## [1] 0.2618756## Warning: Using `size` aesthetic for lines was deprecated in\n## ggplot2 3.4.0.\n## ℹ Please use `linewidth` instead.\n## This warning is displayed once every 8 hours.\n## Call `lifecycle::last_lifecycle_warnings()` to see\n## where this warning was generated."},{"path":"effects.html","id":"single-group-es","chapter":"3 効果量","heading":"3.2 単群デザインにおける測定値と効果量","text":"","code":""},{"path":"effects.html","id":"means","chapter":"3 効果量","heading":"3.2.1 平均値","text":"算術平均は、おそらく最もよく使われる中心傾向の尺度である。平均がアウトカム指標として使われることはあまりないが、メタ分析では簡単にプールすることが可能である。例えば、男性の平均身長をセンチメートルやインチで表現し、いくつかの代表的な研究をプールして調査することが可能である。算術平均は、サンプル中の個々の値 \\(x_i\\) をすべて合計し、その合計をサンプルサイズで割ったものである。\\[\\begin{equation}\n\\bar{x} = \\frac{\\sum^{n}_{=1}x_i}{n}\n\\tag{3.3}\n\\end{equation}\\]平均の標準誤差の求め方は、すでに説明した (Chapter 3.1 参照)。サンプルの標準偏差 \\(s\\) をサンプルサイズの平方根で割ればいいだけである。\\[\\begin{equation}\nSE_{\\bar{x}} = \\frac{s}{\\sqrt{n}}\n\\tag{3.4}\n\\end{equation}\\]先に見たように、 R では平均とその標準誤差を簡単に計算することが可能である。平均値のメタ分析を行うには、データセットに少なくとも以下の列が含まれている必要がある。n. 研究の観測数 (サンプルサイズ)。mean. 研究で報告された平均値。sd. 研究で報告された変数の標準偏差。","code":"\n# 再現性のために123のシードを設定する\n# そして、無作為にサンプルを取る (n=50)\nset.seed(123)\nsample <- rnorm(n = 50, mean = 20, sd = 5)\n\n# 平均値を計算する\nmean(sample)## [1] 20.17202\n# 標準誤差を計算する\nsd(sample)/sqrt(50)## [1] 0.6546889"},{"path":"effects.html","id":"props","chapter":"3 効果量","heading":"3.2.2 割合","text":"割合 (proportion) もまた、中心傾向の測定方法である。割合は、サンプルのうち何件が特定のサブグループに分類されるかを指定する。割合は、0 から 1 の値を取ることができ、100 を掛けることでパーセントに変換することができる。割合は、例えば、ある時点の病気の有病率を調べたいときに、アウトカム指標として使われることがある。割合 \\(p\\) を計算するためには、特定のサブグループに属する個人の数 \\(k\\) を全サンプルサイズ \\(n\\) で割る必要がある。\\[\\begin{equation}\np = \\frac{k}{n}\n\\tag{3.5}\n\\end{equation}\\]割合の標準誤差は、以下のように計算することができる。\\[\\begin{equation}\nSE_{p} = \\sqrt{\\frac{p(1-p)}{n}}\n\\tag{3.6}\n\\end{equation}\\]以下のコードを使って、 R の割合とその標準誤差を計算することが可能である。\n割合の範囲が 0 と 1 の間に制限されていることが問題になることがある (Lipsey Wilson 2001, chap. 3)。\\(p\\) が 0 または 1 に近いと、標準誤差が人為的に圧縮され、割合の推定値の精度が過大評価されることになる。これは、サンプル分布と関係がある。\\(p\\) の値が非常に小さいか大きい場合、サンプル分布は Figure 3.1 のような正規分布になることはほとんどない。0-1 の範囲外の計算された割合を持つランダムなサンプルは不可能であるため、分布は右側に裾が伸びる (right-skewed) か、または左側に裾が伸びる (left-skewed)。これを避けるために、割合をプールする前に logit 変換するのが一般的である。logit 変換では、まずオッズを計算する (Chapter 3.3.2.2 参照)。オッズは、特定のカテゴリーに該当する参加者の割合を、そのカテゴリーに該当しない参加者の割合で割ったものとして定義される。そして、自然対数関数 \\(\\log_e\\) を使って、オッズを \\(p=\\) 0.5 が値 0 に等しく、かつ範囲制限のない形式に変換している。これにより、サンプル分布がほぼ正規分布となり、標準誤差にバイアスがないことが確認できる。logit 変換された割合とその標準誤差は以下の式で計算できる (Lipsey Wilson 2001, chap. 3)10:\\[\\begin{equation}\np_{\\text{logit}} = \\log_{e} \\left(\\frac{p}{1-p}\\right)\n\\tag{3.7}\n\\end{equation}\\]\\[\\begin{equation}\nSE_{p_{\\text{logit}}} = \\sqrt{\\frac{1}{np}+\\frac{1}{n(1-p)}}\n\\tag{3.8}\n\\end{equation}\\]幸い、 R のメタ分析機能を使えば、この logit 変換を自動的に行ってくれる。そのため、データセットには以下の列を用意するだけでよい。event. 特定のサブグループ (\\(k\\)) に含まれる観測数。n. サンプルサイズの合計 \\(n\\)。","code":"\n# k と n に以下の値を定義する。\nk <- 25\nn <- 125\n\n# 割合を計算する\np <- k/n\np## [1] 0.2\n# 標準誤差を計算する\nsqrt((p*(1-p))/n)## [1] 0.03577709"},{"path":"effects.html","id":"cors","chapter":"3 効果量","heading":"3.2.3 相関関係","text":"","code":""},{"path":"effects.html","id":"pearson-cors","chapter":"3 効果量","heading":"3.2.3.1 ピアソン積率相関","text":"\n相関とは、2つの変数間の共分散の大きさを表す効果量である。最も一般的なのは、2つの連続変数に対して計算できるピアソン積率相関 (Pearson Product-Moment Correlation)11であり、この積率相関は、例えば、メタ分析の研究者が2つの変数の間の共分散の量を表す効果量として用いることが可能である。積率相関は、例えば、メタ分析で関係の質と幸福度の関係を調べたいときに、効果量として使うことができる。変数 \\(x\\) と変数 \\(y\\) の相関 \\(r_{xy}\\) は、\\(x\\) と \\(y\\) の 共分散 \\(\\text{Cov}(x,y)=\\sigma^{2}_{xy}\\) を、それらの標準偏差\\(\\sigma_x\\) と \\(\\sigma_y\\) の積 で割ったもので定義される。\\[\\begin{equation}\nr_{xy} = \\frac{\\sigma^{2}_{xy}}{\\sigma_x \\sigma_y}\n\\tag{3.9}\n\\end{equation}\\]サンプルサイズ \\(n\\) を用いると、\\(r_{xy}\\) の標準誤差は次のように計算できる。\\[\\begin{equation}\nSE_{r_{xy}} = \\frac{1-r_{xy}^2}{\\sqrt{n-2}}\n\\tag{3.10}\n\\end{equation}\\]積率相関を計算するとき、2つの変数の間の共変動をそれらの標準偏差で標準化する。つまり、2つ以上の研究が同じ尺度で構成要素を測定していれば、あまり意味がなく、相関を計算すれば、自動的に効果を比較することが可能になる。相関は -1 ～ 1 の値をとる。相関の大きさは、しばしば Cohen (1988) の慣例を用いて解釈される。\\(r \\approx\\) 0.10: 小さい効果。\\(r \\approx\\) 0.30: 中程度の効果。\\(r \\approx\\) 0.50: 大きい効果。しかし、これらの慣例はあくまで経験則であることに留意すべきである。対象や先行研究に応じて、相関の大小を定量化する方がはるかに良い場合が多いのである。\n残念ながら、相関は割合 (Chapter 3.2.2) と同様に範囲が限定されており、サンプルサイズの小さい研究に対して標準誤差を推定する際にバイアスをもたらす可能性がある (Alexander, Scozzaro, Borodkin 1989)。そのため、メタ分析では相関を Fisher’s \\(z\\)12 に変換することが一般的である。これも logit 変換と同様に、サンプル分布がほぼ正規分布になるように自然対数関数を用いる (詳しい説明は、Chapter 3.3.2 を参照)。式は次のようになる。\\[\\begin{equation}\nz = 0.5\\log_{e}\\left(\\frac{1+r}{1-r}\\right)\n\\tag{3.11}\n\\end{equation}\\]サンプルサイズ \\(n\\) がわかれば、Fisher’s \\(z\\) の近似標準誤差はこの式で求めることができる (Olkin Finn 1995)。\\[\\begin{equation}\nSE_{z} = \\frac{1}{\\sqrt{n-3}}\n\\tag{3.12}\n\\end{equation}\\]また、 R では cor と log 関数を用いて \\(r_{xy}\\) と \\(z\\) を直接計算することが可能である。ありがたいことに、 R の相関のメタ分析を行う際に、Fisher’s \\(z\\) 変換を手動で行う必要はない。データセットに必要な列は以下の通りである。cor. ある研究の (変換されていない) 相関係数。n. 研究のサンプルサイズ。","code":"\n# 2 つの連続変数 x と y をシミュレート\nset.seed(12345)\nx <- rnorm(20, 50, 10)\ny <- rnorm(20, 10, 3)\n\n# x と y の相関を計算する\nr <- cor(x,y)\nr## [1] 0.2840509\n# Fisher's z を計算する\nz <- 0.5*log((1+r)/(1-r))\nz## [1] 0.2920831"},{"path":"effects.html","id":"pb-cors","chapter":"3 効果量","heading":"3.2.3.2 点双列相関","text":"\nピアソン積率相関は、2つの連続変数間の関係を記述する。一方の変数 \\(y\\) だけが連続的で、もう一方の変数 \\(x\\) が二値的 (つまり、2つの値だけをとる) な場合、\\(x\\) の因子の割合と因子ごとの \\(y\\) 平均値から、\\(y\\) がどれだけ予測できるかを表す点双列相関 (point-biserial correlation) を計算することができる。点双列相関は、以下の式で計算できる。\\[\\begin{equation}\n{r_{pb}}= \\frac{(\\bar{y_1}-\\bar{y_2})\\sqrt{p_1(1-p_1)}}{s_y}\n\\tag{3.13}\n\\end{equation}\\]この式で、\\(\\bar{y_1}\\) は二項変数 \\(x\\) の第1群のみを考えたときの連続変数の平均、\\(\\bar{y_2}\\) は \\(x\\) の第2群のみを考えたときの平均、\\(p_1\\) は \\(x\\) の第1群に該当する症例の割合、\\(s_y\\) は \\(y\\) の標準偏差とする。点双列相関は、 R で cor 関数を使って計算することができる (前節を参照)。与えられた変数の1つが2つの値しかとらず、もう1つが連続的である場合、(近似的な) 点双列相関が自動的に計算される。点双列相関は、後述する標準化平均差とよく似ている (Chapter 3.3.1.2)。どちらの効果量指標も、連続変数の値が 2 群間でどれだけ異なるかを定量化するものである。しかし、点双列相関がメタ分析でプールされることはあまり一般的ではない。積率相関と同様に、点双列相関は、群比率が同じでない場合に範囲制限を受けるなど、メタ分析には好ましくない統計的性質を持っている (Bonett 2020)。連続的なアウトカム変数の群間差に興味がある場合、メタ分析のために点双列相関を標準化平均差に変換することが推奨される (Lipsey Wilson 2001, chap. 3)。点双列相関を標準化平均差に変換する公式は、本書の「各種ツール」の Chapter 17.3 に掲載されている。","code":""},{"path":"effects.html","id":"対照群デザインにおける効果量","chapter":"3 効果量","heading":"3.3 対照群デザインにおける効果量","text":"","code":""},{"path":"effects.html","id":"s-md","chapter":"3 効果量","heading":"3.3.1 (標準化) 平均差","text":"","code":""},{"path":"effects.html","id":"b-group-md","chapter":"3 効果量","heading":"3.3.1.1 群間平均差","text":"群間平均差 (group mean difference) \\(\\text{MD}_{\\text{}}\\) は、2つの 独立した 群間の平均の未標準化の差として定義される。群間平均差は、対照試験や他のタイプの実験的研究で通常見られるように、研究が少なくとも2つの群を含んでいる場合に計算することが可能である。メタ分析では、すべての研究が全く同じ尺度でアウトカムを測定した場合のみ、平均値を使用することが可能である。例えば、体重は科学研究においてほぼ常にキログラムで測定され、糖尿病学では、HbA\\(_{\\text{1c}}\\)値が血糖値の測定に一般的に使用される。平均差は、グループ1の平均値 \\(\\bar{x}_1\\) からグループ2の平均値 \\(\\bar{x}_2\\) を引いた値と定義される。\\[\\begin{equation}\n\\text{MD}_{\\text{}} = \\bar{x}_1 - \\bar{x}_2\n\\tag{3.14}\n\\end{equation}\\]標準誤差は、この式で求めることができる。\\[\\begin{equation}\nSE_{\\text{MD}_{\\text{}}} = s_{\\text{pooled}}\\sqrt{\\frac{1}{n_1}+\\frac{1}{n_2}}\n\\tag{3.15}\n\\end{equation}\\]式中、\\(n_1\\) はグループ 1 のサンプルサイズ、\\(n_2\\) はグループ 2 のサンプルサイズ、\\(s_{\\text{pooled}}\\) は両群のプール標準偏差 (pooled standard deviation) であることを表している。グループ 1 の標準偏差 (\\(s_1\\)) とグループ 2 の標準偏差 (\\(s_2\\)) を用いて、\\(s_{\\text{pooled}}\\) の値は以下のように計算することができる。\\[\\begin{align}\ns_{\\text{pooled}} = \\sqrt{\\frac{(n_1-1)s^2_1+(n_2-1)s^2_2}{(n_1-1)+(n_2-1)}}\n\\tag{3.16}\n\\end{align}\\]ここでは、R で平均差とその標準誤差を計算する例を示す。まず初めに、データをシミュレートしよう。これは、実行可能な値を得るためにのみ行う。実際のメタ分析においては、x1 と x2 の平均値およびその標準偏差 s1 と s2 は、出版された論文から抽出できるであろうし、各群のサンプルサイズ n1 と n2 も同様である。このため、ここで示すものはそれほど重要ではない。このデータを使って、平均差とその標準誤差を、以前の式を使って計算していきたい。通常、これらの計算をここで示したように手作業で行う必要はない。平均値の差のメタ分析では、データセットに以下の列を用意するだけでよい。n.e. 介入・実験群の観測数。mean.e. 介入・実験群の平均値。sd.e. 介入・実験群の標準偏差。n.c. 対照群の観測数。mean.c. 対照群の平均値。sd.c. 対照群の標準偏差。","code":"\n# 母平均が異なる2つの確率変数を生成する\nset.seed(123)\nx1 <- rnorm(n = 20, mean = 10, sd = 3)\nx2 <- rnorm(n = 20, mean = 15, sd = 3)\n\n# 数式に必要な値を計算する\ns1 <- sd(x1)\ns2 <- sd(x2)\nn1 <- 20\nn2 <- 20\n# 差の平均を計算する\nMD <- mean(x1) - mean(x2)\nMD## [1] -4.421357\n# s_pooled を計算する\ns_pooled <- sqrt(\n  (((n1-1)*s1^2) + ((n2-1)*s2^2))/\n    ((n1-1)+(n2-1))\n)\n\n# 標準誤差を計算する\nse <- s_pooled*sqrt((1/n1)+(1/n2))\nse## [1] 0.8577262"},{"path":"effects.html","id":"b-group-smd","chapter":"3 効果量","heading":"3.3.1.2 群間標準化平均差","text":"\n群間の標準化平均差 (standardized mean difference, SMD) \\(\\text{SMD}_{\\text{}}\\) は、プールした標準偏差 \\(s_{\\text{pooled}}\\) で標準化した、独立した2群間の平均値の差と定義される。文献では、標準化平均差は、心理学者で統計学者の Jacob Cohen にちなんで命名された Cohen’s \\(d\\) とも呼ばれる。標準化されていない平均差とは対照的に、\\(\\text{SMD}_{\\text{}}\\) は2群間の差を標準偏差の単位で表現する。これは、2つのグループの生の平均差 \\(\\bar{x_1}\\) と \\(\\bar{x_2}\\) を、両グループのプール標準偏差 \\(s_{\\text{pooled}}\\) で割ることにより実現できる。\\[\\begin{equation}\n\\text{SMD}_{\\text{}} = \\frac{\\bar{x}_1 - \\bar{x}_2}{s_{\\text{pooled}}}\n\\tag{3.17}\n\\end{equation}\\]ここで、\\(s_{\\text{pooled}}\\) は、既に取り上げた式 (3.16) を用いて計算する。メタ分析では標準化平均差の方が非標準化平均差よりもずっとよく使われる。これは、\\(\\text{SMD}_{\\text{}}\\) が研究間で比較できるためで、それぞれの研究が同じ測定器を使ってアウトカムを測定していなかったとしても、比較することが可能になる。標準化によって、\\(\\text{SMD}_{\\text{}}=\\) 1 は常に2群の平均が互いに 1 サンプル標準偏差離れていることを意味し (Figure 3.3 参照)、\\(\\text{SMD}_{\\text{}}=\\) 2 は2標準偏差の差を表す、という効果がある13。\nFigure 3.3: 標準化平均差が1 (正規性、標準偏差が等しく、両群のサンプルサイズが等しいと仮定した場合)。\n標準化することで、平均値の差の大きさを評価することが非常に容易になる。標準化された平均値の差は、Cohen (1988) による慣例を用いて解釈されることが多い。SMD \\(\\approx\\) 0.20: 小さい効果。SMD \\(\\approx\\) 0.50: 中程度の効果。SMD \\(\\approx\\) 0.80: 大きい効果。ピアソン積率相関と同様 (Chapter 3.2.3.1)、経験則に過ぎない。通常、標準化された平均値の差は、その「現実的な」意味合いに基づいて解釈する方がずっと良いのである。効果量は Cohen の基準では小さいかもしれないが、それでも非常に重要である可能性がある。例えば、多くの深刻な病気では、統計的な効果が非常に小さくても、集団レベルでは大きな影響を与え、何百万人もの命を救う可能性があるのである。ある研究では、うつ病の治療において、\\(\\text{SMD}_{\\text{}}=\\) 0.24 のような小さな効果でさえ、患者の命に臨床的に重要な影響を与えることができることが示された (Pim Cuijpers et al. 2014)。この式を使って\\(\\text{SMD}_{\\text{}}\\) の標準誤差を計算することができる (Borenstein et al. 2011)。\\[\\begin{equation}\nSE_{\\text{SMD}_{\\text{}}} = \\sqrt{\\frac{n_1+n_2}{n_1n_2} + \\frac{\\text{SMD}^2_{\\text{}}}{2(n_1+n_2)}}\n\\tag{3.18}\n\\end{equation}\\]ここで、\\(n_1\\) と \\(n_2\\) はグループ 1 とグループ 2 のサンプルサイズであり、\\(\\text{SMD}_{\\text{}}\\) は計算された群間標準化平均差である。R には、\\(\\text{SMD}_{\\text{}}\\) /Cohen’s \\(d\\) を一度に計算できる関数がいくつかある。ここでは、{esc} パッケージ (Lüdecke 2019) に含まれる esc_mean_sd 関数を使用する。このパッケージは今まで使用したことがないので、まずインストールする必要がある (Chapter 2.2 参照)。この出力では、言及すべきことが2つある。まず、計算された標準化平均の差がちょうど 1 であることがわかる。これは、私たちが定義した 2 つの平均の差が (プールされた) 標準偏差と等しいので、理にかなっている。次に、効果量がマイナスであることがわかる。これは、グループ 2 の平均がグループ 1 の平均より大きいからである。これは数学的には正しいのであるが、他の人がより簡単に解釈できるように、計算された効果量の符号を変えなければならないことがある。この例のデータは、介入 (group 1) または介入なし (group 2) を受けた後、人々が1週間に吸うタバコの平均本数を測定した研究から得られたと想像する。この文脈では、介入群では平均喫煙本数が少なかったので、研究結果は肯定的であったとする。したがって、効果量を -1.0 ではなく 1.0 と報告することは理にかなっており、他の人が直感的に介入には正の効果があったと理解できるようになる。効果量の符号が特に重要になるのは、ある研究では高い値が良いアウトカムを意味し、他の研究では低い値が良いアウトカムを意味する尺度を用いた場合である。この場合、すべての効果量が一貫して同じ方向にコード化されていることが不可欠である (例えば、メタ分析のすべての研究で、効果量が大きいほど介入群における転帰が良いことを意味することを確認する必要がある)。多くの場合、標準化平均差に対して小サンプル補正を行い、Hedges’ \\(g\\) と呼ばれる効果量になる。この補正については、Chapter 3.4.1 で取り上げる。標準化平均差のメタ分析を行うには、データセットに少なくとも以下の列が含まれている必要がある。n.e. 介入・実験群の観測数。mean.e. 介入・実験群の平均値。sd.e. 介入・実験群の標準偏差。n.c. 対照群の観測数。mean.c. 対照群の平均値。sd.c. 対照群の標準偏差。標準偏差の外部推定値による標準化SMD を計算するとき、\\(s_{\\text{pooled}}\\) を使うのは、それが母集団における真の標準偏差の代理として機能するからである。しかし、特に研究の規模が小さい場合、サンプルに基づいて計算された標準偏差は、母集団の標準偏差の推定値としては不適切な場合がある。この場合、可能な解決策は、平均差を標準化するために \\(s_{\\text{pooled}}\\) の外部推定値を使用することである (Julian Higgins et al. 2019)。このような外部推定値は、類似の集団でこの研究と同じ測定器を使用した大規模な横断研究から抽出されるかもしれない。","code":"\n# esc パッケージのロード\nlibrary(esc)\n\n# SMD/d を計算するために必要なデータを定義する。\n# 医かは、例として作ったダミーデータ\ngrp1m <- 50   # group 1 の平均値\ngrp2m <- 60   # group 2 の平均値\ngrp1sd <- 10  # group 1 の標準偏差\ngrp2sd <- 10  # group 2 の標準偏差\ngrp1n <- 100  # group1 のサンプルサイズ\ngrp2n <- 100  # group2 のサンプルサイズ\n\n# 効果量を計算する\nesc_mean_sd(grp1m = grp1m, grp2m = grp2m, \n            grp1sd = grp1sd, grp2sd = grp2sd, \n            grp1n = grp1n, grp2n = grp2n)## Effect Size Calculation for Meta Analysis\n## \n##      Conversion: mean and sd to effect size d\n##     Effect Size:  -1.0000\n##  Standard Error:   0.1500\n##            [...]"},{"path":"effects.html","id":"w-group-smd","chapter":"3 効果量","heading":"3.3.1.3 群内 (標準化) 平均差","text":"群内の差を調べる場合、非標準化または標準化された平均差を計算することが可能である。これは通常、同じグループの人々が2つの異なる時点 (例えば、介入前と介入後) で測定される場合である。群間平均差とは異なり、\\(\\text{(S)MD}_{\\text{within}}\\)は独立ではないデータを用いて計算される。例えば、測定点 \\(t_1\\) での人物 \\(\\) の値が、測定点 \\(t_2\\) での同じ人物の値に影響を与えている可能性がある。群内平均差は、通常、異なる時点で測定されたデータに基づいていることから、** (標準化) 平均利得** ((standardized) mean gain)とも呼ばれる。群内平均差 \\(\\text{MD}_{\\text{within}}\\) は、同じ群の \\(t_1\\) と \\(t_2\\) の2つの時点の値を比較するようになった以外は、\\(\\text{MD}_{\\text{}}\\) と同じ方法 ( Chapter 3.3.1.1 参照) で計算される。\\[\\begin{equation}\n\\text{MD}_{\\text{within}} = \\bar{x}_{\\text{t}_2} - \\bar{x}_{\\text{t}_1}\n\\tag{3.19}\n\\end{equation}\\]群内平均差の標準化版を計算したい場合は、より複雑になる。\\(\\text{SMD}_{\\text{within}}\\) をどのように計算すべきかについて、完全なコンセンサスはない。ブログ記事で、Jake Westfall は少なくとも5つの異なる計算方法があることを指摘している。直感的なオプションは、両評価点のプールされた標準偏差 \\(s_{\\text{t}_1}\\) と \\(s_{\\text{t}_2}\\) を使って平均 \\(\\text{MD}_{\\text{within}}\\) を標準化することである。群内デザインでは観測点数が通常同じなので、2つの標準偏差の二乗の和を2で割って \\(s^2_{\\text{pooled}}\\) を求めればよいことになる。そうでない場合は、Chapter 3.3.1.1 の式 (3.16) を使って \\(s_{\\text{pooled}}\\) を計算することが可能である。このことから、以下の式が導かれる。\\[\\begin{equation}\n\\text{SMD}_{\\text{within}} = \\frac{\\bar{x}_{\\text{t}_2} - \\bar{x}_{\\text{t}_1}}{s_{\\text{pooled}}}\n\\tag{3.20}\n\\end{equation}\\]Becker (1988) は、さらに良い解決策を提案した。すなわち、\\(\\text{MD}_{\\text{within}}\\) を介入前の得点の標準偏差 (\\(s_{\\text{t}_1}\\)) で割ることである。この理由は、\\(s_{\\text{t}_1}\\) の方が介入効果の影響を受けにくいことがある14。\\[\\begin{equation}\n\\text{SMD}_{\\text{within}} = \\frac{\\bar{x}_{\\text{t}_2} - \\bar{x}_{\\text{t}_1}}{s_{\\text{t}_1}}\n\\tag{3.21}\n\\end{equation}\\]また、\\(\\text{MD}_{\\text{within}}\\) と \\(\\text{SMD}_{\\text{within}}\\) の標準誤差はこれらの式を使って計算可能である (Borenstein et al. 2011, chap. 4; Becker 1988)。\\[\\begin{equation}\nSE_{\\text{MD}_{\\text{within}}}=\\sqrt{\\dfrac{s^2_{\\text{t}_1}+s^2_{\\text{t}_2}-(2r_{\\text{t}_1\\text{t}_2}s_{\\text{t}_1}s_{\\text{t}_2})}{n}}\n\\tag{3.22}\n\\end{equation}\\]\\[\\begin{equation}\nSE_{\\text{SMD}_{\\text{within}}} = \\sqrt{\\frac{2(1-r_{\\text{t}_1\\text{t}_2})}{n}+\\frac{\\text{SMD}^2_{\\text{within}}}{2n}}\n\\tag{3.23}\n\\end{equation}\\]群内 (標準化) 平均値の差の標準誤差を計算するために、評価点間の相関 \\(r_{\\text{t}_1\\text{t}_2}\\) が必要であることは、実際には問題となることが多い。変数の前後相関は発表された研究でほとんど報告されていないため、先行研究に基づいて \\(r_{\\text{t}_1\\text{t}_2}\\) の値を仮定せざるを得ない。しかし、相関を正確に把握しないと、結果に誤差が生じる可能性がある。一般的に、メタ分析で群内効果量を計算することは避けた方が良いと言われている (Pim Cuijpers et al. 2017)。特に、実験群と対照群の両方のデータがある場合は、前後比較ではなく、\\(t_2\\) における群間 (標準化) 平均差を計算して、治療の効果を測定する方がずっと良い。ただし、対照群を含まない研究のみにメタ分析を行う場合は、群内平均差を計算することが可能である。群内標準化平均差 (群内 (within-group) Cohen’s \\(d\\) とも呼ばれる) は R でこのように計算できる。群内 (標準化) 平均差のメタ分析は、 R では事前に計算された効果量を用いてのみ実行可能となる (Chapter 3.5.1 参照)。今回のデータセットでは、以下の列が必要である。TE: 算出された群内効果量。seTE: 群内効果量の標準誤差。標準化の限界標準化平均差は、間違いなくメタアナリシスで最も頻繁に使用される効果量の指標の1つである。Chapter 3.3.1.2 で述べたように、標準化により、少なくとも理論的には、異なる研究で観察された効果の強さを比較することができる。しかし、標準化は、「免罪符」ではない。ある研究の \\(\\text{SMD}\\) の大きさは、そのサンプルの多様性に大きく依存する (Viechtbauer 2007a も参照)。2 つの同じ研究を行い、アウトカムを測定するために同じ測定器を使用するが、この 2 つの研究は大幅に異なる分散を持つ 2 つの集団で行われたと想像してみよう。この場合、両研究の「生の」平均差が同じであっても、両研究の \\(\\text{SMD}\\) 値は大きく異なるであろう。この場合、一方の研究の効果の「因果」の強さが他方よりはるかに大きいか小さいかを論じることはやや困難である。Jacob Cohen (1994) が有名な論文でと述べたように、「私にとっての の B に対する効果は、私が大きく変動するグループにいるか[…]、まったく変動しない別のグループにいるかには、ほとんど依存しない」(p. 1001)。\nところで、この問題は、一般に使用されている「標準化された」メタアナリシスにおける効果量の測定、例えば相関関係にも当てはまる。さらに、標準化する単位は、思ったよりも明確に定義されていないことが多いことも見た。群間と群内の \\(\\text{SMD}\\)s には様々な選択肢があり、特定の研究でどのアプローチが選ばれたかを切り分けるのは難しい。メタ分析のための標準化効果量の計算方法については、常に研究間で可能な限り一貫性を保つことが必要である。それでも、たとえ標準化を行ったとしても、効果量の一致度には限界があることを心に留めておく必要がある。もちろん、アウトカムがすべての研究で結果が同じ尺度で測定され、生平均差が利用できれば、最高の解決策になるであろう。しかし、多くの研究分野では、そのような方法論的な調和からはほど遠いところにいるのが現状である。したがって、残念ながら、標準化効果量は、第二の最良の選択肢となることもある。","code":"\n# 効果量計算に必要なデータ例を定義\nx1 <- 20    # t1 における平均値\nx2 <- 30    # t2 における平均値\nsd1 <- 13   # t1 における標準偏差\nn <- 80     # サンプルサイズ\nr <- 0.5    # t1 と t2 の相関係数\n\n# 生の平均差を計算\nmd_within <- x2 - x1\n\n# smd を計算:\n# ここで、t1 における標準偏差\n# を使い、平均差を標準化する\nsmd_within <- md_within/sd1\nsmd_within## [1] 0.7692308\n# 標準誤差を計算\nse_within <- sqrt(((2*(1-r))/n) + \n              (smd_within^2/(2*n)))\nse_within## [1] 0.1272722"},{"path":"effects.html","id":"ratios","chapter":"3 効果量","heading":"3.3.2 リスク比とオッズ比","text":"","code":""},{"path":"effects.html","id":"rr","chapter":"3 効果量","heading":"3.3.2.1 リスク比","text":"リスク比 (別名: 相対リスク) とは、その名の通り、2つのリスクの比のことである。リスクとは基本的に割合 (proportion) のことである (Chapter 3.2.2 参照)。リスクは、バイナリ (二値) データを扱う場合に計算可能である。このようなアウトカムは、医学研究において、病気の発症や死亡のリスクを調べる場合によく見られるため、「割合」ではなく「リスク」という用語を使用する。このような事象は、イベントと呼ばれる。治療群と対照群からなる対照臨床試験を行っているとする。ここで興味があるのは、研究期間中に何人の患者があるイベント \\(E\\) を経験したかである。このような研究から得られる結果は、\\(2 \\times 2\\) の表に分類できる (Schwarzer, Carpenter, Rücker 2015, chap. 3.1)。\nTable 3.1: 二値アウトカムを用いた対照研究の結果。\nこのデータに基づいて、治療群と対照群の両方について、調査期間中にイベント \\(E\\) を経験するリスクを計算することが可能である。\\(E\\) を経験した人の数を、その群の総サンプルサイズで割ればよいのである。したがって、治療群のリスクである \\({p_{E}}_{\\text{treat}}\\) は、次のように計算される。\\[\\begin{equation}\n{p_{E}}_{\\text{treat}} = \\frac{}{+b} = \\frac{}{n_{\\text{treat}}}\n\\tag{3.24}\n\\end{equation}\\]そして、対照群のリスク、\\({p_{E}}_{\\text{control}}\\) は、以下のようになる。\\[\\begin{equation}\n{p_{E}}_{\\text{control}} = \\frac{c}{c+d} = \\frac{c}{n_{\\text{control}}}\n\\tag{3.25}\n\\end{equation}\\]そして、リスク比は、治療・介入群のリスクを対照群のリスクで割ったものと定義される。\\[\\begin{equation}\n\\text{RR} = \\frac{{p_{E}}_{\\text{treat}}}{{p_{E}}_{\\text{control}}}\n\\tag{3.26}\n\\end{equation}\\]\\({p_{E}}_{\\text{treat}}\\) と \\({p_{E}}_{\\text{control}}\\) はどちらも 0 と 1 の間の値しか持ち得ないので、RR はいくつかの興味深い性質を持っている。まず、リスク比が負になることはない。次に、治療群と対照群の間に差がない場合、RR は (SMD のように 0 ではなく) 1 という値になる。RR が 1 より大きければ、治療群がイベント \\(E\\) のリスクを増加させることを意味し、RR が 1 より小さければ、介入によってリスクが減少することを意味する。RR の特徴は、同じ大きさの効果は等価ではないということである。例えば、RR \\(=\\) 0.5 は、介入群でリスクが半分になることを意味する。これはリスク比が正規分布に従わないことを意味し、メタ分析では問題になることがある。この問題を避けるために、統合する前にリスク比を 対数リスク比 (log-risk ratio) に変換することもよくある。これにより、漸近正規性、効果量が任意の値になること、値が 0 (効果がないことを意味する) を中心になることが保証される。この変換は、RR の自然対数を取ることによって行われる。\\[\\begin{equation}\n\\log \\text{RR}  = \\log_{e}(\\text{RR})\n\\tag{3.27}\n\\end{equation}\\]そして、対数リスク比の標準誤差は、この式を用いて計算することができる。\\[\\begin{equation}\nSE_{\\log \\text{RR}} = \\sqrt{\\frac{1}{}+\\frac{1}{c} - \\frac{1}{+b} - \\frac{1}{c+d}}\n\\tag{3.28}\n\\end{equation}\\]R の (対数) リスク比はこのように計算することができる。\nゼロセルがあると、リスク比の計算が難しくなる。実際には、\\(\\) または \\(c\\) (あるいはその両方) がゼロであることがあり、これは治療群でも対照群でもイベントが記録されていないことを意味する。RRの計算式を見ると、なぜこれが問題なのかがよくわかる。\\(\\) (治療群のイベント) がゼロなら、\\({p_{E}}_{\\text{treat}}\\) もゼロで、RR はゼロになる。\\(c\\) がゼロの場合はさらに問題で、\\({p_{E}}_{\\text{control}}\\) がゼロということになり、ゼロで割れない ということがわかる。この問題は、連続性補正 (continuity correction) を用いて対処されることがよくある。最も一般的な連続性補正の方法は、ゼロになっている全てのセルに0.5の増分を加えることである (Gart Zweifel 1967) 。また、対照群と治療群のサンプルサイズが非常に不均等な場合は、治療群連続性補正 (Sweeting, Sutton, Lambert 2004) を用いることもできる。しかし、そのような補正は偏った結果につながるという証拠もある (Efthimiou 2018)。(固定効果) Mantel-Haenszel 法というメタ解析のプール手法は、メタ解析のすべての研究にゼロセルが存在しない限り、補正せずに扱うことが可能である。したがって、後者のシナリオに当てはまらない限り、連続性補正は避けた方がよいだろう。ゼロセル問題の特殊な形として、ダブルゼロスタディがある。これは、\\(\\) と \\(c\\) の両方がゼロである研究である。直感的には、このような研究の結果は、介入群と対照群のリスクが同程度であり、RR=1であることを意味していると考えるだろう。残念ながら、そう簡単ではない。2つのグループの間に本当の効果があるけれども、その差を検出するにはサンプルサイズが小さすぎたということは大いにあり得る。特に、\\(E\\) が発生する確率が非常に低い場合には、この可能性が高くなる。あるマッドサイエンティストが、雷に打たれる危険を減らすとされる薬、Fulguridone の効果を評価する無作為化比較試験を行ったとする。彼は100人を薬物投与群と対照群のどちらかに均等に割り振り、3年間観察した。試験の結果は、治療群でも対照群でも雷に打たれた人はいなかったので、残念な結果になった。しかし、私たちは、雷に打たれる可能性がどれほど低いか、一般的に知っている。たった100人の観察では、たとえ治療が効くという奇妙な考えを受け入れたとしても、このような稀な出来事における違いを検出するには十分ではない。このため、ダブルゼロ研究は、効果をプールする際に完全に捨てられることが多いのである。リスク比は、ある事象が一般的にどの程度よく起こるかという情報を与えてはくれないのである。メタ分析でリスク比が0.5と報告された場合、例えば、ある介入によってリスクが半分に減少したことがわかる。しかし、リスクが40%から20%に減少したかどうか、あるいは0.004%から0.002%に減少したかどうかはわからない。リスク比が実用的であるかどうかは、文脈に依存する。リスク比0.5が0.002%のリスク低下に相当する場合、集団レベルでは大きな影響を与えないかもしれないが、対象となる事象が例えば重症で衰弱する病気であれば、それでも重要である可能性がある。R でメタ分析を行う場合、通常、研究の対数リスク比を手作業で計算する必要はない。また、データをインポートする際にも、ゼロセルについて心配する必要はない。以下の列はデータセットに含まれている必要がある。event.e. 治療群・実験群におけるイベント数。n.e. 治療群・実験群のサンプルサイズ。event.c. 対照群におけるイベント数。n.c. 対照群のサンプルサイズ。","code":"\n# データを定義\na <- 46         # 治療群のイベント数\nc <- 77         # 対照群のイベント数\nn_treat <- 248  # 治療群のサンプルサイズ\nn_contr <- 251  # 対照群のサンプルサイズ\n\n# リスクを計算\np_treat <- a/n_treat\np_contr <- c/n_contr\n\n# リスク比を計算\nrr <- p_treat/p_contr\nrr## [1] 0.6046292\n# 対数リスク比と標準誤差を計算\nlog_rr <- log(rr)\nlog_rr## [1] -0.5031398\nse_log_rr <- sqrt((1/a) + (1/c) - (1/n_treat) - (1/n_contr))\nse_log_rr## [1] 0.1634314"},{"path":"effects.html","id":"or","chapter":"3 効果量","heading":"3.3.2.2 オッズ比","text":"\nリスク比 (Chapter 3.3.2.1) と同様に、オッズ比も2群2値のアウトカムデータがある場合に計算することが可能である。前回の割合の章 (Chapter 3.2.2) で、オッズを「あるカテゴリーに該当する個数を、そのカテゴリーに該当しない個数で割ったもの」と定義したが、今回は「あるカテゴリーに該当する個数を、そのカテゴリーに該当しない個数で割ったもの」と定義する。Table 3.1 の表記を使うと、治療群と対照群のオッズの計算式は次のようになる。\\[\\begin{equation}\n\\text{Odds}_{\\text{treat}} = \\frac{}{b}\n\\tag{3.29}\n\\end{equation}\\]\\[\\begin{equation}\n\\text{Odds}_{\\text{control}} = \\frac{c}{d}\n\\tag{3.30}\n\\end{equation}\\]オッズが実際に何を意味するのかを正しく解釈するのは難しいだろう。オッズは事象と非事象の比率を表すのであって、事象の 確率 を表すのではない。3人の個人を調査したとする。2人は興味のある事象を経験し、1人は経験しなかったとする。このデータから、その事象の確率 (またはリスク) は \\(p = 2/3 \\approx 66\\%\\) となる。しかし、事象の発生確率は、Odds = \\(\\frac{2}{1}\\) = 2となり、1人の非事象に対して2人の事象があることになる。そして、オッズ比 () は、治療群でのオッズを対照群でのオッズで割ったものと定義される。\\[\\begin{equation}\n\\text{} = \\frac{/b}{c/d}\n\\tag{3.31}\n\\end{equation}\\]リスク比と同様に (Chapter 3.3.2.1 参照)、オッズ比もメタ分析には好ましくない統計的性質を持っている。そのため、オッズ比を自然対数を使って対数オッズ比 (log-odds ratio) に変換することも一般的である。\\[\\begin{equation}\n\\log \\text{}  = \\log_{e}(\\text{})\n\\tag{3.32}\n\\end{equation}\\]対数オッズ比の標準誤差は、この式で計算できる (表記は Table 3.1 を使用する)。\\[\\begin{equation}\nSE_{\\log \\text{}}  = \\sqrt{\\frac{1}{}+\\frac{1}{b}+\\frac{1}{c}+\\frac{1}{d}}\n\\tag{3.33}\n\\end{equation}\\]{esc} パッケージの esc_2x2 関数は、 R における (対数) オッズ比を簡単に計算する方法を提供する。\nリスク比の問題点であるゼロセルやダブルゼロ研究はオッズ比を計算するときにも同じように関係する (Chapter 3.3.2.1 参照)。しかし、オッズ比は RR に比べて、多くの人が理解しにくく、を RR と誤って解釈してしまうという欠点がある。したがって、メタ分析ではリスク比のみを用いるか、結果を報告する際にオッズ比をリスク比に変換することが望ましい場合が多い (Julian Higgins et al. 2019, chap. 6.4.1.2)。この変換は以下の式で行うことが可能である (Zhang Yu 1998)。(訳注:臨床論文でこれを行なっていることはほとんどない。)\\[\\begin{equation}\n\\text{RR} = \\frac{\\text{}}{\\left(1-\\dfrac{c}{n_{\\text{control}}}\\right)+ \\left(\\dfrac{c}{n_{\\text{control}}}\\times \\text{} \\right)}\n\\tag{3.34}\n\\end{equation}\\]R のオッズ比のメタ分析を行うには、以下の列をデータセットに含める必要がある。event.e. 治療群・実験群におけるイベントの数。n.e. 治療群・実験群のサンプルサイズ。event.c. 対照群におけるイベントの数。n.c. 対照群のサンプルサイズ。","code":"\nlibrary(esc)\n\n# データを定義\ngrp1yes <- 45  # 治療群のイベント数\ngrp1no <- 98   # 治療群の非イベント数\ngrp2yes <- 67  # 対照群のイベント数\ngrp2no <- 76   # 対照群の非イベント数\n\n# es.type に \"or\" と設定し、OR を計算\nesc_2x2(grp1yes = grp1yes, grp1no = grp1no,\n        grp2yes = grp2yes, grp2no = grp2no,\n        es.type = \"or\")## \n## Effect Size Calculation for Meta Analysis\n## \n##      Conversion: 2x2 table (OR) coefficient to effect size odds ratio\n##     Effect Size:   0.5209\n##  Standard Error:   0.2460\n##        Variance:   0.0605\n##        Lower CI:   0.3216\n##        Upper CI:   0.8435\n##          Weight:  16.5263\n# es.type に \"logit\" と設定し、logOR を計算\nesc_2x2(grp1yes = grp1yes, grp1no = grp1no,\n              grp2yes = grp2yes, grp2no = grp2no,\n              es.type = \"logit\")## \n## Effect Size Calculation for Meta Analysis\n## \n##      Conversion: 2x2 table (OR) to effect size logits\n##     Effect Size:  -0.6523\n##  Standard Error:   0.2460\n##        Variance:   0.0605\n##        Lower CI:  -1.1344\n##        Upper CI:  -0.1701\n##          Weight:  16.5263"},{"path":"effects.html","id":"irr","chapter":"3 効果量","heading":"3.3.3 発生率比","text":"前に調べた二値アウトカムのデータに対する効果量、リスク比やオッズ比は、２つのグループのイベントの数を比較する方法である。しかし、これらのイベントが発生した時間は直接的には符号化されない。リスク比やオッズ比を計算するとき、両群の観察期間が同等であることを暗黙のうちに仮定している。さらに、リスク比とオッズ比は、イベントが発生するまでの時間に関する情報を提供しない。時間軸がリサーチクエスチョンにそれほど関係しない場合、これでよいだろう。また、二値データが横断的で時間軸が全くない場合もある15。このような場合、リスク比やオッズ比は通常、適切な効果量の指標となる。しかし、ここで、2つのグループの個人の10年間の死亡率を調べる研究を想像してみてみよう。この10年間に起こった出来事 (例えば、死亡) の数は、両群でほぼ同じである可能性がある。しかし、死亡がいつ起こったかを詳しく見てみると、一方の群では最初の数年間に多くのイベントが起こり、他方の群では10年間の観察期間の終わりまでやや多くのイベントが起こっていることがわかる。このデータから計算されるオッズまたはリスク比はおよそ1であり、群間差はないことを示す。しかし、これは重要なことを見逃している。一方のグループの参加者は、たとえ最終的に死亡したとしても、いくらか長く生存しているということである。\n効果量の推定に時間を組み込むために、発生率比 (incidence rate ratio, IRR) を計算することができる。発生率比は、英語では単に rate ratio と呼ばれることもある。発生率比は、2つの発生率から構成されている。この発生率を計算するためには、まず人-時間の概念を理解する必要がある。人-時間とは、研究参加者がイベントを起こす危険性があった時間の総和を表す。人-時間を計算するためには、すべての研究対象者のリスク時間 (日、週、年として表される) を合計する。しかし、リスク時間は人によって異なる。例として、6人の被験者で研究を行う場合を考えてみよう。この研究は、ちょうど10年間続く。各年が終わるごとに、参加者にインタビューを行い、彼らがあるイベントを経験したかどうかを調べる。イベントが発生したことが確認された場合、その参加者の研究は終了し、研究が終了するまでその参加者を調査することはない。本研究の結果を図に示す。\nFigure 3.4: 時間-イベントデータの例\n\n今回の参加者のうち、最後まで研究に参加したのは、Victoria と Lea の2人だけであることがわかる。これは、彼らが 10 年間の観察期間中、イベントを経験しなかったからである。したがって、両者とも 10 年間はアットリスク (訳注: リスクに曝されている状態、追跡中の状態のこと) であった。他の参加者は全員、調査期間中にイベントを体験している。例えば、2 年目に Rebecca を調査したとき、彼女がその前の年にイベントを経験したことを発見した。しかし、私たちが知っているのは、その出来事が2年目に起こったということだけで、正確にはいつ起こったかわからないのである。このような研究データは、区間打ち切りデータと呼ばれ、いわゆる生存解析を行う臨床試験で非常によく見受けられる。データが打ち切られているということは、レベッカが最終的にイベントを経験するまでにどれくらいの期間危険にさらされていたかを部分的にしか知らないということである。私たちは、彼女が1年目以降、2年目の終わりまでにイベントを経験したことを知っているが、それ以上のことは知ることはない。他の情報がないので、イベントが中間のどこかで発生したと仮定して、リスク時間を 1.5 年とすることにする。打ち切られたデータ全てに同じ方式を適用すれば、この研究における人-年のリスクを計算することができる。\\[10 + 1.5+5.5+4.5+8.5+10 = 40\\]\nすなわち、この研究での推定総人-年は40人年ということになる。1年は52週なので、この研究の人-週は \\(40 \\times 52 = 2080\\) と計算できる。実験参加者年数がわかったので、これを \\(T\\) とすると、1年以内の発生率も計算できる。調査期間中に4人の参加者がイベントを経験したことが分かっているので、イベントの数は \\(E=4\\) となる。そして、この式で発生率 IR を計算することができる。\\[\\begin{equation}\n\\text{IR} = \\frac{E}{T}\n\\tag{3.34}\n\\end{equation}\\]この例では、\\(4/40 = 0.1\\) の発生率になる。この発生率は、1000人を1年間追跡調査した場合、100人がその間にそのイベントを経験することを意味する。発生率比 (incidence rate ratio, IRR) を計算するためには、あるグループの発生率を他のグループの発生率で割る必要がある。\\[\\begin{equation}\n\\text{IRR} = \\frac{ E_{\\text{treat}}/T_{\\text{treat}} }{E_{\\text{control}}/T_{\\text{control}}}\n\\tag{3.35}\n\\end{equation}\\]この式で、\\(E_{\\text{treat}}\\) と \\(T_{\\text{treat}}\\) は治療群のイベント数と人時、\\(E_{\\text{control}}\\) と \\(T_{\\text{control}}\\) は対照群のイベント数と人時である。もちろん、2つのグループは、例えば、女性と男性、喫煙者と非喫煙者など、関心のある他の二項対立変数を表すこともできる。IRR は、リスク比やオッズ比と多くの特性を共有している。つまり、IRR は 1 を中心とし、マイナスになることはない。や RR と同様に、発生率比もメタ分析のために対数変換され、対数発生率比が作成される。\\[\\begin{equation}\n\\log \\text{IRR} = \\log_{e}(\\text{IRR})\n\\tag{3.36}\n\\end{equation}\\]これについては、次のように標準誤差を計算することが可能である (Rothman, Greenland, Lash 2008, chap. 14)。\\[\\begin{equation}\nSE_{\\log \\text{IRR}} = \\sqrt{\\frac{1}{E_{\\text{treat}}}+\\frac{1}{E_{\\text{control}}}}\n\\tag{3.37}\n\\end{equation}\\]このように (対数) 発生率比と R の標準誤差を計算することができる。この例では、イベント数 \\(E_{\\text{treat}}\\) と \\(E_{\\text{control}}\\) が全く等しいが、治療群の方がリスクでの人時時間が長い場合をシミュレーションしている。この時間差は、IRR を計算するときに考慮される。したがって、得られる結果は1ではなく、IRR \\(\\approx\\) 0.79 となり、治療群の方が発生率が小さいことがわかる。発生率比は、疫学や予防医学の研究でよく使われる。参加者を長期間にわたって追跡調査し、その間に定期的な評価を行う場合に使用することが可能である。しかし、実際には、メタ分析の一部として IRR を計算する際に考慮すべき注意点が1つある。すなわち、含まれる論文で報告された発生率データが十分に細かいことが重要である。論文では研究期間中のイベントの総数のみを報告し、その間の各評価ポイントで記録されたイベントの数は報告しないこともある。また、そもそも中間評価が行われていない可能性もある。上記の例 (Figure 3.4 参照) では、参加者の危険にさらされている時間を推定するために、単純に、最後の「イベントのない」評価点とイベントが記録された評価点との間の中間点を取ることにする。これは、イベントがいつ起こったかの最良の推測に過ぎないということを心に留めておくことが重要である。中間点を取る場合でも、この例では、推定はまだ約半年ずれている可能性がある。評価点間の時間をできるだけ小さくすれば、人-時推定値は最適になる。研究の評価間隔が粗すぎるかどうかはメタ分析の文脈に依存する。ただし、そのような感度分析を行うことは常に推奨される (Panageas et al. 2007)。これは、異なる人-時推定値に基づく研究の IRR を再計算することを意味する。インターバルの中点を使用しインターバルの中点を使用し最後の「イベントのない」評価ポイントを使用し最後の「イベントのない」評価ポイントを使用しイベントが検出された評価ポイントを使用している。イベントが検出された評価ポイントを使用している。これらの3つのメタ分析の結果がすべて同じ方向を向いていれば、より確信を持って調査結果を公表することが可能である。また、評価期間が研究間であまりに異ならないことを確認する必要がある (例えば、ある研究では毎日イベントを調査し、他の研究では年１回だけ調査する)。メタ分析での IRR の適用性に疑問がある場合、代わりに (または追加で) リスク比またはオッズ比を計算する可能性が常に存在する。ただし、この場合、評価時点が (1 年後など) 各研究で類似していることを確認する必要がある。R の発生率比に基づくメタ分析を計算するためには、データセットに以下の列を用意する必要がある。event.e: 治療群・実験群におけるイベント総数。time.e: 治療群・実験群における人-時 (person-time)。全ての研究で人-時の単位 (人-日、人-週、人-年) を統一して表記する。event.c: 対照群におけるイベント総数。time.c: 対照群における人-時 (person-time)。全ての研究で人-時の単位 (人-日、人-週、人-年) を統一して表記する。ハザード比と発生率比の限界発生率や IRR は、事象データやその事象が発生する時間帯を要約する直感的な方法である。しかし、欠点がないわけではない。発生率を計算するためには、母集団における基礎となるリスクが時間と共に一定であると仮定する (例えば、研究の1年目と2年目の間など)。IRRでは、基礎となるリスクは治療群と対照群で異なるかもしれないが (例えば、治療が事象を経験するリスクを減らすため)、各群内 (within) のリスクは一定であると仮定する。この仮定が非常に単純であることは容易に理解できる。イベントリスクが時間とともに変化しないと仮定することが非常に非現実的なシナリオは多い (Kraemer 2009, 例: 転移性癌患者の死亡)。Bender Beckmann (2019) は、シミュレーション研究に基づいて、IRRの使用は、両群の平均観察期間が大きく異ならないとき、および調査対象イベントのベースラインリスクが比較的低い (25%未満) 場合にのみ適切であると結論づけている。時間-事象データに基づく群間差を表現する代替指標として望ましいのがハザード比 (HR) である。ハザード比は、2つの (比例する) ハザード関数の比で、ある時点 \\(t\\) である事象を経験することの (変化する) 瞬間的なリスク (これを、「ハザード」と言う) を記述している。ハザード比は、一般的に Cox 回帰モデルを用いて、個々の参加者データを基に推定される。すべての研究から対数ハザード比 \\(\\log_{\\text{e}}(\\text{HR})\\) とそれに対応する標準誤差を抽出できれば、逆変量プーリング を用いたメタアナリシスを行うことができる (Chapter 4.1.1 参照)。これは、例えば対数リスクやオッズ比をプールするのと同じように機能する。 R では、対数ハザード比のプーリングは metagen 関数で、sm 引数を \"HR\" に設定して行う (Chapter 4.2.1 参照)。すべての研究が (対数) ハザード比とその標準誤差を報告しているわけではないので、HR をプールすることは実際には大変な問題になることもある。Parmar, Torri, Stewart (1998) は、特に log-rank test の結果や 生存曲線 から対数ハザード比とその分散を導き出す様々な方法について説明している。この方法は手間がかかるが、報告されたデータから IRR を導出する方法も間違いなく手間がかかる。","code":"\n# データを定義\ne_treat <- 28    # 治療群のイベント数\ne_contr <- 28    # 対照群のイベント数\nt_treat <- 3025  # 治療群の Person-time\nt_contr <- 2380  # 対照群の Person-time\n\n# IRR を計算\nirr <- (e_treat/t_treat)/(e_contr/t_contr)\nirr## [1] 0.7867769\n# log-IRR を計算\nlog_irr <- log(irr)\n\n# 標準誤差を計算\nse_log_irr <- sqrt((1/e_treat)+(1/e_contr))"},{"path":"effects.html","id":"es-correction","chapter":"3 効果量","heading":"3.4 効果量補正","text":"ある研究 \\(k\\) に対して計算した効果量 \\(\\hat\\theta_k\\) はその研究の真の効果量 \\(\\theta_k\\) の推定値であり、サンプル誤差 \\(\\epsilon_k\\) により \\(\\hat\\theta_k\\) は \\(\\theta_k\\) から乖離すると、Chapter 3.1 では取り上げた。残念ながら、多くの場合、これは過度の単純化である。先ほどの式では、推定された効果量と真の効果量を分けるのは、サンプル誤差だけである。式に従えば、サンプル誤差が小さくなれば、効果量の推定値は母集団における真の効果量に「自然に」収束していく。しかし、効果量の推定に系統的な誤差、すなわちバイアスが加わると、この限りではない。このようなバイアスは、さまざまな理由がある。効果量指標の数学的特性そのものに起因するものもあれば、研究の実施方法によって生じるバイアスもある。研究の進め方に起因するバイアスに対しては、バイアスの危険性を評価することで対応可能である (バイアスの危険性評価ツールの紹介は Chapter 1.4.5、バイアスの危険性の可視化方法は Chapter 15 を参照)。この判断は、例えばサブグループ解析において、バイアスリスクがプールされた効果の違いに関連しているかどうかを判断するためにも使用可能である (Chapter 7)。効果量の統計的性質に起因するバイアスに対処するために、メタ解析を始める前に、特定の効果量補正手法を用いてデータを調整することが可能である。この章では、よく使われる3つの効果量補正の方法と、それらを R でどのように実装するかを説明する。","code":""},{"path":"effects.html","id":"hedges-g","chapter":"3 効果量","heading":"3.4.1 スモールサンプルバイアス","text":"\n標準化平均差 (SMD) は、2群の連続したアウトカムデータがある場合に計算できる効果量である。しかし、標準化平均差は、研究のサンプルサイズが小さいとき、特に \\(n \\leq\\) 20 (L. V. Hedges (1981)) のとき、上方バイアス (upward bias) を持つことが分かっている。このサンプルサイズが小さいというバイアスは、研究のサンプルサイズが小さい場合、SMD が系統的に真の効果量を過大評価することを意味する。そこで、すべての研究の標準化平均差をスモールサンプルバイアスで補正し、Hedges’ \\(g\\) と呼ばれる効果量を算出することが賢明である。Hedges’ \\(g\\) はこの補正の考案者である Larry Hedges にちなんで名づけられた。未補正の SMD/Cohen’s \\(d\\) を Hedges’ \\(g\\) に変換する式は次のようになる。\\[\\begin{equation}\ng = \\text{SMD} \\times (1-\\frac{3}{4n-9})\n\\tag{3.38}\n\\end{equation}\\]この式で、\\(n\\) は研究の総サンプルサイズを表す。標準化されていない SMD/Cohen’s \\(d\\) を Hedges’ \\(g\\) に変換するには、{esc} パッケージの hedges_g 関数を使うと簡単に可能である。出力でわかるように、Hedges’ \\(g\\) は未補正の SMD より小さくなっている。Hedges’ \\(g\\) は補正前の SMD より大きくなることはなく、サンプルサイズが小さいほど2つの指標の差は大きくなる (Figure 3.5参照)。\nFigure 3.5: サンプルサイズを変化させた時の未補正 SMD 0.2 と補正済み SMD 値\nここで重要なことは、SMD と Hedges’ \\(g\\) という用語が研究報告で同じように使われることがあることである。ある研究が SMD として結果を報告している場合、著者が本当に未補正の標準化平均差を指しているのか、それとも小サンプルバイアス補正が適用されているのか (つまり Hedges’ \\(g\\) が使われているのか) を確認することが適切である。","code":"\n# esc パッケージをロード\nlibrary(esc)\n\n# 未補正 SMD とサンプルサイズ n を定義\nSMD <- 0.5\nn <- 30\n\n# Hedges g に変換\ng <- hedges_g(SMD, n)\ng## [1] 0.4864865"},{"path":"effects.html","id":"unreliable","chapter":"3 効果量","heading":"3.4.2 非信頼性","text":"測定誤差のために効果量の推定値にバイアスがある可能性もある。ほとんどのアンケートやテストは、興味のある結果を完璧に測定することはできない。測定誤差が生じにくい測定器 (訳注: instrument、測定器と訳したが質問紙なども含まれる) ほど、信頼性が高いと言える。ある変数 \\(x\\) を測定する測定器の信頼性は、信頼性係数 \\(r_{xx}\\) で表すことができ、0から1の間の値をとることができる。信頼性はしばしばテスト・再テスト信頼性と定義され、同一人物を同じような状況で短期間に2回以上測定し、その値の相関を計算することで求められる16。2つの連続変数の関係を調べるとき、これらの変数を評価するために使用される調査測定器の一方または両方に信頼性が欠けていると、減衰 (attenuation) と呼ばれる現象が起こることがある。この問題は、1904年に有名な心理学者 Charles Spearman (1904) によって早くも記述されている。例えば、相関を計算するときに、片方または両方の変数に誤差があると、真の相関を過小評価することになる。相関は希釈されるのである。しかし、良いニュースもある。もし、測定の (非) 信頼性の推定値があれば、真の効果の大きさをより良く推定するために、この減衰を補正することが可能なのである。John Hunter Frank Schmidt は、メタ分析の分野で重要な貢献者であり、メタ分析の一部として減衰の補正を行う方法を開発し推進している (Hunter Schmidt 2004, chap. 3 と Chapter 7)。この補正は他のいくつかの手法の一つであり、これらをまとめて「Hunter Schmidt techniques」または「Hunter Schmidt 法」と呼ぶこともある (Hough Hall 1994)。Hunter Schmidt の減衰補正は、(積率) 相関と標準化平均差に適用することができる。まず、メタ解析の一環として研究の積率相関 \\(r_{xy}\\) を計算する際に、変数 \\(x\\) の測定における信頼性の低さを補正したいと仮定する。\\(r_{xx}\\) で示される \\(x\\) の測定の信頼性がわかれば、相関の補正版である \\({r_{xy}}_{c}\\) を計算することが可能である。\\[\\begin{equation}\n{r_{xy}}_{c} = \\frac{r_{xy}}{\\sqrt{r_{xx}}}\n\\tag{3.39}\n\\end{equation}\\]アウトカム \\(x\\) が2群で観測され、その群間の標準化平均差を計算することが目的である場合、同様の方法で補正を行い、\\(\\text{SMD}_c\\)を得ることができる。\\[\\begin{equation}\n\\text{SMD}_c = \\frac{\\text{SMD}}{\\sqrt{r_{xx}}}\n\\tag{3.40}\n\\end{equation}\\]二つの連続変数 \\(x\\) と \\(y\\) を用いて積率相関を計算するとき、\\(y\\) の信頼性係数 \\(r_{yy}\\) もわかっていれば、\\(x\\) と \\(y\\) の両方の信頼性の低さを補正することも可能である。\\[\\begin{equation}\n{r_{xy}}_{c} = \\frac{r_{xy}}{\\sqrt{r_{xx}}\\sqrt{r_{yy}}}\n\\tag{3.41}\n\\end{equation}\\]最後に、標準誤差の補正も必要である。標準誤差の補正は、効果量そのものと同じ方法で行いる。1つの変数 \\(x\\) を補正する場合は、以下の式で計算可能である。\\[\\begin{equation}\nSE_c = \\frac{SE}{\\sqrt{r_{xx}}}\n\\tag{3.42}\n\\end{equation}\\]\\(x\\) と \\(y\\) の両方について補正 (積率相関) したい場合は、以下の式が使える。\\[\\begin{equation}\nSE_c = \\frac{SE}{\\sqrt{r_{xx}}\\sqrt{r_{yy}}}\n\\tag{3.43}\n\\end{equation}\\]\n相関やSMDを補正した後、\\({r_{xy}}_c\\) を Fisher’s \\(z\\) に変換したり(Chapter 3.2.3) \\(\\text{SMD}_c\\) を Hedges’ \\(g\\) に変換するなど(Chapter 3.4.1)、一般的な変換を適用することが可能である。ここでは 、 R を使った例で補正方法を試してみよう。この例の結果を詳しく見ていこう。補正により、相関と SMD が補正前の初期値より大きくなっていることがわかる。しかし、標準誤差が大きくなっていることもわかる。この結果は意図的なもので、標準誤差を補正することで、データに想定される測定誤差を取り込むことができるのである。組織心理学など一部の分野では、減衰補正を適用することが一般的である。しかし、生物医学分野を含む他の分野では、この手順はほとんど使用されていない。メタ分析では、各研究で信頼性係数 \\(r_{xx}\\) (および \\(r_{yy}\\)) が報告されている場合のみ、信頼性の低さに対する補正を実行することが可能である。信頼性係数が報告されていない場合も非常に多い。このような場合、先行研究に基づく測定器の信頼性の値を仮定することがある。しかし、補正が効果量の値に大きな影響を与えることを考えると、\\(r_{xx}\\) の推定値が不適切だと、結果がかなり歪んでしまう。また、メタ分析において、一部の効果量だけを補正し、他の効果量を補正しないようにすることは不可能である。これらの理由により、残念ながら信頼性補正の適用範囲は実際には限定されることが多い。","code":"\n# 未補正の相関と SMD とその標準誤差を定義\nr_xy <- 0.34\nse_r_xy <- 0.09\nsmd <- 0.65\nse_smd <- 0.18\n\n# xとyの信頼性を定義\nr_xx <- 0.8\nr_yy <- 0.7\n\n# x の信頼性の低さを考慮して SMD を補正\nsmd_c <- smd/sqrt(r_xx)\nsmd_c## [1] 0.7267221\nse_c <- se_smd/sqrt(r_xx)\nse_c## [1] 0.2012461\n# x と y の信頼性の低さを考慮して相関を補正\nr_xy_c <- r_xy/(sqrt(r_xx)*sqrt(r_yy))\nr_xy_c## [1] 0.4543441\nse_c <- se_r_xy/(sqrt(r_xx)*sqrt(r_yy))\nse_c## [1] 0.1202676"},{"path":"effects.html","id":"range","chapter":"3 効果量","heading":"3.4.3 範囲指定","text":"Hunter Schmidt (2004, chap. 3 と Chapter 7) によって提案されたもう一つの効果量調整は、範囲制限の問題を扱うものである。範囲制限とは、ある変数 \\(x\\) の変動が、興味のある実際の母集団よりも研究で小さいときに起こる現象である。これは、母集団全体を代表していない可能性のある個体から非常に選択的にサンプルを採取した場合によく起こる。例えば、ある研究で、被験者の年齢と認知機能の相関が報告された場合を考えてみよう。直感的には、これらの変数には確かに相関があると考えるだろう。しかし、65歳から69歳の参加者だけを対象とした研究であれば、この2つの変数の間に (高い) 相関が見られる可能性は極めて低い。これは、調査サンプルの年齢が非常に限定されているためである。年齢には実際の変動がないため、この変数は認知能力の良い予測因子にはなり得ないということである。測定器の信頼性の低さ (前章参照) と同様、これは研究の効果を人為的に減衰させることにつながる。実際には重要な関連がある場合でも、それを検出することができない。SMD や相関 \\(r_{xy}\\) の範囲制限を補正することは可能である。ただし、そのためには、対象母集団の無制限標準偏差 \\(s_{\\text{unrestricted}}\\) を知っている (または推定している) ことが必要である。興味のある母集団は、メタ分析のリサーチクエスチョンによって決定される。例えば、高齢者における年齢と認知機能の関係を調べたい場合、65歳以上の高齢者 (一般的に研究において「高齢者」はこのように定義される) の大規模代表サンプルにおける標準偏差の推定値を検索することが考えられる。もちろん、これは範囲限定であるが、メタ分析で扱う研究集団を反映しているため、年齢を重要な範囲に限定している。範囲制限を補正するためには、制限されていない母集団の標準偏差 \\(s_{\\text{unrestricted}}\\) と、本研究で制限した変数の標準偏差 \\(s_{\\text{restricted}}\\) の比である \\(U\\) を計算する必要がある。\\[\\begin{equation}\nU =  \\frac{s_{\\text{unrestricted}}}{s_{\\text{restricted}}}\n\\tag{3.44}\n\\end{equation}\\]\\(s_{\\text{unrestricted}}\\) の値は、例えば、興味のある変数を評価した過去の代表的な研究から得ることができる。そして、\\(U\\) を用いて、この式で相関の値 \\(r_{xy}\\) を補正することができる。\\[\\begin{equation}\n{r_{xy}}_c = \\frac{U\\times r_{xy}}{\\sqrt{(U^2-1)r_{xy}^2+1}}\n\\tag{3.45}\n\\end{equation}\\]これにより、補正後の相関 \\({r_{xy}}_c\\) を求めることができる。また、同じ式で SMD の補正版も計算できる。\\[\\begin{equation}\n\\text{SMD}_c = \\frac{U\\times \\text{SMD}}{\\sqrt{(U^2-1)\\text{SMD}^2+1}}\n\\tag{3.46}\n\\end{equation}\\]また、\\(r_{xy}\\)とSMDの標準誤差も、それぞれこれらの式で補正する必要がある。\\[\\begin{equation}\nSE_{{r_{xy}}_c} = \\frac{{r_{xy}}_c}{r_{xy}}SE_{r_{xy}}\n\\tag{3.47}\n\\end{equation}\\]\\[\\begin{equation}\nSE_{{\\text{SMD}}_c} = \\frac{{\\text{SMD}}_c}{\\text{SMD}}SE_{\\text{SMD}}\n\\tag{3.48}\n\\end{equation}\\]\n相関やSMDを補正した後、\\({r_{xy}}_c\\) を Fisher’s \\(z\\) に変換したり (Chapter 3.2.3.1 )、\\(\\text{SMD}_c\\) を Hedges’ \\(g\\) に変換するなど (Chapter 3.4.1 )、よくある変換を行うことができるようになっている。では、 R を使った補正を試してみよう。他の Hunter Schmidt の調整と同様に、範囲制限の補正は、他の研究分野よりもある研究分野でより一般的に見られるものである。範囲制限の補正を適用する場合、メタ分析におけるすべての効果量に対して補正を実行することが重要である。技術的には、すべてのメタ分析で範囲制限の補正を行うことは可能であるが、多くの場合、これは必要ではない。実際には、各研究がメタ分析の範囲を完全に表現していることはほとんどない。実際、メタ分析の目的は、個々の研究の結果を超えることである。したがって、範囲制限の補正は、いくつかの研究の範囲が大きく制限されている場合にのみ必要となる場合がある。\n更なる学習\n\nこのガイドでは、信頼性の低さと範囲制限に関する補正のみを取り上げる。なぜなら、これらの問題は実際に最もよく見られるからである。しかし、Hunter\nSchmidt\nは、他にも様々な種類の誤差補正を提案している。いくつかの追加手法とともに、この手法は、心理測定メタ分析\n(psychometric meta-analysis) と呼ばれることもある。\n\nHunter Schmidt の方法について詳しく知りたい方は、彼らの著書である\nMethods Meta-Analysis (Hunter Schmidt 2004)\nがわかりやすく、包括的な概要を提供しているので、参照されたい。Borenstein\net al. (2011)\nの38章にも、短い紹介がある。\n\nHunter Schmidt の手法の多くは、{psychmeta} (Dahlke Wiernik 2019) と呼ばれる R\nパッケージにも実装されている。\n","code":"\n# 補正するための相関関係を定義\nr_xy <- 0.34\nse_r_xy <- 0.09\n\n# 指定 SD と非制限 SD を定義\nsd_restricted <- 11\nsd_unrestricted <- 18\n\n# U を計算\nU <- sd_unrestricted/sd_restricted\n\n# 相関を補正\nr_xy_c <- (U*r_xy)/sqrt((U^2-1)*r_xy^2+1)\nr_xy_c## [1] 0.5091754\n# 標準誤差を補正\nse_r_xy_c <- (r_xy_c/r_xy)*se_r_xy\nse_r_xy_c## [1] 0.1347817"},{"path":"effects.html","id":"よくある問題","chapter":"3 効果量","heading":"3.5 よくある問題","text":"この章では、効果量を計算する際に、実際によく直面する問題にもう少し時間を割きたいと思いる。まず、効果量のデータが異なる形式で報告されている場合にどうすればよいかを説明する。その後、後のステップでメタ解析のプーリングに影響を与える解析単位の問題を検討する。","code":""},{"path":"effects.html","id":"es-formats-different","chapter":"3 効果量","heading":"3.5.1 効果量のデータ形式が異なる","text":"前の章で効果量の計測方法について説明したとき、データセットの列として必要な変数の種類についても触れた。これらの変数は、 R 関数が効果量を計算し、メタ分析を実行するために必要である。例えば、群間標準化平均差のメタ分析を計算するためには、両群の平均値、標準偏差、サンプルサイズを準備する必要がある。すべての研究からこの情報を抽出することができれば、すべてがうまくいく。しかし、実際には、すべての研究が適切な形式で結果を報告しているわけではないことにすぐに気がつくだろう。例えば、2群の生データを報告せず、標準化平均差の計算値とその信頼区間だけを報告する研究もある。また、2群間の差を調べる\\(t\\)-検定や分散分析 (ANOVA) の結果のみを報告する研究もある。このような場合、メタ分析に生の効果量データを使うことができなくなることがよくある。その代わりに、各研究の効果量をあらかじめ計算して、それをプールする必要がある。メタ分析に最低限必要な情報は、研究の効果量と標準誤差であることは、Chapter 3.1 ですでに確認した。したがって、結果を効果量と標準誤差の推定値に変換することができれば、その研究を取り入れることができるのである。Chapter 17 では、他のタイプの報告データから効果量を導き出すのに役立つ効果量コンバータをいくつか紹介している。しかし、これらのツールを使っても、効果量が算出できない研究がある可能性がある。そのような場合に残された方法としては、「研究選択」の章で述べたように、それぞれの論文の著者に何度も連絡を取り、効果量を算出するために必要なデータを提供してもらえないかお願いすることである。それでもダメなら、その研究は除外するしかない。Chapter 4.2.1 では、 R の特殊な関数である metagen について学ぶ。この関数を使うと、事前に計算された効果量のデータをメタ分析することが可能である。この関数を使うには、データセットに以下の列を用意する必要がある。TE. 各研究の効果量の計算値。seTE. 各効果量の標準誤差。","code":""},{"path":"effects.html","id":"unit-of-analysis","chapter":"3 効果量","heading":"3.5.2 分析単位問題","text":"メタ分析において、1つの研究が2つ以上の効果量に寄与することは珍しいことではない。特に、(1)ある研究が2つ以上のグループを含んでいる、(2)ある研究が2つ以上の道具を使って結果を測定している、などの場合がある。どちらの場合も問題がある。メタ分析において、研究が複数の効果量に寄与する場合、メタ分析における各効果量は独立であるという中核的な仮定の1つに違反することになる (Julian Higgins et al. 2019, chap. 6.2 と Chapter 23; Borenstein et al. 2011, chap. 25)。この仮定が満たされない場合、分析単位 (unit analysis) の問題を扱っていることになる。例えば、治療 を検査する群、治療 B を投与する群、そして対照群 C がある。この研究では、2個の効果量を計算することが可能である。結果のデータによって、これらはリスク比、オッズ比、または発生率比、あるいは標準化平均差になる。治療 と対照を比較する効果量 \\(\\hat\\theta_{\\text{-C}}\\) と、治療 B と対照を比較する効果量 \\(\\hat\\theta_{\\text{B-C}}\\) の2つがある。\\(\\hat\\theta_{\\text{-C}}\\) と \\(\\hat\\theta_{\\text{B-C}}\\) の両方を同じメタ分析に含めると、C の情報が2回含まれているため、これらの効果量は独立したものではない。この問題は、二重カウントとも呼ばれる。C を二重カウントしたため、2つの効果量は相関がある。サンプルサイズが全群で等しい場合、この相関は \\(r =\\) 0.5 であることがわかる (Borenstein et al. 2011, chap. 25)。これは、と B が独立した群であるため、相関がないためである。しかし、両方の効果量における対照群は同一であるため、完全な相関は1となり、その中点は 0.5 となる。群の二重カウントは、影響を受ける効果量の精度 (すなわち、標準誤差) を過大評価することになる。これは、メタ分析でこれらの効果に与える重みを増大させ、最終的に結果を歪めることになる。この問題に対処するために、3つの方法がある。共有群のサンプルサイズを分割する。これは、効果量を計算するときに、C 群のサンプルサイズ (例えば \\(n =\\) 200) を との比較と C との比較で均等に分けることを意味する。二値結果のデータを扱う場合は、イベントの数も均等に分割する。この例では、先ほどと同じように2つの効果量を計算したが、今度は C が両方の計算で100人のみで構成されているように見せかける。このアプローチにより、効果量の精度がダブルカウントのために人為的に高くなるという問題が解決される。しかし、効果量が相関したままなので、まだ最適とは言えない (Julian Higgins et al. 2019, 23.3.4)。共有群のサンプルサイズを分割する。これは、効果量を計算するときに、C 群のサンプルサイズ (例えば \\(n =\\) 200) を との比較と C との比較で均等に分けることを意味する。二値結果のデータを扱う場合は、イベントの数も均等に分割する。この例では、先ほどと同じように2つの効果量を計算したが、今度は C が両方の計算で100人のみで構成されているように見せかける。このアプローチにより、効果量の精度がダブルカウントのために人為的に高くなるという問題が解決される。しかし、効果量が相関したままなので、まだ最適とは言えない (Julian Higgins et al. 2019, 23.3.4)。群を削除する。非常に腕力を使う手法は、単純に1つの比較、例えば \\(\\hat\\theta_{\\text{B-C}}\\) をメタ分析から完全に削除することである。これは分析単位の問題を解決するものの、新たな問題を引き起こす。効果量を1つ捨てるだけだと、関連する可能性のある情報を失ってしまうのである。群を削除する。非常に腕力を使う手法は、単純に1つの比較、例えば \\(\\hat\\theta_{\\text{B-C}}\\) をメタ分析から完全に削除することである。これは分析単位の問題を解決するものの、新たな問題を引き起こす。効果量を1つ捨てるだけだと、関連する可能性のある情報を失ってしまうのである。群を合体する。この手法は、2つの群の結果を組み合わせて、1つの比較しか残らないようにするものである。この例では、と B のデータを組み合わせて、プールした結果を C と比較することを意味する。これは、両群の参加者数とイベント数を合計すればよい二値アウトカムデータでは比較的簡単なことである。しかし、平均値や標準偏差のような連続的なデータでは、少し複雑になる。「各種ツール」の Chapter 17.9 には、このようなデータを結合するための R 関数がある。群を合体することで、二重カウントや効果量の相関を回避することが可能である。そのため、この方法はコクランでも推奨されている (Julian Higgins et al. 2019, chap. 23.3.4)。とはいえ、この方法にも欠点がある。2群があまりにも異なり、実際には比較できないものを一緒にしてしまう可能性があるのである。は最先端の介入、B はエビデンスベースの乏しい時代遅れのアプローチでなど、群と B 群の治療がまったく異なることもある。この2つの治療を組み合わせても効果が見られない場合、これが両方のタイプの介入に当てはまるのか、B の効果のなさが単に の効果を希釈したのかを切り分けるのはほぼ不可能である。したがって、アプローチ (1) と (2) は、2群があまりにも異質な場合に使用される。群を合体する。この手法は、2つの群の結果を組み合わせて、1つの比較しか残らないようにするものである。この例では、と B のデータを組み合わせて、プールした結果を C と比較することを意味する。これは、両群の参加者数とイベント数を合計すればよい二値アウトカムデータでは比較的簡単なことである。しかし、平均値や標準偏差のような連続的なデータでは、少し複雑になる。「各種ツール」の Chapter 17.9 には、このようなデータを結合するための R 関数がある。群を合体することで、二重カウントや効果量の相関を回避することが可能である。そのため、この方法はコクランでも推奨されている (Julian Higgins et al. 2019, chap. 23.3.4)。とはいえ、この方法にも欠点がある。2群があまりにも異なり、実際には比較できないものを一緒にしてしまう可能性があるのである。は最先端の介入、B はエビデンスベースの乏しい時代遅れのアプローチでなど、群と B 群の治療がまったく異なることもある。この2つの治療を組み合わせても効果が見られない場合、これが両方のタイプの介入に当てはまるのか、B の効果のなさが単に の効果を希釈したのかを切り分けるのはほぼ不可能である。したがって、アプローチ (1) と (2) は、2群があまりにも異質な場合に使用される。分析単位の問題は、ある研究が複数の測定器を用いて結果を測定した場合にも発生する。これは、解析したい変数をどのように選ぶべきかを決定する明確な「ゴールド・スタンダード」がない場合によくあることである。これらの測定のそれぞれについて効果量を計算しメタ分析に含めると、二重カウントになってしまう。さらに、効果の測定に同じサンプルが使用されるため、効果量には相関がある。この状況に対処するためには、3つのアプローチがある。まず、単純に1つの研究につき1つの測定器を選択する方法である。この選択は、体系的かつ再現可能な方法で行うことが重要である。できることといえば、解析計画書 (Chapter 1.4.2) において、メタ解析のための測定器の階層を定義しておくくらいである。この階層は、特定の測定器の信頼性に関する過去の証拠に基づくことも、どのタイプの測定器が研究課題の内容を最もよく反映しているかに基づくこともできる。そして、この階層によって、複数の測定器が利用可能な場合に、どの測定器を選択するかを明確に決定する。まず、単純に1つの研究につき1つの測定器を選択する方法である。この選択は、体系的かつ再現可能な方法で行うことが重要である。できることといえば、解析計画書 (Chapter 1.4.2) において、メタ解析のための測定器の階層を定義しておくくらいである。この階層は、特定の測定器の信頼性に関する過去の証拠に基づくことも、どのタイプの測定器が研究課題の内容を最もよく反映しているかに基づくこともできる。そして、この階層によって、複数の測定器が利用可能な場合に、どの測定器を選択するかを明確に決定する。また、計算された効果量を用いてそれらを集約し、各研究が1つの効果量 (集約されたもの) しか提供しないようにすることも可能である。これはやや「総当り」的なアプローチである。この場合、効果量が研究内でどの程度強く相関しているかを特定する必要があるが、この値は通常知られていない。Chapter 17.10 では、あらかじめ計算された効果量を、各研究について1つの推定値に集約できる関数を紹介する。また、計算された効果量を用いてそれらを集約し、各研究が1つの効果量 (集約されたもの) しか提供しないようにすることも可能である。これはやや「総当り」的なアプローチである。この場合、効果量が研究内でどの程度強く相関しているかを特定する必要があるが、この値は通常知られていない。Chapter 17.10 では、あらかじめ計算された効果量を、各研究について1つの推定値に集約できる関数を紹介する。第三のアプローチは、利用可能なすべての測定器からのデータを含み、メタ分析において研究が1つ以上の効果量に寄与するという事実を説明できるメタ分析モデルを使用することである。これは「３レベル」メタ分析モデルによって実現されるもので、Chapter 10 で検討する。第三のアプローチは、利用可能なすべての測定器からのデータを含み、メタ分析において研究が1つ以上の効果量に寄与するという事実を説明できるメタ分析モデルを使用することである。これは「３レベル」メタ分析モデルによって実現されるもので、Chapter 10 で検討する。\\[\\tag*{$\\blacksquare$}\\]","code":""},{"path":"effects.html","id":"演習問題-2","chapter":"3 効果量","heading":"3.6 演習問題","text":"\n知識を試そう！\n\n効果量という言葉に明確な定義はあるか？人々は、効果量という言葉で何を指すか？\n\n観測された効果量が母集団の真の効果量から乖離する主な理由を挙げなさい。それはどのように定量化できるのか。\n\nなぜ大規模な研究は小規模な研究よりも真の効果の推定に優れているのか？\n\n効果量の指標は、どのような基準を満たせばメタ分析に使えるのか？\n\n標準化平均差 (Standardized Mean Difference, SMD)\nが1であることは何を表しているのか？\n\n比 (オッズ比など)\nに基づく効果量をプールするためには、どのような変換が必要か。\n\n効果量補正の種類を3つ挙げよ。\n\n分析単位の問題はどのような場合に発生するか？どうすれば回避できるか？\n\n問題の解答は、本書の巻末 Appendix\nにある。\n","code":""},{"path":"effects.html","id":"概要-2","chapter":"3 効果量","heading":"3.7 概要","text":"効果量は、メタ分析の構成要素である。メタ分析を行うには、少なくとも効果量とその標準誤差の推定値が必要である。効果量は、メタ分析の構成要素である。メタ分析を行うには、少なくとも効果量とその標準誤差の推定値が必要である。効果量の標準誤差は、その研究による効果量の推定がどれだけ正確であるかを表している。メタ分析では、精度の高い効果量は、真の効果をより良く推定できるため、より高い重みが与えられる。効果量の標準誤差は、その研究による効果量の推定がどれだけ正確であるかを表している。メタ分析では、精度の高い効果量は、真の効果をより良く推定できるため、より高い重みが与えられる。メタ分析で使用する効果量には様々なものがある。一般的なものは、「1変数」の関係尺度 (平均や割合など)、相関、(標準化) 平均差、そしてリスク比、オッズ比、発生率比などである。メタ分析で使用する効果量には様々なものがある。一般的なものは、「1変数」の関係尺度 (平均や割合など)、相関、(標準化) 平均差、そしてリスク比、オッズ比、発生率比などである。効果量には、測定誤差や範囲制限などによるバイアスが生じることがある。標準化平均差の小サンプルバイアス、信頼性の低さによる減衰、範囲制限の問題など、いくつかのバイアスを補正する公式がある。効果量には、測定誤差や範囲制限などによるバイアスが生じることがある。標準化平均差の小サンプルバイアス、信頼性の低さによる減衰、範囲制限の問題など、いくつかのバイアスを補正する公式がある。その他のよくある問題としては、効果量を計算するために必要なデータを異なる形式で報告している研究、また、複数の効果量を報告している研究で生じる分析単位の問題などがある。その他のよくある問題としては、効果量を計算するために必要なデータを異なる形式で報告している研究、また、複数の効果量を報告している研究で生じる分析単位の問題などがある。","code":""},{"path":"pooling-es.html","id":"pooling-es","chapter":"4 効果量のプール","heading":"4 効果量のプール","text":"険 しい道はもう過ぎ去った。幸いなことに、私たちは今、すべてのメタ分析の核となる部分、すなわち効果量のプールに到達している。この章から直接始めるという誘惑には勝つことができたと思われる。本書では、研究課題の定義、研究データの検索・選択・抽出のガイドライン、効果量の作成方法など、様々なトピックを既に取り上げている。徹底的な準備は優れたメタ分析の重要な要素であり、これから続くステップで大いに役立つことだろう。これまでの章に費やした時間は、十分に投資されたと断言できる。R で効果量をプールすることができるパッケージは数多く存在する。ここでは、Chapter 2.2 で既にインストールした {meta} パッケージの機能を中心に説明する。このパッケージは非常に使い勝手が良く、数行のコードでほぼ全ての重要なメタ分析結果を得ることが可能である。前章では、効果の大きさはアウトカムによって異なる「フレーバー」があることを取り上げた。 {meta} パッケージには、これらの効果量のそれぞれのメトリクス (訳注: 標準化平均差やオッズ比など) について特化したメタ分析関数が含まれている。また、全ての関数はほぼ同じ構造をしている。このように、 {meta} の動作の基本を理解すれば、どの効果量に注目しても、メタ分析のコーディングは簡単にできるようになる。この章では、 {meta} パッケージの一般的な構造について説明する。もちろん、パッケージのメタ分析機能についても、実例を用いてより詳しく解説する。{meta} パッケージでは、効果量がプールされる方法について、多くの詳細を微調整することが可能である。以前述べたように、メタ分析には多くの 「研究者の自由度」が伴う。適用できる統計手法やアプローチに関する選択肢は無数にあり、ある手法が他の手法より優れているかどうかは、しばしば文脈に依存する。\nしたがって、 R で分析を始める前に、メタ分析の統計的な前提条件と、その背後にある数学について基本的な理解を深める必要があるのである。メタ分析の背後にある「考え方」についても触れておくことも重要である。統計学では、この「考え方」はモデルと訳されるが、メタ分析のモデルがどのようなものかを見ていきる。これから見ていくように、メタ分析の性質上、すぐに基本的な判断をしなければならない。固定効果モデルかランダム効果モデルのどちらかを仮定しなければならないのである。他の分析仕様と合わせて、この2つのモデルのうちどの文脈でどちらがより適切なのか、情報に基づいて決定を下すためには、メタ分析プールの背後にある概念についての知識が必要である。","code":""},{"path":"pooling-es.html","id":"fem-rem","chapter":"4 効果量のプール","heading":"4.1 固定効果モデルとランダム効果モデルの比較","text":"メタ分析モデルを規定する前に、まず統計モデルとは実際にどのようなものかを明らかにする必要がある。統計学には「モデル」がたくさんあり、「モデル」と言う言葉は聞いたことがあるだろう。「線形モデル」「一般化線形モデル」「混合モデル」「ガウス加法モデル」「構造方程式モデル」などがある。統計学においてモデルが遍在していることは、この概念がいかに重要であるかを示している。統計ツールボックスはすべて、何らかの形でモデルが基礎となっている。\\(t\\) 検定、ANOVA、回帰の背後にはモデルがある。すべての仮説検定には、それに対応する統計モデルがある。統計モデルを定義するとき、すでに与えられている情報から始める。これは文字通り、データ17 である。メタ分析では、データは、含まれる研究で観察された効果量である。私たちのモデルは、これらの観察されたデータが生成されたプロセスを記述するために使用される。データはブラックボックスの産物であり、私たちのモデルはそのブラックボックスの中で何が起こっているかを明らかにすることを目的としている。一般に、統計モデルとは特殊な「理論」のようなものである。モデルは、観測されたデータを生成したメカニズムを説明しようとするもので、特にそのメカニズム自体が直接観測できない場合に有効である。特に、そのメカニズム自体が直接観測できない場合、そのメカニズムを説明しようとするものである。モデルが説明的であるという性格は、現代の統計学に深く根付いており、メタ分析も例外ではない。説明のための手段としてのモデルの概念化は、統計「文化」の特徴である。Breiman (2001) の有名に推定によると、全統計学者の98％が信奉しているようである。統計モデルを指定することで、データの背後にある「現実」の近似的な表現を見つけようとしている。観測された結果に基づいて、すべての研究の根底にある真の効果量を見つける方法を説明する数式が欲しいのである。Chapter 1.1 で学んだ通り、メタ分析の最終的な目的は、効果量が研究ごとに異なる場合でも、研究全体を特徴づける1つの数値を見つけることである。したがって、メタ分析モデルは、全体的な効果は1つであるにもかかわらず、観察された研究結果がなぜ、どの程度異なるのかを説明する必要がある。まさにこの問いに答えようとするモデルとして、固定効果モデルとランダム効果モデルの2つがある。両者は異なる仮定に基づいているが、すぐにわかるように、両者の間には強い結びつきがある。","code":""},{"path":"pooling-es.html","id":"fem","chapter":"4 効果量のプール","heading":"4.1.1 固定効果モデルの場合","text":"\n固定効果モデルは、すべての効果量が単一の均質な集団に由来すると仮定している。これは、すべての研究が、同じ真の効果量を共有していることを述べている。この真の効果は、メタ分析で計算したい全体的な効果量で、\\(\\theta\\) と表記される。固定効果モデルによると、ある研究 \\(k\\) の観測された効果量 \\(\\hat\\theta_k\\) (「シータ・ハットk」と読む) が \\(\\theta\\) から逸脱する唯一の理由は、そのサンプル誤差 \\(\\epsilon_k\\) (「イプシロン・k」と読む) のためである。固定効果モデルは、ブラックボックスの中身である研究の効果量の違いを生み出す過程が単純で、すべての研究が同じ真の効果量の推定者であることを教えてくれる。しかし、すべての研究は、無限に大きな研究集団から多少なりとも大きなサンプルを抽出することしかできないため、結果はサンプリングエラーに悩まされることになる。このサンプル誤差は、観察された効果が全体的な真の効果から乖離する原因となる。このような関係を表現することが可能である (Borenstein et al. 2011, chap. 11)。\\[\\begin{equation}\n\\hat\\theta_k = \\theta + \\epsilon_k\n\\tag{4.1}\n\\end{equation}\\]注意深く見ると、この数式が不思議なことに Chapter 3.1 の数式と似ていると思われるだろう。それは間違いではない。先ほどの式では、ある研究 \\(k\\) の観測された効果量 \\(\\hat\\theta_k\\) は、その研究の真の効果量 \\(\\theta_k\\) の推定値であり、研究のサンプル誤差 \\(\\epsilon_k\\) が負担している、と定義する。先ほどの式と固定効果モデルの式では、ほんのわずかだが重要な違いがある。固定効果モデルの式では、真の効果量を \\(\\theta_k\\) ではなく、\\(\\theta\\) で表し、添え字 \\(k\\) を削除している。これまでは、個々の研究 \\(k\\) の真の効果量についてのみ記述してきた。固定効果モデルでは、さらに一歩踏み込む。研究 \\(k\\) の真の効果量を見つけると、この効果量は \\(k\\) だけでなく、メタ分析におけるすべての研究についても真であることを教えてくれる。ある研究の真の効果量 \\(\\theta_k\\) と、全体のプール効果量 \\(\\theta\\) は、同一である。固定効果モデルの式から、観測された効果量 \\(\\theta_k\\) が真の全体効果から乖離する理由はただ一つ、サンプル誤差 \\(\\epsilon_k\\) によることがわかる。サンプルエラーとサンプルサイズには関連性があることは、Chapter 3.1 で既に述べた。すべての条件が同じであれば、サンプルサイズが大きくなれば、サンプリングエラーは小さくなる。また、サンプリングエラーは標準誤差で数値で表すことができ、これもサンプルサイズが大きくなると小さくなることを学ぶ。研究の真の全体効果量は不明であるが、この関係を利用して真の全体効果 \\(\\hat\\theta\\) の最良の推定値に到達することが可能である。したがって、標準誤差が小さい研究は、標準誤差が大きい研究よりも、真の全体効果のより良い推定値になるはずである。これをシミュレーションで説明することが可能である。前に使った rnorm 関数を用いて、真の全体効果が \\(\\theta = 0\\) である研究の選択をシミュレートしよう。複数のサンプルを取るが、サンプルサイズを変えて、標準誤差が「観察された」効果間で異なるようにする。シミュレーションの結果は、Figure 4.1 で見ることが可能である。\nFigure 4.1: 効果量と標準誤差の関係\nシミュレーションの結果、興味深いパターンが示された。サンプリング誤差が小さい効果量は、真の効果量 \\(\\theta = 0\\) の周りに凝集していることがわかる。y軸の標準誤差19が大きくなると、効果量の分散が大きくなり、観測された効果が真の効果からどんどんずれていくことがわかる。この挙動は、固定効果モデルの式で予測することが可能である。標準誤差が小さい研究は、サンプル誤差が小さく、全体的な効果量の推定値が真実に近い可能性が高いことが分かっている。観測された効果量はすべて真の効果の推定量であるが、あるものは他のものよりも優れていることを見てきた。したがって、メタ分析で効果をプールする場合、より高い精度 (すなわち、より小さい標準誤差) を持つ効果量に、より大きな重みを与える必要がある。固定効果モデルでプール効果量を計算する場合は、全研究の加重平均を使用する。各研究 \\(k\\) の重み \\(w_k\\) を計算するには、標準誤差を用い、それを二乗して各効果量の分散 \\(s^2_k\\) を求めることができる。分散が小さいほど精度が高いことを示すので、分散の逆数を用いて各研究の重みを決定する。\\[\\begin{equation}\nw_k = \\frac{1}{s^2_k}\n\\tag{4.2}\n\\end{equation}\\]重みがわかれば、加重平均を計算し、真のプール効果 \\(\\hat\\theta\\) を推定することが可能である。各研究の効果量 \\(\\hat\\theta_k\\) に対応する重み \\(w_k\\) を掛け、メタ分析の全研究 \\(K\\) で結果を合計し、すべての個々の重みの合計で割ればよい。\\[\\begin{equation}\n\\hat\\theta = \\frac{\\sum^{K}_{k=1} \\hat\\theta_kw_k}{\\sum^{K}_{k=1} w_k}\n\\tag{4.3}\n\\end{equation}\\]\nこの方法は、メタ分析で平均効果を計算する最も一般的な方法である。分散の逆数を使用するので、しばしば 逆分散重み付け (Inverse-Variance Weighting) または単に逆分散メタ分析と呼ばれる。二値効果量データの場合、加重平均を計算する方法として、Mantel-Haenszel 法、Peto 法、あるいは Bakbergenuly によるサンプルサイズ加重法 (2020) などがある。これらの方法については、Chapter 4.2.3.1 で説明する。{meta} パッケージを使うと、固定効果メタ分析がとても簡単に可能である。しかし、その前に R で 「手動で」逆分散プーリングを試してみよう。この例では、Chapter 2.4 でインポートした SuicidePrevention データセットを使用する。“SuicidePrevention” データセット\nSuicidePrevention のデータセットには、生の効果量が含まれているので、まず効果量を計算する必要がある。この例では、小サンプル調整済み標準化平均差 (Hedges’ \\(g\\)) を計算する。これを行うには、 {esc} パッケージの esc_mean_sd 関数を使用する (Chapter 3.3.1.2)。この関数には es.type という追加の引数があり、これを用いてスモールサンプル補正を行うかどうかを指定することが可能である (es.type = \"g\" と指定; Chapter 3.4.1)。計算の結果、固定効果モデルを仮定したプール効果量は \\(g \\approx\\) -0.23 であった。","code":"\n# dmetar, esc and tidyverse をロード\nlibrary(dmetar)\nlibrary(esc)\nlibrary(tidyverse)\n\n# dmetar からデータセットをロード\ndata(SuicidePrevention)\n\n# Hedges' g と標準誤差を計算\n# - 研究名を \"study\" に保存\n# - その後、パイプを使って\n#   結果をデータフレームに変換\nSP_calc <- esc_mean_sd(grp1m = SuicidePrevention$mean.e,\n                       grp1sd = SuicidePrevention$sd.e,\n                       grp1n = SuicidePrevention$n.e,\n                       grp2m = SuicidePrevention$mean.c,\n                       grp2sd = SuicidePrevention$sd.c,\n                       grp2n = SuicidePrevention$n.c,\n                       study = SuicidePrevention$author,\n                       es.type = \"g\") %>% \n                     as.data.frame()\n\n# データの glimpse を見よう\n# データは Hedges' g (\"es\") と標準誤差 (\"se\") を含む\nglimpse(SP_calc)## Rows: 9\n## Columns: 9\n## $ study       <chr> \"Berry et al.\", \"DeVries et al.\", \"Fleming et al.\" …\n## $ es          <dbl> -0.14279447, -0.60770928, -0.11117965, -0.12698011 …\n## $ weight      <dbl> 46.09784, 34.77314, 14.97625, 32.18243, 24.52054 …\n## $ sample.size <dbl> 185, 146, 60, 129, 100, 220, 120, 80, 107data\n## $ se          <dbl> 0.1472854, 0.1695813, 0.2584036, 0.1762749 …\n## $ var         <dbl> 0.02169299, 0.02875783, 0.06677240, 0.03107286 …\n## $ ci.lo       <dbl> -0.4314686, -0.9400826, -0.6176413, -0.4724727 …\n## $ ci.hi       <dbl> 0.145879624, -0.275335960, 0.395282029 …\n## $ measure     <chr> \"g\", \"g\", \"g\", \"g\", \"g\", \"g\", \"g\", \"g\", \"g\"\n\n# 各研究の 逆分散重みを計算\nSP_calc$w <- 1/SP_calc$se^2\n\n# 重みを使って効果量をプール\npooled_effect <- sum(SP_calc$w*SP_calc$es)/sum(SP_calc$w)\npooled_effect## [1] -0.2311121"},{"path":"pooling-es.html","id":"rem","chapter":"4 効果量のプール","heading":"4.1.2 ランダム効果モデル","text":"これまで見てきたように、固定効果モデルは、メタ分析データの成り立ちや、効果をプールする方法を概念化する一つの方法である。しかし、重要なのは、この方法が現実を適切に反映しているかということである。固定効果モデルは、すべての研究が均質な母集団の一部であり、観察された効果の差の唯一の原因は研究のサンプリング・エラーであると仮定している。もし、サンプリング・エラーなしに各研究の効果量を計算するとしたら、すべての真の効果量は完全に同じになる。この考え方を現実的に確認すると、固定効果モデルの仮定は、多くの実世界のアプリケーションにおいて単純すぎる可能性があることがわかる。メタ分析における研究が常に完全に均質であることは、単純に非現実的である。たとえ微妙な違いであっても、研究内容が異なることはよくある。興味のあるアウトカムは、異なる方法で測定されただろう。治療の種類や強さ、長さが全く同じでないこともある。研究の対象者が全く同じでなかっただろうし、使用した対照群に違いがあっただろう。メタ分析に含まれる研究は、これらの側面のうちの1つだけでなく、同時に複数の側面で異なる可能性がある。もしそうであれば、真の効果におけるかなりの研究間の異質性が予想される。これらのことは、固定効果モデルの有効性を疑わせるものである。例えば、ある研究が異なるタイプの治療法を用いていた場合、一方の治療法が他方の治療法よりも効果的であることは、ごく普通のことと思われる。このような違いが、研究のサンプル誤差によるノイズに過ぎないと考えるのは、あまりに不自然なことだろう。その逆で、研究の効果量に本当の差がある理由は無数にあるのである。ランダム効果モデルは、このような懸念に対応するものである。このモデルは、私たちのデータの背後にある現実をよりよく反映するモデルを提供してくれる。ランダム効果モデルでは、効果量が単一の均質な母集団から抽出された場合よりも分散を示すという事実を考慮したいと思われる (L. V. Hedges Vevea 1998)。したがって、個々の研究の効果は、サンプル誤差だけによる偏差ではなく、別の分散の原因があると仮定する。この追加的な分散成分は、研究が1つの集団から生じているわけではないという事実によってもたらされる。その代わり、各研究は、母集団の「宇宙」から独立に抽出されたものとみなされる。ランダム効果モデルがどのように数式で表現されるかを見てみよう。ランダム効果モデルは、固定効果モデルと同様に、観測された効果量 \\(\\hat\\theta_k\\) が、サンプリングエラー \\(\\epsilon_k\\) を含む研究の真の効果量 \\(\\theta_k\\) の推定値であると仮定することから始まる。\\[\\begin{equation}\n\\hat\\theta_k = \\theta_k + \\epsilon_k\n\\tag{4.4}\n\\end{equation}\\]このように、\\(\\theta\\) の代わりに \\(\\theta_k\\) を使っていることが、すでに重要な違いを示している。ランダム効果モデルは、\\(\\theta_k\\) が1個の単一研究 \\(k\\) の真の効果量であると仮定しているだけである。このモデルでは、\\(\\theta_k\\) の他に、\\(\\zeta_k\\) (訳注: \\(\\zeta\\) は「ゼータ」と読む) で示される第二の誤差要因が存在することを仮定している。この第二の誤差の原因は、研究 \\(k\\) の真の効果量 \\(\\theta_k\\) でさえ、平均 \\(\\mu\\) を持つ真の効果量の包括的な分布の一部に過ぎないという事実によってもたらされる。\\[\\begin{equation}\n\\theta_k  = \\mu + \\zeta_k\n\\tag{4.5}\n\\end{equation}\\]ランダム効果モデルは、ブラックボックス (S. G. Thompson, Turner, Warn 2001) の内部で、2つのプロセスの階層が起こっていることを教えてくれる: 研究の観察された効果量は、サンプル誤差のためにその真の値から逸脱している。しかし、真の効果量でさえも、真の効果の宇宙からの引き出しに過ぎず、その平均 \\(\\mu\\) を、メタ分析のプール効果として推定したい。2番目の式を1番目の式にあてじはめる (つまり、\\(\\theta_k\\) を2番目の式の定義に置き換える) ことで、ランダム効果モデルを1行で表現可能である (Borenstein et al. 2011, chap. 12)。\\[\\begin{equation}\n\\hat\\theta_k = \\mu + \\zeta_k + \\epsilon_k\n\\tag{4.6}\n\\end{equation}\\]この式から、観測された効果量がプール効果 \\(\\mu\\) から乖離するのは、\\(\\zeta_k\\) と \\(\\epsilon_k\\) の二つの誤差項のためであることが明らかになった。この関係を可視化したものが Figure 4.2 である。ランダム効果モデルの重要な前提は、\\(\\zeta_k\\) の大きさは、\\(k\\) から独立していることことである。つまり、ある研究の \\(\\zeta_k\\) が他の研究の \\(\\zeta_k\\) よりも高いことを事前に示すものは何もないと仮定する。また、\\(\\zeta_k\\) のサイズは偶然の産物だけであると仮定する。これはランダム効果モデルの交換可能性の仮定として知られている (Julian Higgins, Thompson, Spiegelhalter 2009; Lunn et al. 2012, chap. 10.1)。データを見る前に、ある研究 \\(k\\) で \\(\\zeta_k\\) がどの程度大きいかを知ることができるものがない限り、すべての真の効果量は交換可能であると仮定される。どちらのモデルを使うべきか？実際には、完全に均質な研究のセレクションを見つけることは非常に稀である。これは、ベストプラクティスに従って、PICO (Chapter 1.4.1) で分析範囲をできるだけ正確にしようと思っても同じである。医学や社会科学など多くの分野では、ある程度の研究間異質性が予測されるため、常にランダム効果モデルを用いるのが通例である。固定効果モデルは、研究間異質性を検出できなかった場合 (異質性の検出方法については、Chapter 5 で説明する)、および真の効果が固定であると仮定する十分な理由がある場合にのみ使用することができる。これは、例えば、ある研究の正確な複製だけを検討する場合や、1つの大きな研究の部分集合をメタ分析する場合などである。言うまでもなく、このようなことはめったにないため、固定効果モデルを「実際に」適用することはむしろ稀である。priori にランダム効果モデルを用いるのが通例であるとしても、このアプローチに議論されないわけでもない。ランダム効果モデルは、メタ分析の全体効果を計算する際に、小規模な研究にたいしてより注意を払う (Schwarzer, Carpenter, Rücker 2015, chap. 2.3)。しかし、特に小規模研究はバイアスがかかっていることが多い (Chapter 9.2.1 参照)。そのため、固定効果モデルが望ましいとする意見もある (場合もある) (Poole Greenland 1999; Furukawa, McGuire, Barbui 2003)。Stanley, Doucouliagos, Ioannidis (2022) は同様の指摘をし、いくつかの分野においてはランダム効果モデルよりも、いわゆる “unrestricted weighted least squares” (UWLS) モデルを使うべきだと議論している。\nFigure 4.2: ランダム効果モデルのパラメータを示す図。\n","code":""},{"path":"pooling-es.html","id":"tau-estimators","chapter":"4 効果量のプール","heading":"4.1.2.1 研究間異質性の推定値","text":"ランダム効果モデルに関連する課題は、誤差 \\(\\zeta_k\\) を考慮に入れなければならないことである。これを行うには、真の効果量の分布の分散 を推定する必要がある。この分散は、\\(\\tau^2\\) (タウ２乗) として知られている。いったん \\(\\tau^2\\) の値がわかれば、各効果量の逆分散の重みを決定するときに、研究間の異質性を含めることが可能になる。したがって、ランダム効果モデルでは、各観測の調整済みランダム効果重み \\(w^*_k\\) を計算する。その式は次のようになる。\\[\\begin{equation}\nw^*_k = \\frac{1}{s^2_k+\\tau^2}\n\\tag{4.7}\n\\end{equation}\\]\n調整済みランダム効果重みを用いて、固定効果モデルを用いた場合と同様に、逆分散法を用いてプール効果量を算出する。\\[\\begin{equation}\n\\hat\\theta = \\frac{\\sum^{K}_{k=1} \\hat\\theta_kw^*_k}{\\sum^{K}_{k=1} w^*_k}\n\\tag{4.8}\n\\end{equation}\\]この \\(\\tau^2\\) を推定する方法はいくつかあるが、そのほとんどは手作業で行うには複雑すぎる。しかし、幸運なことに、これらの推定量は {meta} パッケージの関数に実装されており、私たちのために自動的に計算をしてくれるのである。以下は、最も一般的な推定量と、それらが {meta} で参照されるコードのリストである。\nDerSimonian-Laird (\"DL\") 推定法 (DerSimonian Laird 1986)。制限付き最尤推定 (Restricted Maximum Likelihood, \"REML\") または最尤推定 (Maximum Likelihood, \"ML\") 法 (Viechtbauer 2005)。Paule-Mandel (\"PM\") 法 (Paule Mandel 1982)。Paule-Mandel 法と実質的に同じである Empirical Bayes (\"EB\") 法 (Sidik Jonkman 2019)。Sidik-Jonkman (\"SJ\") 推定量 (Sidik Jonkman 2005)。これらの推定量のうち、どの推定量が異なる種類のデータに対して最も有効であるかは、現在進行中の研究課題である。研究数 \\(k\\)、各研究の参加者数 \\(n\\)、研究ごとに \\(n\\) がどの程度異なるか、\\(\\tau^2\\) がどの程度大きいかなどのパラメータに依存することが多い。このような様々なシナリオの下での \\(\\tau^2\\) 推定量のバイアスを分析した研究がいくつかある (Veroniki et al. 2016; Viechtbauer 2005; Sidik Jonkman 2007; Langan et al. 2019)。\nおそらく、最もよく使われている推定量は、DerSimonian Laird によるものであろう。この推定量は、RevMan (Cochraneが開発したプログラム) や Comprehensive Meta-Analysis など、過去にメタ分析者がよく使用したソフトウェアに実装されている。また、{meta} でもデフォルトの推定量として使用されている。この歴史的な遺産により、「ランダム効果モデルの使用」が DerSimonian-Laird 推定量の使用と同義で使用されている研究論文をよく見かける。しかし、特に研究数が少なく異質性が高い場合、この推定量に偏りが生じることが分かっている (Hartung 1999; Hartung Knapp 2001a, 2001b; Follmann Proschan 1999; Makambi 2004)。研究数が少なく異質性の高いメタ分析はよくあることなので、これはかなり問題である。\nVeroniki ら (2016) は、概要論文において、様々な\\(\\tau^2\\)推定量の頑健性に関するエビデンスをレビューしている。彼らは、二値・連続効果量のデータには Paule-Mandel 法を、連続アウトカムには制限付き最尤推定量を推奨している。制限付き最尤推定量は、 {metafor} パッケージで使用されるデフォルトの方法でもある。Langan ら (2019) による最近のシミュレーション研究でも同様の結果が得られているが、研究のサンプルサイズが大きく異なる場合、Paule-Mandel 推定量は最適でない可能性があることが分かっている。また、Bakbergenuly ら (2020) の研究では、特に研究数が少ない場合には Paule-Mandel 推定量がよく適していることが分かっている。Sidik-Jonkman 推定量は、モデル誤差分散法としても知られているが、\\(\\tau^2\\)が非常に大きい場合のみ適している (Sidik Jonkman 2007)。どの推定法を使うべきか？どの推定法を使うべきかという鉄則はない。多くの場合，様々な推定量によって得られる結果にはわずかな違いしかないので，この問題はあまり気にする必要はないだろう．疑いがあれば、いつでも異なる \\(\\tau^2\\) 推定量を使って分析を再実行し、結果の解釈が変わるかどうかを確認することができる。以下は、メタ分析における暫定的なガイドライン。連続的なアウトカムデータに基づく効果量については、まず制限付き最尤推定量を使用することができる。連続的なアウトカムデータに基づく効果量については、まず制限付き最尤推定量を使用することができる。バイナリ効果量のデータでは、サンプルサイズに極端なばらつきがなければ、最初に Paule-Mandel 推定量を選択すると良い。バイナリ効果量のデータでは、サンプルサイズに極端なばらつきがなければ、最初に Paule-Mandel 推定量を選択すると良い。サンプル内の効果の不均一性が非常に大きいと信じる十分な理由があり、偽陽性を避けることが非常に高い優先度を持つ場合、Sidik-Jonkman推定量を使用することができる。サンプル内の効果の不均一性が非常に大きいと信じる十分な理由があり、偽陽性を避けることが非常に高い優先度を持つ場合、Sidik-Jonkman推定量を使用することができる。他の人があなたの結果を R 外でできるだけ正確に再現できるようにしたい場合は、DerSimonian-Laird 推定量が選択される方法である。他の人があなたの結果を R 外でできるだけ正確に再現できるようにしたい場合は、DerSimonian-Laird 推定量が選択される方法である。全体として、\\(\\tau^2\\) の推定量は2つのカテゴリに分類される。DerSimonian-Laird や Sidik-Jonkman の推定量のように、閉形式に基づくものもある。つまり、数式を使って直接計算することが可能である。(制限付き) 最尤推定量、Paule-Mandel推定量、経験的ベイズ推定量は、繰り返しアルゴリズムによって \\(\\tau^2\\) の最適値を見つける。そのため、後者の推定量では、計算結果が少し長くなることがある。しかし、ほとんどの場合、このような時間の差はせいぜいわずかなものである。","code":""},{"path":"pooling-es.html","id":"knapp-hartung","chapter":"4 効果量のプール","heading":"4.1.2.2 Knapp-Hartung 調整法","text":"\nまた、\\(\\tau^2\\) 推定量の選択に加えて、いわゆる Knapp-Hartung 調整法20を適用するかどうかを決定しなければならない (Knapp Hartung 2003; Sidik Jonkman 2002)。この調整は、プール効果量 \\(\\hat\\theta\\) の標準誤差 (したがって信頼区間) の計算方法に影響する。Knapp-Hartung 調整法は、研究間異質性の推定値の不確実性を対照しようとするものである。プール効果の有意性検定が通常、正規分布を仮定するのに対して (いわゆる Wald 型 検定)、Knapp-Hartung 法は \\(t\\) 分布に基づいている。Knapp-Hartung の調整はランダム効果モデルでのみ使用でき、通常、プール効果の信頼区間がわずかに大きくなる。\nメタ分析においてモデルの種類を報告\n\nメタ分析を報告する場合、Methods\nセクションに、使用したモデルの種類を明記することを強く勧める。以下はその例である。(訳注:\n英文論文を書くことを想定しているため、以下は訳さずそのままとしている。)\n\n“anticipated considerable -study heterogeneity, \nrandom-effects model used pool effect sizes. restricted\nmaximum likelihood estimator (Viechtbauer, 2005) used calculate\nheterogeneity variance \\(\\tau^2\\).\nused Knapp-Hartung adjustments (Knapp & Hartung, 2003) \ncalculate confidence interval around pooled effect.”\nKnapp-Hartung調整を適用することは通常賢明である。いくつかの研究 (IntHout, Ioannidis, Borm 2014; Langan et al. 2019) は、特に研究数が少ない場合に、これらの調整によって偽陽性の可能性を減らすことができることを示す。しかし、Knapp-Hartung調整の使用は議論の余地がないわけではない。例えば、Wiksten ら (2016) は、効果が非常に均質な場合、この方法は (滅多にない) 反保守的な結果を引き起こすことがあると論じている。","code":""},{"path":"pooling-es.html","id":"pooling-es-r","chapter":"4 効果量のプール","heading":"4.2 R で効果量をプール","text":"学んだことを実践する時が来た。この章の残りの部分では、 R で直接、異なる効果量のメタ分析を実行する方法を探る。このために使用する {meta} パッケージは特別な構造を持っている。メタ分析関数がいくつか含まれており、それぞれが効果量のデータの1つのタイプに焦点を当てている。例えば、固定効果モデルかランダム効果モデルか、どの \\(\\tau^2\\) 推定量を使うか、などである。それとは別に、特定の種類のデータにのみ関連するメタ分析の詳細を調整することができる関数固有の引数がある。Figure 4.3 は、 {meta} の構造を概観したものである。どの関数を使うかを決めるには、まず、どのような効果量データを合成したいのかを明確にする必要がある。最も基本的な区別は、生 (raw) と 事前計算済み (pre-calculated) 効果量データの間のものである。「生」のデータとは、目的の効果量を計算するために必要なすべての情報がデータフレームに格納されているが、実際の効果量はまだ計算されていない場合を指す。先ほど使用した SuicidePrevention データセットには、標準化平均差を計算するために必要な2つのグループの平均、標準偏差、サンプルサイズという生データが含まれている。一方、効果量データには、各研究の最終的な効果量と標準誤差がすでに含まれており、これを「事前計算済み」と呼んでいる。効果指標の補正版 (例えば、Hedges’ \\(g\\)、Chapter 3.4.1) を使用したい場合、プールを始める前に、既に計算済みの効果量データにこの補正が適用されていることが必要である。\nFigure 4.3: メタ分析に関する関数の概略図\n可能であれば、メタ分析には生データを使用することが望ましい。そうすれば、他の人が効果量の計算方法を理解し、結果を再現することが容易になる。しかし、研究結果は異なる方法で報告されることが多いため、実際には生データを使用できないことが多い (Chapter 3.5.1)。このため、各研究の望ましい効果量をすぐに事前計算して、すべての形式が同じになるようにする以外に方法がない。本書の「各種ツール」の Chapter 17 では、報告された効果量を目的のメトリックに変換するのに役立つ公式を紹介している。あらかじめ計算された効果量に対応する関数として、 metagen がある。この名前は、 generic inverse variance meta-analysis の略である。もし、二値データ (割合、リスク比、オッズ比など) で metagen を使用する場合は、 Chapter 3.3.2 で説明したように、この関数を使用する前に効果量を対数変換しておくことが重要である。生の効果量データに頼ることができる場合、 {meta} はそれぞれの効果量タイプに特化した関数を提供する。平均、(標準化) 平均差、相関には、それぞれ metamean , metacont , metacor 関数を使用可能である。 metarate , metaprop , metainc 関数を用いて、(発生) 率、割合、発生率比をプールすることが可能である。 metabin 関数は、リスク比やオッズ比を扱うときに使用する。{meta} のメタ分析関数はすべて同じ構造を持っている。効果量のデータ (生データまたは計算済みデータ) と、解析の詳細を制御するための引数を関数に与えなければならない。各関数で指定可能なコア引数は6つである。studlab. この引数は、各効果量に 研究ラベル を関連付ける。もし、データセットに研究名や著者が保存されている場合は、それぞれの列の名前を指定するだけである (例: studlab =  author)。sm. この引数は、メタ分析で使用する効果量の指標である要約手法を制御する。このオプションは、生の効果量データを使用する関数で特に重要である。 {meta} パッケージは、例えば \"SMD\" や \"\" など、異なる効果量のフォーマットに対するコードを使用する。利用できる要約尺度は各関数で同じではないので、以下のセクションでそれぞれのケースで最も一般的な選択肢を説明する。fixed. この引数に論理値 (TRUE または FALSE) を与える必要があり、固定効果モデルのメタ分析を計算するかどうかを示す21。random. 同様の方法で、この引数はランダム効果モデルを使用するかどうかを制御する。もし comb.fixed とcomb. random の両方が TRUE に設定されていると、両方のモデルが計算されて表示される22。method.tau. この引数は \\(\\tau^2\\) 推定量を定義する。全ての関数は、前の章で既に紹介した異なる推定量のコードを使用する (例えば、DerSimonian-Laird 法の場合: method.tau = \"DL\")。hakn. これはまた別の論理的な引数で、ランダム効果モデルを使用する際に、Knapp-Hartung 調整を適用するかどうかを制御する。data. この引数では、メタ分析データセットの名前を {meta} で指定する。title (必須ではない). この引数には、解析の名前を文字列で指定する。この引数への入力は必須ではないが、後で分析結果を特定するのに役立つ。また、いくつかの追加の引数もあるが、それは後の章で知ることになる。このガイドでは、 {meta} 関数の引数は100以上あるので、すべての引数を説明することはできない。ありがたいことに、これらの引数のほとんどはほとんど必要なく、また賢明なデフォルト値が設定されている。疑問がある場合は、 R コンソールで関数名の前にクエスチョンマーク (例: ?metagen) を付けて実行すると、関数のドキュメントを開くことが可能である。\n\nデフォルトの引数とポジションマッチング\n\nR\nの初心者にとって、関数におけるデフォルト引数と位置ベースのマッチングについて学んでおくと良い。\n\nデフォルトの引数は、関数を書いた人が指定したものである。関数では引数をあらかじめ定義された値に設定し、別の値を明示的に指定しない限り自動的に使用される。{meta}\nでは、すべての引数ではないが、多くの引数がデフォルト値を持っている。\n\nデフォルト値は、関数ドキュメントの「使用法」のセクションに表示される。関数が引数のデフォルト値を定義している場合、デフォルトの動作に満足できない場合を除き、関数呼び出しに含める必要はない。\n\nデフォルト値がない引数は、常に関数呼び出しの中で指定する必要がある。{meta}\nパッケージには gs\nという便利な関数があり、これを使うことで特定の引数に使われるデフォルト値を確認することができる。例えば、\ngs(“method.tau”)\nを実行してみよう。もし、デフォルト値がなければ、 gs は\nNULL を返す。\n\nR\n関数のもう一つの興味深い点は、ポジション・マッチングである。通常、関数を呼び出す際には、引数の名前とその値を書かなければならない。しかし、ポジション・マッチングを使えば、引数の名前を書かずに、引数の値だけを入力すればよい。これは、引数をドキュメントに登場するのと同じ\n位置 で指定すれば可能である。\n\n例えば、sqrt\n関数を考えてみよう。この関数を書き出すと、sqrt(x = 4)\nとなる。しかし、数値である x\nが最初の引数であることが分かっているので、単に sqrt(4)\nとタイプしても同じ結果になる。\n","code":""},{"path":"pooling-es.html","id":"pre-calculated-es","chapter":"4 効果量のプール","heading":"4.2.1 事前算出された効果量のデータ","text":"それでは、メタ分析関数のツアーを metagen から始めよう。これまで学んだように、この関数は事前に計算された効果量のデータに使用することが可能である。最初の例では、この関数を使用して ThirdWave データセットのメタ分析を実行する。\nこのデータセットには、いわゆる “Third Wave” の心理療法が大学生の知覚ストレスに及ぼす影響を調べた研究が含まれている。各研究について、試験後における治療群と対照群の標準化平均差を計算し、小サンプル補正を適用する。したがって、このメタ分析で使用される効果量の指標は、Hedges’ \\(g\\)である。それでは、データを見てみよう。\n“ThirdWave” データセット\n\nThirdWave のデータセットも {dmetar}\nパッケージに直接含まれている。{dmetar}\nをインストールし、ライブラリからロードした後、\ndata(SuicidePrevention) を実行すると、自動的に R\n環境にデータセットが保存される。これでデータセットが利用できる。もし、{dmetar}\nがインストールされていない場合は、インターネットから\n.rda\nファイルとしてデータセットをダウンロードして作業ディレクトリに保存し、R\nStudio ウィンドウでクリックするとインポートすることができる。\nこのデータセットには8つの列があり、そのうち最も重要なのは Author、TE 、seTE であることがわかる。TE 列は各研究の \\(g\\) 値、 seTE は \\(g\\) の標準誤差を表している。その他の列は、各研究が該当するサブグループカテゴリを記述する変数を表す。これらの変数は今のところ関係ない。これで、どのようなメタ分析を行いたいかを考え始めることが可能である。サブグループの列を見ると、少なくともバイアスリスク、対照群、介入期間、介入タイプ、実施形態に関して研究が異なっていることがわかる。このことから、研究間の異質性が予想され、すべての研究の真の効果が一定であると仮定することは意味がないことがよくわかる。したがって、私たちはプールのためにランダム効果モデルを使用することができる。連続アウトカムデータでのロバストなパフォーマンスから、この例では制限付き最尤推定量(\"REML\") を選択する。また、偽陽性結果のリスクを減らすために Knapp-Hartung 調整を使用する。基本的な疑問が解決されたので、metagen の呼び出し方法もかなり簡単になる。この関数を使用する際には、必ず指定しなければならない関数固有の引数が2つある。TE. 計算された効果量が含まれるデータセットの列の名前である。TE. 計算された効果量が含まれるデータセットの列の名前である。seTE. 効果量の標準誤差が格納される列の名前。seTE. 効果量の標準誤差が格納される列の名前。残りは、前章ですでに取り上げた一般的な {meta} 引数である。この解析では標準化平均差を扱うので、sm = \"SMD\" も指定している。しかし、この例では、効果量がすでに各研究で計算されているので、これは結果に対して実際の効果はない。出力で効果量を SMD としてラベル付けするように関数に指示すだけである。これで metagen の最初の呼び出しを設定するのに必要なすべての情報が得られた。この関数の結果を m.gen というオブジェクトに格納する。これで m.gen オブジェクトにすべてのメタ分析結果が格納された。概要を知る簡単な方法は summary 関数を使うことである23。さあ、R を使った最初のメタ分析の結果である。解き明かすことがたくさんあるので、順を追って出力を見ていきよう。出力の最初の部分には、個々の研究、その効果量と信頼区間が含まれている。効果は事前に計算されているので、ここで見るべき新しいものはあまりない。%W(random) 列は、ランダム効果モデルが各研究に帰着させた重み (パーセント) を示している。メタ分析では、de Vibe の研究が 7.9% と最も大きな重みを占めていることがわかる。最小の重みは Ratanasiripong による研究に与えられている。この研究の信頼区間を見ると、なぜこのような結果になったのかがわかる。プールされた効果の信頼区間は非常に広く、標準誤差が非常に大きく、したがってこの研究の効果量の推定はあまり正確ではないことを意味している。出力の最初の部分には、個々の研究、その効果量と信頼区間が含まれている。効果は事前に計算されているので、ここで見るべき新しいものはあまりない。%W(random) 列は、ランダム効果モデルが各研究に帰着させた重み (パーセント) を示している。メタ分析では、de Vibe の研究が 7.9% と最も大きな重みを占めていることがわかる。最小の重みは Ratanasiripong による研究に与えられている。この研究の信頼区間を見ると、なぜこのような結果になったのかがわかる。プールされた効果の信頼区間は非常に広く、標準誤差が非常に大きく、したがってこの研究の効果量の推定はあまり正確ではないことを意味している。さらに、メタ分析に含まれる研究の総数も出力される。\\(K=\\) 18件の研究が組み合わされたことがわかる。さらに、メタ分析に含まれる研究の総数も出力される。\\(K=\\) 18件の研究が組み合わされたことがわかる。次節では、その中核となるプール効果量を示す。推定値は約 0.58 であり、95%信頼区間は約 0.38～0.78 であることがわかる。また、効果量が有意であるかどうかの検定結果も示されている。その結果、\\(p<\\) 0.001 となった。重要なのは、関連する検定統計量も表示されることで、これは t で表示される。これは、\\(t\\) 分布に基づく Knapp-Hartung 調整を適用する。次節では、その中核となるプール効果量を示す。推定値は約 0.58 であり、95%信頼区間は約 0.38～0.78 であることがわかる。また、効果量が有意であるかどうかの検定結果も示されている。その結果、\\(p<\\) 0.001 となった。重要なのは、関連する検定統計量も表示されることで、これは t で表示される。これは、\\(t\\) 分布に基づく Knapp-Hartung 調整を適用する。その下に、研究間異質性に関する結果が表示されている。ここで表示される結果のいくつかについては、後の章で詳しく説明するので、ここでは \\(\\tau^2\\) にのみ注目しよう。\\(\\tau^2\\) の横には、真の効果の分散の推定値 \\(\\tau^2\\) = 0.08 が表示されている。\\(\\tau^2\\) の信頼区間は0を含まないので (0.03–0.35)、\\(\\tau^2\\) は0より有意に大きいことがわかる。これらのことから、私たちのデータには研究間の異質性が存在し、ランダム効果モデルが良い選択であったことがわかる。その下に、研究間異質性に関する結果が表示されている。ここで表示される結果のいくつかについては、後の章で詳しく説明するので、ここでは \\(\\tau^2\\) にのみ注目しよう。\\(\\tau^2\\) の横には、真の効果の分散の推定値 \\(\\tau^2\\) = 0.08 が表示されている。\\(\\tau^2\\) の信頼区間は0を含まないので (0.03–0.35)、\\(\\tau^2\\) は0より有意に大きいことがわかる。これらのことから、私たちのデータには研究間の異質性が存在し、ランダム効果モデルが良い選択であったことがわかる。最後のセクションは、メタ分析についての詳細である。逆分散法を用いて効果をプールしたこと、制限付き最尤推定量を用いたこと、Knapp-Hartung 調整を適用したことなどがわかる。最後のセクションは、メタ分析についての詳細である。逆分散法を用いて効果をプールしたこと、制限付き最尤推定量を用いたこと、Knapp-Hartung 調整を適用したことなどがわかる。また、 m.gen に格納されている情報にも直接アクセス可能である。メタ分析の結果である {meta} には、たくさんのオブジェクトがデフォルトで格納されており、ドキュメントの “value” セクションを見れば、これが何を意味しているかが分かる。また、 $ 演算子を使って、特定の分析結果を表示すことが可能である。例えば、プール効果は TE.random として格納される。fixed =  FALSE を指定した場合でも、 {meta} の関数は常に内部で固定効果モデルの結果も計算している。そのため、固定効果モデルを仮定したプール効果にもアクセスすることが可能である。この推定値はランダム効果モデルの結果とはかなり乖離していることがわかる。分析の詳細を変更したい場合、 update.meta 関数が役に立つ。この関数は、入力として {meta} オブジェクトと、変更したい引数を必要とする。例えば、制限付き最尤推定量の代わりに Paule-Mandel を使用した場合に結果が大きく異なるかどうかをチェックしたいとする。このコードを使ってそれを行うことが可能である。プール効果はあまり変わらないが、Paule-Mandel 推定量では、\\(\\tau^2\\)の近似値がやや大きくなることがわかる。最後に、結果を保存しておくと後々便利である。 {meta} で生成されたオブジェクトは、save 関数を使って簡単に .rda ( R data) ファイルとして保存することが可能である。","code":"\nlibrary(tidyverse) # 'glimpse' に必要\nlibrary(dmetar)\nlibrary(meta)\n\ndata(ThirdWave)\nglimpse(ThirdWave)## Rows: 18\n## Columns: 8\n## $ Author               <chr> \"Call et al.\", \"Cavanagh et al.\", \"DanitzOrsillo\"…\n## $ TE                   <dbl> 0.7091362, 0.3548641, 1.7911700, 0.1824552, 0.421…\n## $ seTE                 <dbl> 0.2608202, 0.1963624, 0.3455692, 0.1177874, 0.144…\n## $ RiskOfBias           <chr> \"high\", \"low\", \"high\", \"low\", \"low\", \"low\", \"high…\n## $ TypeControlGroup     <chr> \"WLC\", \"WLC\", \"WLC\", \"no intervention\", \"informat…\n## $ InterventionDuration <chr> \"short\", \"short\", \"short\", \"short\", \"short\", \"sho…\n## $ InterventionType     <chr> \"mindfulness\", \"mindfulness\", \"ACT\", \"mindfulness…\n## $ ModeOfDelivery       <chr> \"group\", \"online\", \"group\", \"group\", \"online\", \"g…\nm.gen <- metagen(TE = TE,\n                 seTE = seTE,\n                 studlab = Author,\n                 data = ThirdWave,\n                 sm = \"SMD\",\n                 fixed = FALSE,\n                 random = TRUE,\n                 method.tau = \"REML\",\n                 hakn = TRUE,\n                 title = \"Third Wave Psychotherapies\")\nsummary(m.gen)## Review:     Third Wave Psychotherapies\n##                       SMD            95%-CI %W(random)\n## Call et al.        0.7091 [ 0.1979; 1.2203]        5.0\n## Cavanagh et al.    0.3549 [-0.0300; 0.7397]        6.3\n## DanitzOrsillo      1.7912 [ 1.1139; 2.4685]        3.8\n## de Vibe et al.     0.1825 [-0.0484; 0.4133]        7.9\n## Frazier et al.     0.4219 [ 0.1380; 0.7057]        7.3\n## Frogeli et al.     0.6300 [ 0.2458; 1.0142]        6.3\n## Gallego et al.     0.7249 [ 0.2846; 1.1652]        5.7\n## Hazlett-Steve…     0.5287 [ 0.1162; 0.9412]        6.0\n## Hintz et al.       0.2840 [-0.0453; 0.6133]        6.9\n## Kang et al.        1.2751 [ 0.6142; 1.9360]        3.9\n## Kuhlmann et al.    0.1036 [-0.2781; 0.4853]        6.3\n## Lever Taylor…      0.3884 [-0.0639; 0.8407]        5.6\n## Phang et al.       0.5407 [ 0.0619; 1.0196]        5.3\n## Rasanen et al.     0.4262 [-0.0794; 0.9317]        5.1\n## Ratanasiripong     0.5154 [-0.1731; 1.2039]        3.7\n## Shapiro et al.     1.4797 [ 0.8618; 2.0977]        4.2\n## Song & Lindquist   0.6126 [ 0.1683; 1.0569]        5.7\n## Warnecke et al.    0.6000 [ 0.1120; 1.0880]        5.2\n## \n## Number of studies combined: k = 18\n## \n##                         SMD           95%-CI    t  p-value\n## Random effects model 0.5771 [0.3782; 0.7760] 6.12 < 0.0001\n## \n## Quantifying heterogeneity:\n##  tau^2 = 0.0820 [0.0295; 0.3533]; tau = 0.2863 [0.1717; 0.5944];\n##  I^2 = 62.6% [37.9%; 77.5%]; H = 1.64 [1.27; 2.11]\n## \n## Test of heterogeneity:\n##      Q d.f. p-value\n##  45.50   17  0.0002\n## \n## Details on meta-analytical method:\n## - Inverse variance method\n## - Restricted maximum-likelihood estimator for tau^2\n## - Q-profile method for confidence interval of tau^2 and tau\n## - Hartung-Knapp adjustment for random effects model\n\nm.gen$TE.random## [1] 0.5771158\nm.gen$TE.fixed## [1] 0.4805045\nm.gen_update <- update.meta(m.gen, \n                            method.tau = \"PM\")\n\n# Get pooled effect\nm.gen_update$TE.random## [1] 0.5873544\n# Get tau^2 estimate\nm.gen_update$tau2## [1] 0.1104957\nsave(m.gen, file = \"path/to/my/meta-analysis.rda\") # example path"},{"path":"pooling-es.html","id":"pooling-smd","chapter":"4 効果量のプール","heading":"4.2.2 (標準化) 平均差","text":"\n2つの群の平均と標準偏差の形式で表される生の効果量データは、 metacont を使ってプールすることが可能である。この関数は、標準化された群間平均差と標準化されていない群間平均差の両方に使用することが可能である。これらは sm = \"SMD\" または sm = \"MD\" を指定することで得ることが可能である。それ以外では、7つの関数固有の引数を指定する必要がある。n.e. 治療・実験群の観測数。n.e. 治療・実験群の観測数。mean.e. 治療・実験群における平均値。mean.e. 治療・実験群における平均値。sd.e. 治療・実験群における標準偏差。sd.e. 治療・実験群における標準偏差。n.c. 対照群の観測数。n.c. 対照群の観測数。mean.c. 対照群の平均値。mean.c. 対照群の平均値。sd.c. 対照群の標準偏差。sd.c. 対照群の標準偏差。method.smd. これは sm = \"SMD\" のときのみ関係する。 metacont 関数では、3種類の標準化平均差を計算することが可能である。 metacont 関数では、3種類の標準化平均差を計算することが可能である。 method.smd = \"Cohen\" と設定すると、補正されていない標準化平均差 (Cohen’s \\(d\\)) が効果量指標として使用される。他の2つのオプションは、Hedges’ \\(g\\) を計算する \"Hedges\" (デフォルトと推奨) と、Glass’ \\(\\Delta\\) (「デルタ」と読む) を計算する \"Glass\" である。Glass’ \\(\\Delta\\)は、平均差を標準化するために、プールされた標準偏差の代わりに対照群の標準偏差を使用する。この効果量は、一次研究で複数の治療群がある場合に使われることがあるが、通常、メタ分析では好まれない指標である。method.smd. これは sm = \"SMD\" のときのみ関係する。 metacont 関数では、3種類の標準化平均差を計算することが可能である。 metacont 関数では、3種類の標準化平均差を計算することが可能である。 method.smd = \"Cohen\" と設定すると、補正されていない標準化平均差 (Cohen’s \\(d\\)) が効果量指標として使用される。他の2つのオプションは、Hedges’ \\(g\\) を計算する \"Hedges\" (デフォルトと推奨) と、Glass’ \\(\\Delta\\) (「デルタ」と読む) を計算する \"Glass\" である。Glass’ \\(\\Delta\\)は、平均差を標準化するために、プールされた標準偏差の代わりに対照群の標準偏差を使用する。この効果量は、一次研究で複数の治療群がある場合に使われることがあるが、通常、メタ分析では好まれない指標である。今回の分析例では、Chapter 2.4 と Chapter 4.1.1 で扱った “SuicidePrevention” データセットを再利用している。サンプルに含まれるすべての研究が完全に同一ではないので、ランダム効果モデルを使用することが保証される。また、Knapp-Hartung 調整と\\(\\tau^2\\)の制限付き最尤推定量も再び使用する予定である。 metacont にスモールサンプルバイアスを補正するように指示し、効果量のメトリックとしてHedges’ \\(g\\) を生成する。結果はオブジェクトに保存され、 m.cont と名付ける。全体としては、このようなコードになる。その結果を見てみよう。この出力を見て、Chapter 4.2.1 で受け取った出力と比較すると、すでに {meta} の最大の資産の1つが見えている。すなわち、metagen や metacont とは異なるデータ型を必要とする異なる関数であるが、出力の構造はほぼ同じように読むことができる。このため、結果の解釈は非常に容易である。ランダム効果モデルによるプール効果は \\(g=\\) -0.23 であり、95%信頼区間は -0.09 から -0.37 の範囲であることがわかる。この効果は有意である (\\(p=\\) 0.006)。効果量が負の符号を持つことがわかる。このメタ分析の文脈では、好ましいアウトカムであることを表し、対照群と比較して治療群で自殺念慮がより低かったことを意味する。これを他の人にわかりやすくするために、効果量の符号を一貫して逆にし (たとえば、代わりに \\(g=\\) 0.23 と書く)、正の効果量が常に「正の」結果を表すようにしてもよいだろう。制限付き最尤法では、研究間の異質性分散は \\(\\tau^2\\) = 0.004と推定される。\\(\\tau^2\\) 値を見ると、信頼区間は0を含んでおり、真の効果量の分散は0より有意に大きくないことがわかる。詳細では、効果量の指標としてHedges’ \\(g\\) が使われたことが示されている。","code":"\n# meta と dmetar がロードされていることを確認\nlibrary(meta)\nlibrary(dmetar)\nlibrary(meta)\n\n# dmetar からデータセットをロード (またはネットからダウンロードし自分で開く)\ndata(SuicidePrevention)\n\n# metcont を使って結果をプール。\nm.cont <- metacont(n.e = n.e,\n                   mean.e = mean.e,\n                   sd.e = sd.e,\n                   n.c = n.c,\n                   mean.c = mean.c,\n                   sd.c = sd.c,\n                   studlab = author,\n                   data = SuicidePrevention,\n                   sm = \"SMD\",\n                   method.smd = \"Hedges\",\n                   fixed = FALSE,\n                   random = TRUE,\n                   method.tau = \"REML\",\n                   hakn = TRUE,\n                   title = \"Suicide Prevention\")\nsummary(m.cont)## Review:     Suicide Prevention\n## \n##                     SMD             95%-CI %W(random)\n## Berry et al.    -0.1428 [-0.4315;  0.1459]       15.6\n## DeVries et al.  -0.6077 [-0.9402; -0.2752]       12.3\n## Fleming et al.  -0.1112 [-0.6177;  0.3953]        5.7\n## Hunt & Burke    -0.1270 [-0.4725;  0.2185]       11.5\n## McCarthy et al. -0.3925 [-0.7884;  0.0034]        9.0\n## Meijer et al.   -0.2676 [-0.5331; -0.0021]       17.9\n## Rivera et al.    0.0124 [-0.3454;  0.3703]       10.8\n## Watkins et al.  -0.2448 [-0.6848;  0.1952]        7.4\n## Zaytsev et al.  -0.1265 [-0.5062;  0.2533]        9.7\n## \n## Number of studies: k = 9\n## Number of observations: o = 1147\n## \n##                          SMD             95%-CI     t p-value\n## Random effects model -0.2304 [-0.3734; -0.0874] -3.71  0.0059\n## \n## Quantifying heterogeneity:\n##  tau^2 = 0.0044 [0.0000; 0.0924]; tau = 0.0661 [0.0000; 0.3040]\n##  I^2 = 7.4% [0.0%; 67.4%]; H = 1.04 [1.00; 1.75]\n## \n## Test of heterogeneity:\n##     Q d.f. p-value\n##  8.64    8  0.3738\n## \n## Details on meta-analytical method:\n## - Inverse variance method\n## - Restricted maximum-likelihood estimator for tau^2\n## - Q-Profile method for confidence interval of tau^2 and tau\n## - Hartung-Knapp adjustment for random effects model (df = 8)\n## - Hedges' g (bias corrected standardised mean difference; using exact formulae)"},{"path":"pooling-es.html","id":"二値アウトカム","chapter":"4 効果量のプール","heading":"4.2.3 二値アウトカム","text":"","code":""},{"path":"pooling-es.html","id":"pooling-or-rr","chapter":"4 効果量のプール","heading":"4.2.3.1 リスク比とオッズ比","text":"\nmetabin 関数は、二値データ、特にリスク比 (Risk Ratio, RR) とオッズ比 (Odds Ratio, ) に基づく効果量をプールするために使用することが可能である。この関数を使い始める前に、まず、これらの効果量に基づくメタ分析について、いくつかの特殊性を議論する必要がある。Chapter 4.1.1 と Chapter 4.1.2.1 で取り上げた一般的な逆分散 (generic inverse variance) 法を用いて、二値の効果量をプールすることが可能である。各効果の対数オッズ比または対数リスク比、および標準誤差を計算する必要があり、その後、効果量の分散の逆数を使用してプーリング重みを決定することが可能である。しかし、この方法は二値アウトカムのデータには最適ではない (Julian Higgins et al. 2019, chap. 10.4.1)。薄いデータを扱っているとき、すなわちイベント数または総サンプルサイズが小さいとき、標準誤差は二値効果量の推定値としては精度が高くない可能性がある。","code":""},{"path":"pooling-es.html","id":"mantel-haenszel","chapter":"4 効果量のプール","heading":"4.2.3.1.1 Mantel-Haenszel法","text":"このため、Mantel-Haenszel 法 (Mantel Haenszel 1959; Robins, Greenland, Breslow 1986) は、二値アウトカム・データを持つ研究の重みを計算する代替手段としてよく使用されている。また、metabin で使用されるデフォルトのアプローチでもある。この方法は、研究の重みを決定するために、治療と対照群におけるイベントと非イベントの数を使用する。リスク比とオッズ比の計算は、それぞれ以下の式で求められる。リスク比:\\[\\begin{equation}\nw_k = \\frac{(a_k+b_k) c_k}{n_k}\n\\tag{4.9}\n\\end{equation}\\]オッズ比:\\[\\begin{equation}\nw_k = \\frac{b_kc_k}{n_k}\n\\tag{4.10}\n\\end{equation}\\]式中、Chapter 3.3.2.1 と同じく、\\(a_k\\) は治療群のイベント数、\\(c_k\\) は対照群のイベント数、\\(b_k\\) は治療群の非イベント数、\\(d_k\\) は対照群の非イベント数、\\(n_k\\) は全体のサンプルサイズとしている。\n","code":""},{"path":"pooling-es.html","id":"peto-法","chapter":"4 効果量のプール","heading":"4.2.3.1.2 Peto 法","text":"第二のアプローチは、Peto 法 (Yusuf et al. 1985)である。このアプローチの本質は、私たちがすでに知っている逆分散の原則に基づくものである。ただし、特殊な効果量であるPeto オッズ比を使用し、ここでは \\(\\hat\\psi_k\\) (訳注: \\(\\psi\\) は「プサイ」と読む) と表記する。この \\(\\hat\\psi_k\\) を計算するためには、治療群で観測された事象である \\(O_k\\) を知り、治療群の予想例数である \\(E_k\\) を計算する必要がある。\\(O_k-E_k\\)の差を \\(O_k\\) と \\(E_k\\) の差の分散 \\(V_k\\) で割ると、対数変換された \\(\\hat\\psi_k\\) になる。先ほどと同じセル表記で、\\(E_k\\)、\\(O_k\\)、\\(V_k\\)を計算する式は以下の通りである。\\[\\begin{equation}\nO_k = a_k\n\\tag{4.11}\n\\end{equation}\\]\n\\[\\begin{equation}\nE_k = \\frac{(a_k+b_k)(a_k+c_k)}{a_k+b_k+c_k+d_k}\n\\tag{4.12}\n\\end{equation}\\]\\[\\begin{equation}\nV_k = \\frac{(a_k+b_k)(c_k+d_k)(a_k+c_k)(b_k+d_k)}{{(a_k+b_k+c_k+d_k)}^2(a_k+b_k+c_k+d_k-1)}\n\\tag{4.13}\n\\end{equation}\\]\\[\\begin{equation}\n\\log\\hat\\psi_k = \\frac{O_k-E_k}{V_k}\n\\tag{4.14}\n\\end{equation}\\]そして、効果量のプール時には、\\(\\log\\hat\\psi_k\\)の分散の逆数を重みとして用いる24。","code":""},{"path":"pooling-es.html","id":"bakbergenuly-サンプルサイズ法","chapter":"4 効果量のプール","heading":"4.2.3.1.3 Bakbergenuly-サンプルサイズ法","text":"最近、Bakbergenuly ら (2020) は、効果の重みが研究のサンプルサイズだけで決まる別の方法を提案し、この方法が Mantel Haenszel による方法より望ましい可能性があることを示している。これをサンプルサイズ法と呼ぶことにする。この方法の計算式はとても簡単である。治療群と対照群のサンプルサイズ \\(n_{\\text{treat}_k}\\) と \\(n_{\\text{control}_k}\\) だけ分かれば良い。\\[\\begin{equation}\nw_k = \\frac{n_{\\text{treat}_k}n_{\\text{control}_k}}{n_{\\text{treat}_k} + n_{\\text{control}_k} }\n\\tag{4.15}\n\\end{equation}\\]このプール法を metabin に実装すると、固定効果モデルとランダム効果モデルによる重みと全体効果は同じになる。プールされた効果の \\(p\\) 値と信頼区間だけが異なる。\nプール方法はどれを使うべきか？Chapter 3.3.2.1 では、ゼロセルと連続性補正の問題について、すでに詳しく述べた。ゼロセルがある場合、Peto法、サンプルサイズ法ともにそのまま使用できるが、Mantel-Haenszel 法を使用する場合はゼロセルに0.5を加算するのが一般的である。これは metabin のデフォルトの動作でもある。しかし、連続性補正の使用は、バイアスのある結果につながる可能性があるため、推奨されていない (Efthimiou 2018)。Mantel-Haenszel 法は、ある特定のセルが含まれる研究ですべてゼロである場合にのみ本当に連続性補正を必要とするが、そのようなケースはほとんどない。そのため、通常は metabin で MH.exact = TRUE と設定し、連続性補正を行わない exact Mantel-Haenszel 法を使用することが推奨される。Peto 法にも限界がある。まず、オッズ比にしか使用できない。また、シミュレーション研究では、(1) 治療群と対照群の観察数が同程度のとき、(2) 観察された事象が稀なとき (<1%)、\n(3) 治療効果が過度に大きくないときにのみ,\nこの方法がうまく機能することが示された (Bradburn et al. 2007; Sweeting, Sutton, Lambert 2004)。最後に、Bakbergenuly-サンプルサイズ法は、かなり新しい手法であり、他の2つの手法に比べて研究が進んでいない。全体として，ほとんどの場合，コクランの一般的な評価 (Julian Higgins et al. 2019, chap. 10.4) に従い、Mantel-Haenszel 法 (連続性補正なし) を使用することが望ましいと思われる。オッズ比が望ましい効果量の指標であり、関心のある事象が稀であると予想される場合は、Peto 法を用いることができる。","code":""},{"path":"pooling-es.html","id":"ppoolbin","chapter":"4 効果量のプール","heading":"4.2.3.1.4 R における二値効果量のプール","text":"metabin には、8つの重要な関数固有の引数がある。event.e. 治療・実験群におけるイベント数。event.e. 治療・実験群におけるイベント数。n.e. 治療/実験群の観測数。n.e. 治療/実験群の観測数。event.c. 対照群におけるイベント数。event.c. 対照群におけるイベント数。n.c. 対照群の観測数。n.c. 対照群の観測数。method. 使用するプール法。これは、 \"Inverse\" (一般的な逆分散プール)、 \"MH\" (Mantel-Haenszel; デフォルトおよび推奨)、 \"Peto\" (Peto method)、または \"SSW\" (Bakbergenuly-サンプルサイズ法; sm = \"\" 時のみ) のいずれかになる。method. 使用するプール法。これは、 \"Inverse\" (一般的な逆分散プール)、 \"MH\" (Mantel-Haenszel; デフォルトおよび推奨)、 \"Peto\" (Peto method)、または \"SSW\" (Bakbergenuly-サンプルサイズ法; sm = \"\" 時のみ) のいずれかになる。sm. 計算する要約指標 (＝効果量の指標)。リスク比には \"RR\" を、オッズ比には \"\" を使用することができる。sm. 計算する要約指標 (＝効果量の指標)。リスク比には \"RR\" を、オッズ比には \"\" を使用することができる。incr. ゼロセルの連続性補正のために追加する増分を指定する。incr = 0.5 とすれば、0.5 の増分値が加算される。incr = \"TACC\" とすると、治療群連続性補正法が用いられる (Chapter 3.3.2.1参照)。前述したように、通常はこの引数を省略し、連続性補正を適用しないことが推奨される。incr. ゼロセルの連続性補正のために追加する増分を指定する。incr = 0.5 とすれば、0.5 の増分値が加算される。incr = \"TACC\" とすると、治療群連続性補正法が用いられる (Chapter 3.3.2.1参照)。前述したように、通常はこの引数を省略し、連続性補正を適用しないことが推奨される。MH.exact. もし method = \"MH\" ならば、この引数を TRUE に設定し、 Mantel-Haenszel 法の連続性補正を使用しないようにすることが可能である。MH.exact. もし method = \"MH\" ならば、この引数を TRUE に設定し、 Mantel-Haenszel 法の連続性補正を使用しないようにすることが可能である。この実践的な例では、 DepressionMortality データセットを使用する。このデータセットは、Cuijpers Smit (2002) によるメタ分析に基づいており、全死因死亡率に対するうつ病の影響を調査している。このデータセットには、うつ病のある人とない人の数、そして両群の何人が数年後に死亡したかが含まれている。\n“DepressionMortality” データセット\n\nDepressionMortality のデータセットも\n{dmetar}\nパッケージに直接含まれている。{dmetar}\nをインストールし、ライブラリからロードした後、\ndata(SuicidePrevention) を実行すると、自動的に R\n環境にデータセットが保存される。これでデータセットが利用できる。もし、{dmetar}\nがインストールされていない場合は、インターネットから\n.rda\nファイルとしてデータセットをダウンロードして作業ディレクトリに保存し、R\nStudio ウィンドウでクリックするとインポートすることができる。\nまず、データセットを見てみよう。\nこの例では、Cuijpers Smit が行ったように、効果量の指標としてリスク比を計算する。ランダム効果プールモデルを使用し、二値アウトカムデータを扱うので、\\(\\tau^2\\)の Paule-Mandel 推定量を使用する。データを見ると、サンプルサイズが研究によってかなり異なっており、Paule-Mandel 法がややバイアスされる可能性がある (Chapter 4.1.2.1 参照)。これを踏まえて、感度分析として他の \\(\\tau^2\\) 推定量も試してみて、結果が大きく異なるかどうかを確認することも可能である。このデータセットにはゼロセルが含まれていないので、連続性補正の心配はなく、すぐに正確な Mantel-Haenszel 法を使うことができる。メタ分析の結果は m.bin というオブジェクトに保存する。プール効果量はRR \\(=\\) 2.02であることがわかる。このプール効果は有意であり (\\(p<\\) 0.001)、うつ病にかかると死亡リスクが2倍になることを示している。研究間の異質性分散の推定値は、\\(\\tau^2 \\approx\\) 0.19である。また、\\(\\tau^2\\) の信頼区間はゼロを含まず、研究間の実質的な異質性を示している。最後に、出力の詳細セクションを見ると、 metabin 関数は、意図したようにプールに Mantel-Haenszel 法を使用したことがわかる。上記で発表したように、\\(\\tau^2\\) の推定方法が結果に影響を与えるかどうか見てみよう。update.meta 関数を使って、分析を再実行するが、今回は制限付き最尤推定量を使用する。ここで、TE.random を調べて、プールされた効果をもう一度見てみよう。ここで忘れてはならないのは、二値アウトカムのメタ分析は、実際には効果量を対数変換したものを使用して行われるということである。結果を表示す際に、metabin は便宜上、効果量のメトリクスを元の形式に再変換しているだけである。このステップは、メタ分析オブジェクトの要素を検査する場合には実行されていない。対数変換された効果量を再変換するには、その値を指数化する必要がある。指数化は対数変換の「逆関数」であり、 R で exp 関数を使って実行可能である25。これを実際に使ってみよう。制限付き最尤推定量によるプール効果もほぼ同じであることがわかる。次に、\\(\\tau^2\\) の推定値を見てみよう。この値は多少乖離しているが、最初の結果の妥当性を心配するほどではない。metabin の呼び出しは、オッズ比をプールすることにしても、全く同じになる。変更する必要があるのは sm 引数だけで、これは \"\" に設定する必要がある。もう一度関数呼び出し全体を書き出す代わりに、update.meta 関数を再度使用して、プールされた を計算することが可能である。出力では、オッズ比を用いたプール効果はOR = 2.29であることがわかる。","code":"\nlibrary(dmetar)\nlibrary(tidyverse)\nlibrary(meta)\n\ndata(DepressionMortality)\nglimpse(DepressionMortality)## Rows: 18\n## Columns: 6\n## $ author  <chr> \"Aaroma et al., 1994\", \"Black et al., 1998\", \"Bruce et al., 19…\n## $ event.e <dbl> 25, 65, 5, 26, 32, 1, 24, 15, 15, 173, 37, 41, 29, 61, 15, 21,…\n## $ n.e     <dbl> 215, 588, 46, 67, 407, 44, 60, 61, 29, 1015, 105, 120, 258, 38…\n## $ event.c <dbl> 171, 120, 107, 1168, 269, 87, 200, 437, 227, 250, 66, 9, 24, 3…\n## $ n.c     <dbl> 3088, 1901, 2479, 3493, 6256, 1520, 882, 2603, 853, 3375, 409,…\n## $ country <chr> \"Finland\", \"USA\", \"USA\", \"USA\", \"Sweden\", \"USA\", \"Canada\", \"Ne…\nm.bin <- metabin(event.e = event.e, \n                 n.e = n.e,\n                 event.c = event.c,\n                 n.c = n.c,\n                 studlab = author,\n                 data = DepressionMortality,\n                 sm = \"RR\",\n                 method = \"MH\",\n                 MH.exact = TRUE,\n                 fixed = FALSE,\n                 random = TRUE,\n                 method.tau = \"PM\",\n                 hakn = TRUE,\n                 title = \"Depression and Mortality\")\nsummary(m.bin)\n## Review:     Depression and Mortality\n##                           RR        95%-CI %W(random)\n## Aaroma et al., 1994     2.09 [1.41;  3.12]        6.0\n## Black et al., 1998      1.75 [1.31;  2.33]        6.6\n## Bruce et al., 1989      2.51 [1.07;  5.88]        3.7\n## Bruce et al., 1994      1.16 [0.85;  1.57]        6.5\n## Enzell et al., 1984     1.82 [1.28;  2.60]        6.3\n## Fredman et al., 1989    0.39 [0.05;  2.78]        1.2\n## Murphy et al., 1987     1.76 [1.26;  2.46]        6.4\n## Penninx et al., 1999    1.46 [0.93;  2.29]        5.8\n## Pulska et al., 1998     1.94 [1.34;  2.81]        6.2\n## Roberts et al., 1990    2.30 [1.92;  2.75]        7.0\n## Saz et al., 1999        2.18 [1.55;  3.07]        6.3\n## Sharma et al., 1998     2.05 [1.07;  3.91]        4.7\n## Takeida et al., 1997    6.97 [4.13; 11.79]        5.3\n## Takeida et al., 1999    5.81 [3.88;  8.70]        6.0\n## Thomas et al., 1992     1.33 [0.77;  2.27]        5.3\n## Thomas et al., 1992     1.77 [1.10;  2.83]        5.6\n## Weissman et al., 1986   1.25 [0.66;  2.33]        4.8\n## Zheng et al., 1997      1.98 [1.40;  2.80]        6.3\n## \n## Number of studies combined: k = 18\n## \n##                          RR           95%-CI    t  p-value\n## Random effects model 2.0217 [1.5786; 2.5892] 6.00 < 0.0001\n## \n## Quantifying heterogeneity:\n##  tau^2 = 0.1865 [0.0739; 0.5568]; tau = 0.4319 [0.2718; 0.7462];\n##  I^2 = 77.2% [64.3%; 85.4%]; H = 2.09 [1.67; 2.62]\n## \n## Test of heterogeneity:\n##      Q d.f.  p-value\n##  74.49   17 < 0.0001\n## \n## Details on meta-analytical method:\n## - Mantel-Haenszel method\n## - Paule-Mandel estimator for tau^2\n## - Q-profile method for confidence interval of tau^2 and tau\n## - Hartung-Knapp adjustment for random effects model\nm.bin_update <- update.meta(m.bin, \n                            method.tau = \"REML\")\nexp(m.bin_update$TE.random)## [1] 2.02365\nm.bin_update$tau2## [1] 0.1647315\nm.bin_or <- update.meta(m.bin, sm = \"OR\")\nm.bin_or## Review:     Depression and Mortality\n##\n## [...]\n## \n## Number of studies combined: k = 18\n## \n##                          OR           95%-CI    t  p-value\n## Random effects model 2.2901 [1.7512; 2.9949] 6.52 < 0.0001\n## \n## Quantifying heterogeneity:\n##  tau^2 = 0.2032 [0.0744; 0.6314]; tau = 0.4508 [0.2728; 0.7946];\n##  I^2 = 72.9% [56.7%; 83.0%]; H = 1.92 [1.52; 2.43]\n## \n## Test of heterogeneity:\n##      Q d.f.  p-value\n##  62.73   17 < 0.0001\n## \n## Details on meta-analytical method:\n## - Mantel-Haenszel method\n## - Paule-Mandel estimator for tau^2\n## - Q-profile method for confidence interval of tau^2 and tau\n## - Hartung-Knapp adjustment for random effects model"},{"path":"pooling-es.html","id":"m-gen-bin","chapter":"4 効果量のプール","heading":"4.2.3.1.5 事前に計算された二値効果量のプール","text":"各研究のリスク比やオッズ比を計算するために必要な生の効果量のデータを抽出できないことがある。例えば、主要な研究でオッズ比が報告されていても、この効果量の根拠となるデータがない場合がある。著者が元のデータを提供してくれない場合、事前に計算された効果量のデータに基づいてメタ分析を行う必要が出てくるだろう。学習したように、これを行うために使用できる関数は metagen である。二値アウトカムデータを扱うとき、事前に計算された効果量データを使う以外に選択肢がない場合は、本当に注意しなければならない。 metagen 関数は逆分散法を用いて効果量をプールし、Mantel-Haenszel 法のようなより良いオプションは使用できない。しかし、他のすべてがうまくいかない場合には、まだ有効な選択肢である。DepressionMortality のデータセットを使って、事前に計算された効果量のメタ分析を行うシミュレーションをしてみよう。m.bin の TE と seTE オブジェクトを抽出し、各研究の効果量と標準誤差を取得することが可能である。この情報を DepressionMortality データセットに保存する。ここで、信頼区間の下限と上限はわかっているが、標準誤差がわからない効果が1つあると想像してみよう。このようなシナリオをシミュレートするために、(1) 研究7 (Murphy et al., 1987) の標準誤差を欠損と定義し (つまり、その値を NA に設定)、(2) データセットに新しい空の2列、 lower と upper を定義し、(3) lower と upper に研究7で対数変換した「報告」信頼区間を記入することにする。では、先ほど作成したデータを見てみよう。このようなデータセットを見つけることは、実際には珍しいことではない。ほとんどの研究では対数リスク比を計算することができるだろうが、その他のいくつかの研究では、(対数変換した) リスク比とその信頼区間しか情報がないことが多いのである。幸いなことに、 metagen を使用すると、そのようなデータであってもプールすることが可能である。引数 lower と upper には、信頼区間の下限と上限を含む列の名前を指定するだけでよいのである。標準誤差が利用できない場合、 metagen 関数はこの情報を使って効果に重み付けをする。関数の呼び出しは次のようになる。出力では、\\(K=\\) 18 すべての研究がメタ分析で結合できたことがわかる。これは、 metagen が研究7について提供された lower と upper の情報を使用したことを意味する。また、逆分散法を用いた結果は、先ほどの Mantel-Haenszel 法の結果とほぼ同じであることが出力されている。","code":"\nDepressionMortality$TE <- m.bin$TE\nDepressionMortality$seTE <- m.bin$seTE\n# 研究 7 の seTE を NA に設定\nDepressionMortality$seTE[7] <- NA\n\n# 空の列 'lower' と 'upper' を作成\nDepressionMortality[,\"lower\"] <- NA\nDepressionMortality[,\"upper\"] <- NA\n\n# 研究 7 の 'lower' と 'upper' に値を入れる\n# いつものごとく、二値効果量は対数変換が必要\nDepressionMortality$lower[7] <- log(1.26)\nDepressionMortality$upper[7] <- log(2.46)\nDepressionMortality[,c(\"author\", \"TE\", \"seTE\", \"lower\", \"upper\")]##                   author      TE    seTE  lower  upper\n## 1    Aaroma et al., 1994  0.7418 0.20217     NA     NA\n## 2     Black et al., 1998  0.5603 0.14659     NA     NA\n## 3     Bruce et al., 1989  0.9235 0.43266     NA     NA\n## 4     Bruce et al., 1994  0.1488 0.15526     NA     NA\n## 5    Enzell et al., 1984  0.6035 0.17986     NA     NA\n## 6   Fredman et al., 1989 -0.9236 0.99403     NA     NA\n## 7    Murphy et al., 1987  0.5675      NA 0.2311 0.9001\n## 8   Penninx et al., 1999  0.3816 0.22842     NA     NA\n## [...]\nm.gen_bin <- metagen(TE = TE,\n                     seTE = seTE,\n                     lower = lower,\n                     upper = upper,\n                     studlab = author,\n                     data = DepressionMortality,\n                     sm = \"RR\",\n                     method.tau = \"PM\",\n                     fixed = FALSE,\n                     random = TRUE,\n                     title = \"Depression Mortality (Pre-calculated)\")\n\nsummary(m.gen_bin)## Review:     Depression Mortality (Pre-calculated)\n##\n## [...]\n## \n## Number of studies combined: k = 18\n## \n##                          RR           95%-CI    z  p-value\n## Random effects model 2.0218 [1.6066; 2.5442] 6.00 < 0.0001\n## \n## Quantifying heterogeneity:\n##  tau^2 = 0.1865 [0.0739; 0.5568]; tau = 0.4319 [0.2718; 0.7462];\n##  I^2 = 77.2% [64.3%; 85.4%]; H = 2.09 [1.67; 2.62]\n## \n## [...]"},{"path":"pooling-es.html","id":"pooling-irr","chapter":"4 効果量のプール","heading":"4.2.3.2 発生率比","text":"\n発生率 (incidence rate) に基づく効果量 (すなわち、発生率比、Chapter 3.3.3) は、 metainc 関数を使用してプールすることが可能である。この関数の引数は metabin と非常によく似ている。event.e: 治療・実験群におけるイベント数。event.e: 治療・実験群におけるイベント数。time.e: 治療・実験群におけるリスクパーソン時間。time.e: 治療・実験群におけるリスクパーソン時間。event.c: 対照群におけるイベント数。event.c: 対照群におけるイベント数。time.c: 対照群におけるリスクパーソン時間。time.c: 対照群におけるリスクパーソン時間。method: metabin と同様に、デフォルトのプール法は Mantel Haenszel によるもの (\"MH\") である。また、一般的な逆分散プーリング (\"Inverse\") を利用することも可能である。method: metabin と同様に、デフォルトのプール法は Mantel Haenszel によるもの (\"MH\") である。また、一般的な逆分散プーリング (\"Inverse\") を利用することも可能である。sm: 要約尺度を指定する。発生率比 (\"IRR\") と発生率差 (\"IRD\") のどちらかを選ぶことができる。sm: 要約尺度を指定する。発生率比 (\"IRR\") と発生率差 (\"IRD\") のどちらかを選ぶことができる。incr: ゼロセルの連続性補正のために追加したいインクリメント。incr: ゼロセルの連続性補正のために追加したいインクリメント。metabin とは対照的に、 metainc はデフォルトでは連続性補正を使用しない。そのため、 MH.exact を TRUE として指定する必要はない。連続性補正は、一般的な逆分散プール法 (method = \"Inverse\") を選択したときのみ行われる。今回の実践例では、 EatingDisorderPrevention データセットを使用する。このデータは、摂食障害の発生率に対する大学ベースの予防的介入の効果を検討したメタ分析に基づいている (Harrer et al. 2020)。このデータセットでは、リスクのある人の時間は人-年として表現されている。\n“EatingDisorderPrevention” データセット\n\nEatingDisorderPrevention のデータセットも\n{dmetar}\nパッケージに直接含まれている。{dmetar}\nをインストールし、ライブラリからロードした後、\ndata(SuicidePrevention) を実行すると、自動的に R\n環境にデータセットが保存される。これでデータセットが利用できる。もし、{dmetar}\nがインストールされていない場合は、インターネットから\n.rda\nファイルとしてデータセットをダウンロードして作業ディレクトリに保存し、R\nStudio ウィンドウでクリックするとインポートすることができる。\nいつものように、まずはデータを見てみよう。\n効果量のデータのプールには metainc を用い、効果量の指標は発生率比とする。プールには Mantel-Haenszel 法を用い、研究間異質性分散の計算には Paule-Mandel 推定量を用いている。プールされた効果は IRR = 0.62 であることがわかる。この効果は、前の例よりも従来の有意水準にやや近いとはいえ、有意である (\\(p=\\) 0.04)。プール効果に基づき、予防的介入は1年以内の摂食障害の発生を38%減少させたと言うことが可能である。最後に、異質性分散 \\(\\tau^2\\) の推定値が0であることがわかる。","code":"\nlibrary(dmetar)\nlibrary(tidyverse)\nlibrary(meta)\n\ndata(EatingDisorderPrevention)\n\nglimpse(EatingDisorderPrevention)## Rows: 5\n## Columns: 5\n## $ Author  <chr> \"Stice et al., 2013\", \"Stice et al., 2017a\", \"Stice et al., 20…\n## $ event.e <dbl> 6, 22, 6, 8, 22\n## $ time.e  <dbl> 362, 235, 394, 224, 160\n## $ event.c <dbl> 16, 8, 9, 13, 29\n## $ time.c  <dbl> 356, 74, 215, 221, 159\nm.inc <- metainc(event.e = event.e, \n                 time.e = time.e,\n                 event.c = event.c,\n                 time.c = time.c,\n                 studlab = Author,\n                 data = EatingDisorderPrevention,\n                 sm = \"IRR\",\n                 method = \"MH\",\n                 fixed = FALSE,\n                 random = TRUE,\n                 method.tau = \"PM\",\n                 hakn = TRUE,\n                 title = \"Eating Disorder Prevention\")\n\nsummary(m.inc)## Review:     Eating Disorder Prevention\n## \n##                        IRR           95%-CI %W(random)\n## Stice et al., 2013  0.3688 [0.1443; 0.9424]       13.9\n## Stice et al., 2017a 0.8660 [0.3855; 1.9450]       18.7\n## Stice et al., 2017b 0.3638 [0.1295; 1.0221]       11.5\n## Taylor et al., 2006 0.6071 [0.2516; 1.4648]       15.8\n## Taylor et al., 2016 0.7539 [0.4332; 1.3121]       40.0\n## \n## Number of studies: k = 5\n## Number of events: e = 139\n## \n##                         IRR           95%-CI     t p-value\n## Random effects model 0.6223 [0.3955; 0.9791] -2.91  0.0439\n## \n## Quantifying heterogeneity:\n##  tau^2 = 0 [0.0000; 1.1300]; tau = 0 [0.0000; 1.0630]\n##  I^2 = 0.0% [0.0%; 79.2%]; H = 1.00 [1.00; 2.19]\n## \n## Test of heterogeneity:\n##     Q d.f. p-value\n##  3.34    4  0.5033\n## \n## Details on meta-analytical method:\n## - Inverse variance method\n## - Paule-Mandel estimator for tau^2\n## - Q-Profile method for confidence interval of tau^2 and tau\n## - Hartung-Knapp adjustment for random effects model (df = 4)"},{"path":"pooling-es.html","id":"pooling-cor","chapter":"4 効果量のプール","heading":"4.2.4 相関関係","text":"\n相関は metacor 関数を用いてプールすることができ、これは一般的な逆分散プーリング法を用いる。Chapter 3.2.3.1 では、相関をプールする前に Fisher’s \\(z\\) 変形が必要であることを説明した。デフォルトでは、 metacor がこの変換を自動的に行ってくれる。したがって、この関数には、研究で報告されたオリジナルの未変換の相関を与えれば十分である。 metacor 関数には、関数固有の引数が2つだけある。cor. (変換前の) 相関係数。n. 調査における観測数。metacor の機能を説明するために、 HealthWellbeing のデータセットを使用する。このデータセットは、健康と幸福の関連性を調べた大規模なメタ分析に基づいている (Ngamaba, Panagioti, Armitage 2017)。\n“HealthWellbeing” データセット\n\nHealthWellbeing のデータセットも\n{dmetar}\nパッケージに直接含まれている。{dmetar}\nをインストールし、ライブラリからロードした後、\ndata(SuicidePrevention) を実行すると、自動的に R\n環境にデータセットが保存される。これでデータセットが利用できる。\n\nもし、{dmetar} がインストールされていない場合は、インターネットから\n.rda\nファイルとしてデータセットをダウンロードして作業ディレクトリに保存し、R\nStudio ウィンドウでクリックするとインポートすることができる。\nそれでは、データを見てみよう。このメタ分析では、研究間の異質性がかなり高いと予想されるため、ランダム効果モデルを採用する。また、\\(\\tau^2\\)は制限付き最尤推定量を用いている。プールされた健康と幸福の関連は \\(r=\\) 0.36 であり、この効果は有意であることがわかる (\\(p<\\) 0.001)。Cohen の法則に従えば、これは中程度のサイズの相関とみなすことができる。出力では、 metacor がすでに Fisher’s \\(z\\) 変換された相関を元の形式に再変換している。しかし、詳細セクションの最後の行を見ると、確かに \\(z\\) 値が効果をプールするために使用されていることがわかる。最後に、このメタ分析で推定された異質性分散は、0より有意に大きいことがわかる。","code":"\nlibrary(dmetar)\nlibrary(tidyverse)\nlibrary(meta)\n\ndata(HealthWellbeing)\nglimpse(HealthWellbeing)## Rows: 29\n## Columns: 5\n## $ author     <chr> \"An, 2008\", \"Angner, 2013\", \"Barger, 2009\", \"Doherty, 2013\"…\n## $ cor        <dbl> 0.620, 0.372, 0.290, 0.333, 0.730, 0.405, 0.292, 0.388, 0.3…\n## $ n          <dbl> 121, 383, 350000, 1764, 42331, 112, 899, 870, 70, 67, 246, …\n## $ population <chr> \"general population\", \"chronic condition\", \"general populat…\n## $ country    <chr> \"South Korea\", \"USA\", \"USA\", \"Ireland\", \"Poland\", \"Australi…\nm.cor <- metacor(cor = cor, \n                 n = n,\n                 studlab = author,\n                 data = HealthWellbeing,\n                 fixed = FALSE,\n                 random = TRUE,\n                 method.tau = \"REML\",\n                 hakn = TRUE,\n                 title = \"Health and Wellbeing\")\nsummary(m.cor)## Review:     Health and Wellbeing\n##                        COR           95%-CI %W(random)\n## An, 2008            0.6200 [0.4964; 0.7189]        2.8\n## Angner, 2013        0.3720 [0.2823; 0.4552]        3.4\n## Barger, 2009        0.2900 [0.2870; 0.2930]        3.8\n## Doherty, 2013       0.3330 [0.2908; 0.3739]        3.7\n## Dubrovina, 2012     0.7300 [0.7255; 0.7344]        3.8\n## Fisher, 2010        0.4050 [0.2373; 0.5493]        2.8\n## [...]\n## \n## Number of studies combined: k = 29\n## Number of observations: o = 853794\n## \n##                         COR           95%-CI     t  p-value\n## Random effects model 0.3632 [0.3092; 0.4148] 12.81 < 0.0001\n## \n## Quantifying heterogeneity:\n##  tau^2 = 0.0241 [0.0141; 0.0436]; tau = 0.1554 [0.1186; 0.2088];\n##  I^2 = 99.8% [99.8%; 99.8%]; H = 24.14 [23.29; 25.03]\n## \n## Test of heterogeneity:\n##         Q d.f. p-value\n##  16320.87   28       0\n## \n## Details on meta-analytical method:\n## - Inverse variance method\n## - Restricted maximum-likelihood estimator for tau^2\n## - Q-profile method for confidence interval of tau^2 and tau\n## - Hartung-Knapp adjustment for random effects model\n## - Fisher's z transformation of correlations"},{"path":"pooling-es.html","id":"pooling-mean","chapter":"4 効果量のプール","heading":"4.2.5 プール平均","text":"平均のメタ分析は、 metamean 関数を用いて行うことが可能である。この関数は、データをプールするために一般的な逆分散法を使用する。 metamean を使用する場合、まず、生の平均値と対数変換された平均値のどちらでメタ分析を行うかを決定する必要がある。オッズ比やリスク比とは対照的に、平均の対数変換は通常必要ない。しかし、非負の量 (例えば、身長) の平均を扱うときや、いくつかの平均がゼロに近いときには、変換を使用することが推奨される。これは sm 引数で制御される。sm = \"MRAW\" と設定すると、生の平均がプールされる。sm = \"MLN\" とすると、対数変換が行われる。関数固有の引数は以下の通りである。n: 観測数。mean: 平均値。sd: 平均の標準偏差。sm: プーリングに使用する要約尺度の種類 (上記参照)。今回の実践例では、 BdiScores データセットを使用する。このデータセットには、心理療法や抗うつ剤の治験に参加しているうつ病患者のサンプルで測定された Beck Depression Inventory II (Beck, Steer, Brown 1996) の平均スコアが含まれている (Furukawa et al. 2020)。\n“BdiScores” データセット\n\nBdiScores のデータセットも {dmetar}\nパッケージに直接含まれている。{dmetar}\nをインストールし、ライブラリからロードした後、\ndata(SuicidePrevention) を実行すると、自動的に R\n環境にデータセットが保存される。これでデータセットが利用できる。もし、{dmetar}\nがインストールされていない場合は、インターネットから\n.rda\nファイルとしてデータセットをダウンロードして作業ディレクトリに保存し、R\nStudio ウィンドウでクリックするとインポートすることができる。\nここでの目標は、この研究のコレクションに基づいて、全体の平均的なうつ病スコアを計算することである。ランダム効果モデルと制限付き最尤推定量を使って、データセット内の生の平均をプールする。その結果を m.mean というオブジェクトに保存する。ランダム効果モデルを仮定したプール平均は \\(m\\) = 31.12である。また、このメタ分析における研究間異質性分散 \\(\\tau^2\\) は、0より有意に大きいことがわかる。","code":"\nlibrary(dmetar)\nlibrary(tidyverse)\nlibrary(meta)\ndata(BdiScores)\n\n# 最初の４列だけ必要\nglimpse(BdiScores[,1:4])## Rows: 6\n## Columns: 4\n## $ author <chr> \"DeRubeis, 2005\", \"Dimidjian, 2006\", \"Dozois, 2009\", \"Lesperanc…\n## $ n      <dbl> 180, 145, 48, 142, 301, 104\n## $ mean   <dbl> 32.6, 31.9, 28.6, 30.3, 31.9, 29.8\n## $ sd     <dbl> 9.4, 7.4, 9.9, 9.1, 9.2, 8.6\nm.mean <- metamean(n = n,\n                   mean = mean,\n                   sd = sd,\n                   studlab = author,\n                   data = BdiScores,\n                   sm = \"MRAW\",\n                   fixed = FALSE,\n                   random = TRUE,\n                   method.tau = \"REML\",\n                   hakn = TRUE,\n                   title = \"BDI-II Scores\")\nsummary(m.mean)## Review:     BDI-II Scores\n## \n##                     mean             95%-CI %W(random)\n## DeRubeis, 2005   32.6000 [31.2268; 33.9732]       18.0\n## Dimidjian, 2006  31.9000 [30.6955; 33.1045]       19.4\n## Dozois, 2009     28.6000 [25.7993; 31.4007]        9.1\n## Lesperance, 2007 30.3000 [28.8033; 31.7967]       17.0\n## McBride, 2007    31.9000 [30.8607; 32.9393]       20.7\n## Quilty, 2014     29.8000 [28.1472; 31.4528]       15.8\n## \n## Number of studies: k = 6\n## Number of observations: o = 920\n## \n##                         mean             95%-CI\n## Random effects model 31.1221 [29.6656; 32.5786]\n## \n## Quantifying heterogeneity:\n##  tau^2 = 1.0937 [0.0603; 12.9913]; tau = 1.0458 [0.2456; 3.6043]\n##  I^2 = 64.3% [13.8%; 85.2%]; H = 1.67 [1.08; 2.60]\n## \n## Test of heterogeneity:\n##      Q d.f. p-value\n##  14.00    5  0.0156\n## \n## Details on meta-analytical method:\n## - Inverse variance method\n## - Restricted maximum-likelihood estimator for tau^2\n## - Q-Profile method for confidence interval of tau^2 and tau\n## - Hartung-Knapp adjustment for random effects model (df = 5)\n## - Untransformed (raw) means"},{"path":"pooling-es.html","id":"pooling-props","chapter":"4 効果量のプール","heading":"4.2.6 割合","text":"\nmetaprop 関数は、割合のプールに使用することが可能である。Chapter 3.2.2で、メタ分析を行う前に割合を logit 変換しておくとよいことを既に説明した。sm = \"PLOGIT\" を指定すると、 metaprop 関数が自動的にこれを行う。もし、生の比率をプールしたい場合は、 sm = \"PRAW\" を使用することができるが、これは推奨されていないことを覚えていただきたい。metaprop が割合のプールを行うデフォルトの方法は、少々特殊である。logit 変換された値を使用する場合、この関数はプールのために逆分散法を使用せず、一般化線形混合効果モデル (generalized linear mixed-effects model, GLMM) を構築する。基本的には、この関数はロジスティック回帰モデルをデータに当てはめ、真の効果量が研究間で異なるという事実を説明するために、ランダム効果を含んでいる。「混合効果モデル」という言葉を聞いたことがあるだろう。このようなモデルは、多くの研究分野の一次研究でよく使用されている。この章では、混合効果モデルの特殊な応用例であるサブグループ解析やメタ回帰について説明し、このテーマをもう少し深く掘り下げていきる。しかし、今のところ、混合効果モデルとは何かという一般的な考え方を理解しておけば十分である。混合効果モデルは、「固定」成分と「ランダム」成分の両方を含む回帰モデルである。固定要素は、\\(\\beta\\) 重みである。非常に単純な回帰モデルでは、切片 \\({\\beta_0}\\) と回帰項 \\({\\beta_1}x\\) の2つの \\(\\beta\\) 項が含まれる。これらを組み合わせて、他の量 \\(x\\) を通じて観測データ \\(y\\) を予測する。この予測は完全とは言い難く、ランダムな誤差 \\(\\epsilon_i\\) が残る。これを合わせると、次のような式になる。\\[\\begin{equation}\n{y}_i = {\\beta_0} + {\\beta_1}x_i +  \\epsilon_i\n\\tag{4.16}\n\\end{equation}\\]重要なのは、この式の\\(\\beta\\) 重みの値は各観測 \\(\\) で同じままであることである。\\(x\\) の値は観測ごとに変わるだろうが、\\(\\beta_0\\) と \\(\\beta_1\\) は固定なので変わることはない。この回帰式は、ランダム効果を加えると混合効果モデルになる。このランダム効果項を \\(u_i\\) と表記する。添え字 \\(\\) で示すように、ランダム効果項は各オブザベーションで異なる値を持つことができる。\\(u_i\\) 項は0を中心とし、固定効果による推定値を増加させたり、減少させたりすることができる。\\[\\begin{equation}\n{y}_i = {\\beta_0} + {\\beta_1}x_i + u_i + \\epsilon_i\n\\tag{4.17}\n\\end{equation}\\]メタ分析は、このモデルの特殊なタイプで、\\(\\beta_1x_i\\) 項が存在しないものと見なすことができる。このモデルは切片 \\(\\beta_0\\) のみを含み、これはランダム効果モデルにおける全体の効果量 \\(\\mu\\) に相当する。\\(u_i\\) と \\(\\epsilon_i\\) の部分は、メタ分析における \\(\\zeta_k\\) と \\(\\epsilon_k\\) の誤差項に相当する。このことから、メタ分析は混合効果回帰モデルと等価であることがわかる。しかし、この混合効果モデルには切片とそれに連なるランダム効果しか含まれていない。二項ロジットリンクを用いると26、したがって、(一般化) ロジスティック混合効果モデルを適用してプール効果を推定することが可能である。GLMM は割合だけでなく、オッズ比や発生率比のような二値やカウントデータに基づく他のアウトカム指標にも適用できる (Stijnen, Hamza, Özdemir 2010) 。GLMMは二値アウトカムデータのメタ分析に普遍的に推奨されているわけではないが (Bakbergenuly Kulinskaya 2018) 、割合についてはその使用が提唱されている (Schwarzer et al. 2019)。GLMM を metaprop の一部として使用すると、次の3つの意味がある: (1) 出力は、各効果のメタ分析重みを表示しない、(2) \\(\\tau^2\\)推定量は \"ML\" にしか設定できない (最尤法を使用してGLMMを推定するので)、(3) \\(\\tau^2\\) の推定量の信頼区間が存在しなくなる。この情報が必要な場合は、逆分散メタ分析の実行に切り替えることが可能である。 metaprop には、5つの関数固有の引数がある。event. イベント数。event. イベント数。n. 観測数。n. 観測数。method. プーリング手法。GLMM (method = \"GLMM\") あるいは逆 (Inverse) 分散プーリング (method = \"Inverse\") のいずれかを指定することができる。method. プーリング手法。GLMM (method = \"GLMM\") あるいは逆 (Inverse) 分散プーリング (method = \"Inverse\") のいずれかを指定することができる。incr. ゼロセルでの連続性補正のために追加される増分。これは、逆分散プーリングが使用される場合にのみ関係する。incr. ゼロセルでの連続性補正のために追加される増分。これは、逆分散プーリングが使用される場合にのみ関係する。sm. 使用する要約尺度を指定する。sm = \"PLOGIT\" (デフォルト)とすることで、logit 変換された比率を使用することが推奨される。sm. 使用する要約尺度を指定する。sm = \"PLOGIT\" (デフォルト)とすることで、logit 変換された比率を使用することが推奨される。metaprop 関数の説明のために、 OpioidMisuse データセットを使用することにする。このデータは、米国の青年・若年成人における処方オピオイドの誤用12ヶ月有病率を調査したメタ分析から得られたものである (Jordan et al. 2017)。\n“OpioidMisuse” データセット\n\nOpioidMisuse のデータセットも {dmetar}\nパッケージに直接含まれている。{dmetar}\nをインストールし、ライブラリからロードした後、\ndata(SuicidePrevention) を実行すると、自動的に R\n環境にデータセットが保存される。これでデータセットが利用できる。もし、{dmetar}\nがインストールされていない場合は、インターネットから\n.rda\nファイルとしてデータセットをダウンロードして作業ディレクトリに保存し、R\nStudio ウィンドウでクリックするとインポートすることができる。\nデータセットをロードして見てみよう。GLMM と logit 変換された割合を用いて有病率データをプールする。出力では、選択された研究における処方オピオイドの誤用のプールされた12ヶ月の有病率は9.4％であり、信頼区間の範囲は8.36から10.66％であることがわかる。前述したように、この出力には各効果の個別の重みが表示されていない。同じように、研究間の異質性の推定値 (\\(\\tau^2 =\\) 0.056) が得られるが、その周りの信頼区間はない。\\[\\tag*{$\\blacksquare$}\\]\n","code":"\nlibrary(dmetar)\nlibrary(meta)\nlibrary(tidyverse)\n\ndata(OpioidMisuse)\nglimpse(OpioidMisuse)## Rows: 15\n## Columns: 3\n## $ author <chr> \"Becker, 2008\", \"Boyd, 2009\", \"Boyd, 2007\", \"Cerda, 2014\", \"Fie…\n## $ event  <dbl> 2186, 91, 126, 543, 6496, 10850, 86, 668, 843, 647, 11521, 1111…\n## $ n      <dbl> 21826, 912, 1084, 7646, 55215, 114783, 527, 9403, 11274, 8888, …\nm.prop <- metaprop(event = event,\n                   n = n,\n                   studlab = author,\n                   data = OpioidMisuse,\n                   method = \"GLMM\",\n                   sm = \"PLOGIT\",\n                   fixed = FALSE,\n                   random = TRUE,\n                   hakn = TRUE,\n                   title = \"Opioid Misuse\")\nsummary(m.prop)## Review:     Opioid Misuse\n##                proportion           95%-CI\n## Becker, 2008       0.1002 [0.0962; 0.1042]\n## Boyd, 2009         0.0998 [0.0811; 0.1211]\n## Boyd, 2007         0.1162 [0.0978; 0.1368]\n## Cerda, 2014        0.0710 [0.0654; 0.0770]\n## Fiellin, 2013      0.1176 [0.1150; 0.1204]\n## [...]\n## \n## \n## Number of studies combined: k = 15\n## Number of observations: o = 434385\n## Number of events: e = 41364\n## \n##                      proportion           95%-CI\n## Random effects model     0.0944 [0.0836; 0.1066]\n## \n## Quantifying heterogeneity:\n##  tau^2 = 0.0558; tau = 0.2362; I^2 = 98.3% [97.9%; 98.7%]; H = 7.74 [6.92; 8.66]\n## \n## Test of heterogeneity:\n##       Q d.f.  p-value             Test\n##  838.21   14 < 0.0001        Wald-type\n##  826.87   14 < 0.0001 Likelihood-Ratio\n## \n## Details on meta-analytical method:\n## - Random intercept logistic regression model\n## - Maximum-likelihood estimator for tau^2\n## - Hartung-Knapp adjustment for random effects model\n## - Logit transformation\n## - Clopper-Pearson confidence interval for individual studies"},{"path":"pooling-es.html","id":"演習問題-3","chapter":"4 効果量のプール","heading":"4.3 演習問題","text":"\n知識を試そう！\n\n固定効果モデルとランダム効果モデルの違いは何か？\n\n固定効果モデルとランダム効果モデルの結果が同じになるケースは考えられるか。\n\n\\(\\tau^2\\)\nとは何か？どのように推定するのか？\n\nKnapp-Hartung\nの調整はどの分布に基づいているか？どのような効果があるか？\n\n「逆分散」 (inverse-variance)\nプーリングとはどういう意味か？この方法が最適解でないのはどのような場合か？\n\n二値アウトカムデータをメタ分析したい。試験群の観察数はほぼ同じで、観察された事象は非常にまれで、治療効果が大きくなることは期待できない。どのようなプール方法を使用するか？\n\nGLMM はどのようなアウトカム指標に使用できるのか。\n\n問題の解答は、本書の巻末 Appendix\nにある。\n","code":""},{"path":"pooling-es.html","id":"要約","chapter":"4 効果量のプール","heading":"4.4 要約","text":"統計学において、モデルは、観測されたデータが生成された過程を記述する、簡略化された「理論」と見なすことができる。メタ分析には、固定効果モデルとランダム効果モデルの2つのモデルがある。統計学において、モデルは、観測されたデータが生成された過程を記述する、簡略化された「理論」と見なすことができる。メタ分析には、固定効果モデルとランダム効果モデルの2つのモデルがある。固定効果モデルが真の効果量が1つであることを仮定しているのに対し、ランダム効果モデルは真の効果量がメタ分析内でも変化することを述べている。したがって、ランダム効果モデルの目的は、データの根底にある真の効果量の分布の平均を見つけることである。固定効果モデルが真の効果量が1つであることを仮定しているのに対し、ランダム効果モデルは真の効果量がメタ分析内でも変化することを述べている。したがって、ランダム効果モデルの目的は、データの根底にある真の効果量の分布の平均を見つけることである。ランダム効果メタ分析では、真の効果量の分散 \\(\\tau^2\\) (研究間異質性分散とも呼ばれる) を推定する必要がある。これにはいくつかの方法があり、どれが一番効果的かは文脈によって異なる。ランダム効果メタ分析では、真の効果量の分散 \\(\\tau^2\\) (研究間異質性分散とも呼ばれる) を推定する必要がある。これにはいくつかの方法があり、どれが一番効果的かは文脈によって異なる。プール効果量を計算する最も一般的な方法は、逆分散法である。しかし、二値アウトカム・データでは、Mantel-Haenszel 法のような他のアプローチが望ましい場合がある。プール効果量を計算する最も一般的な方法は、逆分散法である。しかし、二値アウトカム・データでは、Mantel-Haenszel 法のような他のアプローチが望ましい場合がある。{meta} パッケージには、事前に計算された効果量データのメタ分析を行う関数と、さまざまな種類の「生の」アウトカムデータに対して使用できる関数群がある。{meta} パッケージには、事前に計算された効果量データのメタ分析を行う関数と、さまざまな種類の「生の」アウトカムデータに対して使用できる関数群がある。","code":""},{"path":"heterogeneity.html","id":"heterogeneity","chapter":"5 研究間異質性","heading":"5 研究間異質性","text":"B\nメタ分析で効果量をプールする方法については、すでに説明してきた。今まで見てきたように、固定効果モデルもランダム化モデルも、多くの異なる研究の効果を1つの数値に統合することが目的である。しかし、これは、りんごとオレンジを比較していない場合にのみ意味がある。例えば、メタ分析で計算した全体的な効果は小さいが、非常に高い効果量を持つ外れ値がいくつか残っているということがあり得る。このような情報は集計された効果からは失われ、すべての研究が小さな効果量をもたらしたのか、それとも例外があったのかはわからない。\nメタ分析において、真の効果量がどの程度異なるかを研究間異質性 (-study heterogeneity) と呼ぶ。この概念については、前章でランダム効果モデルとの関連ですでに簡単に触れた。ランダム効果モデルは、研究間の異質性によって研究の真の効果量が異なることを想定している。そのため、この真の効果の分散を定量化する推定値 \\(\\tau^2\\) を含む。これにより、真の効果量分布の平均値として定義されるプール効果を計算することが可能である。ランダム効果モデルは、たとえ異質な研究であっても、常にプール効果量を計算することが可能である。しかし、このプール効果が意味のある方法で解釈できるかどうかはわからない。プール効果だけでは、メタ分析におけるデータをうまく表現できないシナリオがたくさんある。異質性が非常に高く、(例えば、ある治療法の) 真の効果の大きさが正から負までの範囲である場合を想像してみよう。このようなメタ分析のプール効果がプラスであったとしても、真のマイナス効果を持つ研究がいくつかあったということを伝えることができない。その治療法がいくつかの研究で悪影響を及ぼしたという事実は失われてしまう。異質性が高いということは、研究が、真の効果が異なる2つ以上のサブグループに分けられるという事実によって引き起こされることもある。このような情報は研究者にとって非常に貴重であり、効果が低いまたは高い特定の条件を見つけることができるかもしれない。しかし、プール効果を単独で見ると、このような詳細は見逃される可能性がある。極端な場合、異質性が非常に高いと、研究に共通点がなく、プール効果を解釈することが全く意味をなさなくなる可能性すらある。したがって、メタ分析では、常に分析した研究のばらつきを考慮しなければならない。優れたメタ分析では、全体的な効果を報告するだけでなく、この推定値がどの程度信頼できるかを明記する必要がある。そのために不可欠なのが、研究間の異質性を定量化し、分析することである。この章では、異質性を測定するさまざまな方法と、その解釈の仕方を詳しく見ていく。また、データ中の異質性に寄与している研究を検出することができるいくつかのツールについても説明する。最後に、「現実の」メタ分析で異質性が大きい場合の対処について説明する。","code":""},{"path":"heterogeneity.html","id":"het-measures","chapter":"5 研究間異質性","heading":"5.1 異質性の尺度","text":"異質性の尺度の議論を始める前に、まず異質性の意味は一つではないことを明らかにしておく必要がある。例えば、Rücker ら (2008) は、ベースラインまたはデザイン関連の異質性と、統計的異質性を区別している。ベースラインまたはデザイン関連異質性は、研究の母集団または研究設計が研究間で異なる場合に生じる。この種の異質性については、「りんごとオレンジ」問題 (Chapter 1.3) や、研究課題の定義方法 (Chapter 1.4.1) について説明したときにも取り上げた。デザインに関連する異質性は、どのような種類の集団やデザインがメタ分析に適格であるかを決定する適切な PICO を設定することによって、priori に低減させることが可能である。ベースラインまたはデザイン関連異質性は、研究の母集団または研究設計が研究間で異なる場合に生じる。この種の異質性については、「りんごとオレンジ」問題 (Chapter 1.3) や、研究課題の定義方法 (Chapter 1.4.1) について説明したときにも取り上げた。デザインに関連する異質性は、どのような種類の集団やデザインがメタ分析に適格であるかを決定する適切な PICO を設定することによって、priori に低減させることが可能である。一方、統計的異質性は、メタ分析に含まれる効果量推定値の広がりや精度によって影響を受ける、定量化可能な特性である。ベースライン異質性は、統計的異質性 (例えば、含まれる集団間で効果が異なる場合) につながる可能性があるが、必ずしもそうである必要はない。また、メタ分析では、含まれる研究自体が事実上同一であっても、高い統計的異質性を示すことがある。このガイド (および他のほとんどのメタ分析のテキスト) では、「研究間の異質性」という用語は、統計的な異質性のみを指す。一方、統計的異質性は、メタ分析に含まれる効果量推定値の広がりや精度によって影響を受ける、定量化可能な特性である。ベースライン異質性は、統計的異質性 (例えば、含まれる集団間で効果が異なる場合) につながる可能性があるが、必ずしもそうである必要はない。また、メタ分析では、含まれる研究自体が事実上同一であっても、高い統計的異質性を示すことがある。このガイド (および他のほとんどのメタ分析のテキスト) では、「研究間の異質性」という用語は、統計的な異質性のみを指す。","code":""},{"path":"heterogeneity.html","id":"cochran-q","chapter":"5 研究間異質性","heading":"5.1.1 Cochran’s \\(Q\\)","text":"ランダム効果モデルに基づくと、観察された効果が研究ごとに異なる原因となる変動要因は 2 つあることが分かっている。サンプリングエラー \\(\\epsilon_k\\) と、研究間の異質性による誤差 \\(\\zeta_k\\) である (Chapter 4.1.2)。研究間異質性を定量化したいときに困難なこととして、変動のうち、どの程度がサンプリングエラーに起因し、どの程度が真の効果量の違いに起因するのかを識別することである。伝統的にメタ分析では、研究のサンプル誤差と実際の研究間の異質性を区別するために、Cochran’s \\(Q\\) (Cochran 1954) を使用している。Cochran’s \\(Q\\) は、加重二乗和 (weighted sum squares, WSS)として定義されている。これは、各研究の観察効果 \\(\\hat\\theta_k\\) の要約効果 \\(\\hat\\theta\\) からの偏差を、研究の分散の逆数 \\(w_k\\) で重み付けしたものである。\\[\\begin{equation}\nQ = \\sum^K_{k=1}w_k(\\hat\\theta_k-\\hat\\theta)^2\n\\tag{5.1}\n\\end{equation}\\]この式を詳しく見てみよう。まず、プール効果量に適用されるのと同じ逆分散加重が使われていることがわかる。この式の平均値 \\(\\hat\\theta\\) は、固定効果モデルによるプール効果である。個々の効果が要約効果から逸脱する量である残差は、二乗され (値が常に正になるように)、重み付けされ、そして合計される。その結果の値が Cochran’s \\(Q\\) である。\\(w_k\\) による重み付けのため、\\(Q\\) の値は、\\(\\hat\\theta_k\\) が \\(\\hat\\theta\\) からどれだけ乖離しているかだけでなく、研究の精度にも依存する。効果量の標準誤差が非常に小さい (つまり精度が非常に高い) 場合、要約効果からの乖離が小さくても高い重みが与えられ、\\(Q\\) の値が高くなる。\\(Q\\) の値は、データに過剰な変動があるかどうか、つまり、サンプル誤差だけから予想されるよりも多くの変動があるかどうかを確認するために使用することが可能である。もしそうであれば、残りの変動は研究間の異質性に起因すると考えることが可能である。このことをちょっとしたシミュレーションで説明しよう。このシミュレーションでは、\\(Q\\) が2つの異なるシナリオの下でどのように振る舞うかを検証したいと思われる: 研究間の異質性がない場合と、異質性がある場合である。まず、異質性がない場合から始めよう。これは、\\(\\zeta_k=0\\) 、残差 \\(\\hat\\theta_k-\\hat\\theta\\) はサンプリング誤差 \\(\\epsilon_k\\) の積のみであることを意味する。ある平均効果量 \\(\\hat\\theta\\) からの偏差をシミュレートするために、 rnorm 関数を使用することが可能である (正規分布に従うと仮定した)。それらは \\(\\hat\\theta\\) を中心としているので、これらの「残差」の平均はゼロ ( \\(\\mu\\) = 0) であると期待可能である。この例では、母集団の標準偏差が \\(\\sigma=\\) 1 で、標準正規分布になると仮定しよう。正規分布は通常 \\(\\mathcal{N}\\) で示され、残差は \\(\\mu=\\) 0 と \\(\\sigma=\\) 1 の正規分布から得られることを次のように記号化することが可能である。\\[\\begin{equation}\n\\hat\\theta_k-\\hat\\theta \\sim \\mathcal{N}(0,1)\n\\tag{5.2}\n\\end{equation}\\]これを R で試してみよう。\\(K\\) = 40 効果量の残差 \\(\\hat\\theta_k-\\hat\\theta\\) を rnorm を使って描画してみる。標準正規分布が rnorm のデフォルトなので、より単純なコード rnorm(40) を使うこともできる。さて、この \\(n=\\) 40 回サンプルを描くという作業を何度も何度も繰り返すというシミュレーションをしてみよう。これは replicate 関数を使って実現可能である。この関数では、rnorm の呼び出しを1万回繰り返すように指示した。その結果得られた値を error_fixed というオブジェクトに保存する。サンプリングエラー \\(\\epsilon_k\\) に加えて、研究間の異質性 (\\(\\zeta_k\\) 誤差) が存在すると仮定する2番目のシナリオを続ける。これは、真の効果量の分散を表す rnorm の 2 回目の呼び出しを追加することでシミュレートすることが可能である。この例では、真の効果量が標準正規分布に従うと仮定する。このコードを使って、\\(K\\) = 40 件の研究に、かなりの研究間異質性を持たせて 1 万回のメタ分析の残差をシミュレートすることが可能である。異質性ありとなしのメタ分析について、\\(\\hat\\theta_k-\\hat\\theta\\) の残差をシミュレーションしたので、\\(Q\\) の値についても同じことをしてみよう。 このシミュレーションでは、分散、したがって各研究の重み \\(w_k\\) が1であると仮定することによって \\(Q\\) の式を少し単純化し、結果として \\(w_k\\) が式から脱落するようにすることが可能である。つまり、先ほどの rnorm の呼び出しを使って、結果を二乗して合計し、この処理を1万回繰り返せばよいことになる。以下はそのコードである。\\(Q\\) の重要な特性は、\\(\\chi^2\\) の分布に (おおよそ) 従うと仮定されていることである。\\(\\chi^2\\) 分布は、加重二乗和のように、正の値のみを取ることが可能である。これは、その 自由度、つまり d.f. によって定義される。\\(\\chi^2\\) 分布は、小さな d.f. では右に裾が広がっているが、自由度が大きくなると正規分布に近づいていく。同時に、自由度は期待値、つまりそれぞれの \\(\\chi^2\\) 分布の平均値でもある。\\(Q\\) が \\(K-1\\) の自由度を持つ \\(\\chi^2\\) 分布にほぼ従うと仮定する (\\(K\\) はメタ分析における研究数)。もし、効果量の差がサンプリングエラーによってのみ起きたものである場合。これは、\\(K-1\\) の自由度を持つ \\(\\chi^2\\) 分布の平均が、サンプリング・エラーだけによって期待できる \\(Q\\) の値を教えてくれることになる。この説明は非常に抽象的なので、より具体的にするために、シミュレーションした値の分布を見てみよう。以下のコードでは、効果量「残差」と \\(Q\\) の値のヒストグラムをプロットするために、 hist 関数を使用している。また、各プロットに理想化された分布を示す線を追加している。このような分布は、正規分布の場合は dnorm 関数で、\\(\\chi^2\\) の場合は dchisq 関数で生成することが可能である。以下は、R で描いたプロットである。プロット生成に使用したコードがわかりにくいと思われるだろうが、心配はいらない。このシミュレーションのためだけに使用したものであり、実際のメタ分析の一部として作成されるプロットではない。4 つのヒストグラムにあるものを見ていこう。最初の行は、効果量「残差」の分布で、異質性のあるものとないものがある。異質性のないデータは、私たちがプロットに含めた標準正規分布の線に忠実に沿っていることがわかる。これは、データがこの正確な分布を仮定して rnorm によって生成されたので、非常に論理的である。しかし、異質性を追加したデータは、標準正規分布に従いない。データの分散はより大きくなり、より重い尾を持つ分布になる。さて、これが2行目の \\(Q\\) の値の分布とどう関係しているのかを探ってみよう。異質性がない場合、\\(Q\\) 値は、特徴的な右に歪んだ \\(\\chi^2\\) 分布に従っている。プロットでは、実線は自由度 39 の \\(\\chi^2\\) 分布の形状を示している (各シミュレーションで使われたのは、d.f. = \\(K-1\\) および \\(K\\) = 40 であるため)。シミュレーションされたデータはこの曲線にかなりよく従っていることがわかる。これは大きな驚きではない。私たちは、異質性がないとき、\\(Q\\) が \\(K-1\\) の自由度を持つ \\(\\chi^2\\) 分布に従うことを知っている。このシミュレーションデータもまさにこのケースである。バラツキはサンプル誤差によってのみ存在したのである。異質性のある例では、分布は全く異なるように見える。シミュレーションされたデータは、期待された分布に全く従っていないように見える。値は目に見えて右にシフトしており、分布の平均は約 2 倍高くなっている。研究間にかなりの異質性がある場合、\\(Q\\) 値は、異質性がないという仮定で期待される \\(K-1\\) の値よりもかなり高くなると結論づけることが可能である。これは、研究間の異質性の存在をシミュレートするために、データに余分な変動を加えたので、驚くことではない。これはやや長い説明であったが、それでも、\\(Q\\) の統計的特性をどのように利用できるかをより理解するのに役立っただろう。 Cochran’s \\(Q\\) は、メタ分析における変動が、異質性がないという帰無仮説の下で期待する量を著しく超えているかどうかを検定するのに利用可能である。この異質性の検定はメタ分析でよく使われるもので、Chapter 4 に戻ると、{meta} もデフォルトで提供してくれていることがわかる。これはよく Cochran’s \\(Q\\) test と呼ばれるが、実はこれは誤記である。Cochran自身は \\(Q\\) をこのように使うことを意図してはいないかった (Hoaglin 2016)。\nCochran’s \\(Q\\) は、非常に重要な統計量である。これは、Higgins Thompsonの \\(^2\\) 統計量や \\(H^2\\) など、異質性を定量化する他の一般的な方法がこれに基づいていることが主な理由である。これらの尺度については、次のセクションで説明した。Cochran’s \\(Q\\) は、\\(\\tau^2\\) を計算する異質性分散推定でも使われている。最も有名なのは DerSimonian-Laird 推定量である27。\n\\(Q\\) の課題と \\(Q\\)-検定\n\n\\(Q\\)\nはメタアナリシスでよく使われ報告されているが、欠点がいくつかある。例えば\nHoaglin (2016)\nは、\\(Q\\) が自由度 \\(K-1\\) の \\(\\chi^2\\)\n分布に従うという仮定はメタ分析における \\(Q\\)\nの実際の振る舞いを反映しておらず、したがって DerSimonian-Laird\n法などにはバイアスがあるかもしれないと論じている。\n\nより現実的な問題として、\\(Q\\)\nは研究の数 \\(K\\) と精度\n(すなわち研究のサンプルサイズ)\nが増加したときの両方で増加する。したがって、\\(Q\\)\nとそれが有意であるかどうかは、メタアナリシスの規模、ひいてはその統計的検出力に大きく依存することになる。\n\nこのことから、異質性を評価する際には、\\(Q\\)-検定の有意性だけに頼るべきではないことがわかる。メタアナリシスでは、\\(Q\\)-検定の有意性に基づいて固定効果モデルかランダム効果モデルのどちらを適用するかを決めることがある。ここで述べた理由から、このアプローチは全く推奨されない。\n","code":"\nset.seed(123) # 結果を再現するために必要\nrnorm(n = 40, mean = 0, sd = 1)##  [1] -0.56048 -0.23018  1.55871  0.07051  0.12929\n##  [6]  1.71506  0.46092 -1.26506 -0.68685 -0.44566\n##  [...]\n\nset.seed(123)\nerror_fixed <- replicate(n = 10000, rnorm(40))\nset.seed(123)\nerror_random <- replicate(n = 10000, rnorm(40) + rnorm(40))\nset.seed(123)\nQ_fixed <- replicate(10000, sum(rnorm(40)^2))\nQ_random <- replicate(10000, sum((rnorm(40) + rnorm(40))^2))\n# 残差 (theta_k - theta) のヒストグラム\n# - error_fixed と error_random 両方の\n#   シミュレーション値のヒストグラムを作成\n# - `lines` を使い、青色で正規分布を追加\n\nhist(error_fixed, \n     xlab = expression(hat(theta[k])~-~hat(theta)), prob = TRUE, \n     breaks = 100, ylim = c(0, .45), xlim = c(-4,4),\n     main = \"No Heterogeneity\")\nlines(seq(-4, 4, 0.01), dnorm(seq(-4, 4, 0.01)), \n      col = \"blue\", lwd = 2)\n\nhist(error_random, \n     xlab = expression(hat(theta[k])~-~hat(theta)), prob = TRUE, \n     breaks = 100,ylim = c(0, .45), xlim = c(-4,4),\n     main = \"Heterogeneity\")\nlines(seq(-4, 4, 0.01), dnorm(seq(-4, 4, 0.01)), \n      col = \"blue\", lwd = 2)\n\n\n# Q-values のヒストグラム\n# - Q_fixed と Q_random 両方の\n#   シミュレーション値のヒストグラムを作成\n# - `lines` を使い、青色でカイ二乗分布を追加\n\n# まず、自由度 (k-1)　を計算\n# 注意: k=40 件の研究を毎回のシミュレーションで使用\ndf <- 40-1\n\nhist(Q_fixed, xlab = expression(italic(\"Q\")), prob = TRUE, \n     breaks = 100, ylim = c(0, .06),xlim = c(0,160),\n     main = \"No Heterogeneity\")\nlines(seq(0, 100, 0.01), dchisq(seq(0, 100, 0.01), df = df), \n      col = \"blue\", lwd = 2)\n\nhist(Q_random,  xlab = expression(italic(\"Q\")), prob = TRUE, \n     breaks = 100, ylim = c(0, .06), xlim = c(0,160),\n     main = \"Heterogeneity\")\nlines(seq(0, 100, 0.01), dchisq(seq(0, 100, 0.01), df = df), \n      col = \"blue\", lwd = 2)"},{"path":"heterogeneity.html","id":"i-squared","chapter":"5 研究間異質性","heading":"5.1.2 Higgins & Thompson’s \\(I^2\\) 統計量","text":"\\(^2\\) 統計量 (J. P. Higgins Thompson 2002) は、研究間の異質性を定量化する別の方法で、Cochran’s \\(Q\\) に直接基づいている。これは、サンプリングエラーによって引き起こされない効果量の変動の割合と定義されている。\\(^2\\) は、異質性がないという帰無仮説のもと、自由度 \\(K-1\\) を持つ \\(\\chi^2\\) 分布に従っているという前提に基づいて作成されている。これは、異質性がない場合 (すなわち、 \\(K-1\\)) のとき、\\(Q\\) 観察値が 期待された \\(Q\\) 値をどの程度超えているかをパーセントで定量化するものである。\\(^2\\) の計算式は次のようになる。\\[\\begin{equation}\n^2 = \\frac{Q-(K-1)}{Q}\n\\tag{5.3}\n\\end{equation}\\]ここで、\\(K\\) は研究の総数である。 \\(^2\\) の値は 0% より低くすることはできないので、\\(Q\\) が \\(K-1\\) より小さい場合は、負の値ではなく、単に \\(0\\) とする28。\\(^2\\) がどのように計算されるかを説明するために、先ほどの \\(Q\\) のシミュレーション値を使用しよう。まず、異質性がないと仮定した Q_fixed の 10 番目のシミュレーション値を選ぶ。そして、上の式を使って、\\(^2\\) を計算する。結果がマイナスなので、ゼロに切り上げると、\\(^2\\) = 0% となる。この値は、効果量のばらつきの 0% が研究間の異質性に起因していることを示している。これは、シミュレーションに使用した設定と一致している。今度は、Q_random の 10 番目のシミュレート値で同じことをしよう。このシミュレーションの \\(^2\\) 値は約 50% で、変動の約半分が研究間異質性に起因していることがわかる。この例の変動は、サンプル誤差と研究間異質性のシミュレーションに等しく基づいているので、これも私たちの予想に沿ったものである。メタ分析における研究間異質性を報告するために \\(^2\\) 統計量を使用することは一般的であり、\\(^2\\) は {meta} から得られる出力にデフォルトで含まれている。この統計量の人気は、この統計量をどう解釈するかの「経験則」が存在することと関連しているだろう (J. P. Higgins Thompson 2002)。\\(^2\\) = 25%: 低い異質性\\(^2\\) = 25%: 低い異質性\\(^2\\) = 50%: 中程度の異質性\\(^2\\) = 50%: 中程度の異質性\\(^2\\) = 75%: 実質的な異質性を有する。\\(^2\\) = 75%: 実質的な異質性を有する。","code":"\n# 10 回目の Q のシミュレーションを表示\nQ_fixed[10]## [1] 35.85787\n# k を定義\nk <- 40\n\n# I^2 を計算\n(Q_fixed[10] - (k-1))/Q_fixed[10]## [1] -0.08762746\n(Q_random[10] - (k-1))/Q_random[10]## [1] 0.5692061"},{"path":"heterogeneity.html","id":"h2-統計量","chapter":"5 研究間異質性","heading":"5.1.3 \\(H^2\\) 統計量","text":"\\(H^2\\) 統計量 (J. P. Higgins Thompson 2002) も Cochran’s \\(Q\\) から派生したもので、\\(^2\\) に似ている。これは、\\(Q\\) で測定される観測された変動と、サンプル誤差による期待分散の比を記述するものである。\\[\\begin{equation}\nH^2 = \\frac{Q}{K-1}\n\\tag{5.4}\n\\end{equation}\\]\\(Q\\) が \\(K-1\\) より小さい場合、その値を人為的に修正する必要がないため、\\(H^2\\) の計算は \\(^2\\) の計算よりわずかにエレガントである。研究間の異質性がない場合、\\(H^2\\) は 1 (またはそれ以下) に相当する。1 より大きい値は、研究間の異質性があることを示す。\\(^2\\) と比較すると、発表されたメタ分析でこの統計量が報告されることは、はるかに少ない。しかし、\\(H^2\\) は {meta} のメタ分析関数の出力にデフォルトで含まれている。","code":""},{"path":"heterogeneity.html","id":"tau","chapter":"5 研究間異質性","heading":"5.1.4 異質性分散 \\(\\tau^2\\) と標準偏差 \\(\\tau\\)","text":"異質性分散 \\(\\tau^2\\) については、すでに Chapter 4.1.2 で詳しく説明してきた。そこで述べたように、\\(\\tau^2\\) は、私たちのデータの基礎となる真の効果量の分散を定量化するものである。\\(\\tau^2\\) の平方根をとると、\\(\\tau\\) が得られ、これは真の効果の大きさの標準偏差である。\\(\\tau\\) の大きな特徴は、効果量と同じ尺度で表現されていることである。これは、たとえば、一次調査におけるサンプルの年齢の平均と標準偏差を解釈するのと同じように、これを解釈できることを意味した。\\(\\tau\\) の値は、真の効果量の範囲について何かを教えてくれる。例えば、\\(\\tau\\) に 1.96 を掛け、プール効果量にこの値を加減することで、真の効果量の95%信頼区間を計算することが可能である。Chapter 4.2.1 で計算した m.gen メタ分析を使って、これを試してみることが可能である。このメタ分析におけるプール効果と \\(\\tau\\) 推定値がどのようなものであったか、もう一度見てみよう。\\(g=\\) 0.58、\\(\\tau=\\) 0.29であることがわかる。このデータに基づいて、95%真の効果量の信頼区間の下限と上限を計算することが可能である。0.58 \\(-\\) 1.96 \\(\\times\\) 0.29 = 0.01 と 0.58 \\(+\\) 1.96 \\(\\times\\) 0.29 = 1.15。「不確かさの不確かさは？」: \\(\\tau^2\\) の信頼区間の計算研究間異質性分散推定値の不確実性 (すなわち、\\(\\tau^2\\) 付近の信頼区間) を定量化する方法は、現在も検討されている分野である。いくつかのアプローチが考えられるが、その妥当性は \\(\\tau^2\\) 推定量の種類に依存する (Chapter 4.1.2.1)。{meta} パッケージは Veronikki (2016)の推奨に従い、ほとんどの推定量に対して \\(Q\\)-Profile 法 (Viechtbauer 2007b) を使用する。\\(Q\\)-Profile 法は、\\(Q\\) の改良版である一般化 \\(Q\\)-統計量 \\(Q_{\\text{gen}}\\)を用いた手法である．標準版の\\(Q\\)が固定効果モデルに基づくプール効果を用いるのに対し，\\(Q_{\\text{gen}}\\) はランダム効果モデルに基づいている。ランダム効果モデルによる全体効果である \\(\\hat\\mu\\) とランダム効果モデルに基づく重みを用いて偏差を計算する。\\[\\begin{equation}\nQ_{\\text{gen}} = \\sum_{k=1}^{K} w^*_k (\\hat\\theta_k-\\hat\\mu)^2\n\\tag{5.5}\n\\end{equation}\\]ここで、\\(w^*_k\\) はランダム効果重み ( Chapter 4.1.2.1 を参照) である。\\[\\begin{equation}\nw^*_k = \\frac{1}{s^2_k+\\tau^2}\n\\tag{5.6}\n\\end{equation}\\]また、\\(Q_{\\text{gen}}\\) は自由度 \\(K-1\\) の \\(\\chi^2\\) 分布に従うことが示されている。一般化　\\(Q\\)　統計量は \\(\\tau^2)\\) の値が大きいか小さいかで異なる値の \\(Q_{\\text{gen}}\\) を返す関数 \\(Q_{\\text{gen}}(\\tau^2)\\) と考えることができる。この関数の結果は、\\(\\chi^2\\) 分布となる。この \\(\\chi^2\\) 分布は明確に予測できるパターンに従っているので、例えば 95% カバーする信頼区間を簡単に求めることができる。その自由度 \\(K-1\\) に基づいて、2.5 と97.5 パーセンタイルの \\(\\chi^2\\) の値を求めればよい。 R では、これは分位数関数 qchisq を使用して簡単に行うことができる。例えば qchisq(0.975, df=5) とする。\\(Q\\)-Profile 法は、この関係を利用して、\\(\\tau^2\\) 付近の信頼区間を繰り返し計算する手法である(いわゆる「プロファイリング」)。この方法では、\\(Q_{\\text{gen}}(\\widetilde{\\tau}^2)\\) の値を増加させながら、\\(\\chi^2\\) 分布に基づく信頼区間の下限と上限の期待値に到達するまで繰り返し計算する。\\(Q\\)-Profile 法は、{meta} 関数の中で method.tau.ci = \"QP\" という引数で指定することができる。これはデフォルトの設定であり、この引数を手動で追加する必要はない。唯一の例外は、DerSimonian-Laird 推定法 (method.tau = \"DL\") を使用した場合である。この場合，自動的に Jackson (2013) による別の手法が使用される (手動で method.tau.ci = \"J\" と指定することで可能)。通常、{meta} のデフォルトの動作から外れる必要はないが、メタアナリシスにおいて、どの方法で \\(\\tau^2\\) の信頼区間を計算したかを報告することは、他の人にとって有益な場合がある。","code":"\n# 効果プール\nm.gen$TE.random## [1] 0.5771158\n# tau 推定\nm.gen$tau## [1] 0.2863311"},{"path":"heterogeneity.html","id":"het-measure-which","chapter":"5 研究間異質性","heading":"5.2 どの方法を使うべきか？","text":"メタアナリシスで異質性を評価・報告する場合、統計的検出力の影響をあまり受けず、かつ頑健な指標が必要です。コクランの \\(Q\\) は、研究の数が増えれば増えるほど、また精度 (すなわち研究のサンプルサイズ) が上がれば上がる。つまり、\\(Q\\) とそれが有意であるかどうかは、メタアナリシスの規模、その統計的検出力に大きく依存することになる。したがって、研究間の異質性を評価する際には、\\(Q\\)、特に \\(Q\\)-検定だけに頼るべきではない。一方、\\(^2\\) は、分析対象の研究数の変化に対して敏感ではない。解釈も比較的簡単で、多くの研究者がその意味を理解している。一般的に、メタアナリシス報告書に異質性の指標として \\(^2\\) を含めることは悪い考えではない。特に、この統計量の信頼区間を示すことで、他の人が推定値の正確さを評価することができるようになる。\nしかし、文献上ではよく使われているが、\\(^2\\) も異質性を測る完璧な指標ではない。異質性の絶対的な尺度ではなく、その値はやはり含まれる研究の精度に大きく依存する (Borenstein et al. 2017; Rücker et al. 2008)。上で述べたように、\\(^2\\) は単純にサンプリングエラー \\(\\epsilon\\) によって引き起こされない変動の割合である。研究がどんどん大きくなれば、サンプリングエラーはゼロになる傾向があり、同時に \\(^2\\) は100%になる傾向がある。ただし、これは単に研究のサンプルサイズが大きくなったからである。したがって、\\(^2\\) にだけ頼るのは良い選択肢とは言えない。\\(H^2\\) は \\(^2\\) と似たような挙動をするので、この統計量にも同じ注意点がある。一方、\\(\\tau^2\\) と \\(\\tau\\) の値は、研究数とその精度に依存しない。研究数や研究規模が大きくなっても系統的に増加することはない。しかし、\\(\\tau^2\\) が実用上どの程度の意味を持つのか、解釈しにくいことがある。例えば、ある研究で真の効果量の分散が \\(\\tau^2=\\) 0.08 であることが分かったとする。この分散が意味のあるものなのか、そうでないものなのかを判断するのは、自分自身にとっても、他の人にとっても、難しい場合がある。予測区間 (Prediction intervals, PIs) は、この限界を克服する良い方法である (IntHout et al. 2016)。予測区間は、現在の証拠に基づき、将来の研究の効果がどの範囲に収まると予想できるかを示している。予測区間が完全に介入に有利な「正」側にあるとする。これは、効果はさまざまであっても、我々が調査した文脈全体では、介入は将来有益であると期待されることを意味する。予測区間にゼロが含まれる場合、これについてはあまり確信が持てないが、広い予測区間はかなり一般的であることに注意する必要がある。全体効果の予測区間 \\(\\hat\\mu\\) を計算するために、推定された研究間異質性分散 \\(\\hat\\tau^2\\) とプール効果の標準誤差 \\(SE_{\\hat\\mu}\\) の両方を使用する。標準誤差の二乗と \\(\\hat\\tau^2\\) の値を合計し、その平方根をとる。これによって、予測区間の標準偏差 \\(SD_{\\text{PI}}\\) が得られる。予測範囲は自由度\\(K-1\\)の\\(t\\)分布を仮定しているので、\\(SD_{\\text{PI}}\\) に \\(t_{K-1}\\) の97.5値を掛け、その結果を \\(\\hat\\mu\\) に加算・減算することになる。これは、プールされた効果の95%予測区間を与える。95%予測区間の計算式は次のようになる。\\[\\begin{align}\n\\hat\\mu &\\pm t_{K-1, 0.975}\\sqrt{SE_{\\hat\\mu}^2+\\hat\\tau^2} \\notag \\\\\n\\hat\\mu &\\pm t_{K-1, 0.975}SD_{\\text{PI}} \\tag{5.7}\n\\end{align}\\]{meta} の関数はすべて、プール効果に対する予測区間を提供することができるが、デフォルトではない。メタ分析を実行する際には、予測区間が出力されるように prediction = TRUE という引数を追加する必要がある。まとめると、メタ分析の異質性を特徴付ける際に、一つの指標だけに頼らないことが望ましいということである。少なくとも、常に \\(^2\\) (信頼区間付き) と予測区間を報告し、それに従って結果を解釈することが推奨される。","code":""},{"path":"heterogeneity.html","id":"het-R","chapter":"5 研究間異質性","heading":"5.3 R での異質性評価","text":"異質性指標について学んだことを、実際にどのように使うことができるかを見てみよう。例として、これまで使ってきた m.gen メタ分析オブジェクトの異質性をもう少し詳しく調べてみよう (このオブジェクトは Chapter 4.2.1 で生成した)。metagen オブジェクトのデフォルトの出力には予測区間が含まれていないため、まずこれを更新する必要がある。単純に update.meta 関数を使用し、prediction の区間を追加で出力するように指示する。これで、結果を再確認することができる。この出力では、前に定義したすべての異質性測定の結果が表示される。まず、Quantifying heterogeneity のセクションから始めよう。ここで、\\(\\tau^2=\\) 0.08であることがわかる。\\(\\tau^2\\) (0.03 - 0.35)の信頼区間はゼロを含まず、私たちのデータに何らかの研究間異質性が存在することを示している。 \\(\\tau\\) の値は 0.29 である。これは、真の効果量が、効果量の尺度 (ここでは、Hedges’ \\(g\\)) で表される、\\(SD=\\) 0.29 の推定標準偏差を有することを意味する。2 行目を見ると、\\(^2=\\) 63%、\\(H\\) (\\(H^2\\) の平方根) は 1.64 であることがわかる。これは、データにおける変動の半分以上が、真の効果量の差から生じていると推定されることを意味している。Higgins Thompson の「経験則」を用いると、この異質性の量は中程度から大きいと特徴づけることが可能である。プール効果の直下に、予測区間が表示されている。これは、\\(g=\\) -0.06 から 1.21 までの範囲である。これは、現在のエビデンスに基づいて、将来のいくつかの研究が負の治療効果を発見する可能性があることを意味する。しかし、この区間はかなり広く、非常に高い効果も可能であることを意味する。最後に、\\(Q\\) と Test heterogeneity も提示されている。 \\(Q\\) = 45.5 であることがわかる。これは、この分析の \\(K-1=\\) 17 の自由度に基づいて期待されるものよりずっと多いものである。その結果、異質性検定は有意である (\\(p<\\) 0.001)。しかし、前に述べたように、\\(Q\\) の欠陥が知られている以上、 この検定だけに基づいて評価を行うべきではない。\nメタアナリシスにおける異質性量の報告\n\nこの例における異質性の量をどのように報告する文章を例示する。\n\n“-study heterogeneity variance estimated \\(\\hat\\tau^2\\) = 0.08 (95%CI: 0.03-0.35),\n\\(^2\\) value 63% (95%CI:\n38-78%). prediction interval ranged \\(g\\) = -0.06 1.21, indicating \nnegative intervention effects ruled future\nstudies.”\nでは、これらの結果から何がわかるのだろうか。全体として、ここで示している指標は、中程度からかなりの異質性がデータに存在することを教えてくれる。このメタ分析における効果は完全な異質という訳ではないが、研究間の真の効果量には明らかに何らかの差がある。したがって、この異質性の原因を探るのは良いアイデアだろう。効果量が大きく、実際には「当てはまらない」研究が 1 つまたは 2 つある可能性がある。これは、この分析における異質性を増大させ、さらに悪いことには、真の効果の過大評価につながった可能性がある。一方、プールされた効果は、サンプルサイズが非常に大きい 1 つの研究が予想外に小さい効果量を報告したことに大きく影響されている可能性もある。これは、プール効果が治療の真の効果を過小評価していることを意味する可能性がある。これらの懸念に対処するため、次に、プールした結果の頑健性を評価するための手続きを説明する。外れ値分析と影響度分析である。\\(^2\\) > 50% “Guideline”研究間の異質性について、具体的にいつさらなる解析が必要かを決める鉄則はない。実際に使われることもあるアプローチは、\\(^2\\) が 50% より大きいときに外れ値や影響力のあるケースをチェックすることである。この閾値に達すると、少なくとも中程度の異質性があり、変動の (半分以上が) 真の効果量の差に起因していると仮定することができる。この「経験則」は、やや恣意的なものであり、これまで述べてきた \\(^2\\) の問題を考えると、決して完全なものではない。しかし、メタ分析でプールされた効果のよりロバストなバージョンを得ようとするときに、priori に一貫した方法で指定することができるので、実用的な観点から役に立つ。","code":"\nm.gen <- update.meta(m.gen, prediction = TRUE)\nsummary(m.gen)## Review:     Third Wave Psychotherapies\n## \n## [...]\n## \n## Number of studies combined: k = 18\n## \n##                         SMD            95%-CI    t  p-value\n## Random effects model 0.5771 [ 0.3782; 0.7760] 6.12 < 0.0001\n## Prediction interval         [-0.0572; 1.2115]              \n## \n## Quantifying heterogeneity:\n##  tau^2 = 0.0820 [0.0295; 0.3533]; tau = 0.2863 [0.1717; 0.5944];\n##  I^2 = 62.6% [37.9%; 77.5%]; H = 1.64 [1.27; 2.11]\n## \n## Test of heterogeneity:\n##      Q d.f. p-value\n##  45.50   17  0.0002\n## \n## Details on meta-analytical method:\n## - Inverse variance method\n## - Restricted maximum-likelihood estimator for tau^2\n## - Q-profile method for confidence interval of tau^2 and tau\n## - Hartung-Knapp adjustment for random effects model (df = 17)\n## - Prediction interval based on t-distribution (df = 16)"},{"path":"heterogeneity.html","id":"outliers","chapter":"5 研究間異質性","heading":"5.4 外れ値と影響力のある事例","text":"\n前述したように、研究間の異質性は、効果量が極端に大きい 1 つまたは複数の研究によって引き起こされることがあり、それは全く「適合」しない。これはプールされた効果の推定値を歪める可能性があるため、そのような外れ値を分析から取り除いた後にプールされた効果を再検査することは良い考えである。一方、私たちは、私たちが見つけたプール効果推定値が頑健であるかどうか、つまり、一つの研究に大きく依存しないかどうかも知りたいと思われる。したがって、私たちの分析の効果を一方向に大きく押し上げるような研究があるかどうかも知りたいのである。このような研究は、影響力のあるケースと呼ばれており、この章の後半でこのトピックに時間を割くことにしよう。","code":""},{"path":"heterogeneity.html","id":"basic-outlier","chapter":"5 研究間異質性","heading":"5.4.1 基本的な外れ値除去","text":"ある研究の効果を「外れ値」と定義するには、いくつかの方法がある (Viechtbauer Cheung 2010)。簡単で、やや「強引な」アプローチは、研究の信頼区間がプール効果の信頼区間と重ならない場合、その研究を外れ値とみなすことである。外れ値の効果量は、全体の効果量と著しく異なるほど極端である。このような外れ値を検出するために、すべての研究を検索することが可能である。95% 信頼区間の上限がプール効果信頼区間の下限より低いもの (すなわち、極端に小さい効果)。95% 信頼区間の上限がプール効果信頼区間の下限より低いもの (すなわち、極端に小さい効果)。95% 信頼区間の下限がプール効果信頼区間の上限より高いもの (すなわち、極めて大きい効果)。95% 信頼区間の下限がプール効果信頼区間の上限より高いもの (すなわち、極めて大きい効果)。この方法の背景にある考え方は非常に単純である。サンプル誤差が大きい研究は、プール効果からかなり乖離することが予想される。しかし、そのような研究の信頼区間も大きくなるので、信頼区間がプールされた効果の信頼区間と重なる可能性が高くなる。しかし、ある研究が低い標準誤差を持ち、それでも (予想外に) プール効果から大きく逸脱している場合、信頼区間が重ならず、その研究は外れ値として分類される可能性が高い。{dmetar} パッケージには find.outliers という関数があり、この単純な外れ値除去アルゴリズムが実装されている。これは、{meta} オブジェクトから外れ値のある研究を検索し、これらを削除して、結果を再計算する。\n“find.outliers” 関数\n\nfind.outliers 関数は、{dmetar}\nパッケージに含まれている。{dmetar}\nがインストールされ、コンピュータに読み込まれると、この関数を使用できるようになる。もし、{dmetar}\nをインストールしていない場合は、以下の手順でインストールできる。\n\n関数のソースコードにアクセスする オンライン.\n\nソースコード全体をコンソール (R Studio の左下ペイン)\nにコピー＆ペーストし、Enterキーを押して、 R\nに関数を「学習」させる。\n\n{meta} と {metafor}\nパッケージがインストールされ、ロードされていることを確認する。\nfind.outliers 関数は、{meta} メタ分析関数によって生成されたオブジェクトを入力として必要とするだけである。それでは、m.gen オブジェクトに対してどのような結果が得られるか見てみよう。find.outliers 関数が、“DanitzOrsillo” と “Shapiro et al.” という2つの外れ値を検出したことがわかる。また、この関数は、検出された研究を除外しながら、自動的に分析を再実行してきた。各研究のランダム効果重みを表示す列、%W(random) では、外れ値の研究の重みが0に設定され、分析から除外されていることがわかる。出力に基づき、2つの研究が除外されると、\\(^2\\) 異質性がかなり縮小し、\\(^2=\\) 63% から 25% になることがわかる。 \\(\\tau^2\\) の信頼区間はゼロを含み、\\(Q\\) -異質性の検定は有意ではなくなる。その結果、私たちの推定値の予測区間も狭くなっている。今、それは正の値だけを含み、将来の研究にわたるプールされた効果の頑健性をより確実なものにしている。","code":"\nfind.outliers(m.gen)## Identified outliers (random-effects model) \n## ------------------------------------------ \n## \"DanitzOrsillo\", \"Shapiro et al.\" \n##  \n## Results with outliers removed \n## ----------------------------- \n## Number of studies combined: k = 16\n## \n##                         SMD           95%-CI    t  p-value\n## Random effects model 0.4528 [0.3257; 0.5800] 7.59 < 0.0001\n## Prediction interval         [0.1693; 0.7363]              \n## \n## Quantifying heterogeneity:\n##  tau^2 = 0.0139 [0.0000; 0.1032]; tau = 0.1180 [0.0000; 0.3213];\n##  I^2 = 24.8% [0.0%; 58.7%]; H = 1.15 [1.00; 1.56]\n## \n## Test of heterogeneity:\n##      Q d.f. p-value\n##  19.95   15  0.1739\n## \n## [...]"},{"path":"heterogeneity.html","id":"influence-analysis","chapter":"5 研究間異質性","heading":"5.4.2 影響力分析","text":"ここまでで、メタ分析における外れ値の検出と除去の基本的な方法を学んできた。しかし、プール効果の頑健性について懸念を引き起こすのは、極端な効果量だけではない。効果量が特に大きくなくても小さくても、全体の結果に非常に大きな影響力を及ぼす研究もある。例えば、メタ分析で全体的な効果を発見しても、その有意性は1つの大きな研究に依存している可能性がある。これは、影響力のある研究を取り除くと、プールされた効果が統計的に有意でなくなることを意味している。このような情報は、私たちの結果がいかに頑健であるかを一般に伝えるために非常に重要である。外れ値の研究と影響力のある研究とは、重複している部分もあるが、若干意味が異なる。外れ値は効果の大きさによって定義されるが、必ずしもメタ分析の結果に大きな影響を与える必要はない。外れ値を削除しても、平均効果量やデータの異質性が大きく変化しないことは十分にあり得る。一方、影響力のある事例とは、効果の高低にかかわらず、定義上、プール効果や異質性に大きな影響を与える研究のことを指す。もちろん、効果量が極端に大きい研究が影響力のあるケースになりえないということではない。実際、前章の例で説明したように、外れ値も影響力があることが多い。しかし、必ずしもそうなる訳ではない。影響力のある研究を特定するテクニックはいくつかあり、前回説明した基本的な外れ値除去よりも少し高度なものである。これらは leave-one-法に基づいている。このアプローチでは、メタ分析の結果を \\(K\\) 回再計算し、毎回一つの研究を除外 (leave ) する。このデータに基づいて、さまざまな影響力診断 (Influence Diagnosis) を計算することができる。影響力診断は、メタ分析の全体推定値に最も影響を与える研究を検出し、この大きな影響力がプール効果を歪めていないかどうかを評価することが可能である (Viechtbauer Cheung 2010)。{dmetar} パッケージには InfluenceAnalysis という関数が含まれており、1つの関数でこれらの様々な影響力診断を計算することが可能である。この関数は、{meta} 関数で作成されたあらゆるタイプのメタ分析オブジェクトに使用することが可能である。\n“InfluenceAnalysis” 関数\n\nInfluenceAnalysis 関数は、{dmetar}\nパッケージに含まれている。{dmetar}\nがインストールされ、コンピュータに読み込まれると、この関数を使用できるようになる。もし、{dmetar}\nをインストールしていない場合は、以下の手順でインストールできる。\n\n関数のソースコードにアクセスする オンライン.\n\nソースコード全体をコンソール (R Studio の左下ペイン)\nにコピー＆ペーストし、Enterキーを押して、 R\nに関数を「学習」させる。\n\n{meta}、{metafor}、{ggplot2}、{gridExtra}\nパッケージがインストールされ、ロードされていることを確認する。\nInfluenceAnalysis 関数の使用方法は比較的簡単である。影響度分析を行いたいメタ分析オブジェクトの名前を指定するだけである。ここでは、再び m.gen オブジェクトを使用しよう。InfluenceAnalysis はデフォルトで固定効果モデルを使用するので、random = TRUE を設定して、ランダム効果モデルが使用されるようにする必要がある。この関数は他の引数も取ることができ、主に関数が生成するプロットの種類を制御する。引数については、関数のドキュメントで詳しく説明されている。関数の結果を m.gen.inf というオブジェクトに保存する。InfluenceAnalysis 関数は、Baujatプロット、Viechtbauer Cheung (2010) による影響力診断、効果量と \\(^2\\) 値でソートされた leave-one メタ分析結果という4つの影響診断プロットを作成する。これらのプロットはそれぞれ plot 関数で個別に開くことが可能である。それでは、順を追って見ていこう。","code":"\nm.gen.inf <- InfluenceAnalysis(m.gen, random = TRUE)"},{"path":"heterogeneity.html","id":"baujat","chapter":"5 研究間異質性","heading":"5.4.2.1 Baujat プロット","text":"Baujat プロットは plot 関数を用いて、第2引数に \"baujat\" を指定することで表示できる。Baujat plots (Baujat et al. 2002) は、メタ分析における異質性に過度に寄与している研究を検出するための診断プロットである。横軸に全体の異質性 (Cochran’s \\(Q\\) で測定) に対する各研究の寄与を、縦軸にプール効果量に対するその影響を示している。この「影響力」の値は、leave-one-法により決定され、その研究がメタ分析に含まれる場合と含まれない場合の全体効果の標準化された差を表している。プロットの右側にある研究は、私たちのメタ分析における全体的な異質性に大きく寄与しているので、潜在的に関連するケースと見なすことが可能である。プロットの右上にある研究は、推定された異質性とプールされた効果の両方に大きな影響を与えるので、特に影響力があると思われる。プロットの右側にある2つの研究は、以前すでに検出したものである (“DanitzOrsillo” と “Shapiro et al.”)。この二つの研究は全体の結果に大きな影響を与えないが (サンプルサイズが小さいためと思われる)、メタ分析で見られる異質性に大きな影響を及ぼしている。","code":"\nplot(m.gen.inf, \"baujat\")"},{"path":"heterogeneity.html","id":"inf-diags","chapter":"5 研究間異質性","heading":"5.4.2.2 影響力診断","text":"次のプロットは、各研究のいくつかの影響力診断 (Influence Diagnostics) を含んでいる。これらは、このコードを使ってプロットすることが可能である。このプロットは、各研究について、さまざまな影響力の値を表示していることがわかる。これらの尺度は、どの研究がメタ分析モデルにうまく適合して、どの研究が適合しないかを特徴づけるために使用される。診断の意味を理解するために、左から右、上から下へと簡単に見ていこう。","code":"\nplot(m.gen.inf, \"influence\")"},{"path":"heterogeneity.html","id":"外部標準化残差","chapter":"5 研究間異質性","heading":"5.4.2.2.1 外部標準化残差","text":"最初のプロットは、各研究の外部標準化残差を表示している。名前にあるように、残差は、観察された各効果量 \\(\\hat\\theta_k\\) のプール効果量からの偏差を表している。残差は標準化されており、偏差を計算するために、研究を含まないプールされた効果の「外部」推定値を使用する。「外部」プール効果 \\(\\hat\\mu_{\\setminus k}\\) は、leave-one-法の原則に従って、研究 \\(k\\) を除いた全体効果を計算することによって得られる。そして、得られた残差は、(1) 外部効果の分散 (すなわち、\\(\\hat\\mu_{\\setminus k}\\) の標準誤差の2乗)、(2) 外部プール効果の推定値 \\(\\tau^2\\)、および (3) \\(k\\) の分散によって標準化される。\\[\\begin{equation}\nt_{k} = \\frac{\\hat\\theta_{k}-\\hat\\mu_{\\setminus k}}{\\sqrt{\\mathrm{Var}(\\hat\\mu_{\\setminus k})+\\hat\\tau^2_{\\setminus k}+s^2_k}}\n\\tag{5.8}\n\\end{equation}\\]研究 \\(k\\) がメタ分析にうまく適合すると仮定すると、分母の3つの項は、効果量が平均効果量からどれくらい異なるかを決定する変動源を捕捉した。これらの変動要因は、\\(k\\) のサンプルエラー、真の効果量の分散、およびプール効果量の推定値の不正確さである。もし研究が全体の母集団に合わないならば、残差は3つの分散項だけから予想されるよりも大きくなると仮定可能である。これは、\\(t_k\\) の値を高くし、その研究が「適合しない」影響力のあるケースであることを示している。","code":""},{"path":"heterogeneity.html","id":"mathrmdffits-値","chapter":"5 研究間異質性","heading":"5.4.2.2.2 \\(\\mathrm{DFFITS}\\) 値","text":"\\(\\mathrm{DFFITS}\\) 量の計算は、外部標準化残差の計算と同様である。したがって、DFFITSと \\(t_k\\) の値のパターンは、多くの場合、研究間で比較可能である。これが計算式である。\\[\\begin{equation}\n\\mathrm{DFFITS}_k =  \\dfrac{\\hat\\mu-\\hat\\mu_{\\setminus k}}{\\sqrt{\\dfrac{w_k^{(*)}}{\\sum^{K}_{k=1}w_k^{(*)}}(s^2_k+\\hat\\tau^2_{\\setminus k})}}\n\\end{equation}\\]計算には、研究 \\(k\\) ( Chapter 4.1.1 ) の (ランダム効果) 重みである \\(w_k^{(*)}\\) も必要で、これを重みの合計で割って研究の重みをパーセントで表現することになる。一般に、\\(\\mathrm{DFFITS}\\) の値は、ある研究 ( \\(k\\) ) を削除したときに、プールされた効果がどの程度変化するかを示し、標準偏差で表される。ここでも、値が高いほど、平均効果への影響が大きいので、その研究が影響力のあるケースである可能性を示している。","code":""},{"path":"heterogeneity.html","id":"cook-距離","chapter":"5 研究間異質性","heading":"5.4.2.2.3 Cook 距離","text":"ある研究の Cook 距離 \\(D_k\\) は、\\(\\mathrm{DFFITS}\\) の値と非常によく似た式で計算できる。最大の違いは、\\(D_k\\) の場合、\\(k\\) の有無によるプール効果の差は2乗になることである。この結果、\\(D_k\\) は正の値のみをとることになる。しかし、研究間のパターンは、\\(\\mathrm{DFFITS}\\) の値と似ていることが多い。以下は式である。\\[\\begin{equation}\nD_k =  \\frac{(\\hat\\mu-\\hat\\mu_{\\setminus k})^2}{\\sqrt{s^2_k+\\hat\\tau^2}}.\n\\tag{5.9}\n\\end{equation}\\]","code":""},{"path":"heterogeneity.html","id":"共分散比","chapter":"5 研究間異質性","heading":"5.4.2.2.4 共分散比","text":"研究 \\(k\\) の共分散比は、\\(k\\) のないプール効果の分散 (すなわち、その二乗標準誤差) を初期平均効果の分散で割ることによって算出することが可能である。\\[\\begin{equation}\n\\mathrm{CovRatio}_k = \\frac{\\mathrm{Var}(\\hat\\mu_{\\setminus k})}{\\mathrm{Var}(\\hat\\mu)}\n\\tag{5.10}\n\\end{equation}\\]\\(\\mathrm{CovRatio}_k\\) が 1 以下の値は、研究 \\(k\\) を削除することで、プール効果量 \\(\\hat\\mu\\) のより正確な推定値が得られることを示す。","code":""},{"path":"heterogeneity.html","id":"leave-one-out-tau2-値と-q-値","chapter":"5 研究間異質性","heading":"5.4.2.2.5 Leave-One-Out \\(\\tau^2\\) 値と \\(Q\\) 値","text":"この行の値は非常に簡単に解釈可能である。これらは単に、\\(\\tau^2\\) と Cochran’s \\(Q\\)、研究 \\(k\\) を削除した場合に測定される推定異質性を表示しているだけである。 \\(Q\\) 値と \\(\\tau^2\\) 値、特に後者の値が低いほど異質性が低いことを意味するので、望ましい。","code":""},{"path":"heterogeneity.html","id":"ハット値と研究の重み","chapter":"5 研究間異質性","heading":"5.4.2.2.6 ハット値と研究の重み","text":"最後の行には、各研究の重みとハット値が表示されている。研究重みの計算と意味については、すでに Chapter 4.1.1 で詳しく説明したので、この指標についてはこれ以上説明する必要はないだろう。一方、ハット値とは、研究の重みと等価な別の指標に過ぎない。したがって、影響力分析では、ハット値と重みのパターンは同一になる。これらの指標はすべて、極端な場合、その研究が影響力のあるケースであることを示し、プールした結果の頑健性に悪影響を及ぼす可能性のある値を示している。しかし、このポイントに到達するタイミングはあまり明確ではない。\\(\\mathrm{DFFITS}\\)、Cook 距離または標準化残差値が高すぎるという厳密なルールはない。研究を削除することが適切かどうかを判断するために、研究課題の文脈で影響度分析の結果を評価することが常に必要である。しかし、私たちの判断の指針となる「経験則」がいくつかある。InfluenceAnalysis 関数は、以下の条件のいずれかを満たす場合、その研究を影響力のあるケースとみなす29:\\[\\begin{equation}\n\\mathrm{DFFITS}_k > 3\\sqrt{\\frac{1}{k-1}}\n\\tag{5.11}\n\\end{equation}\\]\\[\\begin{equation}\nD_k > 0.45\n\\tag{5.12}\n\\end{equation}\\]\\[\\begin{equation}\n\\mathrm{hat_k} > 3\\frac{1}{k}.\n\\tag{5.13}\n\\end{equation}\\]影響力があると判断された研究は、 InfluenceAnalysis 機能で生成されたプロットで赤色で表示される。この例では、“DanitzOrsillo” 研究である “Dan” の場合のみ、こうなる。しかし、この研究だけが影響力があると定義されたが、実際にはほとんどのプロットで2個のスパイクが存在した。また、“Sha” (Shapiro et al.) の値も非常に極端なので、影響力のあるケースとして定義することが可能である。そこで、“DanitzOrsillo” と”Shapiro et al.” の研究が影響力を持つ可能性があることがわかる。これは、Baujat プロットに基づき、統計的外れ値だけを見たときに、同じ研究を選択したため、興味深い発見である。このことは、この2つの研究がプールされた効果推定値を歪め、最初のメタ分析で見出された研究間異質性の一部を引き起こしている可能性をさらに裏付けるものである。","code":""},{"path":"heterogeneity.html","id":"loo-ma","chapter":"5 研究間異質性","heading":"5.4.2.3 Leave-One-Out メタ分析結果","text":"\n最後に、leave-one-法を用いて実施されたすべてのメタ分析の全体効果および \\(^2\\) 異質性をプロットすることも可能である。1つはプール効果量、もう1つは leave-one-メタ分析の \\(^2\\) 値でソートされた2つのフォレストプロット ( Chapter 6.2 でもっと詳しく知ることになるプロットのタイプ) を表示すことが可能である。プロットを作成するコードは次のようなものである。これらの2つのフォレストプロットでは、毎回1つの研究を省略して再計算されたプール効果を見ることが可能である。両方のプロットで、中央に破線のある陰影のある領域がある。これは、元のプール効果量の95%信頼区間と推定されたプール効果そのものを表している。最初のプロットは、効果量 (低から高) 順に並べたものである。ここでは、異なる研究を削除したときに、全体の効果推定値がどのように変化するかを見ている。“DanitzOrsillo”と “Shapiro et al.” の2つの研究は、非常に高い効果量を持っているので、それらを取り除くと、全体の効果量が最も小さくなることがわかる。2番目のプロットは、\\(^2\\) で測定された異質性 (低から高) 順に並んでいる。このプロットは、“DanitzOrsillo” と “Shapiro et al.” の研究を除外すると、\\(^2\\) 異質性が最も低くなることを示している。これは、この2つの研究がメタ分析で見られた研究間の異質性の主な「犯人」であるという私たちの発見を裏付けるものである。全体として、この例の外れ値解析と影響力解析の結果は同じ方向を向いている。影響力のある外れ値であると思われる研究が2つある。この2つの研究は、効果量の推定値だけでなく、その精度も歪めてしまうだろう。したがって、この2つの研究を除外した感度分析の結果も実施し、報告する必要がある。","code":"\nplot(m.gen.inf, \"es\")\nplot(m.gen.inf, \"i2\")"},{"path":"heterogeneity.html","id":"gosh","chapter":"5 研究間異質性","heading":"5.4.3 GOSH プロット解析","text":"前章では、leave-one-法に基づく影響度分析を用いて、メタ分析の頑健性を探ってみた。データ中の異質性のパターンを探るもう一つの方法は、いわゆる Graphic Display Heterogeneity (GOSH) プロットである (Olkin, Dahabreh, Trikalinos 2012)。これらのプロットでは、含まれる研究のすべての可能なサブセットに、同じメタ分析モデルを当てはめる。leave-one-法とは対照的に、\\(K\\) モデルだけでなく、\\(2^{k-1}\\) 対の可能なすべての研究の組み合わせに対してモデルを当てはめる。これは、研究の総数が多い場合、GOSH プロットの作成にかなりの計算量がかかることを意味した。そのため、ここで取り上げる R の実装は、最大100万件のランダム化されたモデルしか適合させない。モデルが計算されると、X軸にプール効果量、Y軸に研究間の異質性を表示し、プロットすることが可能である。これにより、例えば、効果量や異質性の量が異なるクラスターなど、特定のパターンを探すことが可能である。GOSH プロットにいくつかの異なるクラスタがある場合、データ中に複数の効果量の「集団」が存在する可能性を示し、サブグループ解析を正当化する。一方、サンプル中の効果量が均質である場合、GOSHプロットは、ほぼ対称的で均質な分布を示す。GOSH プロットを生成するには、{metafor} パッケージの gosh 関数を使用することが可能である。まだパッケージをインストールしていない場合は、今すぐインストールし、ライブラリからロードしてみよう。メタ分析オブジェクト m.gen に対して、GOSH プロットを生成してみよう。そのためには、まず、{meta} パッケージによって作成されたこのオブジェクトを、{metafor} メタ分析オブジェクトに「変換 」する必要がある。{metafor} でメタ分析を行うために使用する関数は rma と呼ばれる。{meta} オブジェクトを rma メタ分析に変換するのはそれほど複雑なことではない。効果量 ( TE )、標準誤差 (seTE)、試験間異質性推定量 (method.tau) を m.gen に格納してこの関数に提供するだけである。引数 test = \"knha\" を指定することで、Knapp-Hartung 調整を使用するように指定することが可能である。新しく生成された {metafor} ベースのメタ分析を m.rma という名前で保存する。{meta} で固定効果モデルを使用した場合、 method.tau を rma の呼び出しに単純にコピーすることはできないことに注意してみよう。代わりに、 rma の method 引数を \"FE\" に設定する必要がある。そして、 m.rma オブジェクトを使用して、GOSH プロットを生成することが可能である。解析の研究数にもよるが、これにはある程度の時間、最大で数時間かかることがある。その結果を res.gosh として保存する。そして、 res.gosh オブジェクトを plot 関数に代入することでプロットを表示すことが可能である。追加の alpha 引数は、グラフ内のドットがどの程度透明であるかを制御する。グラフにはたくさんのデータポイントがあるので、値が「積み重なる」場所を明確にするために小さなアルファ値を使用することは理にかなっている。データには興味深いパターンが見られる。ほとんどの値が比較的高い効果と高い異質性を持つクラスターに集中している一方で、\\(^2\\) の値の分布は大きく右肩下がりの二峰性になっている。推定された異質性がかなり低く、プール効果量も小さい研究の組み合わせがあるようで、結果として「彗星のような」尾を持つ形状になっている。\n効果量 \\(-\\) 異質性のパターンを見て、本当に重要な質問は、どの研究がこの形状を引き起こすのか、ということである。この質問に答えるために、 gosh.diagnostics 関数を使用することが可能である。この機能は、3つのクラスタリングまたは教師なし機械学習アルゴリズムを用いて、GOSH プロットデータからクラスタを検出する。特定されたクラスタに基づいて、この関数は自動的にどの研究が各クラスタに最も貢献しているかを決定する。例えば、異質性の高いクラスターに1つまたは複数の研究が過剰に存在することが分かった場合、これらの研究は単独または組み合わせで、高い異質性の原因である可能性があることを示す。\n“gosh.diagnostics” 関数\n\ngosh.diagnostics 関数は、{dmetar}\nパッケージに含まれている。{dmetar}\nがインストールされ、コンピュータに読み込まれると、この関数を使用できるようになる。もし、{dmetar}\nをインストールしていない場合は、以下の手順でインストールできる。\n\n関数のソースコードにアクセスする オンライン.\n\nソースコード全体をコンソール (R Studio の左下ペイン)\nにコピー＆ペーストし、Enterキーを押して、 R\nに関数を「学習」させる。\n\n{gridExtra}, {ggplot2},\n{fpc}, {mclust}\nパッケージがインストールされ、ロードされていることを確認する。\n\ngosh.diagnostics 関数は、\\(k\\)-平均アルゴリズム (Hartigan Wong 1979)、密度到達性・接続性クラスタリング (density reachability connectivity clustering)、あるいは DBSCAN (Schubert et al. 2017) および ガウス混合モデル (gaussian mixture models) (Fraley Raftery 2002) という3種類のクラスタアルゴリズムを使用してデータのパターンを検出している。これらのアルゴリズムのパラメータのいくつかを調整することが可能である。km.params、 db.params、gmm.params の引数に、各アルゴリズムの挙動を制御する仕様を記述したリスト要素を追加することができる。この例では、\\(k\\)-means と DBSCAN アルゴリズムの細部を少し調整する。 \\(k\\) -平均アルゴリズムは、データ中の2つのクラスタ (「中心」) を探索するよう指定する。db.params では、DBSCAN が使用する eps、つまり \\(\\epsilon\\) の値を変更する。また、各クラスタに必要な最小限のポイント数を決定する MinPts 値も指定する。アルゴリズムのパラメータについては、gosh.diagnostics のドキュメントで詳しく説明されている。どのようなパラメータ指定が最適なのか明確なルールはないので、各アルゴリズムの詳細を何度か試してみて、それが結果にどのような影響を与えるかを確認するとよいだろう。gosh.diagnostics を呼び出すコードは次のようになる。(訳注: 数分かかることがある。)出力には、各アルゴリズムが検出したクラスタの数が表示される。各アプローチは異なる数学的戦略でデータを分割しているので、クラスタ数が同じでないのは当然である。Identification potential outliers では、この手順により、クラスタの構成に大きな影響を与える3つの研究 (研究3、研究4、研究16) を特定できたことがわかる。また、 gosh.diagnostics オブジェクトをプロットして、結果をもう少し詳しく調べることも可能である。これは、いくつかのプロットを生成した。最初の3つのプロットは、各アルゴリズムによって見つかったクラスタリングソリューションと、各クラスタ内の各研究に関連するクラスタインバランスの量を表している。この情報に基づいて、Cook 距離が各研究について計算され、これは、ある研究が検出されたクラスタに大きな影響を与えるかどうか (したがって、影響力のあるケースであるかもしれない) を判断するために使用される。他のプロットも GOSH プロットであるが、選択された研究が含まれる解析を表す陰影のついたポイントが表示された。例えば、研究 3 が含まれるほぼすべての結果は、高い異質性の値と高い効果量を持つクラスタに属していることがわかる。研究 4 が含まれる結果は、異質性にばらつきがあるが、一般的に平均効果がやや小さいことがわかる。研究16の結果は、研究 3 の結果と似ているが、もう少し分散している。gosh.diagnostics 関数が特定した3つの研究を削除して、メタ分析を再実行するとどうなるかを見てみよう。3 番と 16 番の研究が “DanitzOrsillo” と “Shapiro et al.” であることがわかる。この2つの研究は、以前の分析でも影響力があることが分かっている。研究番号 4 は “de Vibe” によるものである。この研究は、特に極端な効果量ではないが、観察された効果量が平均より小さいにもかかわらず、信頼区間が狭いことから、高い重みを持つことがわかる。このことは、この研究が影響力を持つ理由を説明できるだろう。この3つの研究を取り除くと、推定される異質性に大きな影響を与えることがわかる。\\(\\tau^2\\) の値はほぼゼロになり、\\(^2\\) の値も非常に低く、効果量の変動の 4.6% のみが真の効果量の差によるものであることを示している。プール効果 \\(g\\) = 0.48 は、最初の推定値 \\(g=\\) 0.58 よりは小さいが、それでも同じ桁の範囲内である。全体として、最初に計算した平均的な効果は、外れ値や影響力のある研究によって、あまり大きくバイアスされてはいないことを示している。影響力解析の結果を報告“DanitzOrsillo”, “de Vibe et al.”, “Shapiro et al.” がメタアナリシスで影響力のある研究だと判断されたとする。この場合、これらの研究を除外した感度解析の結果も報告するべきである。影響力のある研究を削除した場合の変化を読者にわかりやすくするために、元の結果と感度分析の結果の両方を表示した表を作成することができる。この表には、少なくともプール効果、その信頼区間、\\(p\\) 値、そして予測区間や \\(^2\\) 統計量 (およびその信頼区間) のような異質性のいくつかの尺度を含める必要がある。また、どの研究が影響力のあるケースとして削除されたかを明記し、新しい結果がどのデータに基づいているのかを他の人が理解できるようにすることも重要である。以下は、以前行った m.gen メタアナリシスにおいて作成した表の一例である。1Removed outliers: DanitzOrsillo, de Vibe, Shapiro.このような表は、他の感度解析の結果をさらに行に追加することができ、非常に便利である。例えば、バイアスリスクの低い研究 (Chapter 1.4.5) のみを考慮した分析を行った場合、その結果を3行目に報告することができる。\\[\\tag*{$\\blacksquare$}\\]","code":"\nlibrary(metafor)\nm.rma <- rma(yi = m.gen$TE,\n             sei = m.gen$seTE,\n             method = m.gen$method.tau,\n             test = \"knha\")\nres.gosh <- gosh(m.rma)\nplot(res.gosh, alpha = 0.01)\nres.gosh.diag <- gosh.diagnostics(res.gosh, \n                                  km.params = list(centers = 2),\n                                  db.params = list(eps = 0.08, \n                                                   MinPts = 50))\nres.gosh.diag## GOSH Diagnostics \n## ================================ \n## \n##  - Number of K-means clusters detected: 2\n##  - Number of DBSCAN clusters detected: 4\n##  - Number of GMM clusters detected: 7\n## \n##  Identification of potential outliers \n##  --------------------------------- \n## \n##  - K-means: Study 3, Study 16\n##  - DBSCAN: Study 3, Study 4, Study 16\n##  - Gaussian Mixture Model: Study 3, Study 4, Study 11, Study 16\nplot(res.gosh.diag)\nupdate.meta(m.gen, exclude = c(3, 4, 16)) %>% \n  summary()## Review:     Third Wave Psychotherapies\n##                           SMD            95%-CI %W(random) exclude\n## Call et al.            0.7091 [ 0.1979; 1.2203]        4.6        \n## Cavanagh et al.        0.3549 [-0.0300; 0.7397]        8.1        \n## DanitzOrsillo          1.7912 [ 1.1139; 2.4685]        0.0       *\n## de Vibe et al.         0.1825 [-0.0484; 0.4133]        0.0       *\n## Frazier et al.         0.4219 [ 0.1380; 0.7057]       14.8        \n## Frogeli et al.         0.6300 [ 0.2458; 1.0142]        8.1        \n## Gallego et al.         0.7249 [ 0.2846; 1.1652]        6.2        \n## Hazlett-Stevens & Oren 0.5287 [ 0.1162; 0.9412]        7.0        \n## Hintz et al.           0.2840 [-0.0453; 0.6133]       11.0        \n## Kang et al.            1.2751 [ 0.6142; 1.9360]        2.7        \n## Kuhlmann et al.        0.1036 [-0.2781; 0.4853]        8.2        \n## Lever Taylor et al.    0.3884 [-0.0639; 0.8407]        5.8        \n## Phang et al.           0.5407 [ 0.0619; 1.0196]        5.2        \n## Rasanen et al.         0.4262 [-0.0794; 0.9317]        4.7        \n## Ratanasiripong         0.5154 [-0.1731; 1.2039]        2.5        \n## Shapiro et al.         1.4797 [ 0.8618; 2.0977]        0.0       *\n## Song & Lindquist       0.6126 [ 0.1683; 1.0569]        6.1        \n## Warnecke et al.        0.6000 [ 0.1120; 1.0880]        5.0        \n## \n## Number of studies combined: k = 15\n## \n##                         SMD           95%-CI    t  p-value\n## Random effects model 0.4819 [0.3595; 0.6043] 8.44 < 0.0001\n## Prediction interval         [0.3586; 0.6053]              \n## \n## Quantifying heterogeneity:\n##  tau^2 < 0.0001 [0.0000; 0.0955]; tau = 0.0012 [0.0000; 0.3091];\n##  I^2 = 4.6% [0.0%; 55.7%]; H = 1.02 [1.00; 1.50]\n## \n## Test of heterogeneity:\n##      Q d.f. p-value\n##  14.67   14  0.4011\n## [...]"},{"path":"heterogeneity.html","id":"演習問題-4","chapter":"5 研究間異質性","heading":"5.5 演習問題","text":"\n知識を試そう！\n\nなぜメタ分析の研究間異質性を調べることが重要なのか。\n\n異質性の2つのタイプを挙げられるか？メタ分析の計算にはどちらが関係するか？\n\nCochran’s \\(Q\\)\nの有意性が、研究間異質性の十分な指標とならないのはなぜか。\n\nメタ分析で異質性の大きさを表現するために予測区間を使うメリットは何か。\n\n統計的外れ値と影響力のある研究の違いは何か？\n\nGOSH のプロットは何に使えるのか。\n\n問題の解答は、本書の巻末 Appendix\nにある。\n","code":""},{"path":"heterogeneity.html","id":"要約-1","chapter":"5 研究間異質性","heading":"5.6 要約","text":"メタ分析では、プール効果量だけでなく、この平均的な効果量の根拠となったデータの異質性にも注意を払わなければならない。全体的な効果では、いくつかの研究における真の効果が私たちの点推定値と大きく異なる可能性があることを把握できないのである。メタ分析では、プール効果量だけでなく、この平均的な効果量の根拠となったデータの異質性にも注意を払わなければならない。全体的な効果では、いくつかの研究における真の効果が私たちの点推定値と大きく異なる可能性があることを把握できないのである。Cochran’s \\(Q\\) は、データのばらつきを定量化するためによく使われる。\\(Q\\) は \\(\\chi^2\\) 分布に従うことが分かっているので、この尺度を使うと、サンプル誤差だけに基づいて予想されるよりも多くの変動が存在するかどうかを検出することが可能である。この過剰な変動は、研究の効果量における真の差異を表している。Cochran’s \\(Q\\) は、データのばらつきを定量化するためによく使われる。\\(Q\\) は \\(\\chi^2\\) 分布に従うことが分かっているので、この尺度を使うと、サンプル誤差だけに基づいて予想されるよりも多くの変動が存在するかどうかを検出することが可能である。この過剰な変動は、研究の効果量における真の差異を表している。\\(Q\\) の統計的検定は、しかし、手元にあるデータの種類に大きく依存した。異質性の量を評価するために、\\(Q\\) だけに頼るべきではない。\\(^2\\)、\\(\\tau\\) や予測区間など、追加で使用することができる他の尺度がある。\\(Q\\) の統計的検定は、しかし、手元にあるデータの種類に大きく依存した。異質性の量を評価するために、\\(Q\\) だけに頼るべきではない。\\(^2\\)、\\(\\tau\\) や予測区間など、追加で使用することができる他の尺度がある。メタ分析における平均的な効果は、データに外れ値がある場合、偏りが生じることがある。外れ値は、メタ分析の結果に必ずしも大きな影響を与えるとは限りない。しかし、そのような場合は、「影響力のあるケース (influential cases) 」と呼ばれる。メタ分析における平均的な効果は、データに外れ値がある場合、偏りが生じることがある。外れ値は、メタ分析の結果に必ずしも大きな影響を与えるとは限りない。しかし、そのような場合は、「影響力のあるケース (influential cases) 」と呼ばれる。外れ値や影響力のある症例を特定する方法はいろいろある。もし、そのような研究が検出された場合は、それらを除外してメタ分析を再計算し、私たちの結果の解釈が変わるかどうかを確認することが望ましい。外れ値や影響力のある症例を特定する方法はいろいろある。もし、そのような研究が検出された場合は、それらを除外してメタ分析を再計算し、私たちの結果の解釈が変わるかどうかを確認することが望ましい。","code":""},{"path":"forest.html","id":"forest","chapter":"6 フォレストプロット","heading":"6 フォレストプロット","text":"前\n章では、 R で効果量をプールする方法と、メタ分析で異質性を評価する方法について学んだ。ここからは、メタ分析の中でも楽しい部分で、前のステップで得た結果を可視化していく。メタ分析を可視化する最も一般的な方法は、フォレストプロットである。このプロットは、観察された効果、信頼区間、そして通常は各研究の重み付けをグラフィカルに表示する。また、メタ分析で計算されたプール効果も表示される。全体として、この図によって、含まれる研究の精度や広がり、プール効果が観察された効果量とどのように関連しているのかを素早く調べることが可能である。{meta} パッケージには、 R で直接美しいフォレストプロットを非常に簡単に作成するための関数が組み込まれている。この関数は幅広い機能を持ち、プロットの外観を好きなように変更することが可能である。このフォレストプロット関数と、それを実際にどのように使うことができるかが、この章の主な焦点である。さらに、メタ分析の結果を可視化するための別のアプローチについても簡単に説明する。","code":""},{"path":"forest.html","id":"フォレストプロットとは","chapter":"6 フォレストプロット","heading":"6.1 フォレストプロットとは？","text":"Figure 6.1 は、フォレストプロットの主な構成要素を示している。フォレストプロットの左側には、メタ分析に含まれる各研究の名前が表示される。各研究について、通常はプロットの中央に効果量のグラフが表示され、x 軸に研究の点推定値を示している。推定値の点からは線が伸びており、観察された効果量に対して計算された信頼区間の範囲を示している。通常、点推定値は四角で囲まれている。この四角の大きさは効果量の重み (Chapter 4.1.1) で決まり、重みの大きな研究では大きな四角が、重みの小さな研究では小さな四角が与えられる。通常、フォレストプロットにはメタ分析に使用した効果量のデータも掲載している。これにより、結果を再現するために必要なデータを他の人に提供することが可能である。\nFigure 6.1: フォレストプロットの重要要素\nプロットの下部にある菱形は、平均効果を表している。菱形の長さは、x 軸上のプールされた結果の信頼区間を表している。通常、フォレストプロットには垂直の参照線がある。この線は x 軸上の効果がない値を示している。さらに、フォレストプロットは、例えば、\\(^2\\) や \\(\\tau^2\\) のような異質性指標を表示すことによって強化されることがある。これについては、例で見ていこう。フォレストプロットにおける効果量と信頼区間は、通常、線形スケールで表示される。しかし、要約尺度が比 (オッズ比やリスク比など) である場合、x 軸で対数スケールを使用することが一般的である。これは、1 よりずっと低い値や高い値よりも、1 付近の値の方がより多くあることを意味する。比に意味がある効果量の測定基準は「線形」に解釈することができない (すなわち、RR = 0.50 の「反対」は 1.5 ではなく 2 である。Chapter 3.3.2 を参照)。この場合の効果量の参照線は、通常 1 であり、1 が効果がないことを示す。","code":""},{"path":"forest.html","id":"forest-R","chapter":"6 フォレストプロット","heading":"6.2 R のフォレストプロット","text":"メタ分析オブジェクト (例: metagen、metacont、metabin の結果) の種類に関わらず、 forest.meta 関数を使用してフォレストプロットを作成することが可能である (訳注: 関数名は forest でよい。一般に、 R では、 forest 関数が forest.meta のようにドット以降にクラスを指定したものを自動的に読み込む。)。forest.meta に {meta} オブジェクトを渡すだけで、プロットが作成される。通常、フォレストプロットはデフォルトで非常に良い見た目をしているが、この関数はさらに見た目を整えるための追加引数をたくさん持っている。すべての引数は関数のドキュメントに記載されている (?forest.metaを実行することでアクセス可能)。ここでは、より重要なものをリストアップしよう。sortvar. メタ分析データセットの変数で、フォレストプロットで研究をソートするためのもの。例えば、効果量によって結果を並べ替えたい場合、sortvar = TE というコードを使用することが可能である。sortvar. メタ分析データセットの変数で、フォレストプロットで研究をソートするためのもの。例えば、効果量によって結果を並べ替えたい場合、sortvar = TE というコードを使用することが可能である。comb.fixed. 論理値。固定効果モデルの推定値をプロットに含めるかどうかを示す。comb.fixed. 論理値。固定効果モデルの推定値をプロットに含めるかどうかを示す。comb.random. 論理値。ランダム効果モデルの推定値をプロットに含めるかどうかを示す。comb.random. 論理値。ランダム効果モデルの推定値をプロットに含めるかどうかを示す。text.fixed. 固定効果モデルによるプール効果のラベルを表示する。デフォルトでは \"Fixed effect model\" と表示される。text.fixed. 固定効果モデルによるプール効果のラベルを表示する。デフォルトでは \"Fixed effect model\" と表示される。text.random. ランダム効果モデルによるプール効果のラベル。デフォルトでは \"Random effects model\" と表示される。text.random. ランダム効果モデルによるプール効果のラベル。デフォルトでは \"Random effects model\" と表示される。prediction. 論理値。予測区間をプロットに追加するかどうかを示す。prediction. 論理値。予測区間をプロットに追加するかどうかを示す。label.left と label.right. フォレストプロットの左側と右側に追加されるラベル。例えば、この側の効果は治療に有利であることを明示できる (例: label.left = \"Favors treatment\")。label.left と label.right. フォレストプロットの左側と右側に追加されるラベル。例えば、この側の効果は治療に有利であることを明示できる (例: label.left = \"Favors treatment\")。smlab. プロットの上に表示されるラベル。どの効果量メトリックを使用したかを示すために使用できる。smlab. プロットの上に表示されるラベル。どの効果量メトリックを使用したかを示すために使用できる。xlim. x 軸の限界値、または対称的なフォレストプロットを作成したいときは文字 \"s\" を指定する。結果がゼロから大きく外れている場合や、外れ値を表示させたい場合に関係する。例えば、x 軸を 0 から 2 の範囲にしたい場合、コードは xlim = c(0,2) となる。xlim. x 軸の限界値、または対称的なフォレストプロットを作成したいときは文字 \"s\" を指定する。結果がゼロから大きく外れている場合や、外れ値を表示させたい場合に関係する。例えば、x 軸を 0 から 2 の範囲にしたい場合、コードは xlim = c(0,2) となる。ref. プロットにおける参照線。使用した要約尺度に依存し、デフォルトでは 0 または 1 のどちらかになる。ref. プロットにおける参照線。使用した要約尺度に依存し、デフォルトでは 0 または 1 のどちらかになる。leftcols と rightcols. ここでは、フォレストプロットの左側と右側に表示する変数を指定することができる。この関数がデフォルトで使用する要素がいくつかある。例えば、\"studlab\" は研究のラベル、 \"effect\" は観測された効果量、 effect.ci は効果量とその信頼区間を表す。また、最初に {meta} 関数に提供した data.frame に含まれていれば、ユーザー定義の列を追加することも可能である。この場合、列の名前を文字列として追加するだけである。leftcols と rightcols. ここでは、フォレストプロットの左側と右側に表示する変数を指定することができる。この関数がデフォルトで使用する要素がいくつかある。例えば、\"studlab\" は研究のラベル、 \"effect\" は観測された効果量、 effect.ci は効果量とその信頼区間を表す。また、最初に {meta} 関数に提供した data.frame に含まれていれば、ユーザー定義の列を追加することも可能である。この場合、列の名前を文字列として追加するだけである。leftlabs と rightlabs. フォレストプロットの左側と右側に表示される列に使用されるラベル。leftlabs と rightlabs. フォレストプロットの左側と右側に表示される列に使用されるラベル。print.I2 と print.I2.ci. 論理値。\\(^2\\) 値とその信頼区間を表示すかどうかを指定する。デフォルトでは TRUE。print.I2 と print.I2.ci. 論理値。\\(^2\\) 値とその信頼区間を表示すかどうかを指定する。デフォルトでは TRUE。print.tau2 と print.tau. 論理値。\\(\\tau^2\\) と \\(\\tau\\) の値を表示すかどうかを指定する。デフォルトでは、\\(\\tau^2\\) の値を表示する。print.tau2 と print.tau. 論理値。\\(\\tau^2\\) と \\(\\tau\\) の値を表示すかどうかを指定する。デフォルトでは、\\(\\tau^2\\) の値を表示する。col.square, col.diamond, col.predict. それぞれ、正方形、菱形、予測区間の色 (例: \"blue\") を指定する。col.square, col.diamond, col.predict. それぞれ、正方形、菱形、予測区間の色 (例: \"blue\") を指定する。それではフォレストプロットを作成してみよう。この例では、前の例で使用した m.gen オブジェクトをプロットしている。フォレストプロットでは、効果量によって研究を並べ替え、予測区間を追加し、左側にユーザー定義のラベルを追加している。forest.meta 関数は、デフォルトで \\(\\tau^2\\) 値を出力するが、ここでは不要なので、print.tau2 を FALSE に設定する。最終的にこのようなコードになる。(訳注: 原著では引数が間違っていた。pdrediction が正しい。)forest.meta のプロットの見た目は、すでにかなり良い。また、太めの線がプロットに追加され、プール効果の予測区間を表していることがわかる。各研究のバイアスリスクを表示す列を追加することで、プロットを強化することが可能である。m.gen の生成に使用した ThirdWave データセットには、RiskOfBias という列があり、そこに各研究のバイアスリスク評価が保存されている。メタ分析の計算に metagen を使用している場合 (Chapter 4.2.1)、この関数は自動的にこのデータを m.gen 内に保存する。したがって、 leftcols 引数を使用して、プロットに列を追加することが可能である。この結果、次のようなコードになる。フォレストプロットに各研究のバイアスリスク情報が追加されたことがわかる。","code":"\nforest.meta(m.gen, \n            sortvar = TE,\n            prediction = TRUE, \n            print.tau2 = FALSE,\n            leftlabs = c(\"Author\", \"g\", \"SE\"))\npar(bg=\"#FFFEFA\")\nforest(m.gen, \n       sortvar = TE,\n       prediction = TRUE, \n       print.tau2 = FALSE,\n       leftcols = c(\"studlab\", \"TE\", \"seTE\", \"RiskOfBias\"),\n       leftlabs = c(\"Author\", \"g\", \"SE\", \"Risk of Bias\"))"},{"path":"forest.html","id":"レイアウトの種類","chapter":"6 フォレストプロット","heading":"6.2.1 レイアウトの種類","text":"forest.meta 関数には2つの 「パッケージ済み」レイアウトがあり、これを使用すると、多数の引数を指定することなくフォレストプロットを特定の形式にすることが可能である。そのうちの1つは \"JAMA\" レイアウトで、Journal American Medical Association のガイドラインに従ったフォレストプロットを提供するものである。このレイアウトは、メタ分析を医学雑誌に掲載したい場合に使用される。もう一つのレイアウトは \"RevMan5\" で、Cochrane の Review Manager 5 で生成されるものと同様のフォレストプロットを生成する。","code":"\nforest.meta(m.gen, layout = \"JAMA\")\nforest.meta(m.gen, layout = \"RevMan5\")"},{"path":"forest.html","id":"フォレストプロットを保存","chapter":"6 フォレストプロット","heading":"6.2.2 フォレストプロットを保存","text":"forest.meta によって生成されたフォレストプロットは、PDF、PNG、または scalable vector graphic (SVG) ファイルとして保存することが可能である。base R や {ggplot2} パッケージによって生成される他のプロットとは対照的に、forest.meta の出力はファイルとして保存する際に自動的にサイズ調整されていない。このため、フォレストプロットは 2 辺または 4 辺が切り取られることがあり、すべてが見えるように幅と高さを手動で調整する必要がある。pdf、png、svg 関数を使用すると、 R のコードでプロットを保存することができる。まず、いずれかの関数をコールして、次のコードの出力をドキュメントに保存するように R に指示する。そして、forest.meta 関数の呼び出しを追加する。最後の行では、dev.() とし、生成された出力を上記で指定したファイルに保存する。どの関数も file という引数でファイル名を指定する。ファイルは、その名前で自動的に作業ディレクトリに保存される。さらに、width と height 引数でプロットの大きさを指定することができるので、出力が途切れるような場合に役立つ。最初のフォレストプロットを “forestplot” という名前で保存すると仮定して、以下のようなコードで PDF、PNG、SVG ファイルを生成することが可能である。PDFPNGSVG","code":"\npdf(file = \"forestplot.pdf\", width = 8, height = 7)\n\nforest.meta(m.gen, \n            sortvar = TE,\n            prediction = TRUE, \n            print.tau2 = FALSE,\n            leftlabs = c(\"Author\", \"g\", \"SE\"))\n\ndev.off()\npng(file = \"forestplot.png\", width = 2800, height = 2400, res = 300)\n\nforest.meta(m.gen, \n            sortvar = TE,\n            prediction = TRUE, \n            print.tau2 = FALSE,\n            leftlabs = c(\"Author\", \"g\", \"SE\"))\n\ndev.off()\nsvg(file = \"forestplot.svg\", width = 8, height = 7)\n\nforest.meta(m.gen, \n            sortvar = TE,\n            prediction = TRUE, \n            print.tau2 = FALSE,\n            leftlabs = c(\"Author\", \"g\", \"SE\"))\n\ndev.off()"},{"path":"forest.html","id":"drapery","chapter":"6 フォレストプロット","heading":"6.3 ドレーパリープロット","text":"フォレストプロットは、メタ分析を可視化する最も一般的な方法である。発表されたメタ分析のほとんどにフォレストプロットが含まれており、多くの研究者がその解釈方法を理解している。フォレストプロットは、調査結果の包括的で理解しやすい要約を提供するので、メタ分析レポートにもフォレストプロットを含めることが推奨される。しかし、フォレストプロットだけが結果を説明する手段ではない。メタ分析は、例えば、ドレーパリープロット (Rücker Schwarzer 2021) (drapery plot、訳注: ドレーパリーとは、衣服やカーテンなどのひだのこと。美術史では、衣文とも訳される。) などでも可視化することが可能である。フォレストプロットの欠点は、固定された有意閾値、慣習的に\\(p<\\) 0.05を仮定した信頼区間しか表示できないことである。研究者は、これらの信頼区間に基づいて、効果が有意であるか否かを決定している。近年、\\(p\\) 値の利用をめぐる論争があり (Wellek 2017)、\\(p\\) 値に基づく仮説検定が、多くの研究領域で「再現性の危機」に寄与しているという議論もある (Nuzzo 2014)。ドレーパリープロットは、\\(p\\)-値関数に基づいている。この \\(p\\) 値関数とは、解析結果を解釈する際に \\(p\\) < 0.05 の有意性閾値だけに頼らないために提案されたものである (Infanger Schmidt-Trucksäss 2019)。したがって、\\(p\\) 値関数は 95% 信頼区間を計算するだけでなく、\\(p\\) の値を変化させた場合の信頼区間を示す連続曲線を提供する。ドレーパリープロットでは、各研究の信頼曲線と平均効果の信頼曲線がプロットされる。x 軸は効果量指標を示し、y 軸は仮定された \\(p\\) 値を示す。ドレーパリープロットは、 {meta} の drapery 関数によって生成することが可能である。forest.meta と同様に、この関数に {meta} メタ分析オブジェクトを与えると、自動的にプロットが生成される。追加引数が複数あるが、最も重要なのは以下の引数である。type: y 軸にプロットされる値の種類を定義する。検定統計量の \"zvalue\" (デフォルト)、または \\(p\\)-値 (\"pvalue\") とする。type: y 軸にプロットされる値の種類を定義する。検定統計量の \"zvalue\" (デフォルト)、または \\(p\\)-値 (\"pvalue\") とする。study.results: 論理値。各研究の結果をプロットに含めるかどうかを指定する。FALSE の場合、効果の要約のみが表示される。study.results: 論理値。各研究の結果をプロットに含めるかどうかを指定する。FALSE の場合、効果の要約のみが表示される。labels: この引数を \"studlab\" に設定すると、試験のラベルがプロットに含まれるようになる。labels: この引数を \"studlab\" に設定すると、試験のラベルがプロットに含まれるようになる。legend: 論理値。凡例を表示すかどうかを示す。legend: 論理値。凡例を表示すかどうかを示す。pos.legend. 凡例の位置。\"bottomright\"、\"bottom\"、\"bottomleft\"、\"left\"、\"topleft\"、\"top\"、\"topright\"、\"right\"、\"center\" のいずれかを指定。pos.legend. 凡例の位置。\"bottomright\"、\"bottom\"、\"bottomleft\"、\"left\"、\"topleft\"、\"top\"、\"topright\"、\"right\"、\"center\" のいずれかを指定。メタ分析オブジェクト m.gen を使って drapery 関数を試してみよう。結果として得られるプロットは、各効果量の \\(p\\)-値曲線を含み、すべて逆 V 字の形をしている。太線はランダム効果モデルによる平均効果を表した。プロットで見られる斜線部分は予測区間で、プール効果の信頼区間よりもかなり広い。\\(p\\) 値関数の「ピーク」は、メタ分析における効果量の正確な値を表している。y 軸を下に行くに従って、\\(p\\) 値は小さくなり、信頼区間は広くなり、破線の水平線で示される従来の有意閾値に到達することになる。\\(p\\) がすでに非常に小さいとき (<0.01) に太線が x 軸上でゼロになることから、プロットに基づいて、プール効果量がゼロより大きいことをかなり確信できることがわかる。Rücker et al. (2021) は、ドレーパリープロットは主にフォレストプロットに加えて使用すべきであると推奨している。なぜなら、フォレストプロットは、結果を再現するために必要な効果量情報を含んでいないことがある。\\[\\tag*{$\\blacksquare$}\\]","code":"\ndrapery(m.gen, \n        labels = \"studlab\",\n        type = \"pval\", \n        legend = FALSE)"},{"path":"forest.html","id":"演習問題-5","chapter":"6 フォレストプロット","heading":"6.4 演習問題","text":"\n知識を試そう！\n\nフォレストプロットの主要な構成要素は何か？\n\nメタ分析でフォレストプロットを提示するメリットは何か？\n\nフォレストプロットの限界は何か、ドレーパリープロットはこの限界をどのように克服しているのか。\n\n問題の解答は、本書の巻末 Appendix\nにある。\n","code":""},{"path":"forest.html","id":"要約-2","chapter":"6 フォレストプロット","heading":"6.5 要約","text":"メタ分析の結果は、フォレストプロットで可視化するのが一般的である。メタ分析の結果は、フォレストプロットで可視化するのが一般的である。フォレストプロットは、各研究の効果量と信頼区間をグラフ化したもので、総合効果の計算値も表示される。さらに、プールに使用された効果量データも含まれる。フォレストプロットは、各研究の効果量と信頼区間をグラフ化したもので、総合効果の計算値も表示される。さらに、プールに使用された効果量データも含まれる。フォレストプロットには、各研究が受けた品質評価など、他の種類の情報を追加することも可能である。フォレストプロットには、各研究が受けた品質評価など、他の種類の情報を追加することも可能である。","code":""},{"path":"subgroup.html","id":"subgroup","chapter":"7 サブグループ解析","heading":"7 サブグループ解析","text":"C\nhapter 5 では、研究間異質性の概念と、それがメタ分析においてなぜ重要であるかについて説明した。また、外れ値分析や影響力分析の一環として、どの研究が観察された異質性に寄与しているかを特定するための手法も学んだ。この分析では、純粋に統計学的な立場からメタ分析にアプローチする。データ中のかなりの異質性を「測定」し、その結果、統計的特性に合わない研究 (すなわち、外れ値や影響力のある研究) を除外して、モデルの頑健性を向上させる。\nこの方法は、post hoc な手続きと見なすことができる。外れ値や影響力の分析は、データを見た後に行われ、多くの場合、見つけた結果のために行われるのである。また、データそのもの以外のものには注意を払わない。影響力分析の方法論は、ある研究がモデルの予測に適切に沿わないことを教えてくれるとしても、それがなぜなのかは教えてくれない。原因は、この研究がわずかに異なる研究手法や治療法を用いているからかもしれない。しかし、このことは研究の影響力だけではわからないのである。ある治療法の効果を調べるためにメタ分析を行うとする。その結果、全体としてその治療には効果がないことが分かったとする。しかし、大きな治療効果が認められた研究が 3 つあるとしよう。これらの研究を影響力分析で検出することは可能だろうが、なぜその研究が影響力があるのかはわからない。この 3 つの研究では、他のすべての研究で使用された治療法とわずかに異なる治療法が使用され、この小さなディテールが治療効果に大きな影響を与えたということがあり得るのである。これは画期的な発見だろう。しかし、外れ値解析や影響力分析だけではできない発見である。\nこのことから、データから特定の異質性パターンを見出すためには、別のアプローチが必要であることは明らかである。サブグループ解析は、これを行うための一つの方法であり、モデレータ分析とも呼ばれる。ある種の研究が、なぜ他の研究よりも低い効果や高い効果をもたらすのかを説明し、特定の仮説を検証することが可能である。Chapter 1.4.2 で学んだように、サブグループ検定は priori で定義されるべきである。メタ分析を始める前に、観察された効果量に影響を与える可能性のあるさまざまな研究特性を定義し、それに従って各研究をコーディングする必要がある。効果量が異なる理由は無数にあるが、分析の文脈上、重要なものに限定すべきである。例として、ある種の薬が他の薬より高い効果をもたらすかどうかを調べることができる。あるいは、追跡期間が短い研究と長い研究を比較することもできる。また、研究が実施された文化的地域によって、観察された効果が異なるかどうかを調べることも可能である。メタ分析では、その分野に特化した専門知識があると、その分野の他の科学者や実務者に実際に関連する質問を見つけることができることがある。サブグループ解析の背景にある考え方は、メタ分析が平均的な効果量を計算するだけでなく、エビデンスのばらつきを調べるツールにもなり得るということである。サブグループ解析では、異質性を単に厄介なものとしてではなく、科学的仮説によって説明できるか否かという興味深い変動としてとらえる。最良の場合、これは私たちを取り巻く世界の理解を深めるものとなる。そうでなくとも、少なくとも将来の意思決定の指針となる実用的な洞察を生み出すものとなる。この章では、サブグループ解析の背後にある統計モデルと、 R で直接サブグループ解析を行う方法について説明する。","code":""},{"path":"subgroup.html","id":"fixed-effect-plural","chapter":"7 サブグループ解析","heading":"7.1 固定効果 (複数) モデル","text":"サブグループ解析では、メタ分析に含まれる研究は、1 つの総体的集団から生じているのではないと仮定する。その代わりに、異なるサブグループに分類され、各サブグループが独自の真の全体効果を持つと仮定する。研究の目的としては、サブグループ間の効果量に差がないという帰無仮説を棄却することになる。サブグループ解析の計算は、2 つの部分からなる。まず、各サブグループでの効果をプールする。その後、統計的検定 を用いて、各サブグループの効果を比較する (Borenstein Higgins 2013) 。","code":""},{"path":"subgroup.html","id":"サブグループにおける効果のプール化","chapter":"7 サブグループ解析","heading":"7.1.1 サブグループにおける効果のプール化","text":"最初の部分は、サブグループなしのメタ分析 (Chapter 4.1) と同じ基準が適用されるので、かなり簡単である。もし、サブグループ内のすべての研究が同じ集団から発生し、1つの共有された真の効果を持つと仮定すると、固定効果モデルを使用することが可能である。前に述べたように、研究をより小さなグループに分割しても、実際にはこの仮定が成立しないことがよくある。したがって、代替案は、ランダム効果モデルを使用することである。これは、サブグループ内の研究は、推定したい平均値を持つ母集団から抽出されると仮定する。通常のメタ分析との違いは、各サブグループごとに別々のランダム効果メタ分析を実施することである。論理的には、この結果、各サブグループ \\(g\\) のプール効果 \\(\\hat\\mu_g\\) が得られる。各サブグループはそれぞれ個別のメタ分析を受けるので、\\(\\tau^2\\) 異質性の推定値もサブグループごとに異なる。しかし実際には、個々の異質性の値 \\(\\hat\\tau^2_g\\) は、サブグループ間でプールされた \\(\\tau^2\\) に置き換えられることが多いようである。つまり、すべてのサブグループが研究間の異質性の共通の推定値を共有すると仮定することになる。これは、実用的な理由で行われることがほとんどである。サブグループ内の研究数が少ない場合、例えば \\(k_g \\leq 5\\) (Borenstein et al. 2011, chap. 19) の場合、\\(\\tau^2\\) の推定値が不正確になる可能性がある。この場合、1 つのサブグループにおける研究間異質性の非常に不正確な推定値に頼るよりも、すべてのサブグループで使用するプールされた \\(\\tau^2\\) を計算する方がよいだろう。","code":""},{"path":"subgroup.html","id":"comparing-the-subgroup-effects","chapter":"7 サブグループ解析","heading":"7.1.2 サブグループ効果の比較","text":"次のステップでは、\\(G\\) 件のサブグループ間に 真の差があるかどうかを評価する。この仮定は、サブグループが異なっていること、つまり、少なくとも 1 つのサブグループが研究の異なる集団の一部であることを意味する。これをテストするエレガントな方法は、サブグループのプール効果が、実は1つの大規模研究の観察された効果量に過ぎないというふりをすることである (Borenstein et al. 2011、chap. 19 参照)。例えば、\\(G=3\\) のサブグループ解析を行う場合、3 つの大きな研究の観察された効果量 (および標準誤差) を計算したふりをするのである。このようにサブグループを見ると、通常のメタ分析の異質性を評価するときに直面する質問と非常に似ていることがわかる。効果量の差が、サンプルエラーによってのみ存在するのか、それとも効果量の真の差によって存在するのかを知りたいと思っている。したがって、サブグループの差が、サンプル誤差だけでは説明できないほど大きいかどうかを判断するために、\\(Q\\) の値を使用する。サブグループ効果が観察された効果量であると仮定して、\\(Q\\) の値を計算する。この観察された \\(Q\\) の値は、\\(\\chi^2\\) の分布と仮定した場合の期待値と比較され、この場合は自由度 \\(G-1\\) である (Chapter 5.1.1)。\\(Q\\) の観測値が期待値よりかなり大きい場合、\\(Q\\) 検定の \\(p\\) -値は有意になる。これは、サブグループ間の真の効果量に差があることを示す。この \\(Q\\) 検定は、オムニバス検定である。これは、すべてのサブグループの効果量が等しいという帰無仮説を検定し、少なくとも 2 つのサブグループ、またはそれらの組み合わせが異なる場合に有意であることを示すものである。通常、サブグループ内の研究はランダム効果モデルに従ってふるまうと仮定するが、プールされたサブグループレベルでは状況は異なるように見える。Borenstein Higgins (2013) は、多くの分野で、分析するために選択したサブグループは、可能なサブグループの「宇宙」からランダムに抽出したものとは見なせず、調査したい特性の固定レベルを表していると論じている。例として、雇用形態を挙げる。雇用形態には、“employed” と “unemployed” という2つの固定されたサブグループがある。同じことが、例えば、特定の併存疾患を持つ患者と持たない患者における研究にも当てはまる。\nBorenstein Higgins は、サブグループ解析のためのモデルを固定効果 (複数) モデル (fixed-effects (plural) model) と呼んでいる。「複数」という言葉がついているのは、標準的な固定効果モデル (fixed-effect model) と区別するためである。固定効果 (複数) モデルは、固定効果モデルとランダム効果モデルの両方の特徴を含むハイブリッドな生き物と見ることが可能である。ランダム効果モデルと同様に、データにはサブグループが存在するため、真の効果量は1つではないと仮定する。ただし、サブグループは、サブグループの全宇宙からのランダムな抽選とは見なさない。サブグループの水準は固定で、網羅的であり、一般化が必要ないことを意味する。これは、私たちがサブグループデータを生成するプロセスを固定効果「複数」モデルと呼ぶ理由を明確にする: なぜなら、複数の真の効果量が存在するが、真の効果量は、固定と仮定されるサブグループレベルを表しているからである。Borenstein ら (2011, chap. 19) は、「固定」という言葉が統計学では二つの意味を持つため、少し混乱しているように見えるかもしれないと論じている。従来のメタ分析では、「固定効果」という言葉は「共通効果」と同義に使われる。しかし、サブグループ解析の文脈では、「ランダムではない」ことを強調するために「固定効果」という言葉を使う。固定効果は、一般化することを目的とする包括的な分布の単なるランダムな現れではなく、変数が入ることができる現実かつ唯一のカテゴリである。Figure 7.1 は、サブグループ内の研究がランダム効果モデルに従うと仮定して、固定効果 (複数) モデルを可視化する。\nFigure 7.1: サブグループ内でランダム効果モデルを想定した固定効果 (複数) モデルの可視化。\n\n水準が固定されたサブグループ変数の例\n\n年齢層: 小児、若年成人 (young\nadults)、成人、高齢者\n\n文化的背景: 西洋、非西洋\n\n対照群: 代替療法、最小限治療、治療なし\n\nアウトカム測定手法: 自己報告、専門家判断\n\n研究の質: 高、低、不明\n\n種: 植物、動物\n\nセッティング: 学校、病院、家庭\n\nサブグループの具体的な選択と定義は、メタアナリシスの目的と範囲に基づいて適合させることができ、またそうすべきであることに注意。\n\n固定効果 (複数) モデルは、ランダム効果 (サブグループ内) と固定効果 (サブグループは固定されていると仮定されているため) の両方を含むので、文献上では混合効果モデル (mixed-effects model) としても知られている。Chapter 4.2.6 ですでにこの用語に触れている。たとえば、割合をプールするために使用できる異なるタイプの (一般化) 混合効果モデルについて議論してきた。サブグループ解析に使用するモデルは、メタ分析でよく使用される他の手法と大きく関連している。Chapter 8 では、サブグループ解析が単なるメタ分析の特殊なケースであり、そのために混合効果モデルも使用することを示す予定である。さらに、サブグループの水準が固定であると仮定できない可能性もある。効果が観察された場所によって、効果の大きさが異なるかどうかを評価したいと想像してみよう。ある研究はイスラエルで、ある研究はイタリアで、ある研究はメキシコで、ある研究は中国本土で、効果を評価してきたとする。世界にはたくさんの国があり、国を水準数の固定された因子とはみなすことはできないため、「ランダム」な選択を含んでいることにする。この場合、サブグループを固定的にモデル化するのではなく、ランダム効果として国ごとのばらつきを推定するようにすることが理にかなっている。これは、Chapter 10 で扱うマルチレベル・モデルにつながる。","code":""},{"path":"subgroup.html","id":"limits-subgroup","chapter":"7 サブグループ解析","heading":"7.2 サブグループ解析の限界と落とし穴","text":"直感的には、サブグループ解析は、効果を弱める因子を検出するのに非常に優れたツールであると考えるかもしれない。結局のところ、メタ分析の目的は、利用可能なすべてのエビデンスを調査することである。これは、メタ分析で分析される個体の総数は、通常、一次研究のそれを桁違いに上回ることを意味した。しかし、残念ながら、この方法では、サブグループの違いを検出するための統計的検出力は必ずしも高くはない。これにはいくつかの理由がある (L. V. Hedges Pigott 2004)。まず、サブグループ解析では、サブグループ内の結果は通常ランダム効果モデルを使用してプールされることを覚えておこう。サブグループ内の研究間異質性が大きい場合、プール効果の精度が低下する (すなわち、標準誤差が増加する) ことになる。しかし、サブグループの効果推定値が非常に不正確な場合、これは、それらの信頼区間が大きく重なることを意味する。結果的に、たとえ差が存在するとしても、サブグループ間の有意差を見つけることを難しくする。まず、サブグループ解析では、サブグループ内の結果は通常ランダム効果モデルを使用してプールされることを覚えておこう。サブグループ内の研究間異質性が大きい場合、プール効果の精度が低下する (すなわち、標準誤差が増加する) ことになる。しかし、サブグループの効果推定値が非常に不正確な場合、これは、それらの信頼区間が大きく重なることを意味する。結果的に、たとえ差が存在するとしても、サブグループ間の有意差を見つけることを難しくする。同じように、サブグループ解析で検出したい効果は、通常のメタ分析よりもはるかに低いため、統計的検出力も低くなりがちである。例えば、あるアウトカムを自己報告と専門家の評価で評価する研究間で、効果に差があるかどうかを調べるとした。たとえ差があったとしても、それは非常に小さいものだろう。治療群と対照群の間に有意差を見出すことはしばしば可能である。しかし、研究間の効果量の差を検出することは、差が小さいため、通常より多くの統計的検出力が必要とされ、より困難である。同じように、サブグループ解析で検出したい効果は、通常のメタ分析よりもはるかに低いため、統計的検出力も低くなりがちである。例えば、あるアウトカムを自己報告と専門家の評価で評価する研究間で、効果に差があるかどうかを調べるとした。たとえ差があったとしても、それは非常に小さいものだろう。治療群と対照群の間に有意差を見出すことはしばしば可能である。しかし、研究間の効果量の差を検出することは、差が小さいため、通常より多くの統計的検出力が必要とされ、より困難である。上記の点から、重要な注意事項がある: エビデンスの欠如は、欠如のエビデンスではない。もし、サブグループ間の効果量に差がないとしても、それは自動的にサブグループが同等のアウトカムをもたらすということにはならない。上で述べたように、私たちのサブグループ解析が、効果の真の差を確認するのに必要な統計的検出力を持たないかもしれない様々な理由があるのである。この場合、サブグループが同じ効果を持つと言うのは重大な誤訳である–私たちは、差が存在するかどうか単に知らないのである。このことは、ある治療法が他の治療法よりも優れているかどうかを評価したい場合に、特に問題となる。企業を含む一部の利害関係者は、しばしば治療の同等性を示すことに既得権益を有している。しかし、サブグループ解析は、通常、これを証明する適切な方法ではない。上記の点から、重要な注意事項がある: エビデンスの欠如は、欠如のエビデンスではない。もし、サブグループ間の効果量に差がないとしても、それは自動的にサブグループが同等のアウトカムをもたらすということにはならない。上で述べたように、私たちのサブグループ解析が、効果の真の差を確認するのに必要な統計的検出力を持たないかもしれない様々な理由があるのである。この場合、サブグループが同じ効果を持つと言うのは重大な誤訳である–私たちは、差が存在するかどうか単に知らないのである。このことは、ある治療法が他の治療法よりも優れているかどうかを評価したい場合に、特に問題となる。企業を含む一部の利害関係者は、しばしば治療の同等性を示すことに既得権益を有している。しかし、サブグループ解析は、通常、これを証明する適切な方法ではない。事前にサブグループ検出力分析を行うことで、サブグループ解析において統計的検出力が問題となるかどうかを確認することが可能である。このような分析では、サブグループ解析で検出できる最小の効果量の差を確認することが可能である。各種ツールの Chapter 14.3 では、 R でどのようにサブグループ検出力分析を行うことができるかを説明している。しかし、検出力分析は、せいぜい有用な診断として見られるだけで、私たちの分析の検出力が十分に高く、サブグループが同等であることを示す証明にはならないことに注意してみよう。Schwarzer ら (Schwarzer, Carpenter, Rücker 2015, chap. 4.3) は、一般的な経験則として、サブグループ解析は、メタ分析が少なくとも \\(K=\\) 10 件の研究を含むときにのみ意味をなすと言及している。事前にサブグループ検出力分析を行うことで、サブグループ解析において統計的検出力が問題となるかどうかを確認することが可能である。このような分析では、サブグループ解析で検出できる最小の効果量の差を確認することが可能である。各種ツールの Chapter 14.3 では、 R でどのようにサブグループ検出力分析を行うことができるかを説明している。しかし、検出力分析は、せいぜい有用な診断として見られるだけで、私たちの分析の検出力が十分に高く、サブグループが同等であることを示す証明にはならないことに注意してみよう。Schwarzer ら (Schwarzer, Carpenter, Rücker 2015, chap. 4.3) は、一般的な経験則として、サブグループ解析は、メタ分析が少なくとも \\(K=\\) 10 件の研究を含むときにのみ意味をなすと言及している。サブグループ解析のもう一つの重要な限界は、純粋に観察的であることである (Borenstein Higgins 2013)。メタ分析には、参加者が治療群または対照群のいずれかにランダムに割り付けられたランダム化比較試験 (RCT) しか含まれていないことが多い。このような RCT は、適切に実施されれば、研究で観察された群間差を治療が引き起こしたというエビデンスを提供することが可能である。これは、評価されたアウトカムに影響を与える可能性のあるすべての関連変数が 2 つのグループで等しいために言うことができる。唯一の違いは、一方のグループが治療を受け、もう一方のグループが受けなかったということである。サブグループ解析は、ランダム化された研究のみからなる場合でも、因果関係を示すことができない。サブグループ解析で、ある種の治療が他の治療より効果的であることがわかったとした。この発見が偽りかもしれない理由は無数にある；たとえば、治療 を調査した研究では、治療 B を調査した研究とは別の対照群を使用していた可能性がある。これは、両方の治療が同じように有効である可能性があり、治療タイプが方法論の因子と交絡 (confound) するので、違いを見ているだけだということである。この例は、サブグループ解析の結果を常に批判的に評価する必要があることを強調するものである。最後の重要な落とし穴は、サブグループの定義の仕方である。しばしば、集合的な情報に基づいて研究をサブグループに分類したくなることがある。Schwarzer ら (Schwarzer, Carpenter, Rücker 2015, chap. 4.3) は、よくある例として、研究の平均年齢を挙げている。例えば、高齢者 (65歳以上) と一般成人との間で効果が異なるかどうかを評価したいとする。そこで、報告された平均年齢が65歳以上か以下かによって、研究をこの2つのカテゴリに分類する。もし、平均年齢の高いサブグループで効果が高いことがわかれば、直感的に、高齢者ほど効果が高いことを示していると考えるかもしれない。しかし、この推論には深い欠陥がある。一次研究の平均年齢が 65 歳以上である場合、それよりも若い個人の割合がかなり含まれている可能性がある。その逆もまた然りで、平均年齢が 65 歳より低い場合でも、65 歳より上の人が多く含まれている可能性は十分にあるのである。つまり、「高齢者」サブグループに見られる高い効果は、実際には 65 歳未満の個人によってのみもたらされる可能性がある。逆に、「若い」サブグループでは、低い効果は 65 歳以上の研究対象者によってもたらされた可能性がある。このことは、逆説的な状況をもたらす。すなわち、全体レベルでは、平均年齢が高い研究ほど効果が高いことがわかる。しかし、個人レベルではその逆で、年齢が上がるにつれて効果は低くなる。今述べたシナリオは、いわゆる生態学的バイアス (S. G. Thompson Higgins 2002; Piantadosi, Byar, Green 1988) によって引き起こされるものである。このバイアスは、個人 (ミクロ) レベルの関連を予測するために、集合体 (マクロ) レベルの関係を利用したいときに発生するものである。生態学的バイアスを回避する最善の方法は、サブグループ解析やメタ回帰において、集計情報を決して使用しないことである。しかし、ある研究のすべての個人が 1 つのカテゴリに分類されるとわかっている場合は、状況が違ってくる。例えば、18 歳未満の青少年のみを対象としたいくつかの研究と、成人 (18 歳以上) のみを対象としたいくつかの研究があれば、生態学的バイアスのリスクはほぼ排除される。しかし、効果の違いは、参加者の年齢ではなく、交絡変数によって引き起こされた可能性が残っている。\nサブグループ解析: やって良いことと悪いこと\n\nサブグループ解析は統計的検出力に依存するため、研究数が小さい場合は通常実施する意味がない\n(つまり \\(K\\) < 10)。\n\nサブグループ間の効果量に差がない場合、これは自動的にサブグループが同等な結果をもたらすことを意味するものではない。\n\nサブグループ解析は純粋に観察的なものなので、効果の違いは交絡変数によっても引き起こされる可能性があることを常に念頭に置いておく必要がある。\n\nサブグループ解析において、集合的な研究情報を使用することは、生態学的なバイアスをもたらす可能性があるため、良くない考えである。\n","code":""},{"path":"subgroup.html","id":"subgroup-R","chapter":"7 サブグループ解析","heading":"7.3 R のサブグループ解析","text":"R で学んだことを実行する時が来た。{meta} パッケージを使ってサブグループ解析を行うのは比較的簡単である。{meta} のすべてのメタ分析関数において、 subgroup 引数を指定することが可能である30。これは、どの効果量がどのサブグループに該当するかを関数に伝え、サブグループ解析を実行する。引数 subgroup には、character、factor、logical、numeric の変数を指定することが可能である。唯一気をつけなければならないのは、同じサブグループに属する研究は絶対に同じラベルを持つということである。この例では、再び m.gen メタ分析オブジェクトを使用する。メタ分析の計算に使用した ThirdWave データセットには、サブグループ情報を持ついくつかの列が含まれている。ここでは、バイアスのリスクが高い研究と低い研究の間で効果量に差があるかどうかを調べたい。バイアスリスクの情報は、RiskOfBias 列に格納されている。まず、この列を見てみよう。このコードでは、データセットの最初の数行だけが表示されるように head 関数を使用している。データセット内の各研究は、バイアスのリスク評価を指定するラベルを持っていることがわかる。metagen を使用してメタ分析を計算した際、この情報は内部的に m.gen オブジェクトに保存された。サブグループ解析を行うには、update.meta 関数を使用して m.gen オブジェクトを指定し、subgroup 引数を使用してデータセットのどの列にサブグループラベルが含まれるかを指定する。前に、サブグループ解析は、サブグループ間で共通の推定値 (\\(\\tau^2\\) ) の有無で実施できることも取り上げた。これは、{meta} で tau.common を TRUE または FALSE に設定することで制御することが可能である。とりあえず、各サブグループでの研究間異質性分散の別々の推定値を使用することにしよう。この例では、固定効果 (複数) モデルを適用し、サブグループ内の研究はランダム効果モデルを使用してプールされると仮定する。m.gen にランダム効果モデルの結果が含まれているので、(comb.fixed を FALSE、comb.random を TRUE に設定したので) 何も変更する必要はない。元のメタ分析はランダム効果モデルを用いて行われたため、update.meta は自動的に、サブグループ内の研究もランダム効果モデルを用いてプールすることを想定している。したがって、出来上がったコードは次のようになる。この出力では、Results subgroups と呼ばれる新しいセクションが表示される。出力のこの部分は、各サブグループで別々にプール効果量を示している。バイアスのリスクが高い研究が \\(k=\\) 7 件、バイアスのリスクが低い研究が 11 件であることがわかる。推定された研究間の異質性はかなり異なっており、バイアスのリスクの高い研究では \\(^2=\\) 77% であるが、リスクの低い研究では 26% にすぎない。また、サブグループの効果量も異なっている。\\(g=\\) 0.43 で、バイアスリスクの低い研究の効果推定値は、バイアスリスクの高い研究よりも小さい。バイアスのかかった研究は治療効果を過大評価する可能性が高いので、このことはよく見られる所見である。しかし、その差は統計的に有意なのだろうか？Test subgroup differences には、\\(Q\\)-検定を示している 結果があるので、これで確認することができる。この例では、2つのサブグループがあり、自由度1に基づいている。この検定の \\(p\\)-値は 0.09 で、従来の有意水準より大きいが、それでも傾向レベルの差を示している。また、両方のサブグループで共通の \\(\\tau^2\\) 推定値を仮定した場合の結果も確認することができる。tau.common を TRUE に設定するだけである。この出力では、推定された研究間異質性分散が \\(\\tau^2=\\) 0.069 で、両方のサブグループで同じであることがわかる。２つの \\(Q\\) -検定が提示される。すなわち、groups の異質性 (実際のサブグループ) と within-subgroup の異質性 (サブグループ内の異質性) である。通常のメタ分析と同様に、後者は単にサブグループに過剰な変動があることを示している (\\(p=\\) 0.001)。サブグループ差の検定でも、バイアスリスクが低い研究と高い研究の間に有意な差がないことが示された (\\(p=\\) 0.181)。ここで、\\(\\tau^2\\) が独立しているか、あるいは共通のであるかを仮定して結果を探った。両サブグループの異質性が等しいと仮定する十分な理由がなく、また、各サブグループに最低 \\(k=\\) 7 件の研究があることから、\\(\\tau^2\\) の別々の推定が適切であると考えられる。しかし、少なくともこの例では、どちらのアプローチでも結果の解釈は同じようなものだとわかった。サブグループ解析の結果を報告サブグループ解析の結果は、通常、各サブグループにおける推定効果と異質性、およびサブグループの差の検定の \\(p\\) 値を表示した表で報告される。High\nLow\n上の表で、第３列の \\(p\\) 値はサブグループに特有の効果が有意であることを示している。これは、高バイアスと低バイアスのどちらでも発生する。また、\\(p_{\\textsf{subgroup}}\\) より小さい値は\n高リスクと低リスクの効果の差は有意ではないことを示している。サブグループに特有の \\(p\\) 値を抽出するには、update.meta の結果をオブジェクトとして保存し、このオブジェクトから pval.random.w 要素を $ 演算子を使って抽出する。\\[\\tag*{$\\blacksquare$}\\]","code":"\n# 研究名と 'RiskOfBias' 列、最初のデータを表示\nhead(ThirdWave[,c(\"Author\", \"RiskOfBias\")])##            Author RiskOfBias\n## 1     Call et al.       high\n## 2 Cavanagh et al.        low\n## 3   DanitzOrsillo       high\n## 4  de Vibe et al.        low\n## 5  Frazier et al.        low\n## 6  Frogeli et al.        low\nupdate.meta(m.gen, \n            subgroup = RiskOfBias, \n            tau.common = FALSE)## Review:     Third Wave Psychotherapies\n## \n## Number of studies combined: k = 18\n## \n##                         SMD           95%-CI    t  p-value\n## Random effects model 0.5771 [0.3782; 0.7760] 6.12 < 0.0001\n## Prediction interval              [-0.0572; 1.2115]     \n## \n## Quantifying heterogeneity:\n##  tau^2 = 0.0820 [0.0295; 0.3533]; tau = 0.2863 [0.1717; 0.5944]\n##  I^2 = 62.6% [37.9%; 77.5%]; H = 1.64 [1.27; 2.11]\n## \n## Test of heterogeneity:\n##      Q d.f. p-value\n##  45.50   17  0.0002\n## \n## Results for subgroups (random effects model (HK)):\n##                     k    SMD           95%-CI  tau^2    tau     Q   I^2\n## RiskOfBias = high   7 0.8126 [0.2835; 1.3417] 0.2423 0.4922 25.89 76.8%\n## RiskOfBias = low   11 0.4300 [0.2770; 0.5830] 0.0099 0.0997 13.42 25.5%\n## \n## Test for subgroup differences (random effects model (HK)):\n##                     Q d.f. p-value\n## Between groups   2.84    1  0.0917\n## \n## Details on meta-analytical method:\n## - Inverse variance method\n## - Restricted maximum-likelihood estimator for tau^2\n## - Q-profile method for confidence interval of tau^2 and tau\n## - Hartung-Knapp (HK) adjustment for random effects model (df = 17)\n## - Prediction interval based on t-distribution (df = 16)\nupdate.meta(m.gen, subgroup = RiskOfBias, tau.common = TRUE)## [...]\n##                     k    SMD           95%-CI  tau^2    tau     Q   I^2\n## RiskOfBias = high   7 0.7691 [0.2533; 1.2848] 0.0691 0.2630 25.89 76.8%\n## RiskOfBias = low   11 0.4698 [0.3015; 0.6382] 0.0691 0.2630 13.42 25.5%\n## \n## Test for subgroup differences (random effects model (HK)):\n##                    Q d.f. p-value\n## Between groups  1.79    1  0.1814\n## Within groups  39.31   16  0.0010\n## \n## Details on meta-analytical method:\n## - Inverse variance method\n## - Restricted maximum-likelihood estimator for tau^2 \n##   (assuming common tau^2 in subgroups)\n## [...]"},{"path":"subgroup.html","id":"演習問題-6","chapter":"7 サブグループ解析","heading":"7.4 演習問題","text":"\n知識を試そう！\n\n影響力分析や外れ値分析ではわからないことのうち、何がサブグループ解析ではわかることがあるか？\n\nサブグループ解析の背景にあるモデルが、なぜ固定効果 (複数)\nモデルと呼ばれるのか。\n\nメタ分析の一環として、ある教育研修プログラムの効果が、実施された学区によって異なるかどうかを調べたいと考えている。この問いに答えるために、固定効果\n(複数) モデルを用いたサブグループ解析は適切か？\n\nあなたの友人が、合計9つの研究を含むメタ分析を行った。これらの研究のうち5つが1つのサブグループに分類され、4つが他のサブグループに分類されている。彼女は、サブグループ解析を行うことに意味があるかどうかをあなたに尋ねている。あなたならどうするか？\n\nメタ分析で、分析した治療法が男性よりも女性でより効果的であると著者が主張しているものがあった。この知見は、研究対象者に含まれる女性の割合に基づいて研究をサブグループに分けたサブグループ解析に基づいている。この知見は信頼できるか、またその理由は？\n\n問題の解答は、本書の巻末 Appendix\nにある。\n","code":""},{"path":"subgroup.html","id":"要約-3","chapter":"7 サブグループ解析","heading":"7.5 要約","text":"メタ分析の不均一性を評価する方法はいろいろあるが、これらのアプローチでは、データに過剰な変動が見られる理由を知ることはできない。サブグループ解析では、ある研究の真の効果量が他の研究よりも高い、または低い理由についての仮説を検証することが可能である。メタ分析の不均一性を評価する方法はいろいろあるが、これらのアプローチでは、データに過剰な変動が見られる理由を知ることはできない。サブグループ解析では、ある研究の真の効果量が他の研究よりも高い、または低い理由についての仮説を検証することが可能である。サブグループ解析では、通常、固定効果 (複数) モデルを仮定する。サブグループ内の研究は、ほとんどの場合、ランダム効果モデルを用いてプールされる。その後、全体のサブグループの結果に基づいた \\(Q\\) -検定を使用して、グループが有意に異なるかどうかを判断する。サブグループ解析では、通常、固定効果 (複数) モデルを仮定する。サブグループ内の研究は、ほとんどの場合、ランダム効果モデルを用いてプールされる。その後、全体のサブグループの結果に基づいた \\(Q\\) -検定を使用して、グループが有意に異なるかどうかを判断する。サブグループ解析モデルは、異なるカテゴリ自体が固定されていると仮定されているため、「固定効果」モデルと呼ばれる。サブグループの水準は、可能なカテゴリの宇宙からのランダムな抽選とは見なされない。それらは、サブグループ変数が取り得る唯一の値を表す。サブグループ解析モデルは、異なるカテゴリ自体が固定されていると仮定されているため、「固定効果」モデルと呼ばれる。サブグループの水準は、可能なカテゴリの宇宙からのランダムな抽選とは見なされない。それらは、サブグループ変数が取り得る唯一の値を表す。サブグループ解析を計算する場合、サブグループ内の結果をプールするために、研究間の異質性の推定値を別々にするか、共通にするかを決めなければならない。サブグループ解析を計算する場合、サブグループ内の結果をプールするために、研究間の異質性の推定値を別々にするか、共通にするかを決めなければならない。サブグループ解析は万能ではない。サブグループの差を検出するのに必要な統計的検出力が不足していることが多い。したがって、サブグループの差について有意でない検定は、自動的にサブグループが同等の結果をもたらすことを意味するものではない。サブグループ解析は万能ではない。サブグループの差を検出するのに必要な統計的検出力が不足していることが多い。したがって、サブグループの差について有意でない検定は、自動的にサブグループが同等の結果をもたらすことを意味するものではない。","code":""},{"path":"metareg.html","id":"metareg","chapter":"8 メタ回帰","heading":"8 メタ回帰","text":"前\n章では、メタ分析の「ツール」に新しい手法としてサブグループ分析を追加した。前章で学んだのは、サブグループ解析では、1つの全体的な効果を見つけることから解析の焦点をずらすという点である。その代わりとして、データ中の異質性のパターンとその原因を調査することができるのである。また、サブグループ解析はメタ分析の特殊な形態であることを述べた。「回帰」という言葉を聞いたことがあるかと思われる。回帰分析は、最も一般的な統計手法の1つで、さまざまな分野で使用されている。最も単純な形では、回帰モデルは、ある変数 \\(x\\) の値を使って、別の変数 \\(y\\) の値を予測しようとするものである。通常、回帰モデルは、\\(x\\) と \\(y\\) の両方の値が測定された個人またはサンプルからなるデータに基づいている。メタ回帰では、このロジックは全ての研究に適用される。変数 \\(x\\) は、研究の特徴、たとえば、実施された年などを表す。この情報に基づいて、メタ回帰モデルは、研究の効果量である \\(y\\) を予測しようとする。しかし、予測される変数として効果量が使用されると、より複雑になる。Chapter 3.1 ですでに、観察された効果量 \\(\\hat\\theta\\) は、その標準誤差によって、研究の真の効果のおおよそ正確な推定量になりうることを学んだ。「通常の」メタ分析では、研究に大小の重みを与えることによって、これを考慮に入れている。メタ回帰では、ある研究のサンプル誤差が他より低いとき、その推定値はより「真実」に近いと仮定できるため、モデルはこれらの研究に注意を払う必要がある。メタ回帰は、混合効果モデルを仮定することによって、これを実現する。このモデルは、観察された研究がサンプルエラーや研究間の異質性によって、真の全体効果から逸脱するという事実を説明する。しかし、より重要なのは、1 つまたは複数の変数 \\(x\\)を用いて、真の効果量の差を予測するために使用することである。サブグループ分析も混合効果モデルに基づいていることは、すでに前章で述べたとおりである。この章では、もう少し掘り下げて、なぜサブグループ分析とメタ回帰が本質的に関連しているのかを議論する。メタ回帰は、それなりの限界はあるものの、メタ分析において非常に強力なツールとなり得る。また、非常に汎用性が高い。たとえば、多重メタ回帰は、1つだけでなく、複数の予測変数とそれらの交互作用 (interaction) を含めることができる。本章の後半では、多重メタ回帰と、 R を用いたメタ回帰の実施方法について説明する。","code":""},{"path":"metareg.html","id":"the-metareg-model","chapter":"8 メタ回帰","heading":"8.1 メタ回帰モデル","text":"過去に、参加者を分析単位とする一次研究のデータを使って、すでに回帰を行ったことがあるだろう。メタ分析では、通常、各参加者の個別のデータは得られず、集約された結果に頼るしかない。これが、研究レベルの予測因子でメタ回帰を実行しなければならない理由である。また、一次試験よりもはるかに大きなサンプルで分析を行っても、メタ回帰が有用となるだけのデータポイントが得られない可能性があることを意味する。 Chapter 7.2 で、\\(K<\\) 10 件の時、サブグループ解析が意味をなさないことが多いことを取り上げた。Borenstein ら (2011, chap. 20) は、このガイドラインはメタ回帰モデルにも適用できるかもしれないが、鉄則と見なすべきではないと言及している。従来の回帰では、人物 \\(\\) の値 \\(y_i\\) を、予測因子 (または共変量) \\(x_i\\) と回帰係数 \\(\\beta\\) を使って推定したい。したがって、標準的な回帰式は次のようになる。\\[\\begin{equation}\n\\hat{y_i} = \\beta_0 + \\beta_1x_i\n\\tag{8.1}\n\\end{equation}\\]メタ回帰では、予測したい変数 \\(y\\) は、研究 \\(k\\) の観察された効果量 \\(\\hat\\theta_k\\) (シータハットと読む) である。メタ回帰の式は、正規回帰モデルの式に似ている。\\[\\begin{equation}\n\\hat\\theta_k = \\theta + \\beta x_{k} + \\epsilon_k+\\zeta_k\n\\tag{8.2}\n\\end{equation}\\]この式は、2つの追加項、\\(\\epsilon_k\\) (イプシロン k と読む) と \\(\\zeta_k\\) (ゼータ k と読む) を含んでいることに注意されたい。同じ項がランダム効果モデルの式 (Chapter 4.1.2 ) にもあり、2 種類の独立した誤差を意味する。1 つ目の \\(\\epsilon_k\\) は、研究の効果量が真の効果から逸脱するサンプル誤差である。2 つ目の誤差、\\(\\zeta_k\\) は、研究の真の効果量でさえ、効果量の包括的な分布からサンプルされているに過ぎないことを表している。これは、私たちのデータには研究間の異質性が存在することを意味し、これは異質性分散 \\(\\tau^2\\) によって捕捉される。\n上記の式は、固定効果 (\\(\\beta\\) 係数) とランダム効果 (\\(\\zeta_k\\)) を含むので、メタ回帰で使用されるモデルは、混合効果モデルと呼ばれることも多い。概念的には、このモデルは Chapter 7.1.2 で説明した混合効果モデルと同じで、サブグループ解析がどのように機能するかを説明したものである。","code":""},{"path":"metareg.html","id":"カテゴリカル予測変数のメタ回帰","chapter":"8 メタ回帰","heading":"8.1.1 カテゴリカル予測変数のメタ回帰","text":"実際、前述のように、サブグループ分析は、カテゴリカル予測変数のメタ回帰にほかならない。そのようなカテゴリカル変数は、たとえば、ダミー・コーディング によって含めることができる。\\[\\begin{equation}\n  D_g=\\begin{cases}\n    0: & \\text{Subgroup }\\\\\n    1: & \\text{Subgroup B.}\n  \\end{cases}\n  \\tag{8.3}\n\\end{equation}\\]サブグループ分析をメタ回帰の形で指定するには、共変量 \\(x_k\\) を \\(D_g\\) に置き換えるだけでよい。\\[\\begin{equation}\n\\hat\\theta_k = \\theta + \\beta D_g +\\epsilon_k+\\zeta_k.\n\\tag{8.4}\n\\end{equation}\\]この式を理解するためには、左から右へ読む必要がある。メタ回帰モデルの目的は、他の統計モデルと同様、観測されたデータがどのように生成されたかを説明することである。私たちの場合、これはメタ分析におけるいくつかの研究 (\\(k\\)) の観察された効果量 \\(\\hat\\theta_k\\) である。上の式はレシピのように機能し、観察された効果を生み出すためにどの材料が必要かを教えてくれる。まず、\\(\\theta\\) は回帰モデルにおける切片として機能する。\\(\\theta\\) の値は、サブグループAの真の全体効果量と同じである。この理由を見るために、次の「成分」である項 \\(\\beta D_g\\) を見る必要がある。この項の \\(\\beta\\) の値は、サブグループ とサブグループ B の間の効果量の差 \\(\\theta_{\\Delta}\\) を表している。\\(\\beta\\) の値に、研究がサブグループ (\\(D_g = 0\\)) またはサブグループ B (\\(D_g = 1\\)) のどちらに属しているかによって 0 または 1 のどちらかになる \\(D_g\\) を掛けている。ゼロを掛けるとゼロになるので、サブグループAの研究を扱っているときは、\\(\\beta D_g\\) の項は方程式から完全に外れる。一方、\\(D_g=1\\) のとき、1を掛けるので \\(\\beta\\) が方程式に残り、\\(\\theta\\) に足され、サブグループ B の全体的な効果量が得られる。基本的に、ダミー予測変数は二つの式をひとつに統合する方法である。これは、各サブグループの式を個別に書き出すと、簡単にわかる。\\[\\begin{equation}\n  D_g=\\begin{cases}\n    0: & \\text{$\\hat\\theta_k = \\theta_A + \\epsilon_k+\\zeta_k$}\\\\\n    1: & \\text{$\\hat\\theta_k = \\theta_A + \\theta_{\\Delta} +\\epsilon_k+\\zeta_k$}\n  \\end{cases}\n  \\tag{8.5}\n\\end{equation}\\]このように書くと、この式は、実際には、サブグループ とサブグループ B の2つのモデルを含んでいることが明らかになる。モデル間の主な違いは、\\(\\beta\\) (上の式では \\(\\theta_{\\Delta}\\) と表記) の値によって、第2サブグループの効果が上下に「シフト」されることである。\nFigure 8.1: カテゴリ予測因子を用いたメタ回帰 (サブグループ)。\nこれは、サブグループ分析が通常の回帰と同じように動作することを明確にするもので、ある変数 \\(x\\) を使って \\(y\\) の値を予測する。特別なのは、\\(\\beta x_k\\) が連続的ではなく、ある研究が特定のサブグループに属するかどうかに応じて、予測に追加する固定値であるということである。この固定値 \\(\\beta\\) は、2つのサブグループ間の効果量の差の推定値である。","code":""},{"path":"metareg.html","id":"metareg-continuous","chapter":"8 メタ回帰","heading":"8.1.2 連続予測因子によるメタ回帰","text":"しかし、「メタ回帰」というと、普通は連続変数を予測変数としたモデルを思い浮かべる。そこで、8.2式に示す一般的なメタ回帰の式に戻る。ここでも、前に説明した回帰の用語が使われているが、少し違う目的を持っている。\\(\\theta\\) 項は再び切片を表すが、今度は \\(x = 0\\) のときに予測される効果量を表す。切片に、\\(\\beta x_k\\) 項が加えられる。この部分は、回帰傾きを生成する。つまり、連続変数 \\(x\\) と回帰重み \\(\\beta\\) が掛け算され、共変量値の予測効果を低くしたり高くしたりする。メタ回帰モデルの目的は、研究の予測効果量と真の効果量の差を最小化する \\(\\theta\\) と \\(\\beta\\) の値を見つけることである ( Figure 8.2 を参照)。\nFigure 8.2: 連続変数予測因子と４つの研究のメタ回帰\nメタ回帰式をよく見てみると、2種類の項が含まれていることがわかる。いくつかの項には添え字 (\\(k\\)) があり、他の項には添え字がない。添え字 (\\(k\\)) は、ある値が研究ごとに異なることを示す。ある項が添え字 (\\(k\\)) を含んでいない場合、それはすべての研究で同じである。メタ回帰では、\\(\\theta\\) と \\(\\beta\\) の両方が不変、または固定である。予測変数の変動と観察された効果に基づいて、回帰線の形で、データの根底にある固定パターンを「抽出」しようとするのである。メタ回帰モデルがデータによく当てはまる場合、推定されたパラメータ \\(\\theta\\) と \\(\\beta\\) は、モデルが今まで見たことのない研究の効果量を予測するのに使うことができる (\\(x\\) がわかっていればの話であるが)。\\(\\epsilon_k\\) と研究間異質性 \\(\\zeta_k\\) の両方を考慮すると、メタ回帰は、観察された効果量だけでなく、関心のあるすべての研究の「宇宙」に対して、うまく一般化するモデルを見つけようとするものである。","code":""},{"path":"metareg.html","id":"metareg-model-fit","chapter":"8 メタ回帰","heading":"8.1.3 モデルの適合性を評価","text":"メタ回帰モデルの重要な点は、効果量のプールに使用する「通常の」ランダム効果モデルの拡張とみなすことができる点である。ランダム効果モデルは、傾き項を含まないメタ回帰モデルに過ぎない。傾きがないので、ランダム効果モデルは、各研究について単純に同じ値を予測する。つまり、プールされた効果量の推定値 \\(\\mu\\) であり、これは切片と同じである。\n最初のステップでは、メタ回帰の計算は、したがってランダム効果メタ分析のものとよく似ており、研究間異質性 \\(\\tau^2\\) が Chapter 4.1.2.1 で説明した方法 (例えば、DerSimonian-Laird 法または REML 法) のいずれかを使って推定される。次のステップでは、固定重み \\(\\theta\\) と \\(\\beta\\) が推定される。通常の線形回帰モデルは、通常の最小2乗 (ordinary least squares, OLS) 法を用いて、データに最もよく適合する回帰直線を見つける。メタ回帰では、重み付き最小2乗 (weighted least squares, WLS)と呼ばれる修正された方法が使用され、より小さな標準誤差を持つ研究がより高い重みを与えられるようにする。最適解が見つかったら、新しく追加された回帰項が効果量の異質性の一部を説明しているかどうかを確認することができる。メタ回帰モデルがデータによく適合している場合、真の効果量は、プール効果量 \\(\\hat\\mu\\) と比較して回帰直線からの偏差が小さくなる。この場合、予測因子 \\(x\\) は、メタ分析における異質性分散の一部を説明する。したがって、メタ回帰モデルの適合性は、それが異質性分散のどれだけを説明するかをチェックすることによって評価することができる。混合効果モデルに含まれる予測変数は、残差 (residual)、または説明されない異質性分散の量を最小化する必要があり、これは、\\(\\tau^2_{\\text{unexplained}}\\) で示される。回帰分析では、モデルによって説明される変動の割合を定量化するために、\\(R^2\\) 指数が一般的に使用される。類似の指数である \\(R^2_{*}\\) もメタ回帰で計算することができる。ここでは、観測されたデータ点ではなく、真の効果量 を扱うので、メタ回帰の \\(R^2\\) は、従来の回帰で使われるものと若干異なることを示すために、アスタリスク (\\(*\\)) を追加している。 \\(R^2_*\\) の式は次のようになる。\\[\\begin{equation}\nR^2_* = 1- \\frac{\\hat\\tau^2_{\\text{unexplained}}}{\\hat\\tau^2_{\\text{(total)}}}\n\\tag{8.6}\n\\end{equation}\\]\\(R^2_*\\) は、メタ回帰の傾きでさえ説明できない異質性分散の残差量を使用し、それをメタ分析で最初に発見した異質性の合計で割る。この割合を1から引くと、予測変数によって説明される研究間の異質性のパーセンテージが得られる。また、\\(R^2_*\\) を定式化する別の方法がある。それは、混合効果モデルが、最初のランダム効果プーリングモデルと比較して、異質性の分散をどれだけ低減させるかをパーセントで表すと言うことができる。この結果、次のような式になる。\\[\\begin{equation}\nR^2_* =  \\frac{\\hat\\tau^2_{\\text{REM}}-\\hat\\tau^2_{\\text{MEM}}}{\\hat\\tau^2_{\\text{REM}}}\n\\tag{8.7}\n\\end{equation}\\]この式で、\\(\\hat\\tau^2_{\\text{REM}}\\) はランダム効果プーリングモデルで見つかった研究間異質性の量を表し、\\(\\hat\\tau^2_{\\text{MEM}}\\) は混合効果メタ回帰モデルの (残) 分散 (すなわち、真の効果量に関する「予測誤差」) を表す。通常、私たちは回帰モデルで説明される異質性の量に興味があるだけでなく、私たちの予測因子 \\(x\\) の回帰重量が有意であるかどうかにも興味がある。もしそうであれば、\\(x\\) が研究の効果量に影響を及ぼしていると確信できる。従来の回帰でもメタ回帰でも、回帰重みの有意性は、一般的に Wald-type 検定で評価される。これは、\\(\\beta\\) の推定値をその標準誤差で割ることによって、検定統計量 \\(z\\) を計算することを含む。\\[\\begin{equation}\nz = \\frac{\\hat\\beta}{SE_{\\hat\\beta}}\n\\tag{8.8}\n\\end{equation}\\]\\(\\beta = 0\\) という帰無仮説のもとでは、この \\(z\\) -統計量は、標準正規分布に従う。これは、対応する \\(p\\) -値を計算することができ、予測変数が有意であるかどうかを決定するものである。しかし、\\(z\\)-統計量に基づく検定は、予測変数の有意性を評価する唯一の方法ではない。通常のメタ分析モデルのように、\\(t\\)-分布に基づく検定統計量になる Knapp-Hartung 調整も使用できる ( Chapter 4.1.2.2 を参照)。以前学んだように、Knapp-Hartung 法は、偽陽性のリスクを減らすので、使用することが推奨される。","code":""},{"path":"metareg.html","id":"metareg-R","chapter":"8 メタ回帰","heading":"8.2 R のメタ回帰について","text":"{meta} パッケージには、メタ回帰を行うための関数 metareg が含まれている。この metareg 関数は、入力として {meta} メタ分析オブジェクトと共変量名のみを必要とする。この例では、再び ThirdWave データセット ( Chapter 4.2.1 参照) に基づいた m.gen メタ分析オブジェクトを使用する。メタ回帰を用いて、研究の出版年がその効果量を予測するのに使えるかどうかを調べたいと思われる。デフォルトでは、ThirdWave データセットには出版年を格納する変数がないので、この情報を格納する新しい numeric 変数を作成する必要がある。そのため、この情報を含む新しい numeric 変数を作成する必要がある。ここでは、すべての研究の出版年を ThirdWave データセットに現れるのと同じ順序で単純に連結している。この変数を year31 という名前で保存する。これで、メタ回帰を実行するために必要な情報はすべて揃った。metareg 関数では、最初の引数にメタ分析オブジェクトの名前 m.gen を指定し、2番目の引数に予測変数の名前 year を指定する。結果は m.gen.reg という名前になる。では、その結果を見てみよう。ここでわかることを見ていこう。最初の行では、意図したとおりに混合効果モデルがデータに適合されたことが出力されている。次の数行は、モデルによって説明される異質性の量に関する詳細である。残差異質性分散 (予測変数によって説明されない分散) の推定値が、\\(\\hat\\tau^2_{\\text{unexplained}}=\\) 0.019である。出力には、\\(^2\\) もある。これは、予測変数の包含後、データの変動の29.26%が残りの研究間異質性に帰着することができることを教えてくれる。通常のランダム効果メタ分析モデルでは、\\(^2\\) 異質性が 63% であることがわかっていた。これは、予測変数が真の効果量における差のかなりの量を「説明する」ことができたということになる。最後の行では、\\(R^2_*\\) の値が表示され、この例では 77% となっている。これは、真の効果量の差の77%が出版年によって説明できることを意味し、非常に大きな値である。次のセクションは、Test Residual Heterogeneity を含み、本質的には、すでに以前知った \\(Q\\)-検定である ( Chapter 5.1.1 を参照)。ここでは、予測変数で説明されない異質性が有意であるかどうかを検定する。\\(p\\) = 0.03 であることから有意である。しかし、私たちは \\(Q\\)-検定 (Chapter 5.1.1) の限界を知っているので、この結果にはあまり依存しない方がよいだろう。次の部分は、Test Moderators を示している。この検定も有意であることがわかる (\\(p\\) = 0.0075)。これは、私たちの予測因子である出版年が、実際に研究の効果量に影響を与えることを意味する。最後のセクションでは、推定された回帰係数の詳細を説明する。最初の行は、切片 (intrcpt) の結果を示している。これは、予測因子である出版年がゼロの場合に期待される効果量 (私たちの場合: Hedges’ \\(g\\)) である。この例では、少し不自然なシナリオを表している。これは、0年に実施された研究の予測効果を示しており、\\(\\hat{g}=\\) -36.15となっている。優れた統計モデルは現実を完璧に表現している必要はなく、ただ有用であればよいということを改めて思い起こさせるものとなっている。私たちが主に注目するのは2行目の係数である。このモデルの year の回帰重みの推定値が0.01であることがわかる。これは、1年増えるごとに、研究の効果量 \\(g\\) が0.01ずつ増加することを意味する。したがって、研究の効果量は時間とともに増加していると言えるだろう。95%信頼区間の範囲は 0.005 から 0.3 であり、効果は有意であることがわかる。重要なのは、各回帰係数( tval )に対応する \\(t\\)-統計量も提示されていることである。これは、信頼区間と \\(p\\) -値を計算するために、Knapp-Hartung 法が使用されたことを示す。最初のメタ分析モデルでもこの調整法を使用したので、 metareg はここでも自動的にこの調整法を使用してきた。そうでなければ、\\(z\\) 値と Wald 型信頼区間が提供されるはずであった。{meta} パッケージでは、 bubble 関数を用いてメタ回帰を可視化することができる。これは、推定回帰勾配と各研究の効果量を示すバブルプロット (bubble plot) を作成する。研究の重みを示すために、バブルは異なる大きさを持ち、大きければ大きいほど重みがあることを表す。バブルプロットを作成するためには、メタ回帰オブジェクトを bubble 関数に接続するだけである。研究ラベルも表示させたいので、studlab を TRUE に設定する。完全性を期すために、前章のサブグループ分析 (Chapter 7.3) を、今度はメタ回帰の枠組みで繰り返してみることもできる。これは、カテゴリ予測因子としてバイアスのリスク・アセスメントを使用することを意味する。変数 RiskOfBias はすでに ThirdWave のデータセットに含まれているので、この情報を追加オブジェクトに保存する必要はない。単純に metareg 関数を再度実行すれば良いのであるが、今回は関数の2番目の引数として RiskOfBias を使用する。出力では、\\(R^2_*\\) の値が15.66%で、year の値よりかなり小さいことがわかる。以前の結果と一致して、バイアス・リスク変数が有意な効果量予測因子でないことがわかる (\\(p\\) = 0.13)。モデル結果の下で、metareg が自動的に RiskOfBias をダミー変数に変換していることがわかる。サブグループ “high risk” のプール効果を表す切片の推定値は、\\(g\\) = 0.76 である。バイアスのリスクが低い研究を表す回帰係数の推定値は -0.29 である。このサブグループの効果量を得るには、切片に回帰重みを加える必要があり、その結果、\\(g=\\) 0.76 - 0.29 \\(\\approx\\) 0.47 となる。これらの結果は、\\(\\tau^2\\) の共通の推定値を仮定したサブグループ分析の結果と同じである。","code":"\nyear <- c(2014, 1998, 2010, 1999, 2005, 2014, \n          2019, 2010, 1982, 2020, 1978, 2001,\n          2018, 2002, 2009, 2011, 2011, 2013)\nm.gen.reg <- metareg(m.gen, ~year)\nm.gen.reg## Mixed-Effects Model (k = 18; tau^2 estimator: REML)\n## \n## tau^2 (estimated amount of residual heterogeneity):     0.019 (SE = 0.023)\n## tau (square root of estimated tau^2 value):             0.1371\n## I^2 (residual heterogeneity / unaccounted variability): 29.26%\n## H^2 (unaccounted variability / sampling variability):   1.41\n## R^2 (amount of heterogeneity accounted for):            77.08%\n## \n## Test for Residual Heterogeneity:\n## QE(df = 16) = 27.8273, p-val = 0.0332\n## \n## Test of Moderators (coefficient 2):\n## F(df1 = 1, df2 = 16) = 9.3755, p-val = 0.0075\n## \n## Model Results:\n## \n##         estimate     se   tval   pval    ci.lb    ci.ub \n## intrcpt   -36.15  11.98  -3.01  0.008  -61.551  -10.758  ** \n## year        0.01   0.00   3.06  0.007    0.005    0.031  ** \n## \n## ---\n## Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\nbubble(m.gen.reg, studlab = TRUE)\nmetareg(m.gen, RiskOfBias)## [...]\n## R^2 (amount of heterogeneity accounted for):            15.66%\n## \n## Test for Residual Heterogeneity:\n## QE(df = 16) = 39.3084, p-val = 0.0010\n## \n## Test of Moderators (coefficient 2):\n## F(df1 = 1, df2 = 16) = 2.5066, p-val = 0.1329\n## \n## Model Results:\n## \n##               estimate    se   tval    pval  ci.lb ci.ub \n## intrcpt           0.76  0.15   5.00  0.0001   0.44  1.09  *** \n## RiskOfBiaslow    -0.29  0.18  -1.58  0.1329  -0.69  0.10      \n## [...]\n"},{"path":"metareg.html","id":"multiple-metareg","chapter":"8 メタ回帰","heading":"8.3 多重メタ回帰","text":"前回は、メタ回帰モデルで一つのの予測因子 \\(\\beta x_k\\) を使用するシナリオのみを検討してきた。この例では、研究の効果量が出版された年に依存するかどうかを調べる。しかし今度は、報告された効果量が、研究が掲載された科学雑誌の名声にも依存していると仮定しよう。高い評価を得ている雑誌に掲載された研究が、より高い効果を報告している可能性があると考えている。なぜなら、一流の雑誌では、選ばれた研究は「画期的」な発見をしていることがほとんどだからである。一方、評判の良い雑誌は一般的に質の高い研究を掲載しているというのももっともな話である。もしかしたら、より高い効果量と関連するのは、より良い研究の質だけだろう。そこで、ジャーナルの評判が本当に高い効果と関連しているかどうかを確認するために、この関係が、一流のジャーナルが高品質のエビデンスを出版する可能性が高いという事実によって交絡していないことを確認する必要がある。つまり、ジャーナルの名声と効果量の関係を調査する際には、研究の質をコントロールする必要がある。これや他の多くの研究課題は、多重メタ回帰を使用して対処することができる。多重メタ回帰では、効果の変動を説明するために、1つだけでなく複数の予測変数を使用する。複数の予測変数を使用できるようにするには、前のメタ回帰式 (式8.2参照) を修正して、次のようにする必要がある。\\[\\begin{equation}\n\\hat \\theta_k = \\theta + \\beta_1x_{1k} + ... + \\beta_nx_{nk} + \\epsilon_k + \\zeta_k\n\\tag{8.9}\n\\end{equation}\\]この式は、メタ回帰モデルに \\(n-1\\) より多くの予測変数 \\(x\\) を追加して、多重メタ回帰に変えることができることを示す。この式の3つの点は、理論的には、望むだけの予測変数を追加できることを象徴している。しかし、現実にはもっとやっかいなことが多い。以下では、多重メタ回帰のいくつかの重要な落とし穴と、どのようにすれば頑健で信頼できるモデルを構築できるかを説明する。その前に、多重メタ回帰のもう一つの重要な特徴である交互作用 (interaction) について説明する。","code":""},{"path":"metareg.html","id":"interact","chapter":"8 メタ回帰","heading":"8.3.1 交互作用","text":"ここまでは、モデル内に複数の予測変数 \\(x_1, x_2, \\dots x_n\\) があり、それらの回帰重み \\(\\beta\\) と共に加算される場合のみを考えていた。しかし、多重メタ回帰モデルは、このような加算関係に限定されるわけではない。また、予測変数の交互作用 もモデル化することができる。交互作用とは、ある予測変数 (例: \\(x_1\\) ) と推定効果量との間の関係が、別の共変量 (例: \\(x_2\\) ) の異なる値で変化することを意味する。2つの予測因子とそれらが効果量とどのように関連するかをモデル化したいとする: 出版年 (\\(x_1\\)) と研究の質 (\\(x_2\\)) である。研究の質は次のようにコード化される。\\[\\begin{equation}\n  x_2=\\begin{cases}\n    0: & \\text{low}\\\\\n    1: & \\text{moderate}\\\\\n    2: & \\text{high}\n  \\end{cases}\n  \\tag{8.10}\n\\end{equation}\\]出版年と研究の質の間に交互作用がないと仮定した場合、\\(x_1\\) と \\(x_2\\) の両方に回帰の重み \\(\\beta\\) を与え、数式でその項を一緒に追加することによって、メタ回帰モデルを構築することができる。\\[\\begin{equation}\n\\hat \\theta_k = \\theta + \\beta_1x_{1k} + \\beta_2x_{2k} + \\epsilon_k + \\zeta_k\n\\tag{8.11}\n\\end{equation}\\]しかし、\\(x_1\\) と \\(x_2\\) の関係がもっと複雑だとしたらどうだろうか。先ほどの例のように、より新しい出版年がより高い効果と正に関連している可能性がある。しかし、すべての研究がこのような傾向を示すとは限らない。もしかしたら、質の高い研究で顕著に増加し、質の低い研究の結果は時間の経過とともにほとんど変わらなくなるだろう。効果量 (\\(\\hat\\theta_k\\))、出版年 (\\(x_1\\))、研究の質 (\\(x_2\\))の間のこの想定された関係は、次のように可視化することができる。このグラフは、交互作用の典型的な例を示している。回帰の傾きの急さは、別の予測変数の値に依存することがわかる。質の高い研究では、回帰線の傾きが非常に急で、発表年と効果の間に強い関係があることを示しているが、低質な研究では状況が異なる。このサブグループの回帰直線はほとんど水平で、出版年は結果に全く、あるいはわずかにマイナスの影響を与えることを示している。この例は、交互作用の強みの1つである、予測因子の影響がすべての研究で同じかどうか、あるいは他の特性によって緩和されているかどうかを調べることができることを示している。メタ回帰で交互作用を評価するためには、モデルに交互作用項 を追加する必要がある。私たちの例では、これは私たちのモデルでテストしたい交互作用 \\(x_{1k}x_{2k}\\) を捕捉する3番目の回帰重み \\(\\beta_3\\) を追加することで達成できる。これは、次の数式を与える。\\[\\begin{equation}\n\\hat \\theta_k = \\theta + \\beta_1x_{1k} + \\beta_2x_{2k} + \\beta_3x_{1k}x_{2k}+ \\epsilon_k + \\zeta_k\n\\tag{8.12}\n\\end{equation}\\]線形多重メタ回帰モデルは、このような単純な構成要素で構成されているだけであるが、様々な用途に使用することができる。しかし、 R を用いた多重メタ回帰のフィッティングを始める前に、まずその限界と落とし穴について考えておく必要がある。","code":""},{"path":"metareg.html","id":"limits-metareg","chapter":"8 メタ回帰","heading":"8.3.2 多重メタ回帰にありがちな落とし穴","text":"多重メタ回帰は、適切に適用されれば非常に有用であるが、ある種の注意点がある。実際には (多重) メタ回帰は不適切な使い方や解釈が多く、結果の妥当性が低いという意見もある (JPT Higgins Thompson 2004)。多重メタ回帰モデルを当てはめる際に注意しなければならない点がいくつかあるので、以下に説明する。","code":""},{"path":"metareg.html","id":"過適合-シグナルのないところにシグナルを見いだす","chapter":"8 メタ回帰","heading":"8.3.2.1 過適合: シグナルのないところにシグナルを見いだす","text":"メタ回帰モデル (複数) のリスクをより良く理解するためには、過適合 (overfitting) という概念を理解する必要がある。過適合とは、データにあまりにも近く適合するような統計モデルを構築した場合に起こる。簡単に説明すると、手元のデータはうまく予測できるが、将来のデータはうまく予測できない統計モデルを構築してしまうということである。これは、モデルが、データの変動が真の「シグナル」に由来すると仮定したときに起こるもので、実際にはランダムなノイズしか捉えていない (Iniesta, Stahl, McGuffin 2016)。その結果、モデルは偽陽性の結果を生成する。つまり、何もないところに関係性を見出すのである。\nFigure 8.3: 過適合モデルと頑健適合モデルの予測。\n\nモデル適合のために、回帰は通常の最小二乗法や最尤推定などの最適化技術を利用する。すでに学んだように、メタ回帰は普通の最小二乗法の重み付きバージョンを使用するので (Chapter 8.1.3 参照)、これも例外ではない。「貪欲に」最適化すると、回帰アプローチは過適合に陥りやすい (Gigerenzer 2004)。残念ながら、従来の回帰手法からメタ回帰に移行すると、頑健でないモデルを構築するリスクはさらに高くなる。これにはいくつかの理由がある (JPT Higgins Thompson 2004)。メタ回帰では、含まれる研究の集約された情報しか使えないので、通常、データポイントの数は少ない。メタ回帰では、含まれる研究の集約された情報しか使えないので、通常、データポイントの数は少ない。メタ分析は、すべての利用可能なエビデンスを包括的に概観することを目的としているので、回帰モデルが未知のデータをどれだけ予測できるかを「テスト」できるような追加データが存在しない。メタ分析は、すべての利用可能なエビデンスを包括的に概観することを目的としているので、回帰モデルが未知のデータをどれだけ予測できるかを「テスト」できるような追加データが存在しない。メタ回帰では、効果量の異質性が存在する可能性に対処しなければならない。２つの研究があり、両者の効果量が異なり、信頼区間が重なっていないケースを想像してみよう。２つの研究で異なる値を持つすべての変数が、効果量の差の説明となり得る。しかし、これらの説明のほとんどが偽の説明であることは明らかだろう。メタ回帰では、効果量の異質性が存在する可能性に対処しなければならない。２つの研究があり、両者の効果量が異なり、信頼区間が重なっていないケースを想像してみよう。２つの研究で異なる値を持つすべての変数が、効果量の差の説明となり得る。しかし、これらの説明のほとんどが偽の説明であることは明らかだろう。一般的なメタ回帰、特に多重メタ回帰は、予測変数の「遊び」を非常に簡単にする。データの異質性を説明するために、多数のメタ回帰モデルをテストして、より多くの予測変数を含めたり削除したりすることができる。このアプローチは魅力的で、実際によく見られる。メタ分析では、効果量が異なる理由の説明を見つけたいからである (J. Higgins et al. 2002)。有意なモデルを見つけるまで無限にモデルの一部を変更することができるが、そのモデルは過適合である (つまり、ほとんど統計的ノイズをモデル化している) 可能性が非常に高い。一般的なメタ回帰、特に多重メタ回帰は、予測変数の「遊び」を非常に簡単にする。データの異質性を説明するために、多数のメタ回帰モデルをテストして、より多くの予測変数を含めたり削除したりすることができる。このアプローチは魅力的で、実際によく見られる。メタ分析では、効果量が異なる理由の説明を見つけたいからである (J. Higgins et al. 2002)。有意なモデルを見つけるまで無限にモデルの一部を変更することができるが、そのモデルは過適合である (つまり、ほとんど統計的ノイズをモデル化している) 可能性が非常に高い。メタ回帰モデルを構築する際に、過度の偽陽性を避けるためのガイドラインがいくつか提案されている。\n調査すべき予測変数の数を最小にする。多重メタ回帰では、これは倹約 (parsimony) の概念に変換される。つまり、メタ回帰モデルの適合を評価するとき、少ない予測変数で良い適合を達成するモデルを好む。赤池情報量規準やベイズ情報量規準のような推定量は、この決定を助けることができる。本章の実践例で、これらのメトリックをどのように解釈するかを示す。調査すべき予測変数の数を最小にする。多重メタ回帰では、これは倹約 (parsimony) の概念に変換される。つまり、メタ回帰モデルの適合を評価するとき、少ない予測変数で良い適合を達成するモデルを好む。赤池情報量規準やベイズ情報量規準のような推定量は、この決定を助けることができる。本章の実践例で、これらのメトリックをどのように解釈するかを示す。予測変数の選択は、あらかじめ定義され、科学的に関連性のある、メタ分析で答えたい質問に基づいて行う必要がある。メタ分析モデルに含まれる予測因子 (組み合わせ) を分析レポート (Chapter 1.4.2 ) ですでに定義しておくことが重要である。分析計画に記載されていないメタ分析を実行することになったとしても、それで終わりではない。ただし、この場合は正直に、メタ分析報告書に、データを見た後でモデルの適合を決定したことを記載する必要がある。予測変数の選択は、あらかじめ定義され、科学的に関連性のある、メタ分析で答えたい質問に基づいて行う必要がある。メタ分析モデルに含まれる予測因子 (組み合わせ) を分析レポート (Chapter 1.4.2 ) ですでに定義しておくことが重要である。分析計画に記載されていないメタ分析を実行することになったとしても、それで終わりではない。ただし、この場合は正直に、メタ分析報告書に、データを見た後でモデルの適合を決定したことを記載する必要がある。研究数が少ない場合 (これはよくある)、予測変数の有意性を計算したい場合は、Knapp-Hartung 調整を用いて、より頑健な推定値を得るべきである。研究数が少ない場合 (これはよくある)、予測変数の有意性を計算したい場合は、Knapp-Hartung 調整を用いて、より頑健な推定値を得るべきである。再サンプルされたデータにおけるモデルの頑健性を評価するために、置換を使用することができる。この方法の詳細については後ほど説明する。","code":""},{"path":"metareg.html","id":"多重共線性","chapter":"8 メタ回帰","heading":"8.3.2.2 多重共線性","text":"\n多重共線性 (multi-collinearity) とは、回帰モデル中の1つ以上の予測変数が、他のモデル予測変数によって高い精度で予測されることである (Mansfield Helms 1982)。これは通常、モデル中に相関の高い２つ以上の独立変数があることを意味する。多重共線性の危険性のほとんどは、過適合の問題と関連している。高い共線性は、予測変数の係数推定値 \\(\\hat\\beta\\) を不安定にさせ、データの小さな変化で大きく変化させることがある。また、モデルによって説明される分散の大きさ (ここでは \\(R^2_*\\)) も制限される。メタ回帰における多重共線性は一般的である (Berlin Antman 1994)。重回帰は低度の共線性を扱うことができるが、非常に高い相関を持つ予測変数をチェックし、必要ならコントロールする必要がある。多重共線性の有無を判断するための統合されたイエス・ノールールはない。モデルを適合する前に、非常に高い予測変数の相関 (すなわち、\\(r \\geq\\) 0.8) をチェックすることは、粗雑ではあるものの効果的な方法である。そして、多重共線性は、(1) 近い冗長な予測変数の１つを除去するか、(2) 予測変数を１つの単一変数に結合しようとするかのいずれかによって削減することができる。","code":""},{"path":"metareg.html","id":"過適合のアプローチ","chapter":"8 メタ回帰","heading":"8.3.2.3 過適合のアプローチ","text":"多重メタ回帰モデルを構築するとき、予測変数の選択と包含にさまざまなアプローチがある。ここでは、最も重要なものを、その長所と短所とともに議論する。強制投入. 強制投入法 (または変数指定法) では、すべての関連する予測変数が同時に回帰モデルに強制投入される。 R のほとんどの関数では、これはデフォルトの設定である。これは一般的に推奨される手順であるが、強制投入で使用するすべての予測変数は、やはり事前に定義された、理論に基づいた決定に基づいているべきであることに留意する必要がある。強制投入. 強制投入法 (または変数指定法) では、すべての関連する予測変数が同時に回帰モデルに強制投入される。 R のほとんどの関数では、これはデフォルトの設定である。これは一般的に推奨される手順であるが、強制投入で使用するすべての予測変数は、やはり事前に定義された、理論に基づいた決定に基づいているべきであることに留意する必要がある。階層的. 階層的重回帰は、明確に定義された科学的根拠に基づいて、予測変数を段階的に私たちの回帰モデルに含めることを意味する。まず、以前の研究で効果量の差に関係していた予測変数のみが、その重要性の順序で含まれる。このステップの後、既知の予測変数ではまだ捕捉されていない異質性をこれらの変数が説明するかどうかを調べるために、新しい予測変数を追加することができる。階層的. 階層的重回帰は、明確に定義された科学的根拠に基づいて、予測変数を段階的に私たちの回帰モデルに含めることを意味する。まず、以前の研究で効果量の差に関係していた予測変数のみが、その重要性の順序で含まれる。このステップの後、既知の予測変数ではまだ捕捉されていない異質性をこれらの変数が説明するかどうかを調べるために、新しい予測変数を追加することができる。ステップ・ワイズ. ステップ・ワイズ投入法 (または逐次選択法) とは、変数/予測変数が次々にモデルに追加されることを意味する。一見すると、これは階層的回帰とよく似ているが、決定的な違いがある: ステップ・ワイズ回帰法は、統計的基準に基づいて予測変数を選択する。変数増加法 (前方選択、フォワード選択、forward selection) と呼ばれる手順では、データ中の最大の変動量を説明する変数が、最初の予測変数として使われる。そして、このプロセスを残りの変数について繰り返し、毎回、データ中の説明できない残留変動のほとんどを説明する変数を選択する。また、変数減少法 (後方選択法、backward selection) と呼ばれる手順もあり、まずすべての変数がモデルの予測変数として使用され、次にあらかじめ定義された統計的基準に基づいて、順次削除される。ステップ・ワイズ法の使用を推奨しない文献が多数ある (Chatfield 1995; Whittingham et al. 2006)。上で示した重回帰モデルの一般的な落とし穴を思い出すと、これらの方法が偽の知見を持つ過剰適合モデルを生成する高いリスクを持つことが明らかになる。とはいえ、ステップワイズ法は今でも実務で頻繁に使われているので、これらの手続きが存在することを知っておくことは重要である。ただし、ステップワイズ法を使う場合は、主に探索的に行い、この手法の限界を念頭に置いておくことを勧める。(訳注: これらのほか、変数増減法、変数減増法がある。)マルチモデル推論. マルチモデル法 (または総当たり法) は、分散の大部分を説明する1つの「最良」モデルを連続的に構築しようとしないので、段階的アプローチとは異なる。その代わりに、この手法では、予測変数のすべての可能な組み合わせがモデル化される。これは、いくつかの異なるメタ回帰が作成され、その後、評価されることを意味する。これは、すべての可能な予測変数の組み合わせと、それらがどのように機能するかを完全に調べることができる。共通の発見は、良いモデル適合をもたらす多くの異なる仕様があることである。そして、予測変数の推定係数は、適合したすべてのモデルにわたってプールされ、特定の変数が全体としてどのくらい重要であるかを推論することができる。","code":""},{"path":"metareg.html","id":"multiple-metareg-R","chapter":"8 メタ回帰","heading":"8.3.3 R の多重メタ回帰","text":"\nすべてのインプットの後、 R を使用して最初の多重メタ回帰の適合を開始する時が来た。以下の例は、{meta} パッケージを使用しない最初の例である。その代わりに {metafor} を見てみよう (Viechtbauer 2010)。このパッケージは、メタ分析のための膨大で高度な機能を、素晴らしいドキュメントとともに提供している32。そこで、まず、{metafor} がインストールされており、ライブラリからロードされていることを確認する。このハンズオンでは、 MVRegressionData データセットを使用する。これは「おもちゃ」のようなデータセットで、説明のためにシミュレートしたものである。\n“MVRegressionData” データセット\n\nMVRegressionData のデータセットも\n{dmetar}\nパッケージに直接含まれている。{dmetar}\nをインストールし、ライブラリからロードした後、\ndata(SuicidePrevention) を実行すると、自動的に R\n環境にデータセットが保存される。これでデータセットが利用できる。もし、{dmetar}\nがインストールされていない場合は、インターネットから\n.rda\nファイルとしてデータセットをダウンロードして作業ディレクトリに保存し、R\nStudio ウィンドウでクリックするとインポートすることができる。\nまず、データフレームの構造を見てみよう。このデータセットには6つの変数があることがわかる。yi 列と sei 列は、特定の研究の効果量と標準誤差を格納する。この列は、前に使った TE 列と seTE 列と対応している。この変数名が、{metafor} が使用している標準的な表記方法である。yi は (メタ) 回帰で予測したい観測された効果量 \\(y_i\\) を表し、sei は \\(SE_i\\)で、研究 \\(\\) の標準誤差を表す。他の4つの変数は、メタ回帰で使用される予測変数である。まず、reputation であるが、これは研究が掲載されたジャーナルの (平均値中心の) インパクト・ファクターである。インパクトファクターは、ジャーナルの論文がどれだけ頻繁に引用されるかを定量化し、ジャーナルの名声の代理として使用する。その他の変数は、0 から 10 で評価される研究の質である quality、(平均値中心揃えでスケーリングされた) 出版年である pubyear、そして研究が行われた大陸である continent である。これらの変数は、continent を除き、すべて連続変数である。continent は、ヨーロッパと北アメリカの2つのレベルを持つカテゴリ変数である。","code":"\nlibrary(metafor)\nlibrary(tidyverse)\nlibrary(dmetar)\ndata(MVRegressionData)\n\nglimpse(MVRegressionData)## Rows: 36\n## Columns: 6\n## $ yi         <dbl> 0.09437543, 0.09981923, 0.16931607, 0.17511107, 0.27301641,…\n## $ sei        <dbl> 0.1959031, 0.1918510, 0.1193179, 0.1161592, 0.1646946, 0.17…\n## $ reputation <dbl> -11, 0, -11, 4, -10, -9, -8, -8, -8, 0, -5, -5, -4, -4, -3,…\n## $ quality    <dbl> 6, 9, 5, 9, 2, 10, 6, 3, 10, 3, 1, 5, 10, 2, 1, 2, 4, 1, 8,…\n## $ pubyear    <dbl> -0.85475360, -0.75277184, -0.66048349, -0.56304843, -0.4308…\n## $ continent  <fct> 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1,…"},{"path":"metareg.html","id":"多重共線性の確認","chapter":"8 メタ回帰","heading":"8.3.3.1 多重共線性の確認","text":"前に述べたように、メタ回帰の係数推定が頑健 (robust) であることを確認するために、予測変数の多重共線性をチェックする必要がある。高い相関をチェックする簡単な方法は、すべての連続変数について相互相関行列を計算することである。これは、cor 関数を用いて行うことができる。{PerformanceAnalytics} パッケージ (Peterson Carl 2020) には chart.Correlation という関数があり、これを使うと相関行列を可視化することができる。まず、PerformanceAnalytics パッケージをインストールしてから、このコードを使用する必要がある。変数は確かに相関しているが、おそらくそのうちの 1 つを除外するほどではないだろうということがわかる。","code":"\nMVRegressionData[,c(\"reputation\", \"quality\", \"pubyear\")] %>% cor()##            reputation    quality    pubyear\n## reputation  1.0000000  0.3015694  0.3346594\n## quality     0.3015694  1.0000000 -0.1551123\n## pubyear     0.3346594 -0.1551123  1.0000000\nlibrary(PerformanceAnalytics)\n\nMVRegressionData[,c(\"reputation\", \"quality\", \"pubyear\")] %>% \n  chart.Correlation()"},{"path":"metareg.html","id":"多重メタ回帰モデルの適合","chapter":"8 メタ回帰","heading":"8.3.3.2 多重メタ回帰モデルの適合","text":"さて、最初のメタ回帰モデルは、 {metafor} を使用して適合させることができる。以前は、高いジャーナルの評判がより高い効果量を予測するかどうか、またはこれが単に一流ジャーナルの研究がより高い品質を持つという事実によって引き起こされる思い込みであるかどうかを調べたいと思った。例えば、先行研究から研究の質が効果量を予測することがよく分かっていると仮定しよう。この場合、階層的回帰を実行することは理にかなっている。まず、既知の予測因子である「品質」を含め、次に「評判」がそれ以上の異質性を説明するかどうかをチェックする。これが正しい場合、一流雑誌の研究がより高い品質を持つ傾向があるという事実を制御しても、雑誌の評判は実際に高い効果と関連していると言うことができる。そのために、 {metafor} の rma 関数を使用する。この関数はランダム効果メタ分析を実行し、モデレータが追加されると混合効果メタ回帰モデルへと拡張される。rma 関数は無数の引数を取ることができ、 R コンソールで ?rma を実行すると、その引数を調べることができる。しかし、通常はそのうちのいくつかを指定するだけでよい。yi. 各研究の効果量が格納されているデータフレームの列。yi. 各研究の効果量が格納されているデータフレームの列。sei. 各研究の効果量の標準誤差が格納されているデータフレームの列。sei. 各研究の効果量の標準誤差が格納されているデータフレームの列。data. メタ分析データを格納したデータフレーム名。data. メタ分析データを格納したデータフレーム名。method. 使用したい \\(\\tau^2\\) 推定量。この引数に使用できるコードは、 {meta} のものと同じである (例: \"REML\" restricted maximum likelihood の略)。\"ML\"を使用することが推奨される。これは、後で異なるメタ回帰モデルを比較することができるからである。method. 使用したい \\(\\tau^2\\) 推定量。この引数に使用できるコードは、 {meta} のものと同じである (例: \"REML\" restricted maximum likelihood の略)。\"ML\"を使用することが推奨される。これは、後で異なるメタ回帰モデルを比較することができるからである。mods. このパラメータは、メタ回帰モデルを定義する。まず、モデルを ~ (チルダ) で指定する。次に、含める予測変数を + で区切って追加する (例: variable1 + variable2 )。2 つの変数の間の交互作用は、アスタリスクで表す (例: variable1 * variable2 )。mods. このパラメータは、メタ回帰モデルを定義する。まず、モデルを ~ (チルダ) で指定する。次に、含める予測変数を + で区切って追加する (例: variable1 + variable2 )。2 つの変数の間の交互作用は、アスタリスクで表す (例: variable1 * variable2 )。test. 回帰係数に適用したい検定である。デフォルトの \"z\" または \"knha\" (Knapp-Hartung method) から選択できる。test. 回帰係数に適用したい検定である。デフォルトの \"z\" または \"knha\" (Knapp-Hartung method) から選択できる。まず、予測因子として quality だけを用いてメタ回帰を実行してみよう。その結果を m.qual というオブジェクトに保存して、出力を調べてみる。この出力では、予測変数 quality の結果を Model Results の下で確認できる。トレンド・レベルでは有意であるが (\\(p<\\) 0.1)、回帰の重みは有意ではない (\\(p=\\) 0.069)。合計で、このモデルは異質性の \\(R^2_*=\\) 7.37% を説明する。では、reputation を予測変数に含めるとどうなるか見てみよう。mods の入力に + reputation を追加し、今回は出力を m.qual.rep として保存する。モデル結果のセクションに新しい行が表示され、予測変数 reputation の結果が表示されていることがわかる。モデルは、回帰の重みを 0.034 と推定し、これは非常に有意である (\\(p\\) < 0.001)。また、メタ回帰モデルは、全体としてかなりの量の異質性を説明していることがわかる。正確には、\\(R^2_*\\) = 66.95% である。これは、研究の質でコントロールした場合でも、ジャーナルの評判がより高い効果量と関連していることを意味する。\nしかし、2番目のモデルは本当に最初のモデルよりも適合度が高いのだろうか？これを評価するために、 anova 関数を使用し、比較したい2つのモデルを指定することができる。これは、制限付き最尤法 (\"REML\") の代わりに最尤法 (\"ML\") を用いて両方の混合効果モデルを適合させたからこそ可能なことであることに注意しておこう。この関数はモデルのテストを行い、m.qual.rep が m.qual よりも適合度が高いかどうかを評価するためのいくつかの統計情報を提供する。ここでは、quality と reputation の両方を含むフルモデルである m.qual.rep と、quality のみを含む縮小モデルとを比較する。anova 関数は 尤度比検定を実行し、その結果は LRT 列で見ることができる。この検定は非常に有意であり (\\(\\chi^2_1=\\) 19.11, \\(p<\\) 0.001)、フルモデルが本当に良い適合を提供することを意味する。もう1つの重要な統計量は AICc 列で報告されていて、小さなサンプルで補正された赤池情報量規準 (AIC) を提供する。前に述べたように、AICc は、過適合を避けるために、より多くの予測変数がある複雑なモデルにペナルティを課す。AIC の値が低いと、モデルの性能が良いということに注意を払うことが重要である。この出力では、より多くのパラメータがあるにもかかわらず、フルモデル (AICc = 21.15) が削減モデル (AICc = 37.73) よりも良いAIC値を持っていることがわかる。これらのことは、重回帰モデルが実際に私たちのデータに対して良い適合を提供することを示唆している。","code":"\nm.qual <- rma(yi = yi,\n              sei = sei,\n              data = MVRegressionData,\n              method = \"ML\",\n              mods = ~ quality,\n              test = \"knha\")\n\nm.qual## Mixed-Effects Model (k = 36; tau^2 estimator: ML)\n## \n## tau^2 (estimated amount of residual heterogeneity):     0.066 (SE = 0.023)\n## tau (square root of estimated tau^2 value):             0.2583\n## I^2 (residual heterogeneity / unaccounted variability): 60.04%\n## H^2 (unaccounted variability / sampling variability):   2.50\n## R^2 (amount of heterogeneity accounted for):            7.37%\n## \n## Test for Residual Heterogeneity:\n## QE(df = 34) = 88.6130, p-val < .0001\n## \n## Test of Moderators (coefficient 2):\n## F(df1 = 1, df2 = 34) = 3.5330, p-val = 0.0688\n## \n## Model Results:\n## \n##          estimate      se    tval    pval    ci.lb   ci.ub \n## intrcpt    0.3429  0.1354  2.5318  0.0161   0.0677  0.6181  * \n## quality    0.0356  0.0189  1.8796  0.0688  -0.0029  0.0740  . \n## \n## ---\n## Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\nm.qual.rep <- rma(yi = yi, \n                  sei = sei, \n                  data = MVRegressionData, \n                  method = \"ML\", \n                  mods = ~ quality + reputation, \n                  test = \"knha\")\n\nm.qual.rep## Mixed-Effects Model (k = 36; tau^2 estimator: ML)\n## \n## tau^2 (estimated amount of residual heterogeneity):     0.0238 (SE = 0.01)\n## tau (square root of estimated tau^2 value):             0.1543\n## I^2 (residual heterogeneity / unaccounted variability): 34.62%\n## H^2 (unaccounted variability / sampling variability):   1.53\n## R^2 (amount of heterogeneity accounted for):            66.95%\n## \n## Test for Residual Heterogeneity:\n## QE(df = 33) = 58.3042, p-val = 0.0042\n## \n## Test of Moderators (coefficients 2:3):\n## F(df1 = 2, df2 = 33) = 12.2476, p-val = 0.0001\n## \n## Model Results:\n## \n##             estimate      se    tval    pval    ci.lb   ci.ub \n## intrcpt       0.5005  0.1090  4.5927  <.0001   0.2788  0.7222  *** \n## quality       0.0110  0.0151  0.7312  0.4698  -0.0197  0.0417      \n## reputation    0.0343  0.0075  4.5435  <.0001   0.0189  0.0496  *** \n## \n## ---\n## Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\nanova(m.qual, m.qual.rep)##         df   AIC   BIC  AICc logLik   LRT   pval    QE tau^2    R^2 \n## Full     4 19.86 26.19 21.15  -5.93              58.30  0.03          \n## Reduced  3 36.98 41.73 37.73 -15.49 19.11 <.0001 88.61  0.06 48.32% "},{"path":"metareg.html","id":"モデリング交互作用","chapter":"8 メタ回帰","heading":"8.3.3.3 モデリング交互作用","text":"追加予測変数 pubyear (出版年) と continent との交互作用をモデル化したいとする。出版年と効果量の関係がヨーロッパと北米の研究で異なると仮定する。この仮定を rma 関数でモデル化するために、mods パラメータで予測変数を * と接続する必要がある。anova 関数を用いて直接モデルを比較したくないので、今回は \"REML\" (restricted maximum likelihood) \\(\\tau^2\\) 予測因子を使用する。解釈を容易にするために、モデルを実行する前に MVRegressionData で continent 変数に因子ラベルを追加する。最後の行の pubyear:continentNorth America には、交互作用項の係数が格納されている。 {metafor} は、自動的に交互作用項だけでなく、「通常の」低次予測変数として pubyear と continent の両方を含むことに注意しておこう (むしろ、注意すべき)。また、continent は因子であるため、rma はこれがダミーコード化された予測因子であることを検出し、北米のカテゴリーと比較するために、カテゴリー「ヨーロッパ」を \\(D_g\\) = 0 の基準として使用したことに留意してみよう。この交互作用項は正の係数 (0.63) を持ち、非常に有意であることがわかる (\\(p<\\) 0.001)。これは、近年、効果量が増加していること、また、北米で行われた研究でより強くなっていることを示している。また、私たちがあてはめたモデルは、\\(R^2_*\\) =100% の異質性を説明していることがわかる。なぜこうなったかというと、このデータが説明のためにシミュレーションされたためである。実際には、データの異質性をすべて説明することはほとんどない。むしろ、現実のデータでこのような結果を見つけたら、モデルを過剰に適合させたことになるかもしれないので、心配する必要がある。","code":"\n# 因子ラベルを 'continent' に追加\n# 0 = Europe\n# 1 = North America\nlevels(MVRegressionData$continent) = c(\"Europe\", \"North America\")\n\n# メタ回帰モデルを適合\nm.qual.rep.int <- rma(yi = yi, \n                      sei = sei, \n                      data = MVRegressionData, \n                      method = \"REML\", \n                      mods = ~ pubyear * continent, \n                      test = \"knha\")\n\nm.qual.rep.int## Mixed-Effects Model (k = 36; tau^2 estimator: REML)\n## \n## tau^2 (estimated amount of residual heterogeneity):     0 (SE = 0.01)\n## tau (square root of estimated tau^2 value):             0\n## I^2 (residual heterogeneity / unaccounted variability): 0.00%\n## H^2 (unaccounted variability / sampling variability):   1.00\n## R^2 (amount of heterogeneity accounted for):            100.00%\n## \n## Test for Residual Heterogeneity:\n## QE(df = 32) = 24.8408, p-val = 0.8124\n## \n## Test of Moderators (coefficients 2:4):\n## F(df1 = 3, df2 = 32) = 28.7778, p-val < .0001\n## \n## Model Results:\n## \n##                       estimate    se  tval    pval  ci.lb ci.ub \n## intrcpt                    0.38  0.04  9.24  <.0001   0.30  0.47  *** \n## pubyear                    0.16  0.08  2.01  0.0520  -0.00  0.33    . \n## continentNorth America     0.39  0.06  6.05  <.0001   0.26  0.53  *** \n## pubyear:continent          0.63  0.12  4.97  <.0001   0.37  0.89  *** \n##    North America\n## [...]"},{"path":"metareg.html","id":"並び替え検定","chapter":"8 メタ回帰","heading":"8.3.3.4 並び替え検定","text":"並び替え (permutation) とは、数値や物体を含む集合を取り出し、その集合から繰り返し要素を取り出して順番に並べる数学的な操作である。すでに順序のある数値の集合がある場合、これはデータの順序を並べ替える、つまりシャッフルする処理と同じである。例として、3つの数を含む集合 \\(S=\\{1,2,3 \\}\\) があるとする。この集合の可能な並べ換えの1つは \\((2,1,3)\\) 、別の並べ替えでは \\((3,2,1)\\) となる。並べ替えの結果は、両方とも前の3つの数字を含んでいるが、順番が違うことがわかる。並び替えは並び替え検定にも使われるが、リサンプリング法の特別な種類である。大まかに言うと、リサンプリング法は、同じソースまたは生成プロセスからサンプルされた (少し) 異なるデータを与えることによって、統計モデルの頑健性を検証するために使用される (Good 2013, chap. 3.1)。これは、モデルの係数が本当にデータの根底にある真のパターンを捉えているかどうか、あるいは、モデルを過適合させ、それによって、実際には統計的ノイズであるのに、データのパターンを誤って仮定していないかどうかをより良く評価する方法である。並び替え検定は、メタ回帰が未知の効果量を予測する際にどのように実行されるかを評価できる予備の「テスト」データセットを持っている必要はない。このため、特に、並べ替え検定は、メタ回帰モデルの頑健性を評価するために推奨されている (JPT Higgins Thompson 2004)。メタ回帰モデルで並べ替え検定をどのように実行するかの詳細については、ここではあまり触れない。最も重要な部分は、元のデータ集合のすべての可能な並べ替え、またはランダムに選ばれた多くの並べ替えで得られた検定統計量に基づいて、私たちのモデルの \\(p\\)-値を再計算することである。ここで重要な指標は、並べ替えデータから得られる検定統計量が、元の検定統計量と等しいか大きいか、またその頻度である。例えば、並べ替えデータ 1000 個のうち 50 個で、検定統計量が元の検定統計量より大きいか等しいとすると、\\(p\\) = 0.05となる。メタ回帰モデルに対して並べ替え検定を行うには、{metafor} に内蔵されている permutest という関数を使用する。例として、以前適合した m.qual.rep モデルの結果を再計算してみよう。permutest 関数は rma オブジェクトと一緒に提供するだけである。並べ替え検定は、特に大きなデータセットの場合、計算量が多く実行に時間がかかる。すべての予測変数の結果を含むおなじみの出力が再び表示される。pval* 列を見ると、評判予測変数の \\(p\\)-値が \\(p\\) < 0.001 から \\(p_*\\) = 0.001 に減少していることがわかる。しかし、これはまだ非常に有意であり、予測変数の効果が頑健であることを示している。メタ回帰モデルの結果を報告する前に、必ずこの並べ換え検定を用いることが推奨されている (JPT Higgins Thompson 2004)。\nデータが小さい場合の Permutation 検定\n\nモデルに含まれる研究数 \\(K\\)\nが少ない場合、従来から使われている統計的有意性の閾値 (つまり\\(p\\) < 0.05)\nに到達できないことに注意。\n\nメタ回帰モデルの場合、permutest\nを用いた並べ替え検定は、\\(K\\) > 4\nの場合のみ統計的有意に達することができる (Viechtbauer et al. 2015) 。\n","code":"\npermutest(m.qual.rep)## Test of Moderators (coefficients 2:3):\n## F(df1 = 2, df2 = 33) = 12.7844, p-val* = 0.0010\n## \n## Model Results:\n## \n##             estimate      se    tval   pval*    ci.lb   ci.ub \n## intrcpt       0.4964  0.1096  4.5316  0.2240   0.2736  0.7193      \n## quality       0.0130  0.0152  0.8531  0.3640  -0.0179  0.0438      \n## reputation    0.0350  0.0076  4.5964  0.0010   0.0195  0.0505  *** \n## \n## ---\n## Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1"},{"path":"metareg.html","id":"multimodel-inference","chapter":"8 メタ回帰","heading":"8.3.3.5 マルチモデル推論","text":"私たちはすでに、マルチ・モデル推論と呼ばれる方法で、予測変数の全ての可能な組み合わせをモデル化することができることを述べた。これは、どの予測変数の組み合わせが最良の適合を提供するか、そして、どの予測変数が全体として最も重要であるかを調査することができる。マルチモデル推論を行うには、 multimodel.inference 関数を使用する33。\n“multimodel.inference” 関数\n\nmultimodel.inference 関数は、{dmetar}\nパッケージに含まれている。{dmetar}\nがインストールされ、コンピュータに読み込まれると、この関数を使用できるようになる。もし、{dmetar}\nをインストールしていない場合は、以下の手順でインストールできる。\n\n関数のソースコードにアクセスする オンライン.\n\nソースコード全体をコンソール (R Studio の左下ペイン)\nにコピー＆ペーストし、Enterキーを押して、 R\nに関数を「学習」させる。\n\n{metafor}, {ggplot2},\n{MuMIn}\nパッケージがインストールされ、ロードされていることを確認する。\nこの関数では、以下のパラメータを指定する必要がある。TE. 各研究の効果量。データセットの効果量列の名前を引用符で囲んで指定する必要がある (例: TE = \"effectize\")。TE. 各研究の効果量。データセットの効果量列の名前を引用符で囲んで指定する必要がある (例: TE = \"effectize\")。seTE. 効果量の標準誤差。データセットの標準誤差列の名前を指定する必要があい (引用符で囲んで、例えば seTE = \"se\")。seTE. 効果量の標準誤差。データセットの標準誤差列の名前を指定する必要があい (引用符で囲んで、例えば seTE = \"se\")。data. 効果量、標準誤差、メタ回帰予測変数が含まれるデータフレーム。data. 効果量、標準誤差、メタ回帰予測変数が含まれるデータフレーム。predictors. マルチモデル推論に使用する予測因子を指定する文字の連結配列。予測因子の名前は、data に与えられたデータフレームの列名と同じでなければならない。predictors. マルチモデル推論に使用する予測因子を指定する文字の連結配列。予測因子の名前は、data に与えられたデータフレームの列名と同じでなければならない。method. 効果量のプーリングに使用するメタ分析モデル。固定効果モデルには \"FE\" が用いられる。\"DL\", \"SJ\", \"ML\", \"REML\" など、複数のランダム効果モデルが利用可能である。\"FE\" を使用する場合、Knapp-Hartung 法は固定効果モデルで使用することを意図していないため、test 引数は自動的に \"z\" に設定される。デフォルトは \"REML\" である。method. 効果量のプーリングに使用するメタ分析モデル。固定効果モデルには \"FE\" が用いられる。\"DL\", \"SJ\", \"ML\", \"REML\" など、複数のランダム効果モデルが利用可能である。\"FE\" を使用する場合、Knapp-Hartung 法は固定効果モデルで使用することを意図していないため、test 引数は自動的に \"z\" に設定される。デフォルトは \"REML\" である。test. 検定統計量と信頼区間を計算する際に利用する手法。デフォルトは \"knha\" で、Knapp-Hartung 調整を利用する。コンベンショナルな Wald タイプの検定は、この引数を \"z\" に設定することで計算される。test. 検定統計量と信頼区間を計算する際に利用する手法。デフォルトは \"knha\" で、Knapp-Hartung 調整を利用する。コンベンショナルな Wald タイプの検定は、この引数を \"z\" に設定することで計算される。eval.criterion. 適合したモデルに適用する評価基準。\"AICc\" (デフォルト、 スモールサンプル補正した赤池情報量規準)、 \"AIC\" (赤池情報量規準)、または \"BIC\" (ベイズ情報量規準) のいずれかを指定することが可能である。eval.criterion. 適合したモデルに適用する評価基準。\"AICc\" (デフォルト、 スモールサンプル補正した赤池情報量規準)、 \"AIC\" (赤池情報量規準)、または \"BIC\" (ベイズ情報量規準) のいずれかを指定することが可能である。interaction. FALSE (デフォルト) に設定すると、予測変数間の交互作用は考慮されていない。このパラメータを TRUE に設定すると、すべての交互作用がモデル化される。interaction. FALSE (デフォルト) に設定すると、予測変数間の交互作用は考慮されていない。このパラメータを TRUE に設定すると、すべての交互作用がモデル化される。では、データセット MVRegressionData のすべての予測変数を使って、交互作用なしで マルチモデル推論を実行してみよう。multimodel.inference 関数を実行すると、特に予測変数の数が多い場合、時間がかかることに注意しておこう。\\[~\\]見どころ満載なので、順を追って出力を見ていこう。Multimodel Inference: Final Results. この部分は、適合したモデルについての詳細な情報を提供する。 \\(2^4 = 16\\) 可能なモデルの総数が適合したことがわかる。また、この関数はモデルの比較に補正済みAIC (aicc) を使用していることがわかる。Multimodel Inference: Final Results. この部分は、適合したモデルについての詳細な情報を提供する。 \\(2^4 = 16\\) 可能なモデルの総数が適合したことがわかる。また、この関数はモデルの比較に補正済みAIC (aicc) を使用していることがわかる。Best 5 Models . ここに表示されているのは、AICc が最も低い5つのモデルで、低いものから高いものへとソートされている。予測変数は表の列に、モデルは行に表示される。数字 (重み) または + 記号 (カテゴリ予測変数の場合) は、予測変数/交互作用項がモデルで用いられたことを示し、空のセルは、予測変数が省略されたことを示す。私たちは、 TE ~ 1 + continent + pubyear + reputation が最良の適合を示すことがわかる (AICc = 6.0)。しかし、他の予測変数の組み合わせは、この値に非常に近い。したがって、どのモデルが本当に「ベスト」モデルであるかを言うのは難しい。しかし、上位5つのモデルはすべて予測変数 pubyear を含んでおり、この変数が特に重要である可能性を示唆している。Best 5 Models . ここに表示されているのは、AICc が最も低い5つのモデルで、低いものから高いものへとソートされている。予測変数は表の列に、モデルは行に表示される。数字 (重み) または + 記号 (カテゴリ予測変数の場合) は、予測変数/交互作用項がモデルで用いられたことを示し、空のセルは、予測変数が省略されたことを示す。私たちは、 TE ~ 1 + continent + pubyear + reputation が最良の適合を示すことがわかる (AICc = 6.0)。しかし、他の予測変数の組み合わせは、この値に非常に近い。したがって、どのモデルが本当に「ベスト」モデルであるかを言うのは難しい。しかし、上位5つのモデルはすべて予測変数 pubyear を含んでおり、この変数が特に重要である可能性を示唆している。Multimodel Inference Coefficients. ここでは、すべての予測変数の係数を、それらが出現するすべてのモデルにわたって集約して見ることができる。係数推定値は、 pubyear ( \\(\\hat\\beta\\) = 0.378)で最も大きく、これは以前の発見を裏付ける。近似信頼区間は、Std.Error に格納された値に 1.96 を掛けたものを、Estimate と引き算したり足したりすることで得ることができる。Multimodel Inference Coefficients. ここでは、すべての予測変数の係数を、それらが出現するすべてのモデルにわたって集約して見ることができる。係数推定値は、 pubyear ( \\(\\hat\\beta\\) = 0.378)で最も大きく、これは以前の発見を裏付ける。近似信頼区間は、Std.Error に格納された値に 1.96 を掛けたものを、Estimate と引き算したり足したりすることで得ることができる。モデル平均予測変数の重要度プロット. このプロットでは、すべてのモデルで各予測変数の平均された重要度が表示される。再び、pubyear が最も重要な予測変数であることがわかる。次に、reputation、continent、quality が続く。モデル平均予測変数の重要度プロット. このプロットでは、すべてのモデルで各予測変数の平均された重要度が表示される。再び、pubyear が最も重要な予測変数であることがわかる。次に、reputation、continent、quality が続く。\nマルチモデル推論の限界\n\nこの例から、マルチモデル推論が、効果量の違いを予測するためにどの予測変数が重要であるかを包括的に把握するのに有効な方法であることが明らかになるはずである。\n\nステップ・ワイズ回帰法の問題のいくつかを回避しているとはいえ、この方法はまだ探索的と見なされるべきで、予測変数が分析する研究分野の効果量とどのように関連しているかについて予備知識がない場合に使用することができることに注意。\n\nマルチモデル推論の結果に基づいてメタ回帰モデルを構築することにした場合、これを報告することが極めて重要である。なぜなら、そのようなモデルは\npriori\nな仮説に基づくものではなく、このサンプルにおける統計的特性に基づいて構築されたためである。\n\\[\\tag*{$\\blacksquare$}\\]","code":"\nmultimodel.inference(TE = \"yi\", \n                     seTE = \"sei\",\n                     data = MVRegressionData,\n                     predictors = c(\"pubyear\", \"quality\", \n                                    \"reputation\", \"continent\"),\n                     interaction = FALSE)## Multimodel Inference: Final Results\n## --------------------------\n##  - Number of fitted models: 16\n##  - Full formula: ~ pubyear + quality + reputation + continent\n##  - Coefficient significance test: knha\n##  - Interactions modeled: no\n##  - Evaluation criterion: AICc \n## \n## \n## Best 5 Models\n## --------------------------\n## [...]\n##    (Intrc) cntnn  pubyr   qulty   rpttn df logLik AICc delta weight\n## 12       +     + 0.3533         0.02160  5  2.981  6.0  0.00  0.536\n## 16       +     + 0.4028 0.02210 0.01754  6  4.071  6.8  0.72  0.375\n## 8        +     + 0.4948 0.03574          5  0.646 10.7  4.67  0.052\n## 11       +       0.2957         0.02725  4 -1.750 12.8  6.75  0.018\n## 15       +       0.3547 0.02666 0.02296  5 -0.395 12.8  6.75  0.018\n## Models ranked by AICc(x) \n## \n## \n## Multimodel Inference Coefficients\n## --------------------------\n##                          Estimate  Std. Error   z value  Pr(>|z|)\n## intrcpt                0.38614661 0.106983583 3.6094006 0.0003069\n## continentNorth America 0.24743836 0.083113174 2.9771256 0.0029096\n## pubyear                0.37816796 0.083045572 4.5537402 0.0000053\n## reputation             0.01899347 0.007420427 2.5596198 0.0104787\n## quality                0.01060060 0.014321158 0.7402055 0.4591753\n## \n## \n## Predictor Importance\n## --------------------------\n##        model importance\n## 1    pubyear  0.9988339\n## 2  continent  0.9621839\n## 3 reputation  0.9428750\n## 4    quality  0.4432826"},{"path":"metareg.html","id":"演習問題-7","chapter":"8 メタ回帰","heading":"8.4 演習問題","text":"\n知識を試そう！\n\n一次研究で用いられる従来の回帰分析と、メタ回帰の違いは何か？\n\nサブグループ解析とメタ回帰は密接な関係がある。メタ回帰の公式をどのようにサブグループデータに適応させることができるか？\n\nメタ回帰において、個々の研究に異なる重みを与えるためにどのような方法が用いられるか？\n\nデータによく適合するメタ回帰モデルにはどのような特徴があるか？これを調べるには、どのような指標を用いればよいか？\n\nメタ分析の手法でサブグループ分析を計算する場合、\\(\\tau^2\\)\nの値をサブグループで別々にするか、共通にするか？\n\n(多重) メタ回帰の限界と落とし穴は何か？\n\n(複数の)\nメタ回帰モデルの頑健性を向上させるために利用できる方法を2つ挙げ、それが有用である理由を述べよ。\n\n問題の解答は、本書の巻末 Appendix\nにある。\n","code":""},{"path":"metareg.html","id":"要約-4","chapter":"8 メタ回帰","heading":"8.5 要約","text":"メタ回帰では、従来の回帰手法を研究レベルのデータに適応させる。サブグループ分析は、カテゴリカル予測因子と共通の推定値 \\(\\tau^2\\) を持つメタ回帰の特別なケースと見なすことができる。メタ回帰では、従来の回帰手法を研究レベルのデータに適応させる。サブグループ分析は、カテゴリカル予測因子と共通の推定値 \\(\\tau^2\\) を持つメタ回帰の特別なケースと見なすことができる。メタ回帰モデルの目的は、データにおける真の効果量の違い (すなわち、研究間異質性分散 \\(\\tau^2\\) ) を説明することである。モデルがデータによく合っている場合、回帰直線からの真の効果の偏差は、プール効果からの最初の偏差よりも小さくなるはずである。この場合、説明できない異質性、つまり残差は小さくなる。これは、\\(R^2_*\\) 指数によって捕捉され、モデルによって説明される異質性の変動のパーセンテージを知らせる。メタ回帰モデルの目的は、データにおける真の効果量の違い (すなわち、研究間異質性分散 \\(\\tau^2\\) ) を説明することである。モデルがデータによく合っている場合、回帰直線からの真の効果の偏差は、プール効果からの最初の偏差よりも小さくなるはずである。この場合、説明できない異質性、つまり残差は小さくなる。これは、\\(R^2_*\\) 指数によって捕捉され、モデルによって説明される異質性の変動のパーセンテージを知らせる。多重メタ回帰では、2つ以上の予測変数が同じメタ回帰モデルで使用される。また、交互作用項を導入することで、ある変数の予測値が他の変数の異なる値に対して変化するかどうかを検定することも可能である。多重メタ回帰では、2つ以上の予測変数が同じメタ回帰モデルで使用される。また、交互作用項を導入することで、ある変数の予測値が他の変数の異なる値に対して変化するかどうかを検定することも可能である。多重メタ回帰は非常に汎用性の高い手法であるが、限界がある。多重メタ回帰は、真の関係ではなくランダムなノイズがモデル化されることを意味する、オーバーフィットモデルを非常に容易にする。予測変数の多重共線性は、私たちのモデルの妥当性に脅威を与えるだろう。多重メタ回帰は非常に汎用性の高い手法であるが、限界がある。多重メタ回帰は、真の関係ではなくランダムなノイズがモデル化されることを意味する、オーバーフィットモデルを非常に容易にする。予測変数の多重共線性は、私たちのモデルの妥当性に脅威を与えるだろう。メタ回帰モデルが頑健であることを保証するために、いくつかのアプローチがある。例えば、定義された理論的根拠に基づいてのみモデルを適合させたり、並べ替え検定を使用したりすることができる。マルチモデル推論は、探索的アプローチとして使用することができる。この方法は、潜在的に重要な予測因子を指摘することができ、将来の研究で検証すべき仮説を導き出すために使用することができる。メタ回帰モデルが頑健であることを保証するために、いくつかのアプローチがある。例えば、定義された理論的根拠に基づいてのみモデルを適合させたり、並べ替え検定を使用したりすることができる。マルチモデル推論は、探索的アプローチとして使用することができる。この方法は、潜在的に重要な予測因子を指摘することができ、将来の研究で検証すべき仮説を導き出すために使用することができる。","code":""},{"path":"pub-bias.html","id":"pub-bias","chapter":"9 出版バイアス","heading":"9 出版バイアス","text":"前\n章を振り返ってみると、すでにメタ分析の幅広い技術をカバーしていることがわかる。効果量をプールする方法を学んだだけでなく、発見の頑健性を評価する方法、異質性のパターンを検査する方法、効果に差がある理由についての仮説を検証する方法についても学んだ。これらのアプローチはすべて、メタ分析から有効な結論を引き出すのに役立つ。しかし、これはデータの性質に関するある暗黙の前提の上に成り立っているが、まだそれに挑戦していない。すなわち、メタ分析を行う際、収集したデータが包括的であること、あるいは少なくとも調査中の研究分野を代表するものであることを前提としている。Chapter 1.4.3 で、メタ分析は通常、研究分野を適切に説明する単一の効果量を導き出すために、利用可能なすべてのエビデンスを含めようとすることを述べた。統計学的な観点からは、研究がいくつか欠けていても許容できるだろうが、それはこれらの研究が偶然に「省かれた」場合のみである。残念ながら、多くの場合、メタ分析では既存のエビデンスをすべて網羅することはできない。さらに悪いことに、いくつかの研究は、収集したデータから完全に「ランダムに」して欠落しているわけではないと考えられる理由も十分にある。この世界は不完全であり、科学的実践を支配するインセンティブや「ルール」もまた不完全である。つまり、ある研究がメタ分析に含まれるかどうかを決定するシステム的なバイアスが存在するのである。この問題の良い例が、あまり知られていない薬物療法研究の逸話にある。1990年代には、抗うつ薬 (選択的セロトニン再取り込み阻害薬、SSRIなど) がうつ病患者に有効であることは周知の事実と考えられていた。エビデンスの多くは、抗うつ薬とプラセボを比較した薬物療法の臨床試験のメタ分析によって得られている。抗うつ薬の市場は何十億ドルもの価値があり、着実に成長していることを考えると、抗うつ薬の効果に関する疑問は重要なものである。このことは、Irving Kirsch ら (2002) が書いた「Emperor’s New Drugs」という論文が引き起こした論争を理解するのに役立つだろう。この論争では、結局、物事はそれほど明るくないのではないかと論じた。Kirsch らは、「情報公開法」を利用して、製薬会社が米国食品医薬品局に提供していた未発表の抗うつ剤試験データを入手した。そして、この未発表のデータも考慮すると、プラセボと比較した抗うつ薬の効果はせいぜいわずかであり、臨床的には無視しうるものであることを発見した。Kirsch らは、企業が好ましい知見を持つ研究のみを発表し、「期待はずれ」のエビデンスを持つ研究は非公開にしたためだと主張した (Kirsch 2010)。その後、論争が起こり、Kirsch の主張は今日に至るまで論争の的となっている。この例を選んだのは、どちらかを選ぶためではなく、欠落した研究がメタ分析の推論の妥当性にもたらす潜在的な脅威を説明するためである。メタ分析の文献では、このような問題は通常、出版バイアス (publication bias) という用語で要約されている。出版バイアスの問題は、メタ分析におけるすべての知見が、その根拠となるデータと同程度のものでしかないことを明確に示している。メタ分析の技術は、手元にあるデータでしか機能しない。したがって、収集したデータに歪みがあると、どんなに優れた統計モデルでも固有のバイアスを再現してしまうだけなのである。この基本的な注意点については、本書の一番最初に「ファイルの引き出し」問題 (Chapter 1.3) を取り上げたときに、すでに取り上げていたことを思い出すだろう。実際、「ファイルの引き出し問題」と「出版バイアス」という言葉は、しばしば同義的に使われる。出版バイアスや関連する問題がメタ分析の結果に及ぼす影響は甚大である。治療の効果を過大評価したり、否定的な副作用を見落としたり、実際には無効である理論の信奉を強めたりする原因となり得るのである。そこで本章では、出版バイアスが知見を歪めてしまう様々な形について議論した。また、メタ分析担当者として、データにおける出版バイアスのリスクを調査するために使用できるいくつかのアプローチ、およびそもそも出版バイアスをどのように軽減できるかを見ていこう。","code":""},{"path":"pub-bias.html","id":"types-of-pub-biases","chapter":"9 出版バイアス","heading":"9.1 出版バイアスとは何か？","text":"ある研究が出版される確率がその結果に影響される場合、出版バイアスが存在する (Rothstein, Sutton, Borenstein 2005, chap. 2 5)。研究結果が統計的に有意である場合、あるいは初期仮説を確認する場合、その研究が世に出る可能性が高いというエビデンスが広く存在する (Schmucker et al. 2014; Scherer et al. 2018; Chan et al. 2014; Dechartres et al. 2018)。適格な研究を検索する場合、通常、何らかの形で公表されているエビデンス、例えば、査読付き論文、プレプリント、書籍、その他のアクセス可能な報告書などに制約されることになる。出版バイアスがある場合、これはデータセットに含まれていない研究があることを意味するだけでなく、含まれていない研究に好ましくない知見を持つものである可能性が高いということを意味している。メタ分析の手法を用いれば、母集団における平均的な効果量の偏りのない推定値を求めることが可能である。しかし、サンプルそのものが歪んでいれば、統計学的に「正しい」効果推定値であっても、現実を代表するものではない。これは、氷山の大きさを推し量るのに、その先端しか測っていないようなもので、たとえ水面からの高さを完璧に測ることができたとしても、その結果は必然的に間違っているのである。\n出版バイアスは、実は多くの報告バイアスのうちの1つに過ぎない。メタ分析 (Page et al. 2020) で得られるエビデンスを歪める要因も、他にもいくつかある。引用バイアス (Citation bias): たとえ出版されたとしても、否定的な結果や結論の出ていない研究は、関連する文献に引用される可能性が低くなる。そのため、例えば参考文献検索などで発見することが難しくなる。引用バイアス (Citation bias): たとえ出版されたとしても、否定的な結果や結論の出ていない研究は、関連する文献に引用される可能性が低くなる。そのため、例えば参考文献検索などで発見することが難しくなる。タイムラグバイアス (Time-lag bias): 肯定的な結果を得た研究は、好ましくない結果を得た研究よりも早く発表されることが多い。つまり、最近行われた研究で肯定的な結果を得たものはすでに入手可能であることが多いが、有意でない結果を得たものはそうでないことが多い。タイムラグバイアス (Time-lag bias): 肯定的な結果を得た研究は、好ましくない結果を得た研究よりも早く発表されることが多い。つまり、最近行われた研究で肯定的な結果を得たものはすでに入手可能であることが多いが、有意でない結果を得たものはそうでないことが多い。多重投稿バイアス (Multiple publication bias): 「成功した」研究の結果は、複数の論文で報告される可能性が高く、そのうちの少なくとも1つを見つけることが容易になる。複数の論文にまたがって研究結果を報告するやり方は、「サラミスライス」とも呼ばれる。多重投稿バイアス (Multiple publication bias): 「成功した」研究の結果は、複数の論文で報告される可能性が高く、そのうちの少なくとも1つを見つけることが容易になる。複数の論文にまたがって研究結果を報告するやり方は、「サラミスライス」とも呼ばれる。言語バイアス (Language bias): ほとんどの分野で、エビデンスが発表される主な言語は英語である。他の言語による出版物は、特に研究者自身が翻訳しなければ内容を理解できない場合、発見されにくい。英語の研究が他の言語で発表されたものと系統的に異なる場合、これもまたバイアスを引き起こす可能性がある。言語バイアス (Language bias): ほとんどの分野で、エビデンスが発表される主な言語は英語である。他の言語による出版物は、特に研究者自身が翻訳しなければ内容を理解できない場合、発見されにくい。英語の研究が他の言語で発表されたものと系統的に異なる場合、これもまたバイアスを引き起こす可能性がある。アウトカムバイアス (Outcome reporting bias): 多くの研究、特に臨床試験では、関心のあるアウトカムを複数測定する。これを悪用して、肯定的な結果が得られたアウトカムだけを報告し、仮説を確認できなかったアウトカムは削除する研究者もいる。これもバイアスにつながる。厳密に言えば、研究は発表されているのに、その (好ましくない) 結果は報告されていないため、メタ分析ではまだ見落とされていることになる。アウトカムバイアス (Outcome reporting bias): 多くの研究、特に臨床試験では、関心のあるアウトカムを複数測定する。これを悪用して、肯定的な結果が得られたアウトカムだけを報告し、仮説を確認できなかったアウトカムは削除する研究者もいる。これもバイアスにつながる。厳密に言えば、研究は発表されているのに、その (好ましくない) 結果は報告されていないため、メタ分析ではまだ見落とされていることになる。非報告バイアスは、既存のエビデンスを見つけにくくするシステム的な要因として捉えることができる。しかし、たとえ関連する知見をすべて含めることができたとしても、この結果には欠陥があるだろう。また、研究者が知見を分析・報告する際に適用した疑問のある研究手法 (questionable research practices, QRP) により、バイアスが存在する可能性もある (Simonsohn, Simmons, Nelson 2020)。「研究者の自由度」という概念については、以前すでに触れた (Chapter 1.3)。QRP は、研究者がこの自由度を乱用して、結果を望ましい方向に「曲げる」行為と定義することができる。残念ながら、何が QRP を構成するのかについて明確なコンセンサスはない。しかし、一般的に提案されているいくつかの例がある。最も顕著な QRP のひとつが p-hacking で、従来の有意水準である \\(p<\\) 0.05 に達するまで分析を微調整するものである。これには、外れ値の除去、サブグループの分析、欠損データの処理などが含まれる。別の QRP は HARKing (Kerr 1998) といって、結果が判明した後に仮説を立てることである。HARKing の一つは、探索的分析における発見が、研究の priori な仮説であったかのように装うことである。例えば、研究者が、データセットに対して様々なテストを実行し、有意であったすべてのテストについて仮説を「発明」することがある。これは重大な欠陥のあるアプローチで、研究の偽発見率を高め、偽の発見のリスクを増加させる (など、問題は他にもある)。もう一つのタイプの HARKing は、データによってサポートされなかったすべての仮説を取り下げることであり、これは最終的にアウトカム報告バイアスにつながる可能性がある。","code":""},{"path":"pub-bias.html","id":"addressing-pubbias","chapter":"9 出版バイアス","heading":"9.2 メタ分析における出版バイアス","text":"出版バイアス、報告バイアス、QRP がメタ分析の妥当性に強く有害な影響を与えることは明らかである。バイアスの正確な大きさ、あるいはバイアスが存在するかどうかを知ることは、通常、事実上不可能であるため、これらは大きな課題となっている。\nメタ分析では、QRP と同様に、出版・報告バイアスによる歪みのリスクをある程度軽減する手法を適用することが可能である。そのアプローチには、研究探索に関連するものもあれば、統計的な手法もある。研究検索: Chapter 1.4.3 で、適格な研究を検索するプロセスについて説明してきた。出版バイアスが存在する場合、このステップは非常に重要である。なぜなら、出版された文献を検索しても、すべてのエビデンスを完全に代表していないデータが得られる可能性があることを意味する。学位論文、プレプリント、政府報告書、会議録などを含む灰色文献も検索することで、これに対抗することが可能である。幸いなことに、事前登録も多くの分野で一般的になってきている。これにより、ICTRP や OSF Registries などの研究登録 ( Chapter 1.4.3 の Table 1.1 を参照) を検索して、未発表データのある研究を探し、著者に (まだ) 公開されていないデータを提供してもらえるか尋ねることが可能である34。灰色文献検索は退屈で嫌になるだろうが、努力する価値はある。灰色文献や未発表の文献を含めることで真の効果の過大評価を避けることができることは、大規模な研究でわかっている (McAuley et al. 2000)。研究検索: Chapter 1.4.3 で、適格な研究を検索するプロセスについて説明してきた。出版バイアスが存在する場合、このステップは非常に重要である。なぜなら、出版された文献を検索しても、すべてのエビデンスを完全に代表していないデータが得られる可能性があることを意味する。学位論文、プレプリント、政府報告書、会議録などを含む灰色文献も検索することで、これに対抗することが可能である。幸いなことに、事前登録も多くの分野で一般的になってきている。これにより、ICTRP や OSF Registries などの研究登録 ( Chapter 1.4.3 の Table 1.1 を参照) を検索して、未発表データのある研究を探し、著者に (まだ) 公開されていないデータを提供してもらえるか尋ねることが可能である34。灰色文献検索は退屈で嫌になるだろうが、努力する価値はある。灰色文献や未発表の文献を含めることで真の効果の過大評価を避けることができることは、大規模な研究でわかっている (McAuley et al. 2000)。統計的手法: 統計的手法によって出版物の有無を調べることも可能である。これらの方法はいずれも出版バイアスを直接同定することはできないが、それを示すと思われるデータのある種の特性を調べることが可能である。また、出版バイアスを補正した場合の真の全体効果を定量化するために使用できる手法もある。統計的手法: 統計的手法によって出版物の有無を調べることも可能である。これらの方法はいずれも出版バイアスを直接同定することはできないが、それを示すと思われるデータのある種の特性を調べることが可能である。また、出版バイアスを補正した場合の真の全体効果を定量化するために使用できる手法もある。本章では、出版バイアスを評価・制御するための一般的な統計的手法を紹介する。まず、小規模研究効果に着目した方法から始める (Sterne, Gavaghan, Egger 2000; Schwarzer, Carpenter, Rücker 2015, chap. 5; Rothstein, Sutton, Borenstein 2005, chap. 5)。このアプローチに共通するのは、研究の精度と観察された効果量の関係を見ることで、出版バイアスの指標を見つけるという点である。","code":""},{"path":"pub-bias.html","id":"small-study-effects","chapter":"9 出版バイアス","heading":"9.2.1 小規模研究効果測定法","text":"メタ分析における出版バイアスを評価・補正する方法として、様々な小規模研究効果法がある。その多くは、長年にわたり従来からある手法である。名前にあるように、これらの手法は特に小規模研究に関係している。統計学的な観点からは、これは標準誤差が大きい研究に相当する。小規模研究効果法は、小規模な研究は出版バイアスの餌食になりやすいと仮定している。この前提は、3つの核となる考えに基づいている (Borenstein et al. 2011、第30章参照)。大規模な研究は、多くの資源と時間を投入するため、結果が有意であろうとなかろうと、出版される可能性が高い。大規模な研究は、多くの資源と時間を投入するため、結果が有意であろうとなかろうと、出版される可能性が高い。中程度の規模の研究は、発表されないリスクが高くなる。しかし、統計的検出力が中程度であっても、有意な結果を得るには十分であることが多い。つまり、「好ましくない」 (つまり有意でない) 結果を出したために、出版されない研究もあるということである。中程度の規模の研究は、発表されないリスクが高くなる。しかし、統計的検出力が中程度であっても、有意な結果を得るには十分であることが多い。つまり、「好ましくない」 (つまり有意でない) 結果を出したために、出版されない研究もあるということである。小規模な研究は、発見が有意でないリスクが最も高く、そのため「ファイルの引き出し」に入ったままとなる。小規模な研究では、非常に大きな効果だけが有意となる。つまり、非常に大きな効果量を持つ小規模な研究のみが発表されることになる。小規模な研究は、発見が有意でないリスクが最も高く、そのため「ファイルの引き出し」に入ったままとなる。小規模な研究では、非常に大きな効果だけが有意となる。つまり、非常に大きな効果量を持つ小規模な研究のみが発表されることになる。これらの仮定の背後にあるとされるメカニズムは、非常に単純であることがわかる。本質的には、有意な効果のみが公表されるため、出版バイアスが存在するということである。サンプルサイズが大きいほど有意な結果が得られる確率が高くなるので、出版バイアスは小規模な研究であるほど均等ではない影響がある。","code":""},{"path":"pub-bias.html","id":"funnel-plot","chapter":"9 出版バイアス","heading":"9.2.1.1 ファネルプロット","text":"このガイドの前半 (Chapter 3.1) で、研究のサンプルサイズと標準誤差が密接に関係していることを学んだ。効果量の標準誤差が大きいと、信頼区間が広くなり、効果が統計的に有意でない可能性が高くなる。したがって、小さな研究の効果は、大きな標準誤差を持つ研究に大きく影響すると仮定するのは賢明なことである。収集したデータが出版バイアスによって負担されたと仮定する。この場合、大きな標準誤差を持つ研究は、低い標準誤差を持つ研究よりも効果量が大きいと仮定することが可能である。これは、効果の小さい研究は有意でなく、出版の検討すらされなかった。結果として、メタ分析に含めるられることもない。小規模研究の効果を調べるには、ファネルプロットが一般的である。ファンネルプロットは、x軸に観察された効果量を、y軸に標準誤差の指標をとってプロットしたものである。通常、ファンネルプロットのy軸は反転している (y軸上の「高い」値は、標準誤差が低いことを表している)。出版バイアスがない場合、このようなプロットのデータポイントは、ほぼ対称的な逆さファンネル (漏斗のこと) を形成するはずである。これがファンネルプロットと呼ばれる所以である。プロットの上部にある研究 (標準誤差が小さいもの) は、密接に並んでおり、プール効果量からそれほど離れていないはずである。プロットの下部では、標準誤差が大きくなるにつれて、漏斗が「開き」、効果量がプール効果量の左右に大きく散らばることが予想される。Chapter 3.1 で効果量について学んだことや、Chapter 4.1.1 (Figure 4.1) で固定効果モデルについて議論したことを思い出すと、なぜ研究が漏斗を形成する必要があるのかがわかりやすくなる。標準誤差は、研究の精度を示している: 標準誤差が小さくなればなるほど、観察された効果量は、真の効果量の良い推定量になると予想される。標準誤差が大きい場合、効果量は精度が低く、したがって母集団における実際の効果から大きく外れている可能性が高くなる。では、ファネルプロットを作成し、より具体的にしていこう。メタ分析オブジェクトのファネルプロットを表示すには、 {meta} パッケージの funnel.meta 関数を使用することが可能である。ここでは、メタ分析オブジェクト m.gen に対してファネルプロットを生成する。さらに2つの引数、 xlim と studlab を指定する。最初の引数はプロットにおけるX軸の限界をコントロールし、後者は研究ラベルを含めるようにこの関数に指示する。funnel を実行した後に title 関数を呼び出すと、プロットにタイトルが追加される。コードは次のようになる。すでに説明したように、得られたファネルプロットは、x軸に各研究の効果量 (標準化平均差として表現)、y軸に標準誤差 (大から小へ) を示している。解釈を容易にするため、このプロットには、研究が従うと思われる理想的なファネルの形も含まれている。ファンネルの真ん中の縦線は、平均効果量を示している。m.gen を生成する際にランダム効果モデルを使用したので、ファネルプロットもランダム効果推定値を使用している。少人数研究の影響がなければ、プロットに表示される漏斗で描かれる形状に沿うはずである。この例では、そうなっているだろうか？そうではない。標準誤差が小さい研究ほど、推定された真の効果の周りに集中していることがわかるが、パターンは全体的に非対称に見える。これは、プロットの右下に非常に高い効果量を持つ3つの小さな研究 (Shapiro、Kang、Danitz-Orsillo によるもの) があるためである。しかし、これらの研究には、プロットの左下隅に相当するものがない。非常に高い効果を持つ研究と「均等になる」ような、非常に低い効果量や負の効果量を持つ小規模な研究は存在しないのである。もう一つ気になるのは、サンプルの中で最も精度の高い、de Vibe による研究が、漏斗パターンにうまく従っていないように見えることである。この効果量は、予想よりもかなり小さい。全体として、このデータセットは、出版バイアスを示しそうな非対称のパターンをファネルプロットに示している。3つの小さな研究は、運良く有意になるのに十分な効果を見出したものであり、一方、同様の標準誤差を持ちながら、小さい方、つまり有意でない効果を持つ未発表の研究が存在しても、成功には至らなかったのだろう。非対称パターンと統計的有意性の関係を調べるには、等高線ファンネルプロット (contour-enhanced funnel plot) (Peters et al. 2008) を作成するのが良い方法である (訳注: 「等高線ファンネルプロット」は、「輪郭強調ファンネルプロット」と訳されることもある。)。等高線ファンネルプロットは、出版バイアスと他の非対称性を区別するのに役立つように、プロット内の各研究の有意水準を示す色を含んでいる。funnel.meta 関数では、contour 引数に希望の有意閾値を与えることで等高線を追加することが可能である。通常は、0.9, 0.95, 0.99で、それぞれ \\(p\\) < 0.1, 0.05, 0.01 に相当する。また、 col.contour 引数を使用すると、輪郭の色を指定することが可能である。最後に、プロットに凡例を追加するために、 legend 関数を使用することができ、異なる色の意味を指定することができる。x と y 引数を使用してプロット上に凡例を配置し、 legend でラベルを指定し、 fill 引数を使用して塗りつぶしの色を追加することが可能である。この結果、以下のようなコードになる。ファネルプロットは、3つの陰影領域を含んでいることがわかる。 \\(p<\\) 0.05 と \\(p<\\) 0.01 の領域に特に興味がある。なぜなら、この領域に入る効果量は、伝統的に有意とみなされている。等高線領域を追加すると、3つの小さな研究は、大きな標準誤差があるにもかかわらず、すべて有意な効果を示していることがわかる。同じような標準誤差を持つ研究で、有意でないものが1つだけある。対称性を高めるためにプロットの左下隅にある欠落した研究を「インプット」すると、これらの研究はプロットの非有意領域に位置することになる。大規模な研究については、少しパターンが異なるようである。 \\(p>\\) 0.05 の研究がいくつかあり、効果の分布はあまり偏っていないことがわかる。しかし問題なのは、厳密には有意ではないものの、1つの研究を除くすべての研究が有意性閾値に非常に近い (すなわち、0.1 \\(> p >\\) 0.05 の領域にある) ことである。これらの研究は、元の論文では単に効果量の計算が違っていて、それが有意な結果につながった可能性がある。あるいは、傾向レベルで有意な効果を見出すことが、すでに研究を発表するのに十分な説得力を持っていたのだろう。まとめると、等高線ファンネルプロットによる検証では、非対称性があるのではないか、それは出版バイアスによって引き起こされたのではないかという当初の直感を裏づけるものであった。しかし、結論を急がず、ファンネルプロットを慎重に解釈することが大事である。出版バイアスは、ファネルプロットの非対称性の原因として考えられる多くの理由のうちの1つに過ぎないことを念頭に置かなければならない。\nファネルプロットの非対称性とは\n\n出版バイアスは非対称のファネルプロットにつながるが、同様のパターンを生み出す他の、むしろ「良性」の原因もある\n(Page et al. 2020) 。\n\n非対称性は、研究間の異質性によって引き起こされることもある。ファネルプロットは、効果量の分散が研究のサンプリング誤差によって引き起こされると仮定しているが、研究が異なる真の効果の推定者である可能性を制御することはできない。\n\n小規模な研究では、研究の手順が異なり、その結果、効果が高くなった可能性がある。例えば、臨床研究では、サンプルサイズが小さいと、すべての参加者が意図したとおりに治療を受けていることを確認するのが容易である。大規模な研究ではそうではないため、治療忠実度\n(treatment fidelity)\nが低くなり、その結果、効果も低くなる可能性がある。このような代替説明が妥当かどうかを評価するために、対象研究の特徴を検証することは意味がある。\n\n質の低い研究では、バイアスリスクが高いため、効果量が大きくなる傾向があることは一般的に知られている。大規模な研究はより多くの投資を必要とするため、方法論もより厳密なものになる可能性がある。よって、出版バイアスがない場合でも、ファネルプロットの非対称性につながる可能性がある。\n\n最後に、ファネルプロットの非対称性は、単に偶然に起こる可能性も十分にある。\n(等高線) ファンネルプロットを視覚的に検証して、結果が出版バイアスの影響を受けている可能性を示すいくつかの「レッドフラッグ」が投げ出されたことを確認した。しかし、ファネルプロットをはっきり見ただけで解釈することにも限界がある。結果が「非対称すぎる」場合の明確なルールはなく、ファネルプロットからの推論は常に主観的である。したがって、定量的な方法でファネルプロットの非対称性の存在を評価することが有用である。これは通常、次に説明する Egger の回帰検定によって達成される。","code":"\n# 'meta' パッケージをロード\nlibrary(meta)\n\n# ファンネルプロットを作成\nfunnel.meta(m.gen,\n            xlim = c(-0.5, 2),\n            studlab = TRUE)\n\n# タイトルを追加\ntitle(\"Funnel Plot (Third Wave Psychotherapies)\")\n# 等高線の塗りつぶし色を定義\ncol.contour = c(\"gray75\", \"gray85\", \"gray95\")\n\n# ファンネルプロットを生成 (研究ラベルはなし)\nfunnel.meta(m.gen, xlim = c(-0.5, 2),\n            contour = c(0.9, 0.95, 0.99),\n            col.contour = col.contour)\n\n# 凡例を追加\nlegend(x = 1.6, y = 0.01, \n       legend = c(\"p < 0.1\", \"p < 0.05\", \"p < 0.01\"),\n       fill = col.contour)\n\n# タイトルを追加\ntitle(\"Contour-Enhanced Funnel Plot (Third Wave Psychotherapies)\")"},{"path":"pub-bias.html","id":"eggers-test","chapter":"9 出版バイアス","heading":"9.2.1.2 Egger の回帰検定","text":"Egger の回帰検定 (Egger et al. 1997) は、ファネルプロットの非対称性を検定する定量的手法としてよく利用されている。ファネルプロットの目視検証と同様に、小規模研究の効果を識別するだけで、出版バイアスが存在するかどうかを直接教えてくれるわけではない。この検定は、単純な線形回帰モデルに基づいており、その式は次のようになる。\\[\\begin{equation}\n\\frac{\\hat\\theta_k}{SE_{\\hat\\theta_k}} = \\beta_0 + \\beta_1 \\frac{1}{SE_{\\hat\\theta_k}}\n\\tag{9.1}\n\\end{equation}\\]この式における応答変数 \\(y\\) は、メタ分析で観測された効果量 \\(\\hat\\theta_k\\) を、標準誤差で割ったものである。結果の値は、\\(z\\) -スコアと同等である。これらのスコアは、効果量が有意であるかどうかを直接教えてくれる。 \\(z \\geq\\) 1.96 または \\(\\leq\\) -1.96 のとき、その効果は有意であることがわかる ( \\(p<\\) 0.05)。この応答変数は、研究の標準誤差の逆数に回帰され、それは研究の精度に相当する。しかし、Egger の検定を用いる場合、回帰重み \\(\\beta_1\\) の大きさや有意性にではなく、切片 \\(\\beta_0\\) に関心がある。ファネルの非対称性を評価するためには、\\(\\hat\\beta_0\\) のサイズを検査し、それがゼロから有意に異なるかどうかを調べる。この場合、Egger の検定は、ファネルプロットの非対称性を示す。回帰切片の大きさが、なぜファネルプロットの非対称性について何かを伝えるのかを理解するために、少し時間をとろう。すべての線形回帰モデルにおいて、切片は他のすべての予測変数がゼロのときの \\(y\\) の値を表している。モデルの予測変数は研究の精度なので、切片は精度がゼロの時 (すなわち、研究の標準誤差が無限に大きい時) に期待される \\(z\\) -スコアを示す。出版バイアスがない場合、期待される \\(z\\) -スコアはゼロ付近に散らばるはずである。これは、標準誤差が極端に大きい研究は信頼区間も極端に大きくなり、\\(|z| \\geq\\) 1.96という値になることはほぼ不可能である。しかし、出版バイアスの影響などでファンネルプロットが非対称になると、効果量が非常に大きい小規模な研究がかなり多くなり、\\(z\\) 値が 1.96 以上の値を持つ精度の低い研究が驚くほど多くなることが予想される。この歪みにより、精度がゼロの時の \\(y\\) の予測値はゼロより大きくなり、結果として有意な切片となる。以下のプロットは、Egger の検定の基礎となる回帰の勾配と切片に対するファネルプロットの非対称性の影響を示している。このような回帰モデルを m.gen のデータに当てはめると、どのような結果が得られるか見てみよう。 R を使って、 m.gen の元データを取り出し、応答変数 y と予測変数 x を計算することが可能である。以下のコードでは、パイプ( Chapter 2.5.3 )と {tidyverse} の一部である mutate 関数を使用してこれを行う。その後、linear model function lm を使って、\\(z\\) のスコア y を精度 x に回帰している。パイプの最後の部分では、結果の summary を要求している。結果、この回帰モデルの切片は、\\(\\hat\\beta_0\\) = 4.11であることがわかる。これはゼロより有意に大きく ( \\(t\\) = 4.677, \\(p<\\) 0.001)、ファネルプロットのデータが実際に非対称であることを示している。全体として、これは小規模研究の効果があるという最初の発見を裏づけるものである。しかし、繰り返しになるが、このパターンが出版バイアスに起因しているかどうかは不明である。Egger の切片検定を行うより便利な方法は、 {meta} にある metabias 関数を使用することである。この関数はメタ分析オブジェクトを入力として必要とし、 method.bias 引数を \"linreg\" に設定する必要がある。この関数を m.gen に適用すると、以前と同じ結果が得られる。Egger 検定の結果を報告Egger の検定では、通常、切片の値、その95%信頼区間、\\(t\\) 値と \\(p\\) 値を報告すれば十分である。{dmetar}パッケージでは、eggers.test という便利な関数が含まれている。この関数は metabias のラッパーであり、Eggerの検定の結果をレポートに適した形式で提供する。{dmetar} がインストールされていない場合は、この関数のソースコード online を参照。以下はその例である。eggers.test(m.gen)m.gen で使われている効果量の指標は、スモールサンプルバイアス補正 SMD (Hedges’ \\(g\\) ) である。SMD で Egger 検定を実行すると、偽陽性の結果が膨らむ可能性があると議論されている (J. E. Pustejovsky Rodgers 2019)。これは、研究の標準化平均差と標準誤差が独立していないためである。このことは、群間 SMD の標準誤差を計算するための式 (式3.18、Chapter 3.3.1.2 ) を見れば簡単にわかる。この式は SMD そのものを含んでおり、観察された効果の値が小さくても大きくても研究の標準誤差が変化することを意味している (つまり、SMD とその標準誤差の間には人為的な相関がある)。Pustejovsky Rodgers (2019) は、標準化平均差のファネルプロットの非対称性を検定する際に、標準誤差の修正版を使用することを提案している。標準誤差の式の最初の部分だけが使用され、観察された効果量が式から脱落することを意味している。したがって、式は次のようになる。\\[\\begin{equation}\nSE^*_{\\text{SMD}_{\\text{}}}= \\sqrt{\\frac{n_1+n_2}{n_1n_2}}\n\\tag{9.2}\n\\end{equation}\\]ここで、\\(SE^*_{\\text{SMD}_{\\text{}}}\\) は標準誤差の修正版である。この修正版を使ったときに、Egger の検定が同じ結果を与えるかどうかを確認するのはよい考えだろう。次のコードでは、最初のデータセットに各研究の各群のサンプルサイズを追加し、適合された標準誤差を計算し、それを使って分析を再実行する。正確な数値は異なるものの、結果の解釈は同じであることがわかる。このことは、以前発見したことが確からしいことを示している。metabias で直接 Pustejovsky-Rodgers 法を使う最新の {meta} では、 metabias 関数に、Pustejovsky Rodgers によって提案された補正標準誤差の式で Egger の検定を行うオプションも用意されている。このオプションは method.bias を \"Pustejovsky\" に設定することで使用でる。ただし、これは {meta} メタ分析オブジェクトが、実験グループとコントロールグループのサンプルサイズをそれぞれ n.e と n.c という要素で既に含んでいる場合にのみ可能である。metagen オブジェクトを使用する場合 (上記の例のように)、通常はこのようなことはないため、手動で追加する必要がある。例として、再び m.gen メタ分析オブジェクトを使用してみよう。m.gen$n.e = n1; m.gen$n.c = n2metabias(m.gen, method.bias = \"Pustejovsky\")なお、この設定では、metabias は Egger の検定を行うために式 (9.5) を使用するが、これは先に示した式 (9.1) と等価である。主な違いは、metabias がモデルの予測因子として補正標準誤差を用い、重みとして含まれる効果量の逆分散を用いる点である。しかし、今回の例では、式 (9.1) の両辺に補正された標準誤差を使用している。つまり、上記のようなアプローチと method.bias を \"Pustejovsky\" に設定した場合の結果は完全に一致するわけではない。","code":"\n# パッケージをロード\nlibrary(tidyverse)\n\nm.gen$data %>% \n  mutate(y = TE/seTE, x = 1/seTE) %>% \n  lm(y ~ x, data = .) %>% \n  summary()## [...]\n## \n## Coefficients:\n##             Estimate Std. Error t value Pr(>|t|)    \n## (Intercept)   4.1111     0.8790   4.677 0.000252 ***\n## x            -0.3407     0.1837  -1.855 0.082140 .  \n## ---\n## Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n## \n## [...]\nmetabias(m.gen, method.bias = \"linreg\")## Review:     Third Wave Psychotherapies\n## \n## Linear regression test of funnel plot asymmetry\n## \n## Test result: t = 4.68, df = 16, p-value = 0.0003\n## \n## Sample estimates:\n##    bias se.bias intercept se.intercept\n##  4.1111  0.8790   -0.3407       0.1837\n## \n## Details:\n## - multiplicative residual heterogeneity variance (tau^2 = 1.2014)\n## - predictor: standard error\n## - weight:    inverse variance\n## - reference: Egger et al. (1997), BMJ\n# 実験群 (n1) と対照群 (n2) のサンプルサイズを追加\nn1 <- c(62, 72, 44, 135, 103, 71, 69, 68, 95, \n        43, 79, 61, 62, 60, 43, 42, 64, 63)\n\nn2 <- c(51, 78, 41, 115, 100, 79, 62, 72, 80, \n        44, 72, 67, 59, 54, 41, 51, 66, 55)\n\n# 修正標準誤差を表示\nThirdWave$seTE_c <- sqrt((n1+n2)/(n1*n2))\n\n# 修正標準誤差で 'metagen' を再実行し、メタ分析オブジェクトを取得\nm.gen.c <- metagen(TE = TE, seTE = seTE_c,\n                   studlab = Author, data = ThirdWave, sm = \"SMD\", \n                   fixed = FALSE, random = TRUE, \n                   method.tau = \"REML\", hakn = TRUE, \n                   title = \"Third Wave Psychotherapies\")\n\n# Egger 検定\nmetabias(m.gen.c, method = \"linreg\")## Review:     Third Wave Psychotherapies\n## \n## Linear regression test of funnel plot asymmetry\n## \n## Test result: t = 4.36, df = 16, p-value = 0.0005\n## \n## Sample estimates:\n##     bias se.bias intercept se.intercept\n##  11.1903  2.5667   -1.3535       0.4432\n## \n## Details:\n## - multiplicative residual heterogeneity variance (tau^2 = 2.5334)\n## - predictor: standard error\n## - weight:    inverse variance\n## - reference: Egger et al. (1997), BMJ"},{"path":"pub-bias.html","id":"peters-test","chapter":"9 出版バイアス","heading":"9.2.1.3 Peters の回帰検定","text":"効果量と標準誤差の依存性は、標準化された平均差にのみ適用されるわけではない。この数学的な関連性は、(対数) オッズ比 (Chapter 3.3.2.2) やリスク比 (Chapter 3.3.2.1) などの二値アウトカムデータまたは割合 (Chapter 3.2.2) に基づく効果量にも存在する。二値効果量データを使用したときの偽陽性のリスクの増大を避けるために、Peters ら (Peters et al. 2006) が提案した別のタイプの回帰検定を使用することが可能である。Peters の検定の結果を得るために、対数変換された効果量をサンプルサイズの逆数に回帰させる。\\[\\begin{equation}\n\\log\\psi_k =  \\beta_0 + \\beta_1\\frac{1}{n_k}\n\\tag{9.3}\n\\end{equation}\\]この式において、\\(\\log\\psi_k\\) は二値アウトカムデータに基づく任意の対数変換効果量 (例えば、オッズ比) を表し、\\(n_k\\) は研究 \\(k\\) の総サンプルサイズである。重要なことは、回帰モデルを当てはめるとき、各研究 \\(k\\) には、そのサンプルサイズとイベントカウントに応じて、異なる重み \\(w_k\\) が付けられることである。この結果、重み付け線形回帰となり、メタ回帰モデル (Chapter 8.1.3) と似ている (同一ではない)。重みの式 \\(w_k\\) は次のようなものである。\\[\\begin{equation}\nw_k = \\frac{1}{\\left(\\dfrac{1}{a_k+c_k}+\\dfrac{1}{b_k+d_k}\\right)}\n\\tag{9.4}\n\\end{equation}\\]ここで、\\(a_k\\) は治療群でのイベント数、\\(c_k\\) は対照群でのイベント数である。 \\(b_k\\) と \\(d_k\\) はそれぞれ治療群と対照群での非イベントの数である ( Chapter 3.3.2.1 を参照)。Egger の回帰検定とは対照的に、Peters の検定は、切片の代わりに \\(\\beta_1\\) を使って、ファネルプロットの非対称性を検定した。統計的検定が \\(\\beta_1 \\neq 0\\) を明らかにするとき、データに非対称性が存在すると仮定することが可能である。metabin (Chapter 4.2.3.1) または metaprop (Chapter 4.2.6) 関数を用いて二値アウトカムに基づくメタ分析を計算した場合、 metabias 関数を用いて Peters 検定 を実施することが可能である。適合するメタ分析オブジェクトを用意し、 method.bias の引数に \"peters\" を指定するだけでよい。Chapter 4.2.3.1 で作成した m.bin オブジェクトで、ファネルプロットの非対称性を確認してみよう。覚えているだろうが、このメタ分析ではリスク比を要約の指標として使った。出力の構造は、Egger の検定と同じであることがわかる。出力は、結果が サンプルサイズに基づく回帰検定のものであることを示し、Peters の方法が使用されたことを意味した。検定は有意ではなく (\\(t\\) = -0.08, \\(p\\) = 0.94)、ファンネルプロットは非対称ではないことを示している。\nファネルプロット非対称性検定の統計的検出力\n\nメタ分析に十分な数の研究が含まれている場合のみ、ファネルプロットの非対称性を検定することが推奨される。研究数が少ない場合、Egger\nの検定や Peters\nの検定の統計的検出力が、実際の非対称性を検出するのに十分でないことがある。一般に、\\(K \\geq 10\\)\nのときだけ検定を行うことが推奨されている (Sterne et al. 2011) 。\n\nデフォルトでは、メタアナリシスの研究数がこれより少ないと\nmetabias はエラーを出す。しかし、関数内の\nk.min\n引数をより小さい数字に設定することで、これを防ぐことができる\n(推奨はしない)。\n","code":"\nmetabias(m.bin, method.bias = \"peters\")## Review:     Depression and Mortality\n## \n## Linear regression test of funnel plot asymmetry\n## \n## Test result: t = -0.08, df = 16, p-value = 0.9368\n## \n## Sample estimates:\n##      bias  se.bias intercept se.intercept\n##  -11.1728 138.6121    0.5731       0.1076\n## \n## Details:\n## - multiplicative residual heterogeneity variance (tau^2 = 40.2747)\n## - predictor: inverse of total sample size\n## - weight:    inverse variance of average event probability\n## - reference: Peters et al. (2006), JAMA"},{"path":"pub-bias.html","id":"duval-and-tweedie","chapter":"9 出版バイアス","heading":"9.2.1.4 Duval & Tweedie トリム＆フィル方式","text":"メタ分析において、小規模研究の効果を調べる (そして検定する) 方法をいくつか学んだ。データに出版バイアスが存在する可能性があることを知ることは良いことであるが、主に関心を持っているのは、そのバイアスの大きさである。出版バイアスが推定値をわずかに歪めただけなのか、それとも知見の解釈を変えるほど大規模なものなのかを知りたい。つまり、真の効果量のバイアス補正推定値を算出する方法が必要なのである。しかし、出版バイアスを直接測定することができないことをすでに学んだ。出版バイアスを指摘する可能性のある代理として、小規模研究の効果を使うことしかできない。したがって、出版バイアスそのものではなく、補正された効果推定値を得るために小規模研究の影響を補正することができるだけである。効果量の非対称性が実際に出版バイアスによって引き起こされた場合、この不均衡を補正することで、すべてのエビデンスを考慮したときに真の効果をよりよく表す推定値が得られる。ファネルプロットの非対称性を調整する最も一般的な方法の1つが、Duval & Tweedie トリム＆フィル法 (Duval Tweedie 2000) である。この方法の背後にある考え方は単純で、ファネルプロットが対称になるまで「欠損」効果を埋め込むというものである。そして、得られた「拡張」データセットのプール効果量は、小規模研究の効果を補正する際の推定値を表した。これは、効果の「トリム」 (trim) と「フィル」 (fill) を含む簡単なアルゴリズムによって達成される (Schwarzer, Carpenter, Rücker 2015、5.3.1章)。トリム. まず、このメソッドはファネルプロット内のすべての外れ値研究を識別する。先ほどの例では、これらはプロットの右側に散在しているすべての小規模な研究である。いったん識別されると、これらの研究は トリム、つまり分析から取り除かれ、プールされた効果は、これを除いて再計算される。このステップは、通常、固定効果モデルを使用して実行される。トリム. まず、このメソッドはファネルプロット内のすべての外れ値研究を識別する。先ほどの例では、これらはプロットの右側に散在しているすべての小規模な研究である。いったん識別されると、これらの研究は トリム、つまり分析から取り除かれ、プールされた効果は、これを除いて再計算される。このステップは、通常、固定効果モデルを使用して実行される。フィル. 次のステップでは、再計算されたプール効果が、すべての効果量の中心と仮定される。トリムされた各研究について、漏斗の反対側でその結果を反映するように、1つの効果量が追加される。たとえば、再計算された平均効果が0.5で、トリムされた研究の効果が0.8であれば、ミラーされた研究は0.2の効果を与えられる。これをすべてのトリムされた研究で行うと、ファネルプロットはほぼ対称的に見える。トリムされた効果量と帰属された効果量を含むすべてのデータに基づいて、平均効果量が再計算される (通常、ランダム効果モデルを使用する)。その結果は、補正されたプール効果量の推定値として使用される。フィル. 次のステップでは、再計算されたプール効果が、すべての効果量の中心と仮定される。トリムされた各研究について、漏斗の反対側でその結果を反映するように、1つの効果量が追加される。たとえば、再計算された平均効果が0.5で、トリムされた研究の効果が0.8であれば、ミラーされた研究は0.2の効果を与えられる。これをすべてのトリムされた研究で行うと、ファネルプロットはほぼ対称的に見える。トリムされた効果量と帰属された効果量を含むすべてのデータに基づいて、平均効果量が再計算される (通常、ランダム効果モデルを使用する)。その結果は、補正されたプール効果量の推定値として使用される。トリム＆フィル法に関する重要な注意点は、研究間の異質性が大きい場合、信頼できる結果が得られないことである (Peters et al. 2007; Terrin et al. 2003; Simonsohn, Nelson, Simmons 2014b)。研究が1つの真の効果を共有していない場合、大規模な研究でも平均的な効果から大きく乖離している可能性がある。つまり、出版バイアスの影響を受けている可能性が低いにもかかわらず、そのような研究もトリムされて埋められることになる。これでは、無効な結果になることは容易に想像がつく。{meta} にある trimfill 関数を使用するとトリム＆フィルアルゴリズムをデータに適用することが可能である。この関数は非常にわかりやすいデフォルト値を持っているので、メタ分析オブジェクトと一緒に提供するだけで十分である。この例では、再び m.gen オブジェクトを使用する。しかし、その前に、まず、このメタ分析で観察された \\(^2\\) 異質性の量を確認してみよう。\\(^2\\) = 63%で、この分析における異質性はかなりのものであることがわかる。異質なデータセットにおけるトリム＆フィル法の限界を考慮すると、これは問題であることがわかる。そのため、2つのトリム＆フィル分析を行う。1つは全研究を対象とした分析で、もう1つは Chapter 5.4 (すなわち、研究3と16)。その結果を tf と tf..に保存する。まず、全研究を対象とした1つ目の分析を見てみよう。トリムとフィルの手順で、合計8件の研究が追加されたことがわかる。トリムとフィルの研究には、すでに検出した外れ値だけでなく、比較的高い効果を持つ他のいくつかの小さな研究も含まれている。移植された効果量はすべて非常に低く、大きくマイナスなものも複数あることがわかる。出力はまた、補正された効果の推定値を提供し、それは \\(g=\\) 0.34である。これはまだ有意であるが、最初に m.gen に対して計算した \\(g=\\) 0.58という効果よりはるかに低いものである。では、外れ値を取り除いた解析結果と比較してみよう。\\(g=\\) 0.34では、結果はほぼ同じである。全体として、トリム＆フィル法は、このメタ分析における \\(g=\\) 0.58 のプール効果は、小規模研究の効果により過大評価されていることを示している。実際には、効果はかなり小さいと思われる。この過大評価は出版バイアスに起因する可能性が高いが、確実ではない。他の説明も可能であり、このことはトリム＆フィル推定が無効である可能性がある。最後に、インプットされた研究を含むファネルプロットを作成することも可能である。funnel.meta 関数を trimfill の出力に適用するだけである。以下のコードでは、トリム＆フィルの両方の分析 (外れ値あり、なし) に対して、等高線ファネルプロットを作成している。par 関数を使用すると、両方のプロットを並べて表示すことが可能である。この二つのファネルプロットでは、インプットされた研究は塗りつぶしの色がない円で表されている。","code":"\nm.gen$I2## [1] 0.6263947\n# 全ての研究を使用\ntf <- trimfill(m.gen)\n\n# 外れ値を外して解析\ntf.no.out <- trimfill(update(m.gen, \n                             subset = -c(3, 16)))\nsummary(tf)## Review:     Third Wave Psychotherapies\n##                              SMD             95%-CI %W(random)\n## [...]\n## Filled: Warnecke et al.   0.0520 [-0.4360;  0.5401]        3.8\n## Filled: Song & Lindquist  0.0395 [-0.4048;  0.4837]        4.0\n## Filled: Frogeli et al.    0.0220 [-0.3621;  0.4062]        4.2\n## Filled: Call et al.      -0.0571 [-0.5683;  0.4541]        3.8\n## Filled: Gallego et al.   -0.0729 [-0.5132;  0.3675]        4.0\n## Filled: Kang et al.      -0.6230 [-1.2839;  0.0379]        3.3\n## Filled: Shapiro et al.   -0.8277 [-1.4456; -0.2098]        3.4\n## Filled: DanitzOrsillo    -1.1391 [-1.8164; -0.4618]        3.3\n## \n## Number of studies combined: k = 26 (with 8 added studies)\n## \n##                         SMD           95%-CI    t p-value\n## Random effects model 0.3428 [0.1015; 0.5841] 2.93  0.0072\n## \n## Quantifying heterogeneity:\n##  tau^2 = 0.2557 [0.1456; 0.6642]; tau = 0.5056 [0.3816; 0.8150];\n##  I^2 = 76.2% [65.4%; 83.7%]; H = 2.05 [1.70; 2.47]\n## \n## [...]\n## \n## Details on meta-analytical method:\n## - Inverse variance method\n## - Restricted maximum-likelihood estimator for tau^2\n## - Q-profile method for confidence interval of tau^2 and tau\n## - Hartung-Knapp adjustment for random effects model\n## - Trim-and-fill method to adjust for funnel plot asymmetry\nsummary(tf.no.out)## Review:     Third Wave Psychotherapies\n## [...]     \n## \n## Number of studies combined: k = 22 (with 6 added studies)\n## \n##                         SMD           95%-CI    t p-value\n## Random effects model 0.3391 [0.1904; 0.4878] 4.74  0.0001\n## \n## Quantifying heterogeneity:\n##  tau^2 = 0.0421 [0.0116; 0.2181]; tau = 0.2053 [0.1079; 0.4671];\n##  I^2 = 50.5% [19.1%; 69.7%]; H = 1.42 [1.11; 1.82]\n## [...]\n# 等高線の塗りつぶし色を定義\ncontour <- c(0.9, 0.95, 0.99)\ncol.contour <- c(\"gray75\", \"gray85\", \"gray95\")\nld <- c(\"p < 0.1\", \"p < 0.05\", \"p < 0.01\")\n\n# 'par' を使って１行に表示\npar(mfrow=c(1,2))\n\n# 等高線ファンネルプロット (全てのデータ) \nfunnel.meta(tf, \n            xlim = c(-1.5, 2), contour = contour,\n            col.contour = col.contour)\nlegend(x = 1.1, y = 0.01, \n       legend = ld, fill = col.contour)\ntitle(\"Funnel Plot (Trim & Fill Method)\")\n\n# 等高線ファンネルプロット (外れ値は除去) \nfunnel.meta(tf.no.out, \n            xlim = c(-1.5, 2), contour = contour,\n            col.contour = col.contour)\nlegend(x = 1.1, y = 0.01, \n       legend = ld, fill = col.contour)\ntitle(\"Funnel Plot (Trim & Fill Method) - Outliers Removed\")"},{"path":"pub-bias.html","id":"pet-peese","chapter":"9 出版バイアス","heading":"9.2.1.5 PET-PEESE","text":"\nDuval & Tweedieのトリム＆フィル法は比較的古く、間違いなく小規模研究の効果を調整する最も一般的な方法の1つである。しかし、前述したように完璧とは言い難いアプローチであり、プール効果のバイアス補正版を推定する唯一の方法というわけではない。近年、PET-PEESE (T. D. Stanley Doucouliagos 2014; T. D. Stanley 2008) という手法が、特に SMD がアウトカムとして頻繁に使われる研究分野 (例えば、心理学や教育研究) で、ますます人気が出てきている。これまでのすべての手法と同様に、PET-PEESE は、出版バイアスの潜在的な指標とみなされる小規模研究の効果に狙いを定めている。PET-PEESE は、実際には、精密効果検定 (precision-effect test, PET) と標準誤差付き精密効果推定 (precision-effect estimate standard error, PEESE) の2つの手法を組み合わせたものである。まず、前者から説明しよう。PET 法は、研究の効果量をその標準誤差に回帰させるという単純な回帰モデルに基づいている。\\[\\begin{equation}\n\\theta_k =  \\beta_0 + \\beta_1SE_{\\theta_k}\n\\tag{9.5}\n\\end{equation}\\]Peters の検定と同じように、重み付き回帰を使用する。研究の重み \\(w_k\\) は、分散の逆数として計算される–通常の (固定効果) メタ分析と同じである。\\[\\begin{equation}\nw_k = \\frac{1}{s_k^2}\n\\tag{9.6}\n\\end{equation}\\]注目すべきは、PET 法で使用される回帰モデルは、Egger の検定のものと同等であることである。主な違いは、PET 式では、\\(\\beta_1\\) 係数がファネルの非対称性を定量化し、Egger の検定では、これが切片によって示されることである。しかし、PET 法を用いる場合、\\(\\beta_1\\) で測定されるファネルの非対称性には関心がなく、切片 \\(\\beta_0\\) に関心がある。これは、上の式で、切片がいわゆる限界効果 (limit effect) を表していることがある。この限界効果は、標準誤差が0の研究の期待効果量である。これは、サンプル誤差なしに測定された観察された効果量に相当する。すべてが同じであれば、サンプリング・エラーなしで測定された効果量 \\(\\epsilon_k\\) は、真の全体的な効果そのものを表すことが分かっている。PET 法の背後にある考え方は、予測因子として標準誤差を含めることによって、小規模研究の効果を制御することである。理論的には、これは、すべての小規模研究の効果に対する補正後のメタ分析における真の効果を表す切片 \\(\\beta_0\\) につながるはずである。\\[\\begin{equation}\n\\hat\\theta_{\\text{PET}} = \\hat\\beta_{0_{\\mathrm{PET}}}\n\\tag{9.7}\n\\end{equation}\\]PEESE 法の式は、非常によく似ている。唯一の違いは、2乗 標準誤差を予測変数として使用することである (すなわち、効果量の分散 \\(s_k^2\\) )。\\[\\begin{equation}\n\\theta_k =  \\beta_0 + \\beta_1SE_{\\theta_k}^2\n\\tag{9.8}\n\\end{equation}\\]研究重みの計算式 \\(w_k\\) は変わらないが。標準誤差の二乗の背後にある考え方は、小規模の研究は、特に非常に過剰に推定された効果を報告しやすいということである。この問題は、高い統計的検出力を持つ研究では、それほど顕著にはならないことが推測される。PET 法は、\\(\\beta_0\\) が捉えた真の効果がゼロのときに最もよく機能するのに対し、PEESE は真の効果がゼロでないときによりよい性能を示す。Stanley Doucouliagos (2014) は、それぞれの長所をバランスさせるために、両方の方法を結合することを提案してきた。その結果生まれたアプローチがPET-PEESE 法である。PET-PEESE は、PET または PEESE の切片 \\(\\beta_0\\) を、補正された真の効果の推定値として使用する。PET と PEESE のどちらを使用するかは、PET 法で計算された切片のサイズに依存する。 \\(\\beta_{0_{\\text{PET}}}\\) が、\\(\\alpha\\) = 0.05 の片側検定で、ゼロより有意に大きい場合、PEESE の切片を真の効果量推定値として使用する。PET の切片が0より有意に大きくない場合、PET 推定値のままである。R で回帰モデルを実装する場合、ほとんどの場合、両側検定で係数の有意性を検定するのが通例である (つまり、\\(\\beta\\) の重みが0と有意に異なるかどうかを、方向に関係なく検定する)。 \\(\\alpha\\) = 0.05で片側検定を仮定すると、\\(p\\) < 0.1、および \\(\\beta_0\\) の推定値がゼロより大きいとき、すでに切片が有意であるとみなす35。したがって、PET-PEESE によって推定される真の効果量を求めるルールは次のようになる。\\[\\begin{equation}\n  \\hat\\theta_{\\text{PET-PEESE}}=\\begin{cases}\n    \\mathrm{P}(\\beta_{0_{\\text{PET}}} = 0) <0.1~\\mathrm{}~\\hat\\beta_{0_{\\text{PET}}} > 0: & \\hat\\beta_{0_{\\text{PEESE}}}\\\\\n    \\text{else}: & \\hat\\beta_{0_{\\text{PET}}}.\n  \\end{cases}\n  \\tag{9.9}\n\\end{equation}\\]この -else のロジックを理解するのはやや難しいが、実際の例で説明すると分かりやすいだろう。m.gen メタ分析オブジェクトを使用して、PET-PEESEの真の効果量の推定値を見てみよう。現在、 {meta} における PET-PEESE の素直な実装はないので、線形モデル関数 lm を使用して独自のコードを記述する。しかし、PET と PEESE モデルを適合させる前に、まず、データフレームに必要なすべての変数を準備する必要がある。このデータフレームを dat.petpeese と呼ぶ。最も重要な変数は、もちろん、標準化平均差である。最初に metacont または metagen を使用してメタ分析を実行しても、各研究の計算されたSMDは、常にメタ分析オブジェクトの TE の下に格納される。次に、効果量の標準誤差が必要である。PET-PEESE では、Pustejovsky Rodgers (2019, Chapter 9.2.1.2 を参照) が提案した修正標準誤差 を使用するとよい36。そこで、効果量そのものと相関がないように、修正標準誤差 seTE_c を算出するために適応された式を使用する。また、この変数を dat.petpeese に保存する。さらに、PEESEの予測因子として必要なので、2乗標準誤差を含む変数 seTE_c2 を追加する。最後に、各研究の逆分散重み付け w_k を計算する必要がある。ここで、分散の推定値を得るために、二乗修正標準誤差も使用する。これで、 dat.petpeese には、PET と PEESE の重み付き線形回帰モデルを適合させるために必要なすべての変数が含まれるようになった。次のコードでは、両方のモデルを適合し、summary 関数を使用して推定係数を直接表示する。以下が得られた結果である。PET と PEESE のどちらを使うべきかを判断するため、まず PET 法の結果を見る必要がある。限界推定値は、\\(g\\) = -1.35 であることがわかる。この効果は有意であるが (\\(p\\) < 0.10)、ゼロよりかなり小さいので、PET 推定値を使用すべきことがわかる。しかし、\\(g\\) = -1.35 では、バイアス補正効果の PET の推定値はあまり信頼できない。これは、現実には、研究対象の介入タイプは関心のあるアウトカムに対して非常に負の効果を持つ。つまり、実際には非常に有害であることを示す。これは非常に考えにくいことである。「善意の」介入に効果がないことはありうるが、本当に危険な介入を見つけることは非常にまれである。実は、この結果に見られるのは、PET-PEESE の一般的な限界である。観測された効果量はすべて正符号であるにもかかわらず、補正された効果量は大きく負になっている。出力の2番目の部分を見ると、PEESE についても同じことが言えるが、その推定値はわずかに負であることがわかる ( \\(g=\\) -0.44)。このような場合、切片を真の効果量の点推定値として解釈しないことが最善である。PET-PEESE は、スモールサンプル効果を補正した場合、研究中の介入タイプは効果なしであることを示すと簡単に言うことが可能である。これは基本的に、実際に推定された負の効果量を解釈するのではなく、\\(\\hat\\theta_{\\mathrm{PET-PEESE}}\\) をゼロに設定することを意味する。\nPET-PEESE の限界\n\nPET-PEESE\nは、系統的にプール効果量を過剰に修正するだけでなく、出版バイアスが全くない場合でも、真の効果を過大評価することがある。全体的に、PET-PEESE法は、含まれる研究の数が少ない場合\n(\\(K\\) <\n20)、あるいは研究間の異質性が非常に高い場合 (\\(^2\\) >\n80%)、悪いパフォーマンスを示すことが分かっている (T. D. Stanley 2017)。\n\n研究間の異質性が非常に高い残念ながら、研究数が少なく異質性の高いメタアナリシスはよく見られる。このため、PET-PEESE\nの適用範囲は限定されており、小規模研究の影響を調整する唯一の方法として使用することは勧められない。しかし、この方法が存在し、どのように適用できるかを知っておくことは、一部の研究分野でますます一般的になってきているため、良いことである。\nPET-PEESE で、lm の代わりに rma.uni を使うこの実践例では、PET-PEESE を実装するために、lm 関数と研究の重みを使用した。この方法は、頻繁に使用されているが、全く問題がないわけではない。lm によって実装された重み付き回帰モデルと、例えば rma.uni によって採用されたメタ回帰モデルとの間には、わずかだが決定的な違いがある。lm が乗法誤差モデルを使用するのに対し、メタ分析の関数は通常加法誤差モデルを使用する。この違いについての技術的な詳細はここでは触れない。このトピックについては、Wolfgang Viechtbauer が書いた素晴らしい vignette に詳しい情報が載っている。主なポイントは、サンプリング誤差分散に比例定数を仮定した lm モデルは、メタ分析データには完全に適していないことである。これは、少なくとも感度分析として、lm の代わりに rma.uni を使って PET-PEESE を実装することが示唆されている。現実的には、以下のように rma.uni にモデレータ変数として \\(SE_{\\theta_k}^{(2)}\\) を追加して実行することになる。rma.uni(TE, seTE^2, mods = ~seTE, data = dat, method = \"FE\").","code":"\n# Build data set, starting with the effect size\ndat.petpeese <- data.frame(TE = m.gen$TE)\n# 実験群ｎ (n1) と対照群 (n2) のサンプルサイズ\nn1 <- c(62, 72, 44, 135, 103, 71, 69, 68, 95, \n        43, 79, 61, 62, 60, 43, 42, 64, 63)\n\nn2 <- c(51, 78, 41, 115, 100, 79, 62, 72, 80, \n        44, 72, 67, 59, 54, 41, 51, 66, 55)\n\n# 修正標準誤差を計算\ndat.petpeese$seTE_c <- sqrt((n1+n2)/(n1*n2))\n\n# 修正標準誤差の二乗 (分散) を追加\ndat.petpeese$seTE_c2 <- dat.petpeese$seTE_c^2\ndat.petpeese$w_k <- 1/dat.petpeese$seTE_c^2\n# PET\npet <- lm(TE ~ seTE_c, weights = w_k, data = dat.petpeese)\nsummary(pet)$coefficients##              Estimate Std. Error   t value     Pr(>|t|)\n## (Intercept) -1.353476   0.443164 -3.054119 0.0075732464\n## seTE_c      11.190288   2.566719  4.359764 0.0004862409\n# PEESE\npeese <- lm(TE ~ seTE_c2, weights = w_k, data = dat.petpeese)\nsummary(peese)$coefficients##               Estimate Std. Error   t value     Pr(>|t|)\n## (Intercept) -0.4366495  0.2229352 -1.958639 0.0678222117\n## seTE_c2     33.3609862  7.1784369  4.647389 0.0002683009"},{"path":"pub-bias.html","id":"rucker-ma","chapter":"9 出版バイアス","heading":"9.2.1.6 Rücker の限界メタ分析法","text":"調整効果量の推定値を算出するもう一つの方法は、Rücker らが提案した限界メタ分析 (limit meta-analysis) を行うことである (2011) (訳注: limit meta-analysis は、日本語の訳語はないようである。)。この方法は、PET-PEESE よりも高度で、より複雑な計算を必要とする。そのため、ここではこの方法の背景にある一般的な考え方を理解することに重点を置き、その後の重い作業は R に任せることにする。Rücker の方法の背後にある考え方は、小規模研究の効果によるバイアスを明示的に考慮したメタ分析モデルを構築することである。(ランダム効果) メタ分析の式は、次のように定義可能である。\\[\\begin{equation}\n\\hat\\theta_k = \\mu + \\epsilon_k+\\zeta_k\n\\tag{9.10}\n\\end{equation}\\]ここで、\\(\\hat\\theta_k\\) は研究 \\(k\\) の観察された効果量、\\(\\mu\\) は真の全体効果量、\\(\\epsilon_k\\) はサンプル誤差、\\(\\zeta_k\\) は研究間異質性による偏差を定量化したものである。限界メタ分析では、このモデルを拡張し、小規模研究の効果がある場合、研究の効果量と標準誤差は独立していないという事実を考慮する。これは、出版バイアスが特に小規模な研究に影響すること、そして、小規模な研究は大規模な研究よりも大きな効果量を持つことを知っているために仮定されている。Rücker 法では、このバイアスは、新しい項 ( \\(\\theta_{\\text{Bias}}\\) ) をモデルに導入することによって追加される。これは、\\(\\theta_{\\text {Bias}}\\) が \\(\\epsilon_k\\) および \\(\\zeta_k\\) と相互作用すると仮定している。そして、\\(\\epsilon_k\\) が増加するにつれて、より大きくなる。適応された式は次のようになる。\\[\\begin{equation}\n\\hat\\theta_k = \\mu_* + \\theta_{\\text{Bias}}(\\epsilon_k+\\zeta_k)\n\\tag{9.11}\n\\end{equation}\\]この式では、\\(\\mu_*\\) はもはや全体的な真の効果量を表すのではなく、「標準的な」ランダム効果メタ分析では直接的に相当するものがないグローバル平均であることに注意することが重要である ( \\(\\theta_{\\text{Bias}} =\\) 0 以外の場合)。次のステップは、PET-PEESE (前章参照) の背後にある考え方に似ている。上の式を使って、研究の効果量の推定がだんだん正確になり、個々のサンプル誤差 \\(\\epsilon_k\\) がゼロに近づくと仮定する。これによって、最終的に \\(\\epsilon_k\\) が方程式から脱落する。\\[\\begin{equation}\n\\mathrm{E}(\\hat\\theta_k) \\rightarrow \\mu_{*} + \\theta_{\\text{Bias}}\\zeta_k ~ ~ ~ ~ \\text{} ~ ~ ~ ~ \\epsilon_k \\rightarrow 0.\n\\tag{9.12}\n\\end{equation}\\]この式では、 \\(\\epsilon_k\\) が 0 に近づくにつれて、\\(\\mathrm{E}(\\hat\\theta_k)\\) は \\(\\hat\\theta_k\\) の期待値を示す。ここで作った式は、「限界メタ分析」の一つであり、 大きな標準誤差を持つ研究の歪んだ影響を取り除いた、調整された効果の推定値を提供するものである。\\(\\zeta_k\\) は、通常群間異質性分散 \\(\\tau^2\\) (あるいはその平方根である標準偏差 \\(\\tau\\)) によって表されるので、これを使って式中の \\(\\zeta_k\\) を置き換えれば、この式となるわけである。\\[\\begin{equation}\n\\hat\\theta_{*} =  \\mu_* + \\theta_{\\mathrm{Bias}}\\tau\n\\tag{9.13}\n\\end{equation}\\]ここで、\\(\\hat\\theta_*\\) は、小規模研究の影響を調整した後のプールされた効果量の推定値を表している。Rücker の方法は、最尤法を用い、真の効果量の「縮約」推定値 \\(\\hat\\theta_*\\) などを使い、この式のパラメータを推定することが可能である。さらに、この式を用いて、個々の研究 \\(k\\) ごとに縮約効果量推定値 \\(\\hat\\theta_{{*}_k}\\) を得ることも可能である。\\[\\begin{equation}\n\\hat\\theta_{{*}_k} =  \\mu_* + \\sqrt{\\dfrac{\\tau^2}{SE^2_k + \\tau^2}}(\\hat\\theta_k - \\mu_*)\n\\end{equation}\\]ここで、\\(SE^2_k\\) は、\\(k\\) の二乗標準誤差 (すなわち、観察された分散) を表し、\\(\\hat\\theta_k\\) は、もともと観察された効果量である37。PET-PEESE と比較した Rücker の限界メタ分析法の利点は、異質性分散 \\(\\tau^2\\) が明示的にモデルに含まれていることである。もう一つのより実用的な利点は、 R で limitmeta 関数を使用して、この方法を直接適用できることである。この関数は {metasens} パッケージに含まれている (Schwarzer, Carpenter, Rücker 2020)。{metasens} と {meta} は同じ研究者グループによって開発されたので、通常は非常にシームレスに連携して動作する。例えば、 m.gen メタ分析のリミットメタ分析を行うには、 limitmeta の呼び出しの最初の引数としてそれを与えるだけでよいのである。出力は、まず、各研究の元の推定値 (左) と縮約された推定値 (右) を示している。調整済み効果量は、観察された効果量よりもかなり小さくなっていることがわかる。現在ではマイナスになっているものも複数ある。出力の第2部では、調整されたプール効果推定値が表示されている。これは、\\(g=\\) -0.03、小規模研究の影響を補正した場合、全体的な効果がほぼゼロであることを示している。もし、小規模研究の効果が本当に出版バイアスによるものであるなら、この結果は残念である。最初の発見は完全に偽りで、選択的な出版によって治療が実際には有効でないという事実が隠されていたことを意味するからである。しかし、繰り返しになるが、出版バイアスがこのデータにおける小規模研究の効果の唯一の原動力であったと証明することは難しい。限界メタ分析のファネルプロットを作成することも可能である。 limitmeta の結果を funnel.limitmeta 関数に渡すだけで、funnel.meta によって生成されたものと全く同じように見える。唯一の違いは、プロットに灰色のカーブが追加されることである。この曲線は、Y軸の標準誤差がゼロのときの調整済み平均効果量を示しているが、標準誤差が増加するにつれて、小規模研究の効果によるバイアスが増加することを表している。limitmeta オブジェクトのファンネルプロットを生成する際に、 shrunken 引数を TRUE に設定することで、縮約した研究レベルの効果量推定値を含めることも可能である。以下は、これらのプロットを生成するコードである。limitmeta は標準化平均差を用いたメタ分析にのみ適用できるわけではなく、 {meta} メタ分析オブジェクトであればどのようなものでも使用できる。例として、リスク比を要約指標とする m.bin の調整済み効果量を確認してみよう。この分析では、元の推定値と修正後の推定値はほぼ同じであることがわかる。これは、Peters の検定 (Chapter 9.2.1.3) で、このメタ分析では小規模研究の効果は小さいとされていることを考えると、あまり驚くことではない。","code":"\n# 'metasens' をライブラリからロード\nlibrary(metasens)\n\n# 限界メタ分析を実行\nlimitmeta(m.gen)## Results for individual studies \n## (left: original data; right: shrunken estimates)\n## \n##                           SMD        95%-CI      SMD        95%-CI\n## Call et al.              0.70 [ 0.19; 1.22]    -0.05 [-0.56; 0.45]\n## Cavanagh et al.          0.35 [-0.03; 0.73]    -0.09 [-0.48; 0.28]\n## DanitzOrsillo            1.79 [ 1.11; 2.46]     0.34 [-0.33; 1.01]\n## de Vibe et al.           0.18 [-0.04; 0.41]     0.00 [-0.22; 0.23]\n## Frazier et al.           0.42 [ 0.13; 0.70]     0.13 [-0.14; 0.42]\n## Frogeli et al.           0.63 [ 0.24; 1.01]     0.13 [-0.25; 0.51]\n## Gallego et al.           0.72 [ 0.28; 1.16]     0.09 [-0.34; 0.53]\n## Hazlett-Stevens & Oren   0.52 [ 0.11; 0.94]    -0.00 [-0.41; 0.40]\n## Hintz et al.             0.28 [-0.04; 0.61]    -0.05 [-0.38; 0.26]\n## Kang et al.              1.27 [ 0.61; 1.93]     0.04 [-0.61; 0.70]\n## Kuhlmann et al.          0.10 [-0.27; 0.48]    -0.29 [-0.67; 0.08]\n## Lever Taylor et al.      0.38 [-0.06; 0.84]    -0.18 [-0.64; 0.26]\n## Phang et al.             0.54 [ 0.06; 1.01]    -0.11 [-0.59; 0.36]\n## Rasanen et al.           0.42 [-0.07; 0.93]    -0.25 [-0.75; 0.25]\n## Ratanasiripong           0.51 [-0.17; 1.20]    -0.48 [-1.17; 0.19]\n## Shapiro et al.           1.47 [ 0.86; 2.09]     0.26 [-0.34; 0.88]\n## Song & Lindquist         0.61 [ 0.16; 1.05]     0.00 [-0.44; 0.44]\n## Warnecke et al.          0.60 [ 0.11; 1.08]    -0.09 [-0.57; 0.39]\n## \n## Result of limit meta-analysis:\n## \n##  Random effects model     SMD            95%-CI     z     pval\n##     Adjusted estimate -0.0345 [-0.3630; 0.2940] -0.21   0.8367\n##   Unadjusted estimate  0.5771 [ 0.3782; 0.7760] -0.21 < 0.0001\n## [...]\n# limitmeta オブジェクトを作成\nlmeta <- limitmeta(m.gen)\n\n# カーブ付きファンネル\nfunnel.limitmeta(lmeta, xlim = c(-0.5, 2))\n\n# カーブと縮約研究推定値のファンネル\nfunnel.limitmeta(lmeta, xlim = c(-0.5, 2), shrunken = TRUE)\nlimitmeta(m.bin)## Result of limit meta-analysis:\n## \n##  Random effects model     RR           95%-CI    z     pval\n##     Adjusted estimate 2.2604 [1.8066; 2.8282] 7.13 < 0.0001\n##   Unadjusted estimate 2.0217 [1.5786; 2.5892] 7.13 < 0.0001"},{"path":"pub-bias.html","id":"p-curve","chapter":"9 出版バイアス","heading":"9.2.2 P 曲線","text":"これまで、小規模研究の効果を見ることで出版バイアスのリスクを評価する様々なアプローチについて説明してきた。実施方法は異なるが、これらの方法はすべて、選択的な報告によって研究の効果量がそのサンプルサイズに依存するという考えに基づいている。標準誤差が大きい (つまり精度が低い) 研究は、大規模な研究よりも平均効果量が大きいと仮定する。これは、非常に高い効果量を持つ小規模な研究だけが発表され、その他の研究はファイルの引き出しに入ったままになっていることがある。この「理論」は確かに直感的だが、やや的外れであるという意見もある。小規模研究法は、出版バイアスが効果量によって引き起こされると仮定したが、より現実的なスタンスは、\\(p\\) -値によって作動すると言えるだろう。実際、研究結果は、\\(p<\\) 0.05 である場合にのみ、出版する価値があるとみなされる。先に述べたように、研究は人間によって行われるため、私たちの生活の他の多くの部分と同様に、金と名声に影響される。“significant \\(p\\), PhD” という悪名高いフレーズは、この問題を非常によく捉えている。研究者は、\\(p\\) - 0.05より小さい値を「出す」ようにという大きな外圧にさらされている。研究者は、この有意水準が、自分の研究が出版されるかどうか、また、それが「成功」したとみなされるかどうかを決定することができることを知っているのである。このようなインセンティブは、ネガティブで有意でない知見が出版された文献からますます消えていく理由を説明するだろう (Fanelli 2012)。小規模研究法は、出版バイアスの背後にあるメカニズムを間接的に捉えていると言えるだろう。確かに、報告が選択されることによって、より小さな研究がより高い効果を持つようになることがある。しかし、これは、非常に高い効果によって、\\(p<\\) 0.05の検定統計量を得る機会が増えるから正しいだけである。小規模研究の効果測定法では、\\(p=\\) 0.049 の研究と、\\(p\\) -値が0.051 の研究の間にはほとんど差がない。しかし、実際には、この小さな違いが、研究者にとって大きな意味を持つ。\n以下では、出版バイアスの主な要因として \\(p\\)-値に着目した p-曲線 (p-curve) という手法を紹介する (Simonsohn, Nelson, Simmons 2014b, 2014a; Simonsohn, Simmons, Nelson 2015)。この方法の特徴は、有意な効果量と、その \\(p\\) -値がどのように分布しているかに限定されていることである。これにより、メタ分析データの背後に真の効果があるかどうかを評価することができ、それがどの程度大きいかを推定することが可能である。重要なのは、小規模研究効果法ではできない、\\(p\\) -hacking のような疑わしい研究手法も明示的にコントロールできることである。P 曲線は比較的新しい手法である。これは、近年社会科学に影響を与えた「複製の危機」に対応して開発された (Ioannidis 2005; Open Science Collaboration et al. 2015; McNutt 2014)。この危機は、一見確立されたように見える研究結果の多くが、実は系統的に再現できないという不都合なものであるという観察に端を発している。このため、出版バイアスを検出する方法に新たな関心が寄せられるようになった。メタ分析では、選択的な報告を適切にコントロールできないため、すでに出版された文献に存在するバイアスを単純に再現している可能性がある。P 曲線は、標準的な出版バイアス法、特に Duval & Tweedie trim-fill 法の欠点に対応して開発されたものでもある。Simonsohnら (2014a) は、trim--fill 法は通常小さな下方修正をもたらすだけで、分析データの背後に真の効果が全くないという事実を見過ごすことが多いことを発見してきた。P 曲線はその名の通り、\\(p\\) -値の曲線に基づくものである。 \\(p\\) -曲線はヒストグラムのようなもので、メタ分析において、\\(p<\\) 0.05, \\(p<\\) 0.04, \\(p<\\) 0.03, というような研究数を示している。p-曲線法は、この \\(p\\) -値のヒストグラムの形状は、研究のサンプルサイズに依存するという考えに基づいており、さらに重要なことは、このデータの背後にある真の効果量に依存していることである。これを説明するために、9つのメタ分析の結果をシミュレートしてみる。パターンを明確にするために、これらの架空のメタ分析には、それぞれ膨大な数の \\(K=\\) 10\\(^{\\text{5}}\\) 件の研究が含まれている。9つのシミュレーションのそれぞれで、個々の研究に対して異なるサンプルサイズ ( \\(n=\\) 20から \\(n=\\) 100の範囲) と、異なる真の効果量 ( \\(\\theta=\\) 0から0.5の範囲) を仮定しよう。メタ分析では、すべての研究が1つの真の効果量を共有し、効果が固定効果モデルに従うと仮定する。そして、シミュレーションで有意なすべての効果量の \\(p\\) -値を取り、ヒストグラムを作成する。その結果は、以下のプロットで見ることが可能である。\nFigure 9.1: 異なるサンプルサイズと効果量の P-曲線。\n一番上の段は、真の効果がない場合の有意な \\(p\\) -値の分布を示している。このパターンは、個々の研究のサンプルサイズがどんなに大きくても、すべてのシミュレーションで同じであることがわかる。３つの研究の \\(p\\) 値は、等しく分布しているように見える。\\(p=\\) 0.04というかろうじて有意な値は、\\(p=\\) 0.01と同じぐらいありそうである。このような平坦な \\(p\\) -曲線は、このデータに基礎的な効果がないとき、すなわち、\\(\\theta = 0\\) の帰無仮説が真であるときに出現する。この場合、\\(p\\)-値は一様分布に従うと仮定される。すべての \\(p\\) -値は他のものと同じように可能性がある。帰無仮説 ( \\(\\theta = 0\\) ) が真であるとき、偶然に有意な効果量を見つけることは可能である。これは、偽陽性、つまり、\\(\\alpha\\) エラーになる。しかし、これはありえないことで、私たちはどのようにありえないかを正確に知っている。効果量がゼロの時は一様に分布しているので、\\(p\\) -値の5%は0.05より小さいと予想される。これはまさに、帰無仮説を棄却するための仮説検定でよく使われる \\(\\alpha=\\) 0.05の有意性閾値なのである。\\(p\\)-曲線は、2段目と3段目で全く違って見える。これらの例では、帰無仮説は否定され、データには真の効果が存在する。このため、\\(p\\) -値の分布は右に歪んだ状態になる。このデータが真の効果を捉えている場合、非常に有意な (例えば、\\(p=\\) 0.01) 効果量は、ほとんど有意でない効果 (例えば、\\(p=\\) 0.049) よりも可能性が高くなる。この右に歪んだ状態は、真の効果量と研究サンプルサイズが大きくなるにつれて、ますます顕著になる。しかし、メタ分析では、検出力が極端に低い研究 (すなわち、\\(\\theta=\\) 0.2の小さな効果を検出することを目的としながら、\\(n=\\) 20人の参加者しか含まない) でも、右に歪んだ \\(p\\) -曲線が出現することがわかる。このことから、\\(p\\) -曲線は、真の効果量の変化に対して非常に敏感であることが明らかになった。真の効果量が存在する場合、\\(p\\)-値が有意である分布を見るだけで、それを検出できることがよくある。さて、研究者が \\(p\\)-hack したとき、\\(p\\)-曲線がどのように見えるか想像してみてみよう。通常、アナリストが \\(p\\)-hacking を使い始めるのは、結果が有意ではないが、それに 近い と判断されたときである。そして、\\(p\\) -値が0.05より小さくなるまで分析の詳細が調整される。それはすでに結果を公表するのに十分な値なので、それ以降、\\(p\\) -hackingは行われない。 \\(p\\) -ハッキングが広く行われると、\\(p\\) -曲線が左に歪むことになるのは想像に難くない。 \\(p\\) -0.05をわずかに下回る値が過剰に表現され、非常に有意な結果が過小に表現される。まとめると、\\(p\\) -曲線は、出版バイアスと \\(p\\) -hacking の存在を評価するための診断ツールとして使用できることがわかる。次に、経験的な \\(p\\)-曲線に基づく統計検定のコレクションである p-曲線曲線について説明する。重要なのは、これらのテストはどれも出版バイアスそのものに焦点を当てていないことである。その代わりに、この方法は、このデータに明らかな価値があるかどうかを見つけ出そうとするものである。これは間違いなく、メタ分析で最も関心のあることである。推定した効果が偽りのものでなく、選択的な報告によって引き起こされた人工物であることを確認したいのである。P-曲線は、まさにこの懸念に対応するものである。P-曲線は、発見が現実に存在する効果によってもたらされているのか、あるいは、大げさに言えば、「音と怒りの物語、何の意味もない」のかをチェックすることを可能にした。","code":""},{"path":"pub-bias.html","id":"証拠能力の検定","chapter":"9 出版バイアス","heading":"9.2.2.1 証拠能力の検定","text":"証拠能力の有無を評価するために、p-曲線は2種類の検定を用いる: 右歪度の検定と33%検出力の検定である (後者は \\(p\\) -曲線の平坦性の検定と見なすことができる)。まず、右歪度の検定から始める。すでに学んだように、\\(p\\)-曲線の右歪度は、研究のサンプルサイズとその真の根本的な効果の関数である。したがって、メタ分析の \\(p\\) -曲線が有意に右歪んでいることを確認できるテストは非常に有用である。有意な \\(p\\) -値の分布に有意な右に歪んでいる場合、これは結果が本当に真の効果によって引き起こされていることを示すだろう。","code":""},{"path":"pub-bias.html","id":"右歪度の検定","chapter":"9 出版バイアス","heading":"9.2.2.1.1 右歪度の検定","text":"右歪度を検定するために、p-曲線法ではまず二項検定を用いる。この検定は、二項分布に従うデータに対して使用することが可能である。二項分布は、2つのカテゴリに分けられるデータ (例: 成功/失敗、表/裏、イエス/ノー) に対して仮定することができ、\\(p\\) は結果の1つの確率を示し、\\(q = 1-p\\) は他の結果の確率を示す。二項検定を使用するために、\\(p\\) -曲線を2つのセクションに分割しなければならない。これは、<0.025である \\(p\\) -値の数と、次に>0.025である有意な \\(p\\) -値の数をカウントすることによって行う。 \\(p\\) -曲線の値は0から0.05の範囲にあるので、基本的にはx-軸の中央をカットオフとして使用する。 \\(p\\) -曲線が確かに右に歪んでいる場合、2つのグループの \\(p\\) -値の数が異なることが予想される。これは、0.025より小さい結果を得る確率 \\(p\\) は、0.025より大きい値を得る確率 \\(q\\) よりもかなり高いからである。\\(p\\) -曲線に8つの値があり、そのうちの7つが0.025以下であると想像してみよう。 R の binom.test 関数を使って、\\(p\\) -値の小ささと高さが等しく起こりうるという帰無仮説のもとで、そのようなデータを見つけることがどの程度可能かをテストすることが可能である38。小さい \\(p\\) -値は大きい \\(p\\) -値よりも頻度が高いと仮定しているので、 alternative 引数を \"greater\" に設定することで、片側検定を使用することが可能である。二項検定が有意であることがわかる (\\(p<\\) 0.05)。この例では、\\(p\\) -値 が、低い値より高い値の方が有意に多いことを意味する。全体として、これは \\(p\\) -曲線が右に歪んでおり、真の効果があることを示している。二項検定の欠点は、\\(p\\) -値が実際には連続的であるにもかかわらず、二項化することを要求することである。情報の損失を避けるために、データを二項に変換することを必要としない検定が必要である。P-曲線は、各 \\(p\\) -値に対して \\(p\\) -値を計算することによってこれを実現し、各研究のいわゆる \\(pp\\) -値が得られる。 \\(pp\\) -値は、\\(p\\) -曲線が平坦なとき (すなわち、真の効果がないとき)、\\(p\\) と少なくとも同じ高さの値を得る可能性を示している。これは、有意な値のみを考慮した場合の \\(p\\) の値の確率を示す。 \\(p\\) -値は一様分布に従うので、\\(\\theta = 0\\) , \\(pp\\) -値は、\\([0,1]\\) の範囲に投影する有意な \\(p\\) -値にほかならない。連続アウトカム尺度の場合、これは \\(p\\) -値に20を乗じることで達成される。例えば、\\(p = 0.023\\times20 = 0.46 \\rightarrow pp\\) 。\n\\(k\\) メタ分析で有意な各研究の \\(pp_k\\) -値を用いて、Fisher の方法で右歪度を検定することが可能である。この方法は、20世紀初頭に R. . Fisher によって開発されたメタ分析の「古風な」タイプである (Chapter 1.2 を参照)。Fisherの方法は、いくつかの研究からの \\(p\\) -値を集約し、少なくとも1つが真の効果を測定しているかどうかを検定することが可能である (すなわち、提出された \\(p\\) -値の分布が右に歪んでいるかどうかを検定する)。これは、\\(pp\\) -値を対数変換し、すべての研究 \\(k\\) の結果を合計し、-2 を掛けることを必要とする。結果として得られる値は、\\(2 \\times K\\) の自由度を持つ \\(\\chi^2\\) 分布 ( Chapter 5.1.1 参照) に従う検定統計量となる ( \\(K\\) は \\(pp\\) -値の総数)39。\\[\\begin{equation}\n\\chi^2_{2K} = -2 \\sum^K_{k=1} \\log(pp_k)\n\\tag{9.14}\n\\end{equation}\\]Fisher の方法を簡単な例で試してみよう。 \\(p\\) -曲線が5つの \\(p\\) -値を含んでいると想像してみよう。 \\(p=\\) 0.001, 0.002, 0.003, 0.004 および 0.03とする。右歪度を検定するために、まず、これらの \\(p\\) -値を \\(pp\\) -値に変換しなければならない。式9.15を用いると、このコードで \\(\\chi^2\\) の値を算出することができる。この結果、\\(\\chi^2=\\) 25.96 となる。5 件の研究が含まれているので、自由度は \\(\\text{d.f.} =2\\times5=10\\) となる。この情報を使って、効果がない/右に歪んでいないという帰無仮説のもとで、このデータがどれだけの確率で成り立っているかをチェックすることが可能である。これは R で pchisq 関数を用いて行うことが可能である。 \\(\\chi^2\\) の値と d.f. の数を指定する必要がある。これは、\\(p\\)-値が 0.0026 であることを意味する。これは、帰無仮説が非常にありそうにないことを意味し、したがって棄却される。 \\(\\chi^2\\) 検定の有意な値は、この例では、\\(p\\) -値が実際に右に歪んでいることを教えてくれる。これは、このデータの背後に証拠能力があるという仮定の証拠と見ることが可能である。","code":"\nk <- 7   # p<0.025 である研究数\nn <- 8   # 有意な研究数\np <- 0.5 # k (ヌル仮説) の推定確率\n\nbinom.test(k, n, p, alternative = \"greater\")$p.value## [1] 0.03515625\np <- c(0.001, 0.002, 0.003, 0.004, 0.03)\npp <- p*20\n\n# pp 値を表示\npp## [1] 0.02 0.04 0.06 0.08 0.60\nchi2 <- -2*sum(log(pp))\nchi2## [1] 25.96173\npchisq(26.96, df = 10, lower.tail = FALSE)## [1] 0.002642556"},{"path":"pub-bias.html","id":"平坦度テスト","chapter":"9 出版バイアス","heading":"9.2.2.1.2 平坦度テスト","text":"右歪度の検定が、有意な \\(p\\) -値の分布が真の全体効果を表しているかどうかを決定するために使用できることを確認する。問題は、この検定がデータの統計的検出力に依存することである。したがって、右歪度検定が有意でないとき、これは自動的に証拠能力がないことを意味するわけではない。本当に効果がないのか、あるいは、たとえデータが実際に右に歪んでいても \\(p\\) -曲線における値の数が \\(\\chi^2\\) 検定を有意にするには少なすぎるのか、という2つのことが考えられる。したがって、右歪度の検定が有意でないことの説明として、検出力の欠如を除外しなければならない。右歪度の検定の帰無仮説は、「証拠能力がない」というものである。検定では、基本的に、経験的な \\(p\\)-曲線が平坦でないことを示すことによって、この帰無仮説を棄却しよう。ここで、この論理を逆転させて、\\(p\\)-曲線が平坦である ことを示さなければならない。これは帰無仮説を変更することで可能である。効果がないのではなく、新しい帰無仮説は、\\(p\\) -曲線は小さい効果を含み、結果としてわずかに右に歪んでいると仮定する。平坦性の検定では、\\(p\\) -曲線がわずかに右に歪んでいないことを示すことが目標になる。あるいは、別の言い方をすれば、\\(p\\) -曲線が、非常に、非常に小さな効果に対して私たちが期待するものよりも、著しく平坦であることを確認したい。このような場合、手元のデータでは非常に小さな効果さえも否定され、証拠能力が全くない可能性が高いと言える。P曲線解析は、33%の検出力の検定を通してこれを達成する。このアイデアは、真の効果が非常に小さい場合の各有意な研究 \\(k\\) の期待 \\(pp\\) -値 (すなわち、\\(p\\) の確率) を構築することである。非常に小さいというのは、研究のサンプルサイズを用いて、33%の検出力で検出できる効果量という意味である。この33％という閾値はある程度恣意的なもので、p-曲線の発明者が実質的に無視できる程度の効果を示す大まかな指標として選んだものである。33% 検出力 \\(pp\\) -値がどのように決定されるかの統計的な詳細は割愛するが、アウトカム尺度によって非中心分布 \\(F\\) , \\(t\\) , \\(\\chi^2\\) などの非中心分布の使用を伴うことは知っておく必要がある40。以下、p曲線 (Chapter 9.2.2.2) を用いた効果量推定について、非心分布の概念をより詳細に説明する。要約すると、平坦性検定では、まず、有意な \\(p\\) -値ごとに、33%の検出力で検出できる効果に基づく \\(pp\\) -値を計算する。もし、33%検出力の推定値が私たちの \\(p\\) -値の分布によく合うなら、33%検出力の \\(pp\\) -値は一様分布になる。ちょうど、\\(p\\) -値が、データが帰無仮説 \\(\\theta = 0\\) によく合うとき、一様分布に従うのと同じである。したがって、右歪度検定で使ったのと同じ方法を適用できるが、今回は、計算に 33% の検出力 \\(pp\\) -値を使用する。唯一の違いは、帰無仮説を棄却することに特に注目しないことである。これは、少なくとも小さな効果がデータに存在するという概念を否定している。無視できるほど小さな効果があるか、あるいは全く効果がないかのいずれかである。","code":""},{"path":"pub-bias.html","id":"interpretation-p-curve-results","chapter":"9 出版バイアス","heading":"9.2.2.1.3 P-曲線の結果の解釈","text":"ここまで、経験的に \\(p\\) -曲線を分析することができるいくつかの検定を取り上げた。統計的な概念のいくつかが理解しにくいと感じても、あまり心配しないでみよう。p-曲線の背後にある方法論を把握するのに時間がかかるが、次の実践的な例はこの点で必ず役に立つ。最も重要なのは、p-曲線検定の背後にあるアイデアと、その結果がどのように解釈されるかを理解することである。このセクションでは、後者に焦点を当てる。p-曲線を解釈するとき、私たちは4つの検定結果を意味づけしなければならない。二項右歪度検定と平坦度検定、および \\(pp\\) -値に基づく右歪度検定と平坦度検定のものである。さらに悪いことに、p-曲線解析は、まだカバーしていない2つの追加検定を含んでいる。 half \\(p\\) curve に基づく右歪度検定と平坦度検定である。これらの検定は、前にカバーした \\(pp\\) -値に基づく検定と同じであるが、高い \\(p\\) -値 (すなわち、\\(p<\\) 0.025) にのみ適用されている。half \\(p\\) -curve 検定は、ambitious \\(p\\) -hacking (Simonsohn, Simmons, Nelson 2015) に対するセーフガードとして導入されたものである。可能性は低いが、研究者が \\(p\\) -有意性が高くなるまで結果をハッキングしている可能性がある。しかし、この場合、\\(p\\) -曲線の形状が歪む可能性がある。つまり、真の効果がない場合でも、左ではなく、わずかに右に歪んで見えるだろう。half \\(p\\) -curve に基づく検定は、これを制御することが可能である。なぜなら、野心的な \\(p\\) -ハッカーでさえ、真の効果がない限り、非常に高い \\(p\\) -値 (たとえば \\(p<\\) 0.01) を得ることはますます困難になることがある。定義上、半分の \\(p\\) -曲線は0.025より小さい値しか含まないので、二項検定は実行されない。p-曲線の結果を解釈するとき、私たちは本質的に2つの質問に答えようとする。1つ目は、\\(p\\) -曲線は、証拠能力の存在を示しているか？これは、右歪度の検定を使用して評価することが可能である。証拠能力の存在を確認できない場合、2番目の質問に移る。これは、平坦度検定で評価することができる。具体的には、以下のガイドラインを用いることができる (Simonsohn, Simmons, Nelson 2015)。固有値の存在: 右歪度検定が半分の \\(p\\) -曲線で有意である ( \\(p<\\) 0.05) または右歪度検定の \\(p\\) -値が半分と完全な曲線の両方で<0.1>である。固有値の存在: 右歪度検定が半分の \\(p\\) -曲線で有意である ( \\(p<\\) 0.05) または右歪度検定の \\(p\\) -値が半分と完全な曲線の両方で<0.1>である。証拠となる値がない、または不十分である: 完全曲線に対する平坦度検定は \\(p<\\) 0.05 で有意である または 半曲線に対する平坦度検定 および 二項検定は \\(p<\\) 0.1 で有意である。証拠となる値がない、または不十分である: 完全曲線に対する平坦度検定は \\(p<\\) 0.05 で有意である または 半曲線に対する平坦度検定 および 二項検定は \\(p<\\) 0.1 で有意である。\n「ノーノー」ケースの解釈\n\nどの P\n曲線分析も、最終的には3つの結果のいずれかに帰結する。右歪度検定が有意であるとき、我々は証拠能力があると結論づける。右歪度検定が有意でなく、平坦度検定が有意なとき、これは証拠能力がない\n(または効果がとてもとても小さい) ことを示す。\n\n最後の3つ目の結果は、最も厄介である。適切な表現がないので、「ノーノー」ケースと呼んでいる。これは、証拠能力があることも、ないことも確認できない場合である\n(つまり、右歪度の検定も、平坦度の検定も有意ではない)。\n\n解釈としては、「ノーノー」の場合、真の効果があることを確認できないが、比較的小さな効果も否定できないことを意味している。\n\nこの3つ目の結果は、\\(p\\)\n曲線に含まれる研究数が少ない場合によく起こり、確かにやや期待はずれである。この結果は、\\(p\\)-曲線を見ただけでは真の効果が存在するかどうかわからない、物事を明確にするためにもっと証拠が必要であることを伝えることが多い。\n","code":""},{"path":"pub-bias.html","id":"r-のp曲線解析","chapter":"9 出版バイアス","heading":"9.2.2.1.4 R のP曲線解析","text":"ここまでで、p-曲線分析の背後にある理論について多くを学んだので、そろそろ実世界の例でこの技術を適用し始める時期が来ている。幸運なことに、p-曲線の発明者である Simonsohn、Simmons、Nelson は、以前に説明したすべてのテストを自動的に行い、関連する結果を返すアプリケーションを開発してきた。このp-曲線アプリは、オンライン でも見ることが可能である。\nR で p-曲線を使用するには、 pcurve 関数に頼ることが可能である。この関数はアプリの動作をエミュレートするもので、特に {meta} パッケージで作成されたメタ分析オブジェクトのために設計されている。\n“pcurve” 関数\n\n\npcurve 関数は、{dmetar}\nパッケージに含まれている。{dmetar}\nがインストールされ、コンピュータに読み込まれると、この関数を使用できるようになる。もし、{dmetar}\nをインストールしていない場合は、以下の手順でインストールできる。\n\n関数のソースコードに オンライン\nでアクセスする。\n\nソースコード全体をコンソール (R Studio の左下ペイン)\nにコピー＆ペーストし、Enterキーを押して、 R\nに関数を「学習」させる。\n\n{stringr} と {poibin}\nパッケージがインストールされ、ロードされていることを確認する。\n関数 pcurve の使い方は簡単である。この関数に、以前に作成した {meta} メタ分析オブジェクトを渡すだけでよい。この例では、 metagen 関数 ( Chapter 4.2.1 ) で作成した m.gen メタ分析オブジェクトを再び使用する。しかし、分析を実行する前に、以前に特定した2つの外れ研究 (研究3と研究16、Chapter 5.4 参照) を削除している。これがなぜ良いアイデアなのかは後で説明する。p曲線解析の結果と、観測された \\(p\\) -曲線のプロットの2つが出力される。出力は、メタ分析が \\(k=\\) 9件の有意な効果を含み、それが \\(p\\) -曲線に含まれることを教えてくれる。研究 ( \\(k=\\) 8) のほとんどは、非常に有意な結果 (すなわち、\\(p<\\) 0.025) であった。Results セクションには、分析の主なアウトカムが記載されている。3つの右歪度検定すべてが有意であることがわかる: 二項検定 ( pBinom ; \\(p=\\) 0.02), 完全な \\(p\\)-曲線 \\(pp\\) -値の検定 ( pFull ; \\(p<\\) 0.001) と half \\(p\\)-曲線に基づく検定 ( pHalf ; \\(p=\\) 0.003)41。Chapter 9.2.2.1.3 で設定した基準を適用すると、このデータには証拠能力があることがわかる。次の行では、\\(p\\) が 0.938 から 1 までで、3つの平坦性検定が有意でないことがわかる。これは、非常に論理的に、証拠能力がないわけでも不十分なわけでもないことを教えてくれる。同じ解釈は、出力の Evidential value セクションでも提供されている。この関数による \\(p\\)-曲線は、３種類の線を描く。 実線は、データに基づく経験的な \\(p\\) -曲線。破線は、33%の検出力を仮定して期待される \\(p\\) -値の分布。点線は、効果がないときに期待される一様な分布を表している。実線は目に見えて右に歪んでおり、ちょうど研究が真の効果を測定しているときに期待されるようなものである。全体として、これらの結果は、証拠能力の存在を示し、真の非ゼロ効果があることを示している。出版バイアスがメタ分析の結果に影響を及ぼしていることは、まだ否定できない。しかし、p-曲線の結果に基づいて、私たちが見つけたプール効果は完全に偽りのものではなく、選択的な報告によって生み出された単なる「蜃気楼」でもないと結論づけることができる。興味深いことに、この知見は、いくつかの少量調査効果法を用いて得られた結果とあまり一致していない。PET-PEESE ( Chapter 9.2.1.5 ) と限界メタ分析法 ( Chapter 9.2.1.6 ) はともに、補正平均効果を約0と推定してきた42。","code":"\nlibrary(dmetar)\nlibrary(meta)\n\n# m.gen から外れ値を外して update\nm.gen_update <- update.meta(m.gen, subset = -c(3, 16))\n\n# p-曲線解析を実行\npcurve(m.gen_update)## P-curve analysis \n##  ----------------------- \n## - Total number of provided studies: k = 16 \n## - Total number of p<0.05 studies included into the \n##   analysis: k = 9 (56.25%) \n## - Total number of studies with p<0.025: k = 8 (50%) \n##    \n## Results \n##  ----------------------- \n##                     pBinomial  zFull pFull  zHalf pHalf\n## Right-skewness test     0.020 -3.797 0.000 -2.743 0.003\n## Flatness test           0.952  1.540 0.938  3.422 1.000\n## Note: p-values of 0 or 1 correspond to p<0.001 and p>0.999, \n## respectively.   \n##\n## Power Estimate: 66% (31.1%-87.8%)\n##    \n## Evidential value \n##  ----------------------- \n## - Evidential value present: yes \n## - Evidential value absent/inadequate: no"},{"path":"pub-bias.html","id":"p-curve-es","chapter":"9 出版バイアス","heading":"9.2.2.2 P 曲線効果量推定値","text":"メタ分析に証拠能力があるかどうかを判断するために、経験則に基づく \\(p\\) -曲線の分析がどのように利用できるかを学習してきた。しかし、この方法を用いて決定的な結果を得ても、私たちの洞察はやや限定的なものにとどまるだろう。データに真の効果があることを知ることは非常に有用であるが、この真の効果がどの程度大きいかを知ることができれば、さらによいだろう。幸いなことに、p-曲線はこの問題にも役立ってくれる。研究のサンプルサイズがわかっていれば、\\(p\\) -曲線の形状に最も合う真の効果量を探すことが可能である。これがどのように実現可能なのかを理解するために、まず、非心分布 (non-central distribution) の概念と、それが効果量にどのように関係するかを議論する必要がある。非心分布とは何かを例証するために、間違いなく最も一般的な統計的検定である2標本 \\(t\\) -検定から始める。 \\(t\\) -検定は、2つのグループの平均が異なるかどうかを調べるためによく使われる。\\(t\\) -検定における帰無仮説は、両平均値 \\(\\mu_1\\) と \\(\\mu_2\\) は同一であり、したがって、それらの差はゼロであるということである。帰無仮説が真であるとき、\\(t\\) 統計量は、中心 \\(t\\) -分布に従うと仮定する。中心 \\(t\\) -ディストリビューション分布は、標準正規分布に似ている。帰無仮説は差がないと仮定しているので、\\(t\\) -分布はゼロを中心とする。帰無仮説が正しくないとき、この中心 \\(t\\) -分布は、現実をよく表していないことになる。平均値の間に真の差があるとき、\\(t\\)-値がゼロの周りに中心を持つことは期待できない。その代わりに、\\(t\\) 統計は、非心 \\(t\\) -分布に従う。この非心分布は通常非対称であり、より広い広がりを持つ傾向がある。しかし、最も重要なことは、その中心がゼロから「シフト」していることである。このシフトの大きさは、非心パラメータ \\(\\delta\\) によって制御される。 \\(\\delta\\) が高いほど、非中心分布のピークがゼロから離れることになる。下のグラフはこの挙動を表している。左側には、\\(t\\) -分布の中心、\\(\\delta=\\) 0が表示されている。右側には、\\(t\\) -分布の非心、\\(\\delta=\\) 5が表示されている。右の曲線は対称性が低く、5付近でピークになることがわかるが、対称的で中心的な \\(t\\) -分布の中心は0になっている。左の中心分布は帰無仮説が正しい場合の期待値 \\(t\\) -値を示しているのに対し、右は 対立仮説 が正しい場合の期待値 \\(t\\) -値を示している。別の考え方として、左の曲線は効果がないときの \\(t\\) -分布を、右の曲線は効果があるときの分布を表していると言うことが可能である。中央の分布は、たとえば SMD が0であることを表し、中央でない分布は、SMD = 1.3 の効果に対する期待値 \\(t\\) -値の分布を表す (この値は仮のもの)。効果量が大きいと (つまり、2つのサンプル間の差が大きいと)、非心パラメータ \\(\\delta\\) は高くなり、非心分布は0からますます離れていくだろう。先ほど述べたように、非心 \\(t\\) -分布は、\\(t\\) -検定において対立仮説をモデル化するために用いることが可能である。しかし、統計の教科書に非心分布が載っているのは珍しいことで、それは通常、非心分布は必要ないためである。統計的仮説検定では、通常、対立仮説は非特異的である。2サンプル \\(t\\) -kentei\nを計算するとき、帰無仮説 (「群間に差がない」) にしか興味がない。データが帰無仮説にうまく当てはまらないとき、これを棄却し、何らかの効果が存在すると結論づける。このような検定における対立仮説は、帰無仮説の反対で、2つのサンプル間の平均差がゼロではないことであり、効果がこのサイズまたはこのサイズであることではないのである。具体的な対立仮説が必要になるのは、通常、統計的検定の検出力を計算するときだけである。実験を行う場合、偽陰性の確率が20％以下になるように十分なサンプルサイズを計画するのが通例である。適切なサンプルサイズを用いることで、真の効果が存在する場合に、それを確実に検出できるようにしたいのである。このように、統計的検定が真の効果を発見する確率が、その統計的検出力である。これは、1マイナス偽陽性の確率と定義され、\\(\\beta\\) としても知られている。\\(t\\) -検定に必要なサンプルサイズを計算するために、非心 \\(t\\) -分布が必要である。なぜなら、それは効果があるときの \\(t\\) -値の期待される振る舞いを示すからである。サンプルサイズを計算するために、また真の効果量について値を仮定する必要がある。なぜなら、それは非心パラメータ \\(\\delta\\) に影響し、したがって非心分布の形状に影響を与えるからである。これらの断片をまとめると、非心 \\(t\\) -分布の形状、したがって統計的検出力は、2つのものだけで制御されることがわかる: サンプルサイズと、真の根本的な効果である。同じことが、\\(p\\) -曲線の形状にも当てはまる。その右歪度は、サンプルサイズとデータの真の効果に依存する。これは重要な観察で、\\(p\\) -曲線内の研究のサンプルサイズがわかれば、その真の効果量も推定できることを意味する。p-曲線がどのようにこれを実現するかを見るために、小さな例を見てみよう。独立2サンプル \\(t\\) -検定 (両群の分散が等しいと仮定) の場合、\\(t\\) の値は、群間平均差 \\(\\text{MD}_{\\text{}}\\) をその標準誤差 \\(SE_{\\text{MD}_{\\text{}}}\\) で割ったものに等しくなる。\\[\\begin{equation}\nt_{\\text{d.f.}}= \\frac{\\text{MD}_{\\text{}}}{SE_{\\text{MD}_{\\text{}}}}\n\\tag{9.15}\n\\end{equation}\\]群間平均差と標準誤差の式 (Chapter 3.3.1.1 の式 3.14 と式 3.15 参照) を入れると、次の式になる。\\[\\begin{equation}\nt_{n_{1}+n_{2}-2} = \\frac{\\hat\\mu_{1}-\\hat\\mu_{2}}{s_{\\text{pooled}}\\sqrt{\\dfrac{1}{n_1}+\\dfrac{1}{n_2}}}\n\\tag{9.16}\n\\end{equation}\\]この式から、\\(t\\) の自由度は、両群のサンプルサイズを合わせたもの (\\(n_1+n_2\\)) から2を引いたものと定義されることがわかる。この式を使って、一次研究で報告されたデータから \\(t\\) -値を計算することが可能である。ある研究で、実験群に \\(n_1=\\) 30人、対照群に \\(n_2=\\) 20人の参加者がいたとする。この研究では、第1群と第2群の平均がそれぞれ13と10で、両群の標準偏差が5であったと報告されている。このデータに基づいて、次のコードを使って \\(t\\) を計算することができる。結果は、\\(t_{48} =\\) 2.078 である。この結果は、両者の平均が同一であり、影響がないという帰無仮説を支持するか？この質問に答えるには、 pt 関数を使用することができる。この関数は、d.f. = 48 かつ帰無仮説が真であると仮定するとき、\\(t\\)-値 が 2.078 より大きいことを発見する確率を与える。この確率は、片側 \\(t\\)-検定の \\(p\\) -値に等しい。結果は、\\(p=\\) 0.02 で、検定が有意であることを意味する。したがって、実験群の効果がゼロ (または負) であるという帰無仮説を棄却する。その結果、対立仮説を受け入れる: 実験群に有利な正の効果がある (より高いスコアがより良いアウトカムを表すと仮定)。\\(t\\) 検定の帰無仮説の基礎となる中心 \\(t\\) -分布は、私たちの経験的データにはあまり合わないことがわかっている。また、非心 \\(t\\) -分布が私たちのデータによく合うことも分かっている。しかし、どちらなのかは分からない。今のところ、どの真の効果量、したがって、どの非心パラメータ \\(\\delta\\) が、経験的な \\(t\\) -値が引き出された母集団を本当に表しているかを推測することができるだけである。最初の推測として、発見の背後にある真の効果量は、標準化平均差 \\(\\theta=\\) 0.6であると仮定することが可能である。これは、中〜大の効果があったために、\\(t=\\) 2.078 となったことを意味する。この \\(\\theta\\) の値に基づいて、非心性パラメータは次の式で計算される。\\[\\begin{equation}\n\\delta = \\frac{\\theta}{\\sqrt{\\dfrac{n_{1}+n_{2}}{n_{1}n_{2}}}}\n\\tag{9.15}\n\\end{equation}\\]ここで、\\(n_1\\) と \\(n_2\\) は両グループのサンプルサイズである。この例では、非心性パラメータ \\(\\delta\\) を次のコードで計算することができる。\\(\\delta=\\) 2.078 の時の非心分布 \\(t\\) -分布がどのように見えるかを見るために、少しシミュレーションをしてみよう。rt 関数を用いて、自由度48の100万個のランダムな \\(t\\) -値を2回描く。1回は非心パラメータを0と仮定したとき (これは効果がないというヌル値に等しい)、もう1回は先ほど計算した \\(\\delta\\) の値 (つまり、真の効果は SMD = 0.6 ) を用いて描く。次に、パイプと hist 関数を使って、 R に両シミュレーションのヒストグラムを描かせる。これが結果のプロットである。その中で、左側に中心の \\(t\\)-分布 (効果なし)、右側に非心分布 ( \\(\\theta=\\) 0.6) を見ている。すでに適度な大きさのサンプル ( \\(N=\\) 50 ) があるので、非心分布は、前の図よりも右に歪んでいないように見える。それでも、私たちの仮定した対立仮説の分布は右にシフトし、\\(\\delta\\) の値でピークになることがはっきりわかる。もちろん、中心的な疑問は、この代替分布が本当に正しい分布であり、真の効果が実際には \\(\\theta=\\) 0.6 であるとき、\\(t_ **{48}** =\\) 2.078 より大きい値を得る可能性はどの程度あるのだろうかということである。この質問を検証するために、再び pt 関数を使用することができるが、今回は想定した非心性パラメータ \\(\\delta\\) も提供する。この情報は ncp 引数を用いて追加することが可能である。どのような結果が得られるか、確認してみよう。指定された対立仮説のもとで、私たちの結果より大きな値を得る確率は、およそ50％であることがわかる。これは、約半分の値が、私たちが見つけた \\(t\\) -値より高く、残りの半分は低いと予想されることを意味する。全体として、これは自由度48と真の効果0.6を仮定した非心 \\(t\\) -分布が、私たちの発見を非常によく近似していることを示している。この研究の真の母集団効果は、SMD = 0.6である可能性が非常に高いと思われる。今行ったステップは、本質的に、p-curve が真の効果量を決定するために使用するものでもある。 \\(p\\) -曲線におけるすべての有意な \\(p\\) -値について、\\(t\\) より大きい値を得る確率を計算する。1.ある効果量／非中心性パラメータ。\\(p\\) -値は、\\(x\\) 自由度 (これは研究のサンプルサイズから導き出せる) に基づくこと。\\(p\\) -値は、\\(x\\) 自由度 (これは研究のサンプルサイズから導き出せる) に基づくこと。有意な値( \\(p<\\) 0.05 )のみが \\(p\\) -曲線に含まれることを知る。有意な値( \\(p<\\) 0.05 )のみが \\(p\\) -曲線に含まれることを知る。この結果、重要な研究ごとに \\(pp\\) -値が設定されることになる。 \\(k\\) 。先ほど説明したことに基づいて、研究の \\(pp\\)-値の式は次のように表すことが可能である \\(k\\) :\\[\\begin{equation}\npp(t_k) = \\mathrm{P}(t>t_k~\\vert~\\delta,~\\text{d.f.},~p<0.05)\n\\tag{9.16}\n\\end{equation}\\]研究の自由度は通常知られているので、式中の唯一の未知数は、\\(\\delta\\) 、したがって真の効果量 \\(\\theta\\) である。しかし、正しい真の効果量/ \\(\\delta\\) -値を仮定すると、\\(pp\\) -値の分布が一様になることが分かっているので、この真の効果量を見つけることが可能である。私たちの知見が帰無仮説に合致するとき \\(p\\) -値が一様分布に従うように、結果が 正しい非心分布 (すなわち、点対立仮説) に合致するとき \\(pp\\) -値は一様に分布するのである。したがって、私たちは、たくさんの可能な効果量の候補を試し、得られた \\(\\delta\\) -値を上記の式に差し込み、得られた \\(pp\\) -値の歪度を評価すればよいのである。そして、\\(pp\\) -値の一様分布に最も近い効果量候補が、真の効果の推定値を表す。P-curve は、いわゆる Kolmogorov-Smirnov (KS) 検定の \\(D\\) 距離メトリックを使用して、\\(pp\\) 分布が一様分布からどのくらい逸脱しているかを把握する。P-曲線の効果推定法は pcurve 関数にも実装されている。これを利用するには、 effect.estimation 引数を TRUE に設定する必要がある。また、各研究のサンプルサイズである N を指定する必要がある。最後に、効果量の候補の探索空間を dmax と dmin を用いて制御することが可能である。ここでは、Cohen’s \\(d=\\) 0 と 1 の間の効果量を検索するように pcurve に指示する。dmin は常に 0 以上でなければならないことに注意してみよう–p-曲線が検出できる最小値は効果なしである。出力には、真の効果量の推定値と効果量探索の結果を示すプロットという2つの新しい要素が含まれる。プロットでは、効果量の候補が滑らかなV字型の勾配を形成し、それは効果量 \\(d=\\) 0.389でピークに達した。この時点で、計算された \\(pp\\) 分布と一様分布 (Y軸の \\(D\\) の値で表される) との差は最小であり、これは真の効果の最良推定値を表していることを意味する。重要なことは、p-曲線の効果量の推定は、このプロットのようなV字型のときだけ信頼できるということである。他の不規則な形状は、p-curveが最小値を発見していない可能性を示している。滑らかな下降線を持つプロットは、探索空間が単に狭すぎることを示すだろう。この場合、より高い dmax 値で分析を再実行することは理にかなっている。全体として、p-曲線の推定値 \\(d=\\) 0.389 は、メタ分析で見つけたプール効果 (外れ値を除くと \\(g=\\) 0.45) よりもいくらか低い。しかし、それでも十分に大きく、前回の発見、すなわち、研究には証拠能力があるということと一致する。\nP-曲線解析結果の報告\n\np\n曲線解析の結果を報告する際には、少なくとも3つの右歪度検定と平坦性の検定の\\(p\\)値、およびこれらの結果をどのように解釈したかを記載するとよい。真の効果の大きさが推定されたときは、これも含めるべきである。結果は、次のような表にまとめることができる。\n\np-曲線の開発者は、各解析について、結果が論文のどの部分から抽出され、どのように報告されたかを記述した開示表を作成することを強く推奨している。このような開示表の例は、他のいくつかの実用的なガイドラインと一緒に、Simonsohn\nら (2014b)\nに記載されている。\n\nP-曲線と群間異質性\n\nP-曲線解析から外れ値の研究を除外した理由については、まだ説明する義務がある。外れ値も含めたメタ分析では、研究間の異質性が\n\\(^2=\\) 63%\nとなり、非常に大きな値となった。これは、研究間の異質性が高い場合、p曲線は真の効果量を推定するのに頑健な方法ではないことが分かっているので問題である。\n\nそこで Van Aert ら (2016)\nは、異質性が小から中程度の場合にのみ\np-曲線を使用することを提案している。彼らは p\n曲線が適用できるかどうかを判断する経験則として、\\(^2=\\)\n50%という閾値を提案した。メタ分析における研究間の異質性がこれよりも高い場合の回避策の一つは、例で行ったように、外れ値を含まない効果量をp曲線で表す。さらに良い解決策は、意味のある研究のサブグループが存在する場合、そのサブグループで別の分析を行うことである。\n","code":"\n# 平均差を計算\nmd <- 13-10\n\n# 平均差の標準誤差を計算\nn1 <- 30\nn2 <- 20\ns1 <- s2 <- 5\ns_pooled <- sqrt((((n1-1)*s1^2) + ((n2-1)*s2^2))/\n                   ((n1-1)+(n2-1)))\n\nse <- s_pooled*sqrt((n1+n2)/(n1*n2))\n\n# t-値を計算 (分散の等しい２ーサンプル t 検定と同じ) \nmd/se## [1] 2.078461\npt(2.078, df = 48, lower.tail = F)## [1] 0.0215403\ntheta <- 0.6\ndelta <- theta/sqrt((n1+n2)/(n1*n2))\n\n# Show delta\ndelta## [1] 2.078461\n# '1 のあとに 0 が 6 つ' は、R では '1e6' と書くこともできる\n# \"tidyverse\" パッケージがロードされていること (パイプ用) \nrt(n = 1e6, df = 48, ncp = 0) %>% \n  hist(breaks = 100, \n       col = \"gray50\",\n       xlim = c(-4,8), \n       ylim = c(0, 40000),\n       xlab = \"t-value\",\n       main = NULL)\n\nrt(n = 1e6, df = 48, ncp = delta) %>% \n  hist(breaks = 100, \n       col = \"gray95\",\n       xlim = c(-4,8), \n       ylim = c(0, 40000), \n       add = T)\n# t=2.078 を使用\npt(2.078, df = 48, ncp = delta, lower.tail = FALSE)## [1] 0.5044537\n# 実験群(n1) と対照群 (n2) のサンプルサイズを追加\n# 研究３と６のサンプルサイズを削除\nn1 <- c(62, 72, 135, 103, 71, 69, 68, 95, \n        43, 79, 61, 62, 60, 43, 64, 63)\n\nn2 <- c(51, 78, 115, 100, 79, 62, 72, 80, \n        44, 72, 67, 59, 54, 41, 66, 55)\n\n# 効果推定ありで P 曲線分析を実行\npcurve(m.gen_update, \n       effect.estimation = TRUE,\n       N = n1+n2, \n       dmin = 0,\n       dmax = 1)## P-curve analysis \n##  ----------------------- \n## [...]\n##    \n## P-curve's estimate of the true effect size: d=0.389  "},{"path":"pub-bias.html","id":"selection-models","chapter":"9 出版バイアス","heading":"9.2.3 選択モデル","text":"最後に取り上げるのは、いわゆる選択モデルと呼ばれる出版バイアスの手法である。選択モデルは以前から選択的出版の影響を調べるために提案されていたが (L. V. Hedges 1992, 1984; Iyengar Greenhouse 1988; L. V. Hedges Vevea 1996) 、特にここ数年でその適用への関心が高まっている (McShane, Böckenholt, Hansen 2016; Carter et al. 2019) 。上で取り上げた出版バイアス法は、すべて何らかの「理論」に基づいており、選択的出版がメタ分析の結果になぜ、どのように影響するかを説明するために使用される。例えば、Small-study Effect法は、研究の非出版リスクはサンプルサイズと効果量に比例すると仮定した。P曲線は、\\(p\\)-値 0.05 が「魔法の閾値」として機能するという考えに基づいている。 \\(p \\geq\\) 0.05 の結果は、一般的に統計的に有意な発見よりも、このデータで見つからない可能性がはるかに高いのである。選択モデルは、これらの方法を一般化したものと見ることが可能である。このモデルは、出版バイアスが結果に影響を与えたと考えられるあらゆる種類のプロセスをモデル化することが可能である。つまり、選択モデルは、出版バイアスの発生に関する非常に単純な仮説、または非常に洗練された仮説に基づいてデータをモデル化するために使用することができるのである。すべての選択モデルの背後にある考え方は、ある研究がその結果に応じて出版 (すなわち「選択」) される確率を、多くの場合非常に理想化された方法で予測する分布を指定することである。通常、この結果は研究の \\(p\\) -値で、選択モデルは、\\(p\\) の値を変化させたときの出版確率を返す関数のように見ることが可能である。いったんこのような選択関数が定義されると、選択的出版による想定バイアスを「除去」して、真の効果量の補正推定値を導き出すために使用することが可能である。しかし、この補正された効果は、私たちが定義した選択モデルが本当に正しい場合にのみ、適切なものとなる。私たちは常に、私たちのモデルがデータにうまく適合しているように見えても、選択過程を説明する多くの方法のうちの一つに過ぎないことを心に留めておかなければならない。出版バイアスがどのような過程を経て私たちの結果を形成したかは、必然的に未知のままである。しかし、選択モデルは、出版がデータに影響を与えたかどうか、そしてより重要なことに、出版がどのようにデータに影響を与えたかを広く評価するために非常に役立つ。この章では、ステップ関数に基づく2種類の (かなり単純な) 選択モデルを取り上げる。そこで、まずステップ関数とは何かを明らかにする。","code":""},{"path":"pub-bias.html","id":"step-function-selmodels","chapter":"9 出版バイアス","heading":"9.2.3.1 ステップ関数選択モデル","text":"選択モデル分析を行うには、効果量モデルと選択モデルの2つの要素が必要である。この2つのモデルは、ある入力値 \\(x\\) を使って、その値の確率を返す 関数 と考えることができる。式 \\(f(x_k)\\) で示される効果量モデルは、ランダム効果モデルに等しい。漢族された効果量 \\(\\hat\\theta_k\\) は、平均効果 \\(\\mu\\) の周りを、サンプリング誤差と群間異質性 \\(\\tau^2\\) から偏差した正規分布に従う。\\(\\mu\\) と研究の標準誤差 \\(\\tau^2\\) と効果量が正規分布に従うことを知っていれば、出版バイアスがないと仮定して、効果量の値 \\(x_k\\) をどの程度かを \\(f(x_k)\\) は予測する。しかし、出版バイアスがあるとき、効果量分布と、 \\(f(x)\\) 自体が現実をうまく現さなくなっている。出版の選択により、いくつかの研究はデータの中で過剰に代表されている。おそらく、驚くほど効果量が高く、サンプルサイズは小さい。このため、知らずして、プールモデルに高い重みを与えてしまっている。よって、いくつかの研究は他の研究よりも高い確率で入っていること、そしてその研究には高い「重み」が与えられていることを考慮した、より現実的な \\(f(x)\\) を導き出す必要がある。これを、重み関数 (weight function) \\(w(p_k)\\) で行う。重み関数は、ある研究 \\(k\\) の \\(p\\) 値から選択確率を与える。これを使って、出版バイアスメカニズムを組み込んだ修正版の \\(f(x_k)\\) を定義する。\\(f^*(x_k)\\) は、以下の式で表される (Vevea Woods 2005)。\\[\\begin{equation}\nf^*(x_k) = \\frac{w(p_k)f(x_k)}{\\int w(p_k) f(x_k) dx_k}\n\\tag{9.17}\n\\end{equation}\\]ここで、分数の分母は \\(w(p_k) f(x_k)\\) の積分である。式中の重み関数 \\(w(p_k)\\) は、仮定選択モデルを表す。\\(w(p_k)\\) は、技術的にはどのような形式にもなるが、よく現されるのはステップ関数である (L. V. Hedges Vevea 1996)。\\(w(p_k)\\) をステップ関数とすると、同じセグメントに入る \\(p_k\\) 値 (例えば 0.05 未満の全ての \\(p\\) 値) は、等しい確率で選択される。この区間別選択確率は \\(\\omega_i\\) と現され、区間ごとに変わる。\\(p\\) 値が取りうる値をいくつかのセグメントに分け、それぞれの選択確率を \\(\\omega_1\\), \\(\\omega_2\\), …, \\(\\omega_c\\) とする。セグメントの幅は、カットポイント (ここでは \\(a_i\\) で示す) によって決まる。カットポイントの数と正確な値は、自由に選ぶことが可能である。例えば、\\(w(p_k)\\) が4つのセグメント(従って4つのカットポイント)を含むとき、その内部構造を次のように定義することができる。\\[\\begin{equation}\n  w(p_k) =\\begin{cases}\n    \\omega_1~~~\\text{}~~~0 \\leq p_k \\leq a_1 \\\\\n    \\omega_2~~~\\text{}~~~a_1 \\leq p_k \\leq a_2 \\\\\n    \\omega_3~~~\\text{}~~~a_2 \\leq p_k \\leq a_3 \\\\\n    \\omega_4~~~\\text{}~~~a_3 \\leq p_k \\leq a_4~~~(\\text{}~~~a_4=1).\n  \\end{cases}\n  \\tag{9.18}\n\\end{equation}\\]任意の \\(p\\) 値に対して、上記の関数は、私たちの値が入る \\(p\\) -値の区間に基づいて、特定の選択確率 \\(\\omega\\) (訳注: \\(\\omega\\) は、「オメガ」と読み、\\(w\\) と似ているが異なる文字である。) を返すことがわかる。これをより具体的にするために、カットポイント \\(a_i\\) と選択確率 \\(\\omega_i\\) に実際の値を記入した選択モデルを定義してみる。例えば、メタ分析における出版バイアスのメカニズムは、3つのカットポイントで記述できると仮定可能である。まず、\\(a_1=\\) 0.025がある。この値は、片側 \\(p\\)-値が 0.025、両側 \\(p\\)-値が 0.05 に相当する。 \\(\\omega_1\\) これはほとんどの研究で使われている従来の有意水準なので、\\(p\\)-値 のより小さい \\(a_1=\\) 0.025 の選択確率はすべて100％であると仮定するのは理にかなっている。結局のところ、結果が陽性だった研究をファイルの引き出しに入れる理由はないのである。次に定義するカットポイントは、\\(a_2=\\) 0.05である。この範囲の結果については、選択確率を80%とする。それでもまだ高いが、明らかに有意な結果と比べると低くなる。次に、\\(a_2=\\) 0.05 から \\(a_3=\\) 0.5 までの大きな区間を指定し、この区間では選択確率が60%になるようにする。最後に、非常に高い \\(\\geq\\) 0.5 の \\(p\\)-値の研究については、\\(\\omega_4=\\) 35% とさらに低い確率を定義する。その結果、以下の Figure 9.2 に描かれているような選択モデルが生まれる。\nFigure 9.2: ステップ関数に基づいた選択モデル。\nステップ関数に基づく選択モデルを定義する場合、通常、カットポイント \\(a_i\\) のみを指定する。これがこのモデルにおける唯一の固定パラメータで、選択確率 \\(\\omega = \\omega_1, \\omega_2, \\dots, \\omega_c\\) はデータから推定する。そして、式9.20の式に基づいて、選択モデルをデータに当てはめることが可能である。このとき、最尤法を使って、\\(\\omega\\) を共同で推定し、さらに、\\(\\mu\\) と \\(\\tau^2\\) の補正推定値 (異なる選択確率を考慮したもの) \\(\\omega\\) を推定する。その結果、\\(\\mu\\) の補正された推定値は、想定される出版バイアスのメカニズムを制御した場合の真の平均効果量を表している。以前は、選択確率 \\(\\omega\\) を0%から100%までのパーセンテージで表現していた。しかし、選択モデルをあてはめるときには、\\(\\omega_i\\) は絶対的な選択確率としてではなく、選択の相対的な尤度 という観点から推定される。これは、ステップ関数の最初の区間に基準値1を与えて、\\(\\omega\\) の他のすべての値は、この基準群との関係で選択の尤度を表すということである。たとえば、2番目の区間で \\(\\omega_2\\) =0.5 と推定すると、この区間の研究は、最初の区間 (\\(\\omega_1 = 1\\)) と比較して、選択される可能性が半分しかなかったことを意味する。もちろん、真の平均効果 \\(\\mu\\) の補正された推定値は、選択モデル自体が適切である場合にのみ正確となる。その目安は、選択モデル・パラメーターの尤度比検定 (LRT) が有意であることである。この検定は、選択がなく、相対選択尤度がすべての区間で同一である (すなわち、\\(\\omega_1 = \\omega_2 = \\dots = \\omega_c\\) ) という帰無仮説に基づく。しかし、この有意性検定は、しばしば反保守的な結果を出すことが分かっている(L. V. Hedges Vevea 1996)ことに注意しなければならない。つまり、その結果は慎重に解釈されるべきである。理論的には、選択モデルで使用するカットポイント \\(a_i\\) の数は ad libitum (自由) に選択することが可能である。しかし、カットポイントを追加するごとに、\\(\\omega_i\\) の値を追加で推定しなければならない。メタ分析の規模にもよるが、これはすぐに、各区間で利用可能な研究がわずかである、という問題につながる。これは、各 \\(\\omega_i\\) を適切に推定することをますます困難にしている。したがって、多くのカットポイントを持つ複雑な選択モデルは、研究の数が多いときにのみ適用できる (つまり、\\(K \\geq\\) 100)。残念ながら、ほとんどのメタ分析では、少数の研究しか含まれていない。これは、非常に少ないカットポイントを持つ単純な選択モデルしか適用できないことを意味する。このような単純なモデルの1つの変形が、次に説明する3パラメータ選択モデルである。このモデルは、含まれる研究の数が少ない場合にも適用できるという利点がある (例: \\(K=\\) 15–20)。","code":""},{"path":"pub-bias.html","id":"three-param-selmodel","chapter":"9 出版バイアス","heading":"9.2.3.1.1 ３パラメータ選択モデル","text":"３パラメータモデルは、カットポイントが1つしかない選択モデルである(McShane, Böckenholt, Hansen 2016)。真の効果 \\(\\mu\\) 、研究間異質性分散 \\(\\tau^2\\) 、第2区間の相対尤度 \\(\\omega_2\\) の3パラメータだけを推定する必要があるので、 3パラメータ モデルと呼ばれている43。3パラメータ選択モデルにおいて、単一のカットポイント \\(a_1\\) は0.025に設定され、これは片側 \\(p\\) -値が0.05であることと等しくなっている。これは、\\(p\\) -値の範囲を、統計的に有意とみなせるものと、有意でないものの2つのビンに分割するものである。したがって、\\(\\omega_2\\) は、有意でない結果が出版用に選択される確率を表している44。{metafor} パッケージの selmodel 関数を使うと、 R に様々な種類の選択モデルを当てはめることが可能である45。また、3パラメータの選択モデルにも使用することが可能であるので、これから試してみよう。前回と同様に、例として ThirdWave データセットを使用する。selmodel 関数は {metafor} の rma 関数によって作成されたメタ分析オブジェクトのみを受け取る (Chapter 8.3.3 を参照)。したがって、まずオブジェクトを作成する必要がある。rma の呼び出しでは、 {meta} の metagen 関数 ( Chapter 4.2.1 ) で使用したものと同じ設定を使用する。m.rma オブジェクトを使用して、selmodel を使用して 3 パラメータの選択モデルを適合させることが可能である。関数にステップ関数を適用することを伝えるために、 type 引数を \"stepfun\" に設定する必要がある。引数 steps にはカットポイントを指定する。このモデルでは \\(a_1\\) =0.025 となる。結果を見てみよう。Model Results の下で、選択モデルの真の平均効果量の推定値が \\(g=\\) 0.59 (95%CI: 0.34-0.84) であることを見ることが可能である。興味深いことに、この推定値は、以前に得たプール効果量( \\(g=\\) 0.58)とほぼ同じである。全体として、これはメタ分析が有意でない結果の低い選択確率によって実質的にバイアスされたことを示さないことを示している。この結果は、 Test Selection Model Parameters によって裏付けられ、有意ではない (\\(\\chi^2_1=\\) 0.034, \\(p=\\) 0.85) ことから、\\(\\omega_1\\) と \\(\\omega_2\\) は互いに有意な差がないことを物語っている。Selection Model Resultsの下に、両方のビンにおける相対的な選択尤度の推定値が表示されている。 \\(\\omega_2=\\) 1.15で、2番目のセグメントの選択確率が1番目のセグメントよりわずかに高いことがわかる。実質的な出版バイアスがある場合は、その逆で、有意でない結果の相対選択尤度は、有意な発見と比較してかなり低くなることが予想される。感度分析として、\\(a_1\\) を 0.025 から 0.05 に変更し、分析を再実行することが可能である。カットポイントを0.05に設定するということは、0.05と0.10の間の両側 \\(p\\) -値は、0.05以下の値と同様に「出版可能」であると仮定することである。例えば、「傾向レベル」で有意な結果が選ばれる可能性がある、あるいは、元の研究の中には、研究グループの違いを評価するために片側検定を使っているものがある、などの可能性がある。このカットポイントの変更で結果が変わるかどうか見てみよう。興味深いことに、異なるパターンが見られる。新しい平均効果量推定値は、\\(g=\\) 0.37で、以前より小さくなっている。さらに、尤度検定は有意で、区間が異なることを示している。\\(\\omega_2=\\) 0.18 で、選択尤度 (両側) \\(p>\\) 0.1 は、(僅かに) 有意な \\(p\\) -値のものよりもずっと低いと見ることが可能である。このことは、プール効果が選択的な報告によってわずかに歪められている可能性を示している。特に、明らかに有意でない結果を示した研究がファイル引き出しに収められたためである。","code":"\nlibrary(metafor)\n\n# 新しいオブジェクトの名前を 'm.rma' に設定\nm.rma <- rma(yi = TE,        \n             sei = seTE,\n             data = ThirdWave,\n             slab = Author,\n             method = \"REML\",\n             test = \"knha\")\nselmodel(m.rma,\n         type = \"stepfun\",\n         steps = 0.025)## [...]\n## \n## Model Results:\n## \n## estimate      se    zval    pval   ci.lb   ci.ub \n##   0.5893  0.1274  4.6260  <.0001  0.3396  0.8390  *** \n## \n## Test for Selection Model Parameters:\n## LRT(df = 1) = 0.0337, p-val = 0.8544\n## \n## Selection Model Results:\n## \n##                      k  estimate      se    pval   ci.lb   ci.ub \n## 0     < p <= 0.025  11    1.0000     ---     ---     ---     ---    \n## 0.025 < p <= 1       7    1.1500  0.8755  0.8639  0.0000  2.8660    \n## \n## ---\n## Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\nselmodel(m.rma,\n         type = \"stepfun\",\n         steps = 0.05)## [...]\n## \n## Model Results:\n## \n## estimate      se    zval    pval   ci.lb   ci.ub \n##   0.3661  0.1755  2.0863  0.0370  0.0222  0.7100  * \n## \n## Test for Selection Model Parameters:\n## LRT(df = 1) = 3.9970, p-val = 0.0456\n## \n## Selection Model Results:\n## \n##                    k  estimate     se   pval   ci.lb   ci.ub \n## 0    < p <= 0.05  15    1.0000    ---    ---     ---     ---      \n## 0.05 < p <= 1      3    0.1786 0.1665 <.0001  0.0000  0.5050  *** \n## \n## ---\n## Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1"},{"path":"pub-bias.html","id":"fixed-weights-selmodel","chapter":"9 出版バイアス","heading":"9.2.3.1.2 固定重み選択モデル","text":"先ほど説明した3パラメータ選択モデルでは、カットポイント \\(a_1\\) を1つだけ指定し、選択尤度はモデルによって自由に推定することが可能である。前述したように、３パラメータ・モデルが1つのカットポイントしか使わないということは、比較的少ない研究のメタ分析にも適用可能である。これは、モデルがいくつかのビンにおいて「研究を使い果たす」可能性が低いことがある。しかし、選択尤度 \\(\\omega_i\\) をデータから推定する必要がなければ、選択モデルの大きなサンプルサイズの必要性を回避することができる。単に各区間の固定値 \\(\\omega_i\\) を与えて、課されたモデルのもとで \\(\\mu\\) の推定値がどうなるかをチェックすればよい。このアプローチは、より複雑な選択モデル (つまり、より多くのカットポイントを持つモデル) を適合させることができる一方で、欠点もある。このような固定重み選択モデルを課す場合、あらかじめ指定された \\(\\omega_i\\) の値がすべて正しいと単純に仮定することになる。しかし、モデルが適切でない場合、平均効果の推定値が信用できなくなることを意味する。したがって、固定ウェイトモデルは、想定した選択プロセスが適用された場合、真の効果量がどのように見えるか**を確認する方法と見なすべきである。Vevea Woods (2005) は、このようなマルチカットポイント、固定重みの選択モデルがどのように見えるかの例をいくつか示している。下のプロットは、中程度の選択と厳しい選択を表すステップ関数の2つの例を示している。感度分析として、これらの選択モデルがメタ分析に適切であると仮定したときに、\\(\\mu\\) の推定値がどのように変化するかを確認することが可能である。これを行うには、上に表示されたモデルで使われたすべてのカットポイント、および各区間に与えられた尤度 \\(\\omega_i\\) を定義する必要がある。これらのパラメータが定義されると、 selmodel を呼び出す際に使用することが可能である。新しいカットポイントは steps 引数に、固定尤度は delta に与える必要がある。中程度の選択を代表する選択モデルを課した場合、プール効果量の推定値は \\(g=\\) 0.52であることがわかる。厳しい選択過程を仮定すると、\\(g=\\) 0.46という少し低い効果が得られる。これらの結果は、選択的出版をコントロールした場合でも、観察された効果がかなり頑健であることを示している。しかし、重要なのは、これらの推定値が有効なのは、私たちが規定した選択モデルが現実を代表している場合のみであるということである。\nその他の選択モデル関数\n\nこの例では、選択モデルの基礎となるステップ関数のみを取り上げた。しかし、選択過程をモデル化するために使える関数はこれだけではないことに注意する必要がある。selmodel\n関数には、例えば、半正規分布、ロジスティック分布、負指数分布など、\n連続\n分布に基づいた関数もいくつか含まれている。これらのモデルは、\ntype 引数の仕様を変更することで選択することができる。\n\n使用できるモデルについてすべて説明することはこのガイドの範囲外だが、\nselmodel\n関数のドキュメントが素晴らしいイントロダクションを提供している。このドキュメントには、\n{metafor} がロードされた後に、 R で\n?selmodel を実行することでアクセスすることができる。\n","code":"\n# カットポイントを定義\na <- c(0.005, 0.01, 0.05, 0.10, 0.25, 0.35, 0.50, \n       0.65, 0.75, 0.90, 0.95, 0.99, 0.995)\n\n# それぞれの信頼区間の選択尤度を定義\n# (moderate/severe selection)\nw.moderate <- c(1, 0.99, 0.95, 0.80, 0.75, 0.65, 0.60, \n                0.55, 0.50, 0.50, 0.50, 0.50, 0.50, 0.50)\nw.severe <- c(1, 0.99, 0.90, 0.75, 0.60, 0.50, 0.40, 0.35, \n              0.30, 0.25, 0.10, 0.10, 0.10, 0.10)\n# 中程度の選択を仮定し、モデルを適合\nselmodel(m.rma, type = \"stepfun\", steps = a, delta = w.moderate)## [...]\n## \n## Model Results:\n## \n## estimate      se    zval    pval   ci.lb   ci.ub \n##   0.5212  0.0935  5.5741  <.0001  0.3380  0.7045  *** \n##\n## [...]\n# 高度の選択を仮定し、モデルを適合\nselmodel(m.rma, type = \"stepfun\", steps = a, delta = w.severe)## [...]\n## Model Results:\n## \n## estimate      se    zval    pval   ci.lb   ci.ub \n##   0.4601  0.1211  3.8009  0.0001  0.2229  0.6974  *** \n## [...]"},{"path":"pub-bias.html","id":"pub-bias-which-method","chapter":"9 出版バイアス","heading":"9.3 どの方法を使うべきか？","text":"以上で、出版バイアスの統計的手法に関する考察を終えたい。この章はかなり長くなってしまったが、なぜこれほど多くの異なるアプローチについて議論したのかと聞きたいのではないだろうか。1つの方法を選び、その方法で出版バイアスのリスクを評価し、次に進むだけでは十分ではないのだろうか？短い答えは「ノー」である。出版バイアスの手法は依然として非常に活発な研究テーマであり、多くの研究が長年にわたってさまざまなアプローチの性能を評価してきました (例: Simonsohn, Nelson, Simmons 2014a; T. D. Stanley 2017; Aert, Wicherts, Assen 2016; McShane, Böckenholt, Hansen 2016; Rücker et al. 2011; Terrin et al. 2003; Peters et al. 2007)。残念なことに、まだ明確な勝者は現れていない。それどころか、どの出版バイアス法も他のすべての方法を一貫して凌駕しているというエビデンスもある (Carter et al. 2019)。出版バイアスの方法が異なると、結果が大きく異なることはよくあることで、実際によくあることである。この章の実践的な演習は、その好例である。毎回同じデータセットを使用してきたが、真のバイアス補正効果の推定値は、実質的にゼロから \\(g=\\) 0.59まで幅があった。このことは、手法の選択が結果、ひいては結論に大きな影響を与える可能性があることを強調している。いくつかの方法は、小規模研究の影響をコントロールするとプール効果が完全に消失することを示したが、他の方法は、最初の発見をほぼ裏付けるものであった。この問題に対処するため、出版バイアスを評価する際には、常に複数の手法を用いることを勧める。どの方法がこのデータに最も適しているか、その結果が信頼に足るかどうかを知ることは、不可能ではないにしても、しばしば困難なことである。前述したように、選択的な報告がどの程度結果に影響を及ぼしているのか、正確なところは常に不明である。しかし、いくつかの出版バイアスの手法を適用することで、信頼できる真の効果の範囲に近いものを作り出すことが可能である。\nこの範囲の大きさは、私たちの解釈を導くために使用することが可能である。例えば、PET-PEESE、p-曲線、３パラメータ選択モデルの両方が、最初のプール効果に近い推定値を得た場合、発見の頑健性に対する信頼性が高まる。しかし、各手法が一致しないことが判明した場合は、そうではない。これは、出版バイアスや小規模研究の影響がより不確実であることを意味し、プールされた効果の信頼性も同様に不確実である。いずれにせよ、出版バイアス法の結果は、常に慎重に解釈されるべきである。出版バイアス分析の結果が論争に発展した例もある–たとえば、文献 “ego-depletion” (Friese et al. 2019) 。出版バイアスをコントロールする最善の方法は、未出版のエビデンスを適切に検索し、出版方法を全面的に変更することであることを心に留めておくことが重要である。私たちメタ分析者が思いつく出版バイアスの統計的「証明」は、どれもせいぜい弱いものである。どの方式を適用するかを決定しやすくするために、各方式の長所と短所の簡単な概要を作成した ( Table 9.1 参照)。\nTable 9.1: 出版バイアスを補正し真の効果量を推定する方法。長所と短所の概要。\nこの表には統計的な考察と実際的な考察の両方が含まれており、包括的でも最終的でもないと見るべきだろう。出版バイアスの方法は現在進行中の研究分野であり、より多くのエビデンスが確立されれば、状況は違ってくる可能性がある。\n最後に、研究間異質性が高い場合に許容できる結果を提供する方法は、現在のところ存在しないことに留意が必要である (Aert, Wicherts, Assen 2016、すなわち \\(^2 \\approx\\) 75%)。つまり、異質性が非常に高いメタ分析の出版バイアス分析は、完全に避けるのが最善である。外れ値を含まない解析やより均質なサブグループでの解析は、しばしば実用的な回避策として使用できるが、一般的な問題を解決するものではない。\\[\\tag*{$\\blacksquare$}\\]","code":""},{"path":"pub-bias.html","id":"演習問題-8","chapter":"9 出版バイアス","heading":"9.4 演習問題","text":"\n知識を試そう！\n\n「出版バイアス」という言葉はどのように定義できるか？なぜメタ分析で問題になるのか？\n\n他にどのような報告バイアスがあるか？少なくとも3つ挙げて説明しなさい。\n\n疑わしい研究慣行 (QRP)\nを2つ挙げ、どのようにメタ分析の妥当性を脅かすかを説明しなさい。\n\n小規模研究効果法の基本的な前提を説明しなさい。\n\nデータが小規模研究の効果を示すことがわかったとき、自動的に出版バイアスがあることを意味するか？\n\np-曲線は、メタ分析に含まれるすべての研究の真の効果を推定するのか、それとも「有意な」効果量を持つすべての研究の真の効果だけを推定するのか、どちらか？\n\nどの出版バイアス法が一番性能が良いか。\n\n問題の解答は、本書の巻末 Appendix\nにある。\n","code":""},{"path":"pub-bias.html","id":"要約-5","chapter":"9 出版バイアス","heading":"9.5 要約","text":"出版バイアスは、ある研究が出版された文献の中で体系的に欠落している場合に発生し、その結果、私たちのメタ分析においても発生した。厳密には、出版バイアスは、ある研究が出版される確率がその結果に依存する場合に発生した。しかし、その他にも様々な報告バイアスが存在した。これらの報告バイアスも、ある知見がメタ分析に採用される可能性に影響を及ぼした。例えば、引用バイアス、言語バイアス、アウトカムバイアスなどである。出版バイアスは、ある研究が出版された文献の中で体系的に欠落している場合に発生し、その結果、私たちのメタ分析においても発生した。厳密には、出版バイアスは、ある研究が出版される確率がその結果に依存する場合に発生した。しかし、その他にも様々な報告バイアスが存在した。これらの報告バイアスも、ある知見がメタ分析に採用される可能性に影響を及ぼした。例えば、引用バイアス、言語バイアス、アウトカムバイアスなどである。また、例えば疑わしい研究の実施 (QRP) などにより、発表されたエビデンスに偏りがある可能性もある。よくあるQRPは、\\(p\\) -hackingとHARKingの2つで、どちらもメタ分析で効果を過大評価するリスクを高める可能性がある。また、例えば疑わしい研究の実施 (QRP) などにより、発表されたエビデンスに偏りがある可能性もある。よくあるQRPは、\\(p\\) -hackingとHARKingの2つで、どちらもメタ分析で効果を過大評価するリスクを高める可能性がある。多くの出版バイアス法は、小規模研究効果という考えに基づいている。これらのアプローチは、驚くほど高い効果量を持つ小規模な研究だけが有意な結果を得て、それゆえ出版用に選択されると仮定している。これは、非対称のファンネルプロットをもたらし、出版バイアスの徴候となり得る。しかし、そうである必要はない。小規模研究の効果には、さまざまな「良性」の原因が考えられる。多くの出版バイアス法は、小規模研究効果という考えに基づいている。これらのアプローチは、驚くほど高い効果量を持つ小規模な研究だけが有意な結果を得て、それゆえ出版用に選択されると仮定している。これは、非対称のファンネルプロットをもたらし、出版バイアスの徴候となり得る。しかし、そうである必要はない。小規模研究の効果には、さまざまな「良性」の原因が考えられる。比較的新しい手法であるp-curveは、データ中の有意な効果( \\(p<\\) 0.05 )のパターンを見るだけで、証拠能力をコントロールできるという考えに基づいている。これは、真の効果の有無の検定に使用でき、その大きさを推定することができる。比較的新しい手法であるp-curveは、データ中の有意な効果( \\(p<\\) 0.05 )のパターンを見るだけで、証拠能力をコントロールできるという考えに基づいている。これは、真の効果の有無の検定に使用でき、その大きさを推定することができる。選択モデルは非常に汎用性の高い手法で、様々な出版バイアスのプロセスをモデル化するために使用することが可能である。しかし、想定したモデルが適切である場合にのみ有効な結果が得られ、しばしば非常に多くの研究を必要とした。非常にシンプルな選択モデルである3パラメータモデルも、小規模なデータセットに使用することが可能である。選択モデルは非常に汎用性の高い手法で、様々な出版バイアスのプロセスをモデル化するために使用することが可能である。しかし、想定したモデルが適切である場合にのみ有効な結果が得られ、しばしば非常に多くの研究を必要とした。非常にシンプルな選択モデルである3パラメータモデルも、小規模なデータセットに使用することが可能である。出版バイアスの手法は、他の手法を常に凌駕するものではない。したがって、常に複数の手法を適用し、補正後の効果量を慎重に解釈することが推奨される。未発表のエビデンスの徹底的な検索は、現在の統計的アプローチよりもはるかに優れた方法で出版バイアスのリスクを軽減する。出版バイアスの手法は、他の手法を常に凌駕するものではない。したがって、常に複数の手法を適用し、補正後の効果量を慎重に解釈することが推奨される。未発表のエビデンスの徹底的な検索は、現在の統計的アプローチよりもはるかに優れた方法で出版バイアスのリスクを軽減する。","code":""},{"path":"multilevel-ma.html","id":"multilevel-ma","chapter":"10 「マルチレベル」メタ分析","heading":"10 「マルチレベル」メタ分析","text":"高\n度な分析へようこそ。このガイドの前のパートでは、ほとんどすべてのメタ分析に非常に関連すると思われるトピックに深く潜ってみよう。この背景を踏まえて、より高度なテクニックに進む。以下の方法は、基礎となる数学あるいは R での実装がより複雑であるため、「高度」であるとみなした。しかし、このガイドの前の章を読んでいれば、この後に続く内容を理解し、実装するのに十分な能力を備えているはずである。以下のトピックの多くは、それ自身の本に値するものであり、ここで取り上げるものは、簡単な紹介としてのみ考慮されるべきである。ここで取り上げた内容は、あくまでも簡単な紹介と考えていただきたい。最初の章では、「マルチレベル」メタ分析というトピックを扱う。なぜ「マルチレベル 」という言葉をカギカッコで囲むのか、不思議に思われるだろう。ある研究を「マルチレベル」メタ分析と表現することは、暗に「標準的な」メタ分析に比べて特別なものであることを示している。しかし、これは正しくはない。あらゆるメタ分析モデルは、結果をプールするために、データのマルチレベル構造を前提にしている (Pastor Lazowski 2018)。前の章で、私たちはすでに何度かマルチレベル (メタ分析) モデルを、知らないうちに使っている。マルチレベルメタ分析というと、すぐに思いつくのは 3 レベルメタ分析モデルではないだろうか。このモデルは、確かに私たちが既に知っている固定効果モデルやランダム効果モデルとは多少異なる。そこで、この章では、まず、なぜメタ分析が自然にデータのマルチレベル構造意味をするのか、そして、従来のメタ分析をどのようにして 3 レベルモデルに拡張できるのかを説明する。また、いつものように、このようなモデルを R でどのように適合させることができるかを、実際の例を使って見ていこう。","code":""},{"path":"multilevel-ma.html","id":"multilevel-nature","chapter":"10 「マルチレベル」メタ分析","heading":"10.1 メタ分析のマルチレベル性","text":"メタ分析がなぜデフォルトでマルチレベルになるのかを知るために、Chapter 4.1.2 で説明したランダム効果モデルの式に戻ってみよう。\\[\\begin{equation}\n\\hat\\theta_k = \\mu + \\epsilon_k + \\zeta_k\n\\tag{10.1}\n\\end{equation}\\]ランダム効果モデルで \\(\\epsilon_k\\) (「イプシロン・k」と読む) と \\(\\zeta_k\\) (「ゼータ・k」と読む) という項が導入されているのは、2 つの変動源があると仮定しているからだと説明してきた。1つ目は、個々の研究のサンプルエラー( \\(\\epsilon_k\\) )によるもので、これにより効果量推定値が真の効果量 \\(\\theta_k\\) から差が出ることになる。2 つ目の \\(\\zeta_k\\) は、研究間の異質性を表している。この異質性は、ある研究 \\(k\\) の真の効果量が、やはり真の効果量の包括的な分布の一部に過ぎないという事実によって引き起こされる。この分布は、個々の真の効果量 \\(\\theta_k\\) が引き出されたところから導かれる。したがって、ランダム効果モデルにおける私たちの目的は、\\(\\mu\\) (「ミュー」と読む) で示される真の効果量の分布の平均を推定することである。\\(\\epsilon_k\\) と \\(\\zeta_k\\) の 2 つの誤差項は、メタ分析データにおける「参加者」レベル (レベル 1) と「研究」レベル (レベル2) の 2 つのレベルに対応している。以下の Figure 10.1 は、この構造を象徴している。\nFigure 10.1: 従来のランダム効果モデルのマルチレベル構造\n最下層 (レベル 1) には、参加者 (研究分野によっては、患者、検体など) がいる。これらの参加者は、より大きな単位であるメタ分析に含まれる研究の一部である。この上にある研究の層は、私たちの第２レベルを構成している。メタ分析を行う場合、レベル1のデータは通常すでに「プール」された形で届く (例えば、論文の著者は生データの代わりに研究サンプルの平均と標準偏差を提供してくれる)。しかし、レベル 2 (研究レベル) のプールは、メタ分析の一部として実行されなければならない。伝統的に、このようなタイプのデータはネストと呼ばれ、参加者が研究内に「ネスト」されていると言うことが可能である。ここで、ランダム効果モデルの式 (10.1) に戻ってみよう。この式は暗黙のうちにメタ分析データのマルチレベル構造を記述している。これをより明確にするために、式を 2 つに分割し、それぞれが 2 つのレベルのうちの 1 つに対応するようにする必要がある。そうすると、次のような結果が得られる。レベル1 (参加者) モデル: \\[\\begin{equation}\n\\hat\\theta_k = \\theta_k + \\epsilon_k\n\\tag{10.2}\n\\end{equation}\\]レベル2 (研究) モデル: \\[\\begin{equation}\n\\theta_k = \\mu + \\zeta_k\n\\tag{10.3}\n\\end{equation}\\]すでにお気づきかもしれないが、最初の式の \\(\\theta_k\\) を 2 番目の式の定義に置き換えればよい。そうすると、先ほどのランダム効果モデルの式とまったく同じ式が得られる。固定効果モデルもこのように書くことが可能である。\\(\\zeta_k\\) をゼロに設定するだけである。明らかに、私たちのメタ分析モデルは、すでにマルチレベルの特性を 「内蔵」している。これは、私たちのデータでは、参加者が研究内でネストされていると仮定しているので、この特性を示している。このように、メタ分析には多階層構造が備わっていることがわかる。データを生成した特定のメカニズムをよりよく捉えるために、この構造をさらに拡張することが可能である。そこで、3 レベルモデル (Cheung 2014; Assink, Wibbelink, et al. 2016) の出番となる。統計的独立性は、メタ分析で効果量をプールするときの中心的な前提条件の一つである。効果量の間に依存関係がある (効果量に相関がある) 場合、異質性を人為的に減少させ、その結果、偽陽性の結果につながる可能性がある。この問題は分析単位エラーとして知られており、以前すでに取り上げた (Chapter 3.5.2 参照)。効果量の依存性は、様々な原因から生じる可能性がある (Cheung 2014)。個々の研究の著者によって導入された依存性: 例えば、研究を実施する科学者が複数のサイトからデータを収集したり、複数の介入を一つの対照群と比較したり、同じアウトカムを測定するために異なる質問票を使用したりすることがある。これらのシナリオのすべてにおいて、報告されたデータには何らかの依存性があると考えることが可能である。個々の研究の著者によって導入された依存性: 例えば、研究を実施する科学者が複数のサイトからデータを収集したり、複数の介入を一つの対照群と比較したり、同じアウトカムを測定するために異なる質問票を使用したりすることがある。これらのシナリオのすべてにおいて、報告されたデータには何らかの依存性があると考えることが可能である。メタ分析者自身によって導入される依存性: 例として、ある心理メカニズムに注目したメタ分析を考えてみよう。このメタ分析には、世界の異なる文化圏 (例えば、東アジアと西欧社会) で行われた研究が含まれている。心理メカニズムの種類によっては、同じ文化圏で行われた研究の方が、異なる文化圏で行われた研究よりも結果が似ていることもあり得る。メタ分析者自身によって導入される依存性: 例として、ある心理メカニズムに注目したメタ分析を考えてみよう。このメタ分析には、世界の異なる文化圏 (例えば、東アジアと西欧社会) で行われた研究が含まれている。心理メカニズムの種類によっては、同じ文化圏で行われた研究の方が、異なる文化圏で行われた研究よりも結果が似ていることもあり得る。メタ分析モデルの構造に第 3 の層を組み込むことで、このような依存性を考慮することができる。例えば、異なる質問票に基づく効果量が研究内でネストされているモデルが考えられる。あるいは、研究が文化圏にネストされているモデルを作成することもできる。これにより、次の図に示すような 3 階層のメタ分析モデルが構築される。3 レベルのモデルには 3 つのプール段階があることがわかる。まず、研究者自身が、一次研究の個々の参加者の結果を「プール」し、集約した効果量を報告する。次に、レベル 2 において、これらの効果量は、\\(\\kappa\\) (「カッパ」と読む) で示されるいくつかのクラスタ内にネストされている。これらのクラスタは、個々の研究 (すなわち、多くの効果量が1つの研究にネストされている)、または研究のサブグループ (すなわち、多くの研究が1つのサブグループにネストされており、各研究は 1 つの効果量にのみ寄与する) のいずれかである可能性がある。最後に、集計されたクラスタ効果をプールすると、全体の真の効果量 \\(\\mu\\) になる。概念的には、この平均効果は、固定効果モデルまたはランダム効果モデルでプールされた真の効果 \\(\\mu\\) (「ミュー」と読む) に非常に近いものである。しかし、その違いは、私たちのデータにおける依存効果量を明示的に考慮したモデルに基づいている点にある。3 レベルモデルの式は、これまでと同じレベル表記で書き表すことができる。最大の違いは、2 つの数式ではなく、3 つの数式を定義する必要があることだ。レベル1モデル: \\[\\begin{equation}\n\\hat\\theta_{ij} = \\theta_{ij} + \\epsilon_{ij}\n\\tag{10.4}\n\\end{equation}\\]レベル2モデル: \\[\\begin{equation}\n\\theta_{ij} = \\kappa_{j} + \\zeta_{(2)ij}\n\\tag{10.5}\n\\end{equation}\\]レベル3モデル: \\[\\begin{equation}\n\\kappa_{j} = \\mu + \\zeta_{(3)j}\n\\tag{10.6}\n\\end{equation}\\]ここで、\\(\\hat\\theta_{ij}\\) は、真の効果量 \\(\\theta_{ij}\\) の推定値である。 \\(ij\\) という用語は、「クラスタ \\(j\\) にネストされているある効果量 \\(\\) 」と読み替えることができる。パラメータ \\(\\kappa_{j}\\) はクラスタ \\(j\\) の平均効果量であり、\\(\\mu\\) は全体的な平均母集団効果である。前と同じように、これらの数式をつなぎ合わせて、数式を 1 行に減らすことができる。\\[\\begin{equation}\n\\hat\\theta_{ij} = \\mu + \\zeta_{(2)ij} + \\zeta_{(3)j} + \\epsilon_{ij}\n\\tag{10.7}\n\\end{equation}\\]ランダム効果モデルとは異なり、この式には2つの不均質性項が含まれていることがわかる。一つは \\(\\zeta_{(2)ij}\\)で、これはレベル２のクラスタ内 (within-cluster) 異質性である (つまり、 クラスタ \\(j\\) 内の真の効果量は、平均 \\(\\kappa_j\\) の分布に従う)。もう一つは \\(\\zeta_{(3)j}\\) で、これはレベル 3 のクラスタ間 (-cluster) 異質性である。結果、3 レベルメタ分析適合モデルでは、異質性分散 \\(\\tau^2\\) は一つではなく、レベル 2 用とレベル 3 用の 2 つ推計しなければならない。\n{metafor} パッケージは、特にメタ分析的な 3 レベルモデルの適合に適している。これは、(制限付き) 最尤法を用いて行う。以前は、メタ分析の実行に主に {meta} パッケージの関数を使用していた。なぜなら {meta} の方が若干専門的でなく、初心者に適しているためである。しかし、Chapter 8.3.3 で見たように、 {metafor} パッケージも、データを正しく準備すればかなり使いやすくなっている。具体的にどのように {metafor} を使って R の 3 レベルモデルに適合させるかは、次のセクションのトピックになる46。","code":""},{"path":"multilevel-ma.html","id":"multilevel-R","chapter":"10 「マルチレベル」メタ分析","heading":"10.2 R で３レベルのメタ分析モデルを適合","text":"前述したように、３レベルのメタ分析モデルを適合させるためには、 {metafor} パッケージが必要である。そのため、まずライブラリからロードする必要がある。この例では、Chernobyl データセットを使用する。このデータセットは、1986年のチェルノブイリ原発事故 (Møller Mousseau 2015) によって引き起こされた電離放射線 (「核汚染」) とヒトの突然変異率の相関を調べた実際のメタ分析に緩く基づいている。\n“Chernobyl” データセット\n\nChernobyl データセットは {dmetar}\nパッケージに含まれている。{dmetar}\nをインストールし、ライブラリからロードした後、\ndata(TherapyFormats) を実行すると、自動的に R\n環境にデータセットが保存される。これでデータセットが使用できるようになる。\n\n{dmetar} がインストールされていない場合は、Internet\nから .rda\nファイルとしてデータセットをダウンロードし、作業ディレクトリに保存してから、R\nStudio ウィンドウでクリックしてインポートすることが可能である。\nデータの一般的な構造を見るために、head 関数を使用しよう。これは、先ほどグローバル環境にロードしたデータフレームの最初の 6 行を表示する。このデータセットには 8 つの列がある。最初の列は author で、研究の名前が表示されている。cor 列は放射線被曝と突然変異率の (未変換の) 相関を示し、n はサンプルサイズを示す。z、se.z、var.z 列は Fisher- \\(z\\) で変換した相関 (Chapter 3.2.3.1) とその標準誤差および分散である。radiation 列はモデレーターとして機能し、効果量を全体的に放射線被曝量の低い (low) サブグループと高いサブグループに分割する。es.id 列には、各効果量 (すなわち、データフレームの各行) の識別用 ID を格納している。このデータセットで特徴的なことは、 author に繰り返し入力されていることである。これは、このメタ分析におけるほとんどの研究が、1つ以上の観察された効果量に貢献しているからである。いくつかの研究では、突然変異を測定するためにいくつかの方法を用いたり、複数のタイプの指標となる人物 (例えば、被曝した両親とその子孫) を用いたりしており、これらすべてが研究ごとに複数の効果をもたらす。この構造を見ると、このデータセットの効果量が独立していないことは明らかである。これらはネスト構造になっており、様々な効果量が 1 つの研究にネストされている。したがって、私たちのデータにおけるこれらの依存性を適切にモデル化するために、3 レベルのメタ分析に適合させることは良いアイデアだろう。","code":"\nlibrary(metafor)\n# Load data set from 'dmetar'\nlibrary(dmetar)\ndata(\"Chernobyl\")\nhead(Chernobyl)##                       author  cor   n    z se.z var.z radiation es.id\n## 1 Aghajanyan & Suskov (2009) 0.20  91 0.20 0.10  0.01       low  id_1\n## 2 Aghajanyan & Suskov (2009) 0.26  91 0.27 0.10  0.01       low  id_2\n## 3 Aghajanyan & Suskov (2009) 0.20  92 0.20 0.10  0.01       low  id_3\n## 4 Aghajanyan & Suskov (2009) 0.26  92 0.27 0.10  0.01       low  id_4\n## 5     Alexanin et al. (2010) 0.93 559 1.67 0.04  0.00       low  id_5\n## 6     Alexanin et al. (2010) 0.44 559 0.47 0.04  0.00       low  id_6"},{"path":"multilevel-ma.html","id":"モデルの適合","chapter":"10 「マルチレベル」メタ分析","heading":"10.2.1 モデルの適合","text":"3 レベルのメタ分析モデルは、{metafor} の rma.mv 関数を使用して適合させることが可能である。以下は、この関数の最も重要な引数のリストと、それらの引数の指定方法である。yi. 計算された効果量を含むデータセットの列の名前。この例では、これは z である。Fisher- \\(z\\) で変換された相関は、“未変換”の相関よりも数学的特性が優れていることがある。yi. 計算された効果量を含むデータセットの列の名前。この例では、これは z である。Fisher- \\(z\\) で変換された相関は、“未変換”の相関よりも数学的特性が優れていることがある。V. 計算された効果量の 分散 を含む、データセットの列の名前。この場合、var.z となる。また、\\(SE_k^2 = v_k\\) であるから、効果量の 2 乗標準誤差を使用することも可能である。V. 計算された効果量の 分散 を含む、データセットの列の名前。この場合、var.z となる。また、\\(SE_k^2 = v_k\\) であるから、効果量の 2 乗標準誤差を使用することも可能である。slab. {meta} の studlab と同様に、研究ラベルを含むデータセットの列の名前。slab. {meta} の studlab と同様に、研究ラベルを含むデータセットの列の名前。data. データセットの名前。data. データセットの名前。test. 回帰係数に適用する検定。\"z\" (デフォルト) と \"t\" (推奨; Knapp-Hartung 法に類似した検定を使用) から選択することが可能である。test. 回帰係数に適用する検定。\"z\" (デフォルト) と \"t\" (推奨; Knapp-Hartung 法に類似した検定を使用) から選択することが可能である。method. モデルのパラメータを推定するために用いる手法。REML (推奨; 制限付き最尤法) と ML (最尤法) の両方が利用可能。他のタイプの研究間不均一性推定量 (例えば Paule-Mandel) はここでは適用できないことに注意しておこう。method. モデルのパラメータを推定するために用いる手法。REML (推奨; 制限付き最尤法) と ML (最尤法) の両方が利用可能。他のタイプの研究間不均一性推定量 (例えば Paule-Mandel) はここでは適用できないことに注意しておこう。しかし、最も重要な議論は、randomである。間違いなく、最も厄介なものでもある。この引数では、(ネストされた) ランダム効果を定義する数式を指定する。3 レベルモデルの場合、式は常に ~ 1 で始まり、縦棒 | が続く。縦棒の後ろでは、グループ化変数 (研究、測定、地域など) にランダム効果を割り当てる。このグルーピング変数は、各グループに異なる効果 (すなわち切片) を仮定するようにモデルに指示すので、しばしば ランダム化切片 と呼ばれる。3 レベルモデルでは、2 つのグループ化変数がある。1 つはレベル 2 で、もう 1 つはレベル 3 である。私たちは、これらのグルーピング変数がネストになっていると仮定する。すなわち、レベル 2 でのいくつかの効果が一緒になって、レベル 3 でのより大きなクラスタを構成している。このようなネストしたランダム効果を仮定するために、rma.mv に特別な方法を指示すことが可能である。これは、スラッシュ (/) を使用して、上位と下位のグループ化変数を分離するものである。/ の左側には、レベル 3 (クラスタ) 変数を入れる。右側には、大きなクラスタにネストされた低次の変数を入れる。したがって、式の一般的な構造は ~ 1 | cluster/effects_within_cluster のようになる。この例では、個々の効果量 (レベル2； es.id で定義) は、研究 (レベル 3; author で定義) 内にネストされていると仮定している。この結果、以下の式が得られる: ~ 1 | author/es.id。完全な rma.mv 関数呼び出しは次のようになる。出力には full.model という名前を付けることとした。結果の概要を表示すには、summary 関数を使用する。まず、「分散成分」 (Variance Components) を見てみよう。ここでは、モデルの各レベルについて計算されたランダム効果分散を見ることが可能である。最初の sigma^2.1 は、レベル 3 のクラスタ間分散 (cluster variance) を示している 。この例では、(クラスタがこのモデルにおける研究を表しているため) これは従来のメタ分析における研究間異質性分散 \\(\\tau^2\\) に相当する。2 番目の分散成分 sigma^2.2 は、クラスタ内の分散 (within cluster variance) (レベル 2) を示している。nlvls の列では、各レベルのグループの数を示している。レベル 3 は 14 グループあり、\\(K=\\) 14 件の研究に相当する。2 行目に示すように、これらの 14 の研究は、33 の効果量を含む。Model Results の下に、プール効果の推定値がある。\\(z=\\) 0.52 (95%CI: 0.25–0.80) である。解釈を容易にするために、効果を正規の相関に変換することが推奨される。これは、 {esc} パッケージの convert_z2r 関数を使用して行うことが可能である。この結果、約 \\(r \\approx\\) 0.48 の相関が得られることがわかる。これは大きいといえるだろう。チェルノブイリの放射線被曝と突然変異率の間には、かなりの相関があるようだ。出力された「異質性の検定」は、私たちのデータにおける真の効果量の差を指摘している (\\(p<\\) 0.001)。しかし、この結果は、あまり有益ではない。私たちは、私たちのモデルの各レベルによって捕捉された異質性の分散の正確な量に、より興味がある。異質性のどれだけが研究内の差 (レベル 2) に起因し、どれだけが研究間の差 (レベル 3) に起因しているかを知ることは良いことだろう。","code":"\nfull.model <- rma.mv(yi = z, \n                     V = var.z, \n                     slab = author,\n                     data = Chernobyl,\n                     random = ~ 1 | author/es.id, \n                     test = \"t\", \n                     method = \"REML\")\nsummary(full.model)## Multivariate Meta-Analysis Model (k = 33; method: REML)\n## [...]   \n## Variance Components:\n## \n##             estim    sqrt  nlvls  fixed        factor \n## sigma^2.1  0.1788  0.4229     14     no        author \n## sigma^2.2  0.1194  0.3455     33     no  author/es.id \n## \n## Test for Heterogeneity:\n## Q(df = 32) = 4195.8268, p-val < .0001\n## \n## Model Results:\n## \n## estimate      se    tval    pval   ci.lb   ci.ub \n##   0.5231  0.1341  3.9008  0.0005  0.2500  0.7963  *** \n## [...]\nlibrary(esc)\nconvert_z2r(0.52)## [1] 0.4777"},{"path":"multilevel-ma.html","id":"レベル間の分散分布","chapter":"10 「マルチレベル」メタ分析","heading":"10.2.2 レベル間の分散分布","text":"\\(^2\\) のマルチレベル版を計算することでこの疑問に答えることができる (Cheung 2014)。従来のメタ分析では、\\(^2\\) はサンプリングエラーに起因しない変動量を表した (Chapter 5.1.2 ;すなわち、研究間異質性)。3 レベルモデルでは、この異質性の分散は 2 つの部分に分けられる。1 つはクラスタ内の真の効果量の差に起因し、もう 1 つはクラスタ間の変量に起因するものである。したがって、レベル 2 またはレベル 3 のいずれかに関連する全変動のパーセンテージを定量化する 3 つの値 (\\(^2\\)) が存在する。\n“var.comp” 関数\n\nvar.comp 関数は、{dmetar}\nパッケージに含まれている。{dmetar}\nがインストールされ、コンピュータに読み込まれると、この関数を使用できるようになる。もし、{dmetar}\nをインストールしていない場合は、以下の手順でインストールできる。\n\n関数のソースコードにアクセスする オンライン.\n\nソースコード全体をコンソール (R Studio の左下ペイン)\nにコピー＆ペーストし、Enterキーを押して、 R\nに関数を「学習」させる。\n\n{ggplot2}\nパッケージがインストールされ、ロードされていることを確認する。\nvar.comp 関数は、適合した rma.mv モデルのみを入力として必要とする。出力を i2 に保存し、summary 関数で結果を表示する。出力では、3 つのレベルのそれぞれに起因する全分散のパーセンテージが表示される。レベル 1 のサンプル誤差の分散は非常に小さく、およそ 1% を占めるだけである。クラスタ内の異質性の分散である \\(^2_{\\text{Level 2}}\\) の値ははるかに高く、合計で約 40% になる。しかし、最も大きな割合を占めるのはレベル 3 である。クラスタ間 (ここでは研究間) の異質性は、私たちのデータにおける全変動のうち、\\(^2_{\\text{Level 3}}=\\) 59% を占めている。全体として、3 番目のレベルではかなりの研究間異質性があることを示している。しかし、全体の分散の 3 分の 1 以上という大きな割合が、研究内の差 (differences within studies) によって説明できることもわかる。また、var.comp の出力を plot 関数に代入すると、この全分散の分布を視覚化することができる。","code":"\ni2 <- var.comp(full.model)\nsummary(i2)##         % of total variance    I2\n## Level 1            1.254966   ---\n## Level 2           39.525499 39.53\n## Level 3           59.219534 59.22\n## Total I2: 98.75%\nplot(i2)"},{"path":"multilevel-ma.html","id":"モデルの比較","chapter":"10 「マルチレベル」メタ分析","heading":"10.2.3 モデルの比較","text":"3 レベルモデルの適合は、2 レベルモデルよりもデータの変動をよりよく表す場合にのみ意味がある。2 レベルモデルが 3 レベルモデルに匹敵する適合度を示すことがわかったら、オッカムのカミソリを適用すべきである。というのも、3 レベルモデルより 2 レベルモデルの方が複雑でなく、かつデータをうまく説明できることがある。幸運なことに、{metafor} パッケージは、3 レベルモデルとレベルを一つ取り除いたモデルを比較することが可能である。これを行うには、再び rma.mv 関数を使用した。しかし、今回は、1 つのレベルの分散成分をゼロに設定した。これは、 sigma2 パラメータを指定することにより可能である。c(level 3, level 2)という一般的な形式のベクトルを用意する必要がある。このベクトルには、分散成分をゼロにする場合は 0 を記入し、データからパラメータを推定する場合は NA を使用する。この例では、個々の効果量を研究に入れ込むことでモデルが改善されたかどうかを確認することは理にかなっている。したがって、私たちは、研究間の異質性を表すレベル3分散がゼロに設定されたモデルを適合させる。これは、すべての効果量が独立であると仮定する (独立でないことは分かっている) 単純なランダム効果モデルの適合と同じである。レベル 3 はゼロで一定なので、sigma2 の入力は c(0, NA) となる。この結果、以下のように rma.mv が呼び出され、その出力が l3.removed という名前で保存される。出力では、 sigma^2.1 がゼロに設定されていることがわかる。全体の効果も変化している。しかし、この結果は 3 レベルモデルのものよりも良いのだろうか？これを評価するために、anova 関数を使って両モデルを比較することが可能である。2 レベルの「縮小」モデルに比べ、「完全」 (3 レベル) モデルはより適合度が高いことがわかる。赤池情報量規準 (Akaike Information Criterion, AIC) とベイズ情報量規準 (Bayesian Information Criterion, BIC) は、このモデルの方が低く、良好な性能を示している。両モデルを比較した尤度比検定 (Likelihood Ratio Test, LRT) は有意であり ( \\(\\chi^2_1=\\) 16.1, \\(p<\\) 0.001)、同じ方向を向いている。3 レベルモデルは、1 つの追加パラメータを導入したが (すなわち、自由度が 2 ではなく 3)、この追加された複雑さは正当化されるようだと言える。ネストのデータ構造のモデリングは、おそらく良いアイデアで、プール効果の推定値を改善してきた。しかし、3 レベル構造を維持することには、たとえそれが有意に優れた適合性を提供しない場合であっても、しばしば正当な理由があることに留意してみよう。特に、3 レベルモデルが確かな理論的根拠に基づいていると考えられる場合には、3 レベルモデルを維持することは理にかなっている。例えば、複数の効果量を持つ研究がデータに含まれている場合、これらの効果が独立していることはありえないということがわかる。したがって、ネストされたモデルを維持することは、データがどのように「生成」されたかをより適切に表現しているため、理にかなっている。もし、この例の anova の結果が 2 レベル解を支持していたなら、私たちは研究内の効果は大きく均質であると結論付けたことだろう。しかし、いずれにせよ、3 レベルモデルの結果を報告しただろう。これは、3 レベルモデルがデータ生成過程をよりよく表現していることを知っていることがある。クラスタ変数の重要性が不明確な場合、状況は多少異なる。たとえば、３レベル・モデルにおいて、レベル 3 のクラスタが異なる文化圏を表すとした。研究対象の現象が文化間の変化を示さないことがわかったら、3 番目のレベルを削除して、代わりに 2 レベル・モデルを使用してもまったく問題ない。","code":"\nl3.removed <- rma.mv(yi = z, \n                     V = var.z, \n                     slab = author,\n                     data = Chernobyl,\n                     random = ~ 1 | author/es.id, \n                     test = \"t\", \n                     method = \"REML\",\n                     sigma2 =  c(0, NA))\n\nsummary(l3.removed)## [...]\n## Variance Components:\n## \n##             estim    sqrt  nlvls  fixed        factor \n## sigma^2.1  0.0000  0.0000     14    yes        author \n## sigma^2.2  0.3550  0.5959     33     no  author/es.id \n## \n## Test for Heterogeneity:\n## Q(df = 32) = 4195.8268, p-val < .0001\n## \n## Model Results:\n## \n## estimate      se    tval    pval   ci.lb   ci.ub \n##   0.5985  0.1051  5.6938  <.0001  0.3844  0.8126  *** \n## [...]\nanova(full.model, l3.removed)##         df   AIC   BIC  AICc logLik   LRT   pval      QE \n## Full     3 48.24 52.64 49.10 -21.12              4195.82 \n## Reduced  2 62.34 65.27 62.76 -29.17 16.10 <.0001 4195.82"},{"path":"multilevel-ma.html","id":"three-level-subgroup","chapter":"10 「マルチレベル」メタ分析","heading":"10.3 ３レベルモデルにおけるサブグループ解析","text":"\n３レベルモデルが設定されると、全体効果の推定モデレータを評価することも可能になる。このガイドの前では、サブグループ解析が、ダミー・コード化された予測変数 ( Chapter 8.1 ) のメタ回帰モデルとして表現できることを発見してきた。同様にして、私たちは 「マルチレベル」モデルに回帰項を追加することができ、これは ３レベル混合効果モデル につながる。\\[\\begin{equation}\n\\hat\\theta_{ij} = \\theta + \\beta x_i + \\zeta_{(2)ij} + \\zeta_{(3)j} + \\epsilon_{ij}\n\\tag{10.8}\n\\end{equation}\\]ここで、\\(\\theta\\) は切片、\\(\\beta\\) は予測変数 \\(x\\) の回帰重みである。\\(x_i\\) をダミー (Chapter 8.1) に置き換えると、サブグループ解析に使用できるモデルが得られる。\\(x\\) が連続的であるとき、上記の式は 3 レベルのメタ回帰モデルを表す。カテゴリまたは連続の予測変数は、rma.mv で mods 引数を用いて指定することが可能である。この引数には、チルダ (~) で始まる数式と、その後に予測変数の名前を指定する。複数の予測変数 (例: ~ var1 + var2) を指定することで、多重メタ回帰を行うことも可能である。チェルノブイリの例では、サンプルに含まれる放射線の量 (低、中、高) によって相関が異なるかどうかを確認したい。この情報は、データセットの radiation 列で提供されている。このコードを使って３レベルモデレータモデルを適合させることができる。最初の重要な出力は Test Moderators である。\\(F_{2,28}=\\) 0.45、\\(p=\\) 0.64 であることがわかる。これは、サブグループ間に有意な差がないことを意味する。Model Results はメタ回帰の枠組みで表示される。これは、サブグループ内のプール効果量を得るために、推定値を直接抽出することができないことを意味する。\\(z\\) 最初の値である切片 (intrcpt) は、全体の放射線被曝量が高い場合 (\\(z=\\) 0.58) の値を示している。低線量群および中線量群における効果は、切片の値にそれらの推定値を加えることによって求めることができる。したがって、低線量被曝群における効果は \\(z\\) = 0.58 - 0.19 = 0.39 であり、中線量被曝群における効果は \\(z\\) = 0.58 + 0.20 = 0.78 である。3 レベル (調整効果) モデルの結果を報告3 レベルモデルの結果の報告に際しては、プール効果だけでなく推定分散についても言及するべきである。関数 rma.mv は、レベル 3 とレベル 2 のランダム効果分散を、それぞれ \\(\\sigma^2_1\\) と \\(\\sigma^2_2\\) で示す。しかしながら、この推定分散は、\\(\\tau^2_{\\text{Level 3}}\\) と \\(\\tau^2_{\\text{Level 2}}\\) を使うことが望ましい。この方が、真の (研究) 効果 (つまり異質性の分散) の分散を扱っていることが明確になる。マルチレベルの \\(^2\\) 値も、解釈しやすいという点では適しているが、最初に何を表しているかを説明するという条件が必要である。を使ってモデルを比較する場合、少なくとも尤度比検定を報告するべききである。調整効果 (moderator) 分析の結果は、Chapter 7.3 で示したような表で報告することができる。以下に、anova の結果の報告例を示す。“pooled correlation based three-level meta-analytic model \\(r=\\) 0.48 (95%CI: 0.25-0.66; \\(p\\) < 0.001). estimated variance components \\(\\tau^2_{\\text{Level 3}}=\\) 0.179 \\(\\tau^2_{\\text{Level 2}}=\\) 0.119. means \\(^2_{\\text{Level 3}}=\\) 58.22% total variation can attributed -cluster, \\(^2_{\\text{Level 2}}=\\) 31.86% within-cluster heterogeneity. found three-level model provided significantly better fit compared two-level model level 3 heterogeneity constrained zero (\\(\\chi^2_1=\\) 16.10; \\(p\\)< 0.001).”","code":"\nmod.model <- rma.mv(yi = z, V = var.z, \n                    slab = author, data = Chernobyl,\n                    random = ~ 1 | author/es.id, \n                    test = \"t\", method = \"REML\",\n                    mods = ~ radiation)\n\nsummary(mod.model)## [...]\n## Test of Moderators (coefficients 2:3):\n## F(df1 = 2, df2 = 28) = 0.4512, p-val = 0.6414\n## \n## Model Results:\n##                 estimate    se   tval  pval  ci.lb ci.ub \n## intrcpt             0.58  0.36   1.63  0.11  -0.14  1.32    \n## radiationlow       -0.19  0.40  -0.48  0.63  -1.03  0.63    \n## radiationmedium     0.20  0.54   0.37  0.70  -0.90  1.31    \n## [...]"},{"path":"multilevel-ma.html","id":"rve","chapter":"10 「マルチレベル」メタ分析","heading":"10.4 ロバスト分散推定","text":"前章では、3 レベルメタ分析モデルを紹介し、データにおける効果量間の依存性をモデル化するために、どのように使用できるかを説明してきた。前章で取り入れた階層型モデルは、効果量が完全に独立しているとする「従来の」メタ分析よりも、明らかに私たちのデータセットをより良く表現している。しかし、これはまだ現実の単純化である。実際には、効果量間の依存関係は、現在のネストモデルで捉えられるものよりも複雑であることが多いのである。チェルノブイリのデータセットに戻ると、すでにこのことがわかる。このデータでは、ほとんどの研究が複数の効果量を提供しているが、その理由は研究によって異なっている。いくつかの研究では、異なる対象集団における放射線の影響を比較しており、そのため複数の効果量を報告している。また、同じサンプルに対して異なる方法を用いた研究もあり、これも複数の効果量が報告されていることを意味する。一つの研究の複数の効果量が同じサンプルに基づいている場合、それらのサンプリングエラー (Chapter 10.1 と Chapter 10.3 の 式 10.7 10.8 における \\(\\epsilon_ {ij}\\)) には相関があると期待される。しかし、このことは、今回の３レベルモデルではまだ捉えられていない。上記のモデルは、クラスタ/研究内では、サンプル誤差の相関 (つまり共分散) がゼロであることを仮定している。つまり、1 つのクラスタまたは研究内では、効果量の推定値は独立であると仮定している。\nFigure 10.2: もともと、３レベル (階層) モデルは研究官あるいはクラスタ間の効果量は独立であると仮定している。\nこのセクションでは、拡張された 3 レベル構造、いわゆる相関・階層効果 (Correlated Hierarchical Effects, CHE) モデル (J. E. Pustejovsky Tipton 2021)に時間を割こう。以前の (階層的) 3 レベルモデルと同様に、CHE モデルは、ある共通点 (例えば、同じ研究、作業グループ、文化的地域などに由来する) に基づいて、いくつかの効果量を大きなクラスタに結合することが可能である。このことに加えて、このモデルでは、クラスタ内のいくつかの効果量が同じサンプルに基づいており (例えば、複数の測定が行われたため)、したがってそれらのサンプル誤差は相関していることを明示的に考慮している。現実には、特に、データの依存性構造が複雑であったり、部分的にしか知られていない場合、CHE モデルから始めるとよい (J. E. Pustejovsky Tipton 2021)47。CHE モデルとともに、メタ分析の文脈におけるロバスト分散推定 (Robust Variance Estimation, RVE) についても説明する (L. Hedges, Tipton, Johnson 2010; Tipton Pustejovsky 2015; Tipton 2015)。これは、過去にメタ分析で従属効果量を扱うために頻繁に使用されてきた一連の方法である。RVE の中核は、いわゆるサンドイッチ推定量を中心に展開されている。この推定量は、CHEモデル (および他のメタ分析モデル) と組み合わせて、ロバストな信頼区間と \\(p\\)-値を得るために使用することができる。選択したモデルが、データの複雑な依存構造を完全にうまく捉えていない場合も可能である。そこで、最初の CHE モデルの適合の前に、メタ分析 RVE の概要と サンドイッチ推定量 について、後者がなぜそのような魅力的な名前を持っているのかを探ってみよう。","code":""},{"path":"multilevel-ma.html","id":"sandwich","chapter":"10 「マルチレベル」メタ分析","heading":"10.4.1 サンドイッチ型分散推定量","text":"発表されたメタ分析では、「ロバスト分散推定」という言葉が特殊な使われ方をしていることがあり、これが依存効果量を持つメタ分析データにのみ適用できる特殊な方法であると思われることがある。その逆である。ロバスト分散推定量は、もともと従来の回帰モデルのための手法として開発されたもので、回帰重みの分散 \\(\\hat\\beta\\) を計算するために使われる (Aronow Miller 2019, chap. 4.2.2 など参照)。この推定量は、線形モデルの通常の仮定が満たされない場合でも、漸近的な標準誤差の一貫性のある推定値が得られるため、「ロバスト」推定量と呼ばれる 48 。回帰モデルにおける係数分散のロバスト推定は非常に重要である。分散推定値 49 は、\\(p\\)-値と同様に、推定回帰重量の周りの信頼区間を計算するために使われ、したがってモデルから引き出す推測に直接影響を持つ。ここで取り上げるロバスト分散推定量は、「通常の」回帰モデルで使用されるオリジナルの手法の特別バージョン に過ぎないのである。Hedges, Tipton Jackson (2010) は、依存効果量のあるメタ回帰モデルに使用できる適応型の RVE を発表し、このアプローチはここ数年で拡張されている。これを理解するためには、まずメタ回帰の式をもう一度見てみる必要がある。概念的には、この式は Chapter 8.1 で紹介した式 8.2 と非常によく似ている。それを単に行列表記で表示すだけですある50。\\[\\begin{equation}\n\\boldsymbol{T}_{j}=\\boldsymbol{X}_{j}\\boldsymbol{\\beta} + \\boldsymbol{u}_j +\\boldsymbol{e}_j\n\\tag{10.9}\n\\end{equation}\\]この式は、単純に、\\(\\boldsymbol{T}\\) のある 効果量が、\\(\\boldsymbol{X}\\) のある共変量と関連した回帰の重み \\(\\beta\\) によって予測されることを教えてくれる。また、サンプル誤差 (\\(\\boldsymbol{e}_j\\) で記号化) 以外に、各研究のランダム効果 (\\(\\boldsymbol{u}_j\\) で表記) があり、それによって (混合効果) メタ回帰モデルを生成していることも教えてくれる。特別なのは、この式の添え字 \\(j\\) である。これは、式中の文字が太字 であることとともに、データセット中の各研究またはクラスタ \\(j\\) が複数の効果量を提供する、または提供できることを示している。\\(n_j\\) は、ある研究 \\(j\\) における効果量の数であるとする。そして、\\(j\\) の効果量は、式 \\(\\boldsymbol{T}_j = (T_{j,1}, \\dots, T_{j,{n_j}})^\\top\\) で見る列ベクトルとして書き下すことが可能である。同様に、\\(\\boldsymbol{X}_j\\) は、ある研究 \\(j\\) の共変量を含むデザイン行列であり、次のように書くことができる。\\[\\begin{equation}\n\\boldsymbol{X}_j =\n\\begin{bmatrix}\nx_{1,1}    & \\cdots & x_{1,p}    \\\\\n\\vdots     & \\ddots & \\vdots     \\\\\nx_{n_j,1}  & \\cdots & x_{n_j,p}\n\\end{bmatrix}\n\\tag{10.10}\n\\end{equation}\\]ここで \\(p-1\\) は共変量の総数である51。推定したい回帰係数のベクトル \\(\\boldsymbol{\\beta} = (\\beta_1, \\dots, \\beta_{p})^\\top\\) には、添字 \\(j\\) は含まれていない。なぜなら、回帰係数は全ての研究で同じと仮定されているからである。全体として、この表記は、研究が複数の効果量に貢献できる場合、私たちのデータは、いくつかの小さなデータセットを積み重ねたように見えることを強調している。\\(J\\) は、このデータにおける研究またはクラスタの合計数である。\\[\\begin{equation}\n\\begin{bmatrix}\n\\boldsymbol{T}_1 \\\\\n\\boldsymbol{T}_2 \\\\\n\\vdots \\\\\n\\boldsymbol{T}_J\n\\end{bmatrix}\n=\n\\begin{bmatrix}\n\\boldsymbol{X}_1 \\\\\n\\boldsymbol{X}_2 \\\\\n\\vdots \\\\\n\\boldsymbol{X}_J\n\\end{bmatrix}\n\\boldsymbol{\\beta}\n+\n\\begin{bmatrix}\n\\boldsymbol{u}_1 \\\\\n\\boldsymbol{u}_2 \\\\\n\\vdots \\\\\n\\boldsymbol{u}_J\n\\end{bmatrix}\n+\n\\begin{bmatrix}\n\\boldsymbol{e}_1 \\\\\n\\boldsymbol{e}_2 \\\\\n\\vdots \\\\\n\\boldsymbol{e}_J\n\\end{bmatrix}.\n\\tag{10.11}\n\\end{equation}\\]この式に基づいて、メタ回帰の係数 \\(\\boldsymbol{\\hat\\beta}\\) を推定することができる。信頼区間を計算し、係数の有意性検定を行うには、その分散の推定が必要である。これはロバストサンプリング分散推定量 \\(\\boldsymbol{V_{\\hat\\beta}}\\) を使って実現可能である。その式は次のようになる (L. Hedges, Tipton, Johnson 2010; J. E. Pustejovsky Tipton 2021, suppl. S1)。\\[\\begin{equation}\n\\scriptsize\\boldsymbol{V}^{\\text{R}}_{\\boldsymbol{\\hat\\beta}} =\n\\left(\\sum^J_{j=1}\\boldsymbol{X}_j^\\top\\boldsymbol{W}_j\\boldsymbol{X}_j \\right)^{-1}\n\\left(\\sum^J_{j=1}\\boldsymbol{X}_j^\\top\\boldsymbol{W}_j \\boldsymbol{}_j\\Phi_j \\boldsymbol{}_j \\boldsymbol{W}_j \\boldsymbol{X}_j \\right)\n\\left(\\sum^J_{j=1}\\boldsymbol{X}_j^\\top\\boldsymbol{W}_j\\boldsymbol{X}_j \\right)^{-1}\n\\tag{10.12}\n\\end{equation}\\]この式はかなり複雑に見えるので、細部まで理解する必要はないだろう。今重要なのは、形式と、その「成分」の一部である。まず、この式が三分木構造であることがわかる。左右の括弧で囲まれた部品は、真ん中の部品を取り囲むように同じものが並んでいる。これは、外側の部分が「パン」で内側の部分が「肉」であるサンドイッチのように見え、「サンドイッチ推定量」と名付けられた所以である。この式の重要な「材料」は、\\(\\boldsymbol{\\Phi}_j\\), \\(\\boldsymbol{W}_j\\) \\(\\boldsymbol{}_j\\) の行列である。まず1つ目。\\(\\boldsymbol{\\Phi}_j=\\text{Var}(\\boldsymbol{u}_j +\\boldsymbol{e}_j)\\), は、\\(n_j\\) 行と \\(n_j\\) 列の分散共分散行列 (variance-covariance matrix) である。これは、研究 \\(j\\) の真の依存構造を表している (J. E. Pustejovsky Tipton 2021, Suppl. S1)。残念ながら、効果量が研究内でどのように、どの程度相関しているかはほとんど知られておらず、私たちのメタ分析ですべての研究に関してこれを知ることはさらに困難である。したがって、このモデルでは、いくつかの単純化した仮定を置く必要がある52。CHE モデルは、例えば、効果量間の既知の相関 (known correlation) \\(\\rho\\) があり、 \\(\\rho\\) は全ての研究で同じ値という仮定がある (「一定標本相関 (constant sampling correlation)」の仮定、 J. E. Pustejovsky Tipton 2021)。まず1つ目。\\(\\boldsymbol{\\Phi}_j=\\text{Var}(\\boldsymbol{u}_j +\\boldsymbol{e}_j)\\), は、\\(n_j\\) 行と \\(n_j\\) 列の分散共分散行列 (variance-covariance matrix) である。これは、研究 \\(j\\) の真の依存構造を表している (J. E. Pustejovsky Tipton 2021, Suppl. S1)。残念ながら、効果量が研究内でどのように、どの程度相関しているかはほとんど知られておらず、私たちのメタ分析ですべての研究に関してこれを知ることはさらに困難である。したがって、このモデルでは、いくつかの単純化した仮定を置く必要がある52。CHE モデルは、例えば、効果量間の既知の相関 (known correlation) \\(\\rho\\) があり、 \\(\\rho\\) は全ての研究で同じ値という仮定がある (「一定標本相関 (constant sampling correlation)」の仮定、 J. E. Pustejovsky Tipton 2021)。\\(\\boldsymbol{W}_j\\) 行列には、各効果量の重みが含まれている。前の章 ( 4.1.1 8.1.3 参照) で、効果量推定値の精度を考慮に入れてからプールする必要があることを既に学びんだ。これを行う最適な方法は、分散の逆数を取ることであり、これは、\\(\\boldsymbol{W}_j = \\boldsymbol{\\Phi}^{-1}_j\\) を意味する。先ほど述べたように、\\(\\boldsymbol{\\Phi}_j\\) の真の値はほとんど知られていないので、私たちのモデルに基づく推定値、\\((\\boldsymbol{\\hat\\Phi}_j)^{-1}\\) が使われる53.\\(\\boldsymbol{W}_j\\) 行列には、各効果量の重みが含まれている。前の章 ( 4.1.1 8.1.3 参照) で、効果量推定値の精度を考慮に入れてからプールする必要があることを既に学びんだ。これを行う最適な方法は、分散の逆数を取ることであり、これは、\\(\\boldsymbol{W}_j = \\boldsymbol{\\Phi}^{-1}_j\\) を意味する。先ほど述べたように、\\(\\boldsymbol{\\Phi}_j\\) の真の値はほとんど知られていないので、私たちのモデルに基づく推定値、\\((\\boldsymbol{\\hat\\Phi}_j)^{-1}\\) が使われる53.最後の \\(\\boldsymbol{}_j\\) は調整行列で、メタ分析の研究数が少ない (例えば 40 以下、 L. Hedges, Tipton, Johnson 2010; Tipton Pustejovsky 2015) でも推定量が有効な結果を提供できるようにするものである。推奨されるアプローチは、バイアス低減線形化 (bias-reduced linearization)、つまり“CR2” 法に基づく行列を使うことである(Tipton Pustejovsky 2015)54。最後の \\(\\boldsymbol{}_j\\) は調整行列で、メタ分析の研究数が少ない (例えば 40 以下、 L. Hedges, Tipton, Johnson 2010; Tipton Pustejovsky 2015) でも推定量が有効な結果を提供できるようにするものである。推奨されるアプローチは、バイアス低減線形化 (bias-reduced linearization)、つまり“CR2” 法に基づく行列を使うことである(Tipton Pustejovsky 2015)54。","code":""},{"path":"multilevel-ma.html","id":"fit-rve","chapter":"10 「マルチレベル」メタ分析","heading":"10.4.2 ロバスト分散推定を用いた CHE モデルの適合","text":"それでは、最初の相関・階層効果モデルを R で適合させ、同時にロバスト分散推定を採用し、モデルの誤指定を防ぐ。これまで同様に、{metafor} の rma.mv 関数を使用してモデルを実行できる。今回は、{clubSandwich} パッケージ (J. Pustejovsky 2022)が提供するいくつかの追加関数も必要である。そのため、必ずパッケージをインストールし、ライブラリからロードしておこう。上記のように、CHE モデルは、研究またはクラスタ内の効果量が相関しており、この相関は研究内および研究間で同一であると仮定している。したがって、モデル内で使用する相関係数を定義する必要がある。今回のチェルノブイリのデータでは、相関が大きいと仮定して、\\(\\rho\\) =0.6としよう。これは推測に過ぎず、\\(\\rho\\) の値を変えながら複数の感度分析を行うことを強く勧める。さて、この相関を利用して、各研究の仮定された分散共分散行列を計算することが可能である。これは、{clubSandwich} の impute_covariance_matrix 関数を使用して行う。vi の引数には、各効果量の分散 (すなわち、標準誤差の二乗) を含むデータセットの変数名を指定した。cluster 引数は、各効果量を study または cluster に関連付ける変数を定義する。Chernobyl データセットでは、これは author である。引数 r は、効果量間の定数相関係数を想定している。V で準備した分散共分散行列を用いて、rma.mv モデルの適合を行うことができるようになる。 Chapter 10.3 と同じメタ回帰モデルで、共変量として radiation を用いて解析するとする。最初の引数は formula オブジェクトで、効果量 z が切片 (1) と共変量 radiation によって予測されることを関数に渡した。V 引数には、先ほど作成した分散共分散行列のリストを渡す。また、sparse 引数を TRUE に設定することで、計算を高速化することが可能である。引数 random と data だけが同じである。結果は che.model という名前で保存される。{clubSandwich} の conf_int 関数を使用することで、メタ回帰係数の信頼区間を計算することができる。計算は、適合したモデルと vcov で使用する小サンプル調整 を指定するだけである。推奨通り、\"CR2\" 調整を使用する (Chapter 10.4.1 参照)。Estimate の点推定値は、Chapter 10.3 で得たものと同様であることがわかる。しかし、推定された標準誤差と信頼区間は、はるかに大きくなっている。また、coef_test関数を用いて、回帰重みの \\(p\\) 値 を計算することが可能である。ロバスト分散推定を用いた場合、どの係数も有意ではないことがわかる55。ロバスト分散推定とモデルの誤同定読者の中には、なぜ私たちがロバスト分散推定を使ったモデルに大騒ぎするのか不思議に思われるかもしれない。その主な理由は、多変量・マルチレベルのモデルは、簡単に誤った仕様になりうるからである。CHE モデルでさえ、相関が研究内と研究間で同一であると仮定することで、やや粗雑なモデルであることをすでに学んだ。モデルがデータ中の複雑な依存関係を適切に近似しているかどうかが不明確なことがよくある。この点、ロバスト分散推定は、モデルの潜在的な誤記定に対して、私たちの推論 (すなわち、我々が計算する信頼区間と\\(p\\)値) を保護することができるため、有用である。{robumeta} パッケージこのセクションでは、相関・階層効果モデルと組み合わせたロバスト分散推定を取り上げた。このモデルは、他のいくつかの革新的な技術とともに、Pustejosky Tiptonによって提案されている (2021)。Hedges, Tipton Jackson (2010) による “original” RVE approach と、いくつかの小サンプルの拡張は、 {robumeta} パッケージを使って適用することができる (Z. Fisher, Tipton, Zhipeng 2017)。このパッケージは、Hedges, Tipton Jackson が最初に提案した2種類のモデル、階層的モデルと相関効果モデル (ただし両方を組み合わせたモデルは不可) を使ってメタ回帰を適合させることができる。","code":"\nlibrary(clubSandwich)\n# 想定される定数相関係数\nrho <- 0.6\n# サンプル定数相関係数の実行モデル\nV <- with(Chernobyl, \n          impute_covariance_matrix(vi = var.z,\n                                   cluster = author,\n                                   r = rho))\nche.model <- rma.mv(z ~ 1 + radiation,\n                    V = V,\n                    random = ~ 1 | author/es.id,\n                    data = Chernobyl,\n                    sparse = TRUE)\nconf_int(che.model, \n         vcov = \"CR2\")##            Coef. Estimate    SE d.f. Lower 95% CI Upper 95% CI\n##          intrcpt    0.584 0.578 1.00        -6.76         7.93\n##     radiationlow   -0.190 0.605 1.60        -3.52         3.14\n##  radiationmedium    0.207 0.603 1.98        -2.41         2.83\ncoef_test(che.model, \n          vcov = \"CR2\")##            Coef. Estimate    SE t-stat d.f. (Satt) p-val (Satt) Sig.\n##          intrcpt    0.584 0.578  1.010        1.00        0.497     \n##     radiationlow   -0.190 0.605 -0.315        1.60        0.789     \n##  radiationmedium    0.207 0.603  0.344        1.98        0.764 "},{"path":"multilevel-ma.html","id":"cwb","chapter":"10 「マルチレベル」メタ分析","heading":"10.5 クラスタワイルドブートストラップ","text":"前章では、相関効果モデルと階層効果モデルの適合方法、ロバスト分散推定を用いた信頼区間と係数検定の計算方法について学んだ。もう一つの、そして時には私たちのモデルの係数を検定するのに有利な方法は、ブートストラップ法で、その特別な変種がいわゆるクラスタワイルドブートストラップ (Joshi, Pustejovsky, Beretvas 2021) である。この方法は、メタ分析における研究の総数 \\(J\\) が小さい場合に適している。特に、(私たち自身の チェルノブイリ の例で見たように) 小さなサンプルで過度に保守的な結果につながる可能性がある RVE と比較して、この方法は適している。この方法は、いわゆる多重対比仮説 (multiple-contrast hypothesis) を検定したいときにも有効である。多重対比仮説は、たとえば、ダミー・コード化されたカテゴリ共変量の全体効果を検定したい場合に必要である。クラスタワイルドブートストラップのアルゴリズムワイルドブートストラップは、Null モデル (共変量を追加せずに適合させたモデル) の残差に基づく方法である。クラスタワイルドブートストラップでは、依存効果量を扱うために、例えば CR2 法に基づく調整行列 \\(\\boldsymbol{}_j\\) を用いて残差を変換する (Chapter 10.4.1 参照)。ワイルドブートストラップの一般的なアルゴリズムは以下のようなものである (Joshi, Pustejovsky, Beretvas 2021)。元のデータからフルモデルを計算し、目的の検定統計量 (\\(t\\) 値または \\(F\\) 値) を導出する。元のデータに基づいてヌルモデルを適合し、その残差 \\(\\boldsymbol{e}\\) を抽出する。各研究またはクラスタ \\(j\\) について、分布56からランダムな値を引き、\\(j\\) の残差にこのランダムな値をかける。元のデータに基づく Null モデルの予測値に変換された残差を加えることで、新しいブートストラップされた効果量を生成する。ブートストラップされた効果量値を用いて，再度フルモデルを適合させ，再度検定統計量を計算する。そして、ステップ 3 から 5 を \\(R\\) 回繰り返す。Boostrap \\(p\\) 値は、boostrap 検定統計量が元データに基づくものより極端であった回数の割合として導出される。ブートストラップを用いて多重対比仮説を検定するには、{wildmeta} パッケージを使用することができる (Joshi Pustejovsky 2022)。次の例のためにこのパッケージをインストールし、ライブラリからロードしておく必要がある。さらに、{tidyverse} の関数を用いて、Chernobyl データセットに新しい変数を生成し、そこに各研究の年号を保存する。次に、この変数をメタ回帰モデル rma.mv の 新しい予測変数 として使用した。これは、単に最初の引数で year を数式に追加し、共変数をセンタリング、スケールするために scale 関数を適用した。また、この式ではもう一つ、切片の 1 を 0 に変更している。これは切片がないことを意味し、「年」の予測値は放射線のレベルごとに層別される57。この結果を che.model.bs として保存する。ブートストラップを始める前に、実施したい検定について線形対比を定義する必要がある。例えば、変数 radiation の全体的な調整効果を検定したいとする。これを行うには、 {clubSandwich} の constrain_equal 関数を使用して、検定のための制約行列を作成する必要がある。帰無仮説は、変数 radiation の3つのレベルの間で効果が等しいというもので、constraints 引数を 1:3 にセットする。さらに、coefs 引数には先ほどフィットしたモデルの係数を指定した。結果は rad.constraints という名前で保存される。{wildmeta} の Wald_test_cwb 関数を用いて、多重対比仮説のブートストラップ \\(p\\) -値を計算することができる。適合したフルモデル、制約行列、使用したいスモールサンプル調整の種類、そしてブートストラップ複製の数である R を指定する必要がある。検出力が向上するため、高い複製数 (例: 1000以上) を使用することを勧める。この例では、2000 回を使用し、結果を cw.boot として保存する。繰り返しの回数にもよるが、この処理は終了までに数分かかることがある。調整効果の検定の結果、\\(p\\) -値は 0.36 で、有意ではないことがわかる。私たちは以前、Chapter 10.3 の放射強度の調整効果分析でも同様の所見を得た。plot 関数を使用すると、すべてのブートストラップ複製における検定統計量の密度 を可視化することも可能である。","code":"\n# {wildmeta} と {tidyverse} をロードする\nlibrary(wildmeta)\nlibrary(tidyverse)\n\n# year という変数を追加\nChernobyl$year <- str_extract(Chernobyl$author, \n                              \"[0-9]{4}\") %>% as.numeric()\nche.model.bs <- rma.mv(z ~ 0 + radiation + scale(year),\n                       V = V,\n                       random = ~ 1 | author/es.id,\n                       data = Chernobyl,\n                       sparse = TRUE)\nrad.constraints <- constrain_equal(constraints = 1:3,\n                                   coefs = coef(che.model.bs))\nrad.constraints##      [,1] [,2] [,3] [,4]\n## [1,]   -1    1    0    0\n## [2,]   -1    0    1    0\ncw.boot <- Wald_test_cwb(full_model = che.model.bs,\n                         constraints = rad.constraints,\n                         adjust = \"CR2\",\n                         R = 2000)\ncw.boot##           Test Adjustment CR_type Statistic    R  p_val\n## 1 CWB Adjusted        CR2     CR0   Naive-F 2000 0.3595\nplot(cw.boot, \n     fill = \"lightblue\", \n     alpha = 0.5)"},{"path":"multilevel-ma.html","id":"演習問題-9","chapter":"10 「マルチレベル」メタ分析","heading":"10.6 演習問題","text":"\n知識を試そう！\n\nなぜ「マルチレベル」モデルではなく「３レベル」モデルと言う方が正確なのか？\n\n３レベルメタ分析モデルはいつ有用か？\n\n効果量依存性の一般的な原因を2つ挙げなさい。\n\nマルチレベル \\(^2\\)\nの統計量はどのように解釈すればよいか。\n\n調整効果 (moderator)\n変数の効果を取り入れるために、どのように３レベルモデルを拡張することができるのか？\n\n問題の解答は、本書の巻末 Appendix\nにある。\n\\[\\tag*{$\\blacksquare$}\\]","code":""},{"path":"multilevel-ma.html","id":"要約-6","chapter":"10 「マルチレベル」メタ分析","heading":"10.7 要約","text":"すべてのランダム効果メタ分析は、マルチレベルモデルに基づいている。3 レベル目が追加された場合、3 レベルメタ分析モデルと呼ばれる。このようなモデルは、クラスタ化した効果量データの取り扱いに適している。すべてのランダム効果メタ分析は、マルチレベルモデルに基づいている。3 レベル目が追加された場合、3 レベルメタ分析モデルと呼ばれる。このようなモデルは、クラスタ化した効果量データの取り扱いに適している。3 レベルモデルは、従属効果量に使用することができる。例えば、1 つの研究が複数の効果量に寄与している場合、これらの結果が独立しているとは通常仮定できない。3 レベルモデルは、効果量がより大きなクラスタ (研究など) に ネストされていると仮定することで、この問題を制御する。3 レベルモデルは、従属効果量に使用することができる。例えば、1 つの研究が複数の効果量に寄与している場合、これらの結果が独立しているとは通常仮定できない。3 レベルモデルは、効果量がより大きなクラスタ (研究など) に ネストされていると仮定することで、この問題を制御する。従来のメタ分析とは異なり、3 レベルモデルでは、クラスタ内のランダム効果分散と、クラスタ間の 2 つの異質性分散を推定することが可能である。従来のメタ分析とは異なり、3 レベルモデルでは、クラスタ内のランダム効果分散と、クラスタ間の 2 つの異質性分散を推定することが可能である。3 レベルモデルを用いて、カテゴリまたは連続予測変数を検定することも可能である。これは、3 レベル混合効果モデルをもたらす。3 レベルモデルを用いて、カテゴリまたは連続予測変数を検定することも可能である。これは、3 レベル混合効果モデルをもたらす。","code":""},{"path":"sem.html","id":"sem","chapter":"11 構造方程式モデリングメタ分析","heading":"11 構造方程式モデリングメタ分析","text":"前\n章で、メタ分析モデルにはマルチレベル構造が内在していることを示した。この性質を利用して、例えば、従来のメタ分析を３レベルモデルに拡張することができる。\n統計的手法に関しては、よく別々の箱に入れられることがあるが、これは非常におかしなことである。研究や実務では、統計のそれぞれの手法は無関係なものとして扱われることが多いが、実際はそうではない。例えば、分散分析 (ANOVA) とカテゴリ予測変数の線形回帰は本質的に同じことを行なっていると教えると、多くの社会科学の学生はたいてい驚く58。2つの方法が異なる文脈で使われ、別個のものとして教えられてきたときに、このようになることがある。この例と同じように、マルチレベルモデルを構造方程式モデル (Structural Equation Model, SEM) の特殊な形態として捉え始めたのはごく最近のことである (Mehta Neale 2005; Bauer 2003) 。すでに学んだように、すべてのメタ分析はマルチレベルモデルに基づいている。結果として、プール効果量が潜在 (または未観測) 変数として扱われる構造方程式モデルとしてメタ分析を扱うことが可能である (Cheung 2015a, chap. 4.6)。要するに、メタ分析はマルチレベルモデルなので、構造方程式モデルとしても表現できるのである。\nこれは、これまで取り上げられてきた種類のメタ分析を構造方程式モデリングの観点から概念化できることを意味するだけではない。SEM を使って、より複雑なメタ分析モデルを構築することもできるようになるのである。メタ分析的な SEM を用いて、因子分析的なモデルを検証したり、アウトカムを複数含む多変量メタ分析を実行することが可能である (これらは、応用例の一部に過ぎない)。メタ分析 SEM は、利用可能なすべてのエビデンスを考慮した上で、文献中のあるモデルが実際に成り立っているかどうかを評価したい場合に役立つ。逆に、ある理論がエビデンスに裏付けられていないかどうか、あるいはさらに興味深いことに、その理論がサブグループにしか適用されないかどうかをチェックするためにも使用することが可能である。メタ分析的な SEM の手法を適用するには、もちろん構造方程式モデリングに基本的に慣れていることが前提になる。そこで次のセクションでは、構造方程式モデリングの背後にある一般的な考え方と、そのメタ分析的な拡張について簡単に説明する。","code":""},{"path":"sem.html","id":"what-is-meta-sem","chapter":"11 構造方程式モデリングメタ分析","heading":"11.1 メタ分析構造方程式モデリングとは？","text":"構造方程式モデリングは、顕在 (観測) 変数と潜在変数の関係に関する仮説を検定するために用いられる統計手法である (Kline 2015, chap. 1)。潜在変数は、観測されないか、観測可能のどちらかである。例えば、パーソナリティは、例えば、アンケートの様々な項目を通して間接的にしか測定できない構成要素である。SEM では、顕在変数と潜在変数の間の仮定された関係 (「構造」) が、測定された顕在変数を用いて、その測定誤差を考慮しながらモデル化される。SEM 分析は、「従来の」統計的仮説検定 (例えば、\\(t\\)-検定など) とは多少違う点がある。通常、統計的検定は、\\(H_0: \\mu_1 = \\mu_2\\) (ここで、\\(\\mu_1\\) と \\(\\mu_2\\) は2つのグループの平均) のような帰無仮説に対する検定を伴う。このような検定では、研究者は、帰無仮説を棄却することを「目的」とし、これによって、2つのグループが異なると結論づけることができることがある。しかし、SEM では、特定の構造モデルが事前に提案され、適合度が十分であれば、このモデルを受け入れることを「目的」とする (Cheung 2015a, chap. 2.4.6)。","code":""},{"path":"sem.html","id":"モデル仕様","chapter":"11 構造方程式モデリングメタ分析","heading":"11.1.1 モデル仕様","text":"一般に、SEM は一連の行列によって指定され、数学的に表現される。行列は、 R の data.frame オブジェクトのように、行と列を含む単純な表と考えることができる (実際、ほとんどのデータフレームは、.matrix 関数を用いて簡単に行列に変換することが可能)。視覚的には、SEM はパス図として表現することができる。このようなパス図は、通常、非常に直感的であり、その解釈も簡単である。したがって、まず最初に SEM を視覚的に示し、その後、行列表記に移行しよう。","code":""},{"path":"sem.html","id":"パス図","chapter":"11 構造方程式モデリングメタ分析","heading":"11.1.1.1 パス図","text":"パス図は、SEM をグラフィカルに表現したものである。パス図の描き方について完全なコンセンサスは得られていないが、いくつかの規約がある。ここでは、パス図の主な構成要素と、それらが表現するものを紹介した。例として、単純な線形 (「非メタ分析」) 回帰モデルのパス図を作成してみよう。このモデルでは、\\(y\\) を \\(x\\) で予測したい。モデル式は次のようなものである。\\[\\begin{equation}\ny_i = \\beta_0 + \\beta_1x_i + e_i\n\\tag{11.1}\n\\end{equation}\\]さて、この数式を「分解」してみよう。このモデルにおいて、\\(x_i\\) と \\(y_i\\) は観測された変数である。観測されない (潜在) 変数はない。\\(y\\) の真の母平均は回帰切片 \\(\\beta_0\\) であり、\\(\\mu_x\\) は \\(x\\) の母平均を示す。観測された予測変数の分散 \\(x\\) は \\(\\sigma^2_x\\) で示される。 \\(x\\) が \\(y\\) の完全な予測因子でない場合、\\(y\\) に関連する残留誤差分散 \\(\\sigma^2_{e_y}\\) がある程度存在することになる。以下の通り、2つの回帰係数がある。\\(\\beta_0\\) は切片で、\\(\\beta_1\\) は \\(x\\) の傾きである。これらの構成要素を用いて、線形回帰モデルのパス図を作成すると、以下のようになる。また、このグラフモデルを出発点として、回帰モデルの式を組み立て直すことができる。このモデルから、\\(y\\) は、\\(x \\times \\beta_1\\) と \\(1 \\times \\beta_0\\) という二つの要素に影響されていることが推測できる。 この二つの要素を足し合わせると、再び先ほどの \\(y\\) の式にたどり着く。","code":""},{"path":"sem.html","id":"行列表現","chapter":"11 構造方程式モデリングメタ分析","heading":"11.1.1.2 行列表現","text":"SEM を行列で表現する方法はいくつかある (Jöreskog Sörbom 2006; Muthén Muthén 2012; McArdle McDonald 1984)。ここでは、Reticular Action Model (RAM) の定式化に焦点を当てることにする (McArdle McDonald 1984)。なぜなら、この後に紹介する {metaSEM} パッケージでは、この式が使用されているからである。RAM は4つ行列を使用する。\\(\\boldsymbol{F}\\)、\\(\\boldsymbol{}\\)、\\(\\boldsymbol{S}\\)、\\(\\boldsymbol{M}\\) という4つ行列を使用する。 \\(\\boldsymbol{M}\\) 行列は、今回取り上げるメタ分析的SEMに適合させる必要はないので、ここでは省略した(より広範な紹介は Cheung 2015a を参照)。先ほどの線形回帰モデルに、残りの \\(\\boldsymbol{}\\) , \\(\\boldsymbol{F}\\) , \\(\\boldsymbol{S}\\) 行列を指定する。この3つ行列は、すべて同じ行と列数で、モデルで持っている変数 \\(x\\) と \\(y\\) に対応している。したがって、回帰モデルの一般的な行列構造は、常に次のようになる。\\(\\boldsymbol{}\\) 行列: 一方向矢印\\(\\boldsymbol{}\\) 行列は、パス・モデル中の非対称 (単一方向) 矢印を表す。この行列は、矢印が始まる変数の列のエントリを検索し ( \\(x\\) )、次に矢印が終わる変数行列の行のエントリを検索することによって埋めることが可能である ( \\(y\\) )。矢印の値 \\(\\beta_1\\) は、選択された列と行が行列の中で交差する場所に置かれる ( \\(i_{y,x}\\) )。このモデルには、変数間の他のパスがないので、残りのフィールドを0で埋める。したがって、例の \\(\\boldsymbol{}\\) 行列は次のようになる。\\(\\boldsymbol{S}\\) 行列: 一方向矢印\\(\\boldsymbol{S}\\) 行列は、含まれる変数について推定したい (共) 分散を表している。予測変数である \\(x\\) については、分散 \\(\\sigma^2_x\\) (「シグマ x 二乗」と読む) を推定する必要がある。予測変数 \\(y\\) については、予測誤差の分散 \\(\\sigma^2_{e_y}\\) (「シグマ e y 二乗」と読む) を知りたい。したがって、\\(\\boldsymbol{S}\\) をこのように指定する。\\(\\boldsymbol{F}\\) 行列: 一方向矢印\\(\\boldsymbol{F}\\) 行列は、モデルで観測された変数を指定することが可能である。変数が観測されたことを指定するために、単に行列のそれぞれの対角フィールドに1を挿入する。このモデルでは、\\(x\\) と \\(y\\) の両方が観測されているので、両方の対角フィールドに 1 を挿入する。これらの行列が設定されると、SEM のパラメータを推定することができ、指定されたモデルがどれだけデータに適合しているかを評価することができるようになる。これにはいくつか行列代数と最尤推定によるパラメータ推定が含まれるが、数学的な細かい説明はここでは省略する。このステップの背後にある詳細を理解したい場合は、Cheung (2015a) の4.3章を参照。","code":""},{"path":"sem.html","id":"sem-の観点からのメタ分析","chapter":"11 構造方程式モデリングメタ分析","heading":"11.1.2 SEM の観点からのメタ分析","text":"ここで、メタ分析モデルと SEM に関する知識を組み合わせて、メタ分析を構造方程式モデル (Cheung 2008) として定式化しよう。はじめに、ランダム効果モデルの式に戻りよう。前回、メタ分析モデルがマルチレベル構造に従っていることをすでに説明してきたが (Chapter 10.1)、これは次のようなものである。レベル １\\[\\begin{equation}\n\\hat\\theta_k = \\theta_k + \\epsilon_k\n\\tag{11.2}\n\\end{equation}\\]レベル ２\\[\\begin{equation}\n\\theta_k = \\mu + \\zeta_k\n\\tag{11.3}\n\\end{equation}\\]最初のレベルでは、研究 \\(k\\) で報告された効果量 \\(\\hat\\theta_k\\) が、真の効果量 \\(\\theta_k\\) の推定値であると仮定する。観測された効果量が真の効果から乖離しているのは、サンプリングエラー \\(\\epsilon_k\\)、分散 \\(\\widehat{\\text{Var}}(\\hat\\theta_k)=v_k\\) で表されるからである。\nランダム効果モデルでは、各研究の真の効果量でさえ、レベル２の真の効果量の母集団からしか抽出されないと仮定する。この真の効果量の母集団の平均 \\(\\mu\\) が推定したいものであり、プール効果量を表す。これを推定するためには、真の効果量の分散 \\(\\widehat{\\text{Var}}(\\theta)=\\tau^2\\) (つまり、研究間異質性) も推定する必要がある。固定効果モデルはランダム効果モデルの特殊なケースで、\\(\\tau^2\\) がゼロであると仮定する。このモデルを SEM グラフとして表現することは、非常に簡単である。レベル１のパラメータを潜在変数として、観察している効果量がどのように生まれたかを「説明」する (Cheung 2015a, chap. 4.6.2)。モデルの図では、ある研究 \\(k\\) の観察された効果量 \\(\\hat\\theta_k\\) は、２つのアームによって「影響」されていることがわかる。２つのアームとは、分散 \\(v_k\\) を持つサンプルエラー \\(\\epsilon_k\\)、および分散 \\(\\tau^2\\) を持つ真の効果量 \\(\\theta_k\\) である。","code":""},{"path":"sem.html","id":"段階メタ分析-sem-アプローチ","chapter":"11 構造方程式モデリングメタ分析","heading":"11.1.3 ２段階メタ分析 SEM アプローチ","text":"上記では、SEM の観点から (ランダム効果) メタ分析モデルを定義してみた。これは理論的には面白いが、このモデルは以前取り上げたメタ分析手法と比較して能力が高いわけでも低いわけでもない。単に、ランダム効果モデルを仮定して効果量をプールすることを記述しているだけである。メタ分析 SEM の汎用性を本当に生かすには、２段階アプローチが必要である (Tang Cheung 2016; Cheung 2015a, chap. 7)。２段階構造方程式モデリング (Two-Stage Structural Equation Modeling, TSSEM) では、まず、各研究の効果量をプールする。通常、これらの効果量は、モデリングに使用する複数の変数間の相関である。 各研究 \\(k\\) の相関は、ベクトル \\(\\boldsymbol{r_k} = (r_1, r_2, \\dots, r_p)\\) で表される。ここで、 \\(p\\) は、(ユニークな) 相関の総数である。通常のランダム効果モデルと同様に、サンプリングエラー \\(\\epsilon_k\\) と研究間の異質性 \\(\\zeta_k\\) (「ゼータ・k」と読む) により、研究 \\(k\\) で観測された各相関は真の平均相関 \\(\\rho\\) (「ロー」と読む) から乖離すると仮定する。\\(\\boldsymbol{r_k}\\) が1つの研究に含まれる複数の相関を表すことを考慮すると、ランダム効果モデルの式は次のようになる。\\[\\begin{align}\n  \\boldsymbol{r_k} &= \\boldsymbol{\\rho} + \\boldsymbol{\\zeta_k} + \\boldsymbol{\\epsilon_k} \\notag \\\\\n  \\begin{bmatrix} r_1 \\\\ r_2 \\\\ \\vdots \\\\ r_p \\end{bmatrix} &=\n  \\begin{bmatrix} \\rho_1 \\\\ \\rho_2 \\\\ \\vdots \\\\ \\rho_p \\end{bmatrix} +\n  \\begin{bmatrix} \\zeta_1 \\\\ \\zeta_2 \\\\ \\vdots \\\\ \\zeta_p \\end{bmatrix} +\n  \\begin{bmatrix} \\epsilon_1 \\\\ \\epsilon_2 \\\\ \\vdots \\\\ \\epsilon_p \\end{bmatrix} \\tag{11.4}\n\\end{align}\\]このモデルを用いて、プール相関のベクトル \\(\\boldsymbol{r}\\) を計算することが可能である。この最初のプール化ステップにより、研究間の効果の異質性を評価し、ランダム効果モデルまたはサブグループ分析を使用すべきかどうかを判断することが可能である。{metaSEM} パッケージで使用されている最尤法に基づくアプローチのおかげで、部分的にデータが欠損している研究であっても、このステップに含めることが可能である。次に、第二段階として、加重最小二乗法 ( Chapter 8.1.3 参照) を用いて、指定した構造方程式モデルを当てはめる。指定したモデル \\(\\rho(\\hat\\theta)\\) の関数は、以下の式で表される (Cheung Chan 2009; Cheung 2015a, chap. 7.4.2)。\\[\\begin{equation}\nF_{\\text{WLS}}(\\hat\\theta) =  (\\boldsymbol{r} - \\rho(\\hat\\theta))^\\top \\boldsymbol{V}^{-1} (\\boldsymbol{r} - \\rho(\\hat\\theta))\n\\tag{11.5}\n\\end{equation}\\]ここで、\\(\\boldsymbol{r}\\) はプール相関ベクトルである。この式の重要な部分は、\\(\\boldsymbol{V}^{-1}\\) (「ブイ・インバース」と読む) で、これは \\(\\boldsymbol{r}\\) の共分散を含む逆行列である。この行列は、重み付けに使用される。重要なのは、この第2ステップの式は、ランダム効果モデルでも固定効果モデルでも同じである。なぜなら、研究間の異質性が存在する場合は、第1ステップですでに考慮されているからである。","code":""},{"path":"sem.html","id":"multivariate-ma","chapter":"11 構造方程式モデリングメタ分析","heading":"11.2 多変量メタ分析","text":"メタ分析 SEM の最初の事例を紹介しよう。まずは、SEM 法を使った多変量メタ分析から始めたい。多変量メタ分析では、1つ以上の効果を同時に推定しようとする。このようなメタ分析は、主なアウトカムが1つだけでなく、複数あるような研究テーマを研究している場合に有効である。ある種の治療の効果を調べることを想像してみよう。この治療法では、ほとんどの専門家が2種類のアウトカムを重要とみなし、したがってほとんどの研究で評価されているとしよう。多変量メタ分析では、1つのモデルで両方のアウトカムに対する効果量を共同で推定することで、この問題に対処することができる。この多変量解析のアプローチでは、2つのアウトカム間の相関を考慮することも可能である。これは、一方のアウトカムで高い効果量を持つ研究が、もう一方のアウトカムでも高い効果量を持つかどうかを判断するために使用することができる。あるいは、2つのアウトカムに負の関係があるか、まったく関係がないかがわかるだろう。なお、多変量メタ分析は、SEMの枠組み以外でも実行可能となる (Schwarzer, Carpenter, Rücker 2015, chap. 7; Gasparrini, Armstrong, Kenward 2012)。しかし、ここでは、SEMの観点からそれらを実行する方法を紹介した。この例と次の例では、Mike Cheung (2015b)によって開発されたメタ分析 SEM のための偉大なパッケージである {metaSEM} を使用することになる。いつものように、まず {metaSEM} パッケージをインストールし、ライブラリからロードする必要がある。今回の例でも、 {dmetar} の ThirdWave データセットを使用する ( Chapter 4.2.1 を参照)。デフォルトでは、このデータセットには、知覚されたストレスに対する効果というアウトカムしか含まれていない。さて、このメタ分析のほとんどの研究が、もう1つの重要なメンタルヘルス関連のアウトカムである不安に対する効果も測定していると想像してみよう。多変量メタ分析を使用して、ストレスと不安に対する効果、および両者がどのように互いに関連しているかを共同で推定したい。したがって、先に進むために両方のアウトカムのデータが含まれる新しいデータフレームを作成する必要がある。まず、各研究で報告された不安に対する効果 (Hedges’ \\(g\\) と表す)、およびその標準誤差を含むベクトルを定義する。また、各研究で報告されたストレスと不安の間の共分散を含むベクトルも定義する必要がある。1つの研究では、不安のアウトカムを評価していないので、情報がないことを示すために、3つのベクトルで NA を使用する。そして、このデータを ThirdWave の情報と合わせて、ThirdWaveMV という新しいデータフレームを作成する。このデータセットには、効果量の分散である Stress_var と Anxiety_var を設定する。分散は、標準誤差を二乗することで得られる。見てわかるように、新しいデータセットには、ストレスと不安の両方の効果量が、それぞれのサンプル分散と一緒に含まれている。Covariance 列は、各研究で測定されたストレスと不安の間の共分散を格納している。実際の研究でよくある問題は、2つのアウトカム間の共分散 (または相関) がオリジナルの研究で報告されていないことである。この場合、アウトカム間の相関に関する合理的な仮定に基づいて、共分散を推定する必要がある。各研究の共分散がまだわかっていないとしよう。どのように推定できるだろうか？良い方法は、2つのアウトカム間の相関を評価した過去の文献を探すことで、今扱っているのと同じようなコンテキストで探すことができると最適である。例えば、臨床試験の介入後テストにおいて、ストレスと不安は非常に高い相関があり、\\(r_{\\text{S,}} \\approx\\) 0.6であると文献で見つけたとしよう。この想定される相関に基づいて、ある研究 \\(k\\) の共分散を次の公式を使って近似可能である (Schwarzer, Carpenter, Rücker 2015, chap. 7)。\\[\\begin{equation}\n\\widehat{\\text{Cov}}(\\theta_{1},\\theta_{2}) = SE_{\\theta_{1}} \\times SE_{\\theta_{2}} \\times \\hat\\rho_{1, 2}\n\\tag{11.6}\n\\end{equation}\\]今回のデータを使って、\\(r_{\\text{S,}} \\approx\\) 0.6とすると、この式は R で次のように実装可能である。なお、このように共分散を計算する場合、想定する相関の選択によって結果に大きな影響を与えることがある。したがって、(1) 常に想定した相関係数を報告し、(2) 感度分析を行い、選んだ相関によって結果がどう変わるかを検証することが強く望まれる。","code":"\nlibrary(metaSEM)\n# 不安の効果(Hedges g) を定義\nAnxiety <- c(0.224,0.389,0.913,0.255,0.615,-0.021,0.201, \n             0.665,0.373,1.118,0.158,0.252,0.142,NA, \n             0.410,1.139,-0.002,1.084)\n\n# 不安の効果の標準偏差\nAnxiety_SE <- c(0.193,0.194,0.314,0.165,0.270,0.233,0.159,\n                0.298,0.153,0.388,0.206,0.256,0.256,NA,\n                0.431,0.242,0.274,0.250)\n\n# ストレスと不安の共変量\nCovariance <- c(0.023,0.028,0.065,0.008,0.018,0.032,0.026, \n                0.046,0.020,0.063,0.017,0.043,0.037,NA, \n                0.079,0.046,0.040,0.041)\nThirdWaveMV <- data.frame(Author = ThirdWave$Author,\n                          Stress = ThirdWave$TE,\n                          Stress_var = ThirdWave$seTE^2,\n                          Anxiety = Anxiety,\n                          Anxiety_var = Anxiety_SE^2,\n                          Covariance = Covariance)\n\nformat(head(ThirdWaveMV), digits = 2)##            Author Stress Stress_var Anxiety Anxiety_var Covariance\n## 1     Call et al.   0.71      0.068   0.224       0.037      0.023\n## 2 Cavanagh et al.   0.35      0.039   0.389       0.038      0.028\n## 3   DanitzOrsillo   1.79      0.119   0.913       0.099      0.065\n## 4  de Vibe et al.   0.18      0.014   0.255       0.027      0.008\n## 5  Frazier et al.   0.42      0.021   0.615       0.073      0.018\n## 6  Frogeli et al.   0.63      0.038  -0.021       0.054      0.032\n\n# SE = sqrt(var) より、分散の２乗根を使用\ncov.est <- with(ThirdWaveMV, \n                sqrt(Stress_var) * sqrt(Anxiety_var) * 0.6)"},{"path":"sem.html","id":"モデルの指定","chapter":"11 構造方程式モデリングメタ分析","heading":"11.2.1 モデルの指定","text":"多変量メタ分析モデルを指定するために、プログラム的に TSSEM 手順 (前章参照) に従う必要はないし、RAM 行列を指定する必要もない。このような比較的単純なモデルであれば、 {metaSEM} の meta 関数を使用すれば、たった1ステップでメタ分析 SEM を適用することが可能である。meta を使用するには、3つの必須引数を指定するだけである。y. 効果量データを含むデータセットの列である。多変量メタ分析では、cbind を用いて、効果量を含む列を結合する必要がある。y. 効果量データを含むデータセットの列である。多変量メタ分析では、cbind を用いて、効果量を含む列を結合する必要がある。v. 効果量の分散を含むデータセットの列。多変量メタ分析では、cbind を用いて、対象とする分散列を結合する必要がある。また、効果量間の共分散を含む列も含める必要がある。引数の構造は cbind(variance_1, covariance, variance_2) である。v. 効果量の分散を含むデータセットの列。多変量メタ分析では、cbind を用いて、対象とする分散列を結合する必要がある。また、効果量間の共分散を含む列も含める必要がある。引数の構造は cbind(variance_1, covariance, variance_2) である。data. 効果量と分散が格納されたデータセット。data. 効果量と分散が格納されたデータセット。適合したモデルを m.mv という名前で保存する。ひとつ重要な点として、meta を実行する前に、{meta} パッケージがロードされていないことを確認しておこう。{meta} と {metaSEM} には同じ名前の関数がいくつかあり、 R でコードを実行するときにエラーにつながる可能性がある。detach 関数を使ってパッケージを “unload” することができる。結果として得られる m.mv オブジェクトは、summary を用いて検証したい。","code":"\nm.mv <- meta(y = cbind(Stress, Anxiety), \n             v = cbind(Stress_var, Covariance, Anxiety_var),\n             data = ThirdWaveMV)\n\nsummary(m.mv)## [...]\n## Coefficients:\n##            Estimate Std.Error lbound ubound z value Pr(>|z|)    \n## Intercept1    0.570     0.087  0.399  0.740  6.5455  5.9e-13 ***\n## Intercept2    0.407     0.083  0.244  0.570  4.9006  9.5e-09 ***\n## Tau2_1_1      0.073     0.049 -0.023  0.169  1.4861   0.1372    \n## Tau2_2_1      0.028     0.035 -0.041  0.099  0.8040   0.4214    \n## Tau2_2_2      0.057     0.042 -0.025  0.140  1.3643   0.1725    \n## ---\n## Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n## [...]\n## \n## Heterogeneity indices (based on the estimated Tau2):\n##                              Estimate\n## Intercept1: I2 (Q statistic)   0.6203\n## Intercept2: I2 (Q statistic)   0.5292\n## \n## Number of studies (or clusters): 18\n## [...]\n## OpenMx status1: 0 (\"0\" or \"1\": The optimization is considered fine.\n## Other values may indicate problems.)"},{"path":"sem.html","id":"結果の評価","chapter":"11 構造方程式モデリングメタ分析","heading":"11.2.2 結果の評価","text":"SEM モデルが最尤法を使って適合していることを考えると、まず出力の最後にある OpenMx status を最初にチェックする。最尤推定は最適化手順であり、手元のデータに対する最適解が見つかるまで、パラメータが繰り返し変更される。しかし、特に複雑なモデルでは、何度繰り返しても最適解に到達しないことがある。その場合、最尤法は停止して、これまでに近似したパラメータ値を出力した。しかし、このようなモデルの構成要素の値は間違っている可能性が高く、信用するべきではない。このモデルの OpenMx status は 0 であり、最尤推定がうまくいったことを示している。もし、このステータスが 0 または 1 以外であった場合、このコードを使ってモデルを再実行する必要がある。この出力では、プールされた2つの効果量が Intercept1 と Intercept2 として表示される。効果量は、meta の呼び出しに挿入した順番に番号が振られている。プールされた効果量は、\\(g_{\\text{Stress}}\\) = 0.57 および \\(g_{\\text{Anxiety}}\\) = 0.41であることがわかる。どちらの効果量も有意である。異質性指標では、\\(^2\\) の値も見ることが可能である。 \\(^2_{\\text{Stress}}\\) = 62% と \\(^2_{\\text{Anxiety}}\\) = 53%で、両方のアウトカムにかなりの研究間異質性があることがわかる。また、研究間異質性分散 \\(\\tau^2\\) の直接推定値も示されている。2つの推定値だけでなく、3つの推定値があることがわかる。この意味を理解するために、m.mv オブジェクトから「ランダム」な値を抽出することが可能である。次に、vec2symMat 関数を使用して、係数行列を作成する。行列の行と列には、変数名である Stress と Anxiety を付ける。ここで、\\(\\tau^2\\) の3つの値の意味がよくわかる。これらは、行列の対角線上の研究間分散 (異質性) を表している。他の2つのフィールドでは、行列はストレスと不安の間の推定共分散を示している。共分散は相関の未標準化バージョンに過ぎないので、cov2cor 関数を用いて、これらの値を相関に変換することが可能である。極めて論理的に、行列の対角要素の相関は1であることがわかる。ストレスと不安に対する効果の相関は、\\(r_{\\text{S,}}\\) = 0.45 である。これは興味深い発見で、治療法の知覚ストレスに対する効果と不安に対する効果との間に正の相関があることを示している。ストレスに対する効果が高い治療法は、不安に対する効果も高いようだと言うことが可能である。m.mv の要約で示される信頼区間は Wald 型の区間であることに注意しておこう (Chapter 4.1.2.2 を参照)。このような Wald タイプの信頼区間は、特に小さなサンプルでは不正確な場合がある (DiCiccio Efron 1996)。したがって、尤度に基づく信頼区間を用いて、別の方法で信頼区間を構築することが重要である場合がある。meta 関数を再実行し、さらに intervals.type = \"LB\" を指定することで、これらの CI を得ることが可能である。m.mv の出力には、研究間異質性 \\(\\tau^2\\) のゼロでない推定値が含まれていることがすでにわかった。したがって、今適合したモデルは、ランダム効果モデルであると結論づけることが可能である。meta 関数は自動的にランダム効果モデルを使用する。出力された \\(^2\\) の値を考慮すると、これは確かに適切であると結論づけることが可能である。しかし、固定効果モデルを適用したい場合は、解析を再実行し、パラメータ RE.constraints = matrix(0, nrow=2, ncol=2) を追加することで、適用することが可能である。これは、\\(\\tau^2\\) の値をすべて0に拘束する零行列を作成する。","code":"\nrerun(m.mv)\ntau.coefs <- coef(m.mv, select = \"random\")\n# 行列を作成\ntc.mat <- vec2symMat(tau.coefs)\n\n# 列名と行名をつける\ndimnames(tc.mat)[[1]] <- dimnames(tc.mat)[[2]] <- c(\"Stress\", \n                                                    \"Anxiety\")\n\ntc.mat##             Stress    Anxiety\n## Stress  0.07331199 0.02894342\n## Anxiety 0.02894342 0.05753271\ncov2cor(tc.mat)##            Stress   Anxiety\n## Stress  1.0000000 0.4456613\n## Anxiety 0.4456613 1.0000000\nm.mv <- meta(y = cbind(Stress, Anxiety), \n             v = cbind(Stress_var, Covariance, Anxiety_var),\n             data = ThirdWaveMV,\n             intervals.type = \"LB\")\nm.mv <- meta(y = cbind(Stress, Anxiety), \n             v = cbind(Stress_var, Covariance, Anxiety_var),\n             data = ThirdWaveMV,\n             RE.constraints = matrix(0, nrow=2, ncol=2))"},{"path":"sem.html","id":"結果の可視化","chapter":"11 構造方程式モデリングメタ分析","heading":"11.2.3 結果の可視化","text":"多変量メタ分析モデルをプロットするには、plot 関数を使用する。また、プロットの外観を変更するために、いくつかの追加指定を行う。全てのスタイリングオプションを見たい場合は、コンソールに ?metaSEM::plot.meta を貼り付けて、Enterキーを押してみよう。それでは、見ていこう。プロットには2つの軸がある: ストレスへの効果を示す x 軸と、不安への効果を示す y 軸である。また、両方のアウトカムに対するプール効果とその95%信頼区間が表示されている (黒い菱形で表されている)。プロットの中央には、両変数のプール効果が赤い菱形で示されている。小さい青い楕円は、私たちのプールされた効果の95%信頼区間を表し、大きい黒い楕円は、95%予測区間を表している (Chapter 5.2) 59。最後に、黒丸は個々の研究を示し、破線の楕円は95%信頼区間を表す。","code":"\nplot(m.mv, \n     axis.labels = c(\"Perceived Stress\", \"Anxiety\"), \n     randeff.ellipse.col = \"#014d64\",\n     univariate.arrows.col = \"gray40\",\n     univariate.arrows.lwd = 9,\n     univariate.polygon.col = \"gray40\",\n     estimate.ellipse.col = \"gray40\",\n     estimate.col = \"firebrick\")"},{"path":"sem.html","id":"cfa","chapter":"11 構造方程式モデリングメタ分析","heading":"11.3 確証的因子分析","text":"確証的因子分析 (Confirmatory Factor Analysis, CFA) は、観測された変数が仮定された潜在変数にどのように関係するかを特定する一般的な SEM 手法である (B. Thompson 2004, chap. 1.1 1.2)。CFA は、アンケートや他のタイプのアセスメントの心理測定特性を評価するためによく使用される。それは、研究者が、評価された変数が、測定しようとする潜在変数を本当に測定しているかどうか、および複数の潜在変数がお互いにどのように関係するかを決定することを可能にする。頻繁に使用されるアンケートについては、通常、異なるアンケート項目間の相関を報告する多くの実証研究が存在した。このようなデータは、メタ分析的な SEM に使用することが可能である。これにより、すべての利用可能なエビデンスに基づいて、どの潜在因子構造が最も適切であるかを評価することが可能である。この例では、睡眠の問題についての (架空の) 質問票の潜在的な因子構造を確認したい。質問票には、睡眠の問題を特徴づける2つの異なる潜在変数を測定すると仮定する。不眠症 (insomnia) と倦怠感 (lassitude、一般的に倦怠感は fatigue) である。Koffel Watson (2009) は、睡眠の訴えは、実際にこれらの2つの潜在因子によって記述され得ると主張した。メタ分析 CFA を実践するために、私たちが想像した睡眠アンケートを評価した11件の研究結果をシミュレートした。このデータセットを SleepProblems と名付けた。これらの研究のそれぞれには、私たちの質問票によって直接測定された睡眠に関する不満の症状間の相互相関が含まれている。これらの測定指標には、睡眠の質、睡眠潜時、睡眠効率、日中機能不全、hypersomnia (すなわち、寝過ぎ) が含まれる。最初の3つの症状は、いずれも不眠症を潜在変数として測定しているので関連があり、日中機能不全と過眠症は、倦怠感要因の症状なので関連があると推測される。提案された構造をグラフィカルなモデルとして表現すると、次のようになる60。","code":""},{"path":"sem.html","id":"データ準備","chapter":"11 構造方程式モデリングメタ分析","heading":"11.3.1 データ準備","text":"まず、モデルに使用する SleepProblems データを見てみよう。このデータセットは特殊な構造を持っている。それは list オブジェクトであり、(1) 行列の list と (2) 数値ベクトルを含んでいる。リストは非常に汎用性の高い R オブジェクトであり、異なる要素を 1 つの大きなオブジェクトに結合することが可能である。リストは $ 演算子を用いて、データフレームのようにアクセスすることができる。names 関数を使用すると、リスト内のオブジェクトの名前を表示すことが可能である。\n“SleepProblems” データセット\n\nSleepProblems データセットは {dmetar}\nパッケージに含まれている。{dmetar}\nをインストールし、ライブラリからロードした後、\ndata(TherapyFormatsGeMTC)\nを実行すると、自動的にデータセットが R\n環境にセーブされる。これでデータセットが利用できるようになる。\n\nもし、{dmetar} がインストールされていない場合は、インターネット\nから .rda\nファイルとしてダウンロードし、作業ディレクトリに保存した後、R Studio\nのウィンドウでクリックするとインポートすることが可能である。\nこのリストには、実際の data と、各研究のサンプルサイズである n の 2 つの要素が含まれていることがわかる。data オブジェクトはそれ自体が list であるため、 names 関数を使用してそのコンテンツの名前を取得することも可能である。また、$ 演算子を使って data に含まれる特定の要素を表示すことも可能である。data リストには11の要素があり、含まれる11の研究ごとに1つずつある。Coleman et al. (2003) の研究を詳しく見ると、データは5つの変数を持つ相関行列として格納されていることがわかる。行列の各行と列は、私たちの質問票で評価された睡眠の不定愁訴の症状の1つに対応した。Coleman et al. (2003) の研究では、各症状の組み合わせについて相関が報告されている。しかし、いくつかのフィールドで欠損値 ( NA としてコード化) を持つ研究を使用することも可能である。これは、メタ分析SEMが、少なくともある程度は、欠損データを扱うことができることがある。先に進む前に、このようなリストを自分で作成する方法を簡単に説明しよう。2つの研究の相関行列を抽出し、それをデータフレームとして R にインポートしたい。データフレームを df1 と df2 と呼ぶとすると、以下の「レシピ」を使用して、さらなる解析に適した list オブジェクトを作成することが可能である。","code":"\ndata(SleepProblems)\nnames(SleepProblems)## [1] \"data\" \"n\"\nnames(SleepProblems$data)## [1] \"Coleman et al. (2003)\"  \"Salazar et al. (2008)\" \n## [3] \"Newman et al. (2016)\"   \"Delacruz et al. (2009)\"\n## [5] \"Wyatt et al. (2002)\"    \"Pacheco et al. (2016)\"\n## [...]\nSleepProblems$data$`Coleman et al. (2003)`##            Quality Latency Efficiency DTDysf HypSomnia\n## Quality       1.00    0.39       0.53  -0.30     -0.05\n## Latency       0.39    1.00       0.59   0.07      0.44\n## Efficiency    0.53    0.59       1.00   0.09      0.22\n## DTDysf       -0.30    0.07       0.09   1.00      0.45\n## HypSomnia    -0.05    0.44       0.22   0.45      1.00\n# データフレームを行列に変換\nmat1 <- as.matrix(df1)\nmat2 <- as.matrix(df2)\n\n# 行ラベルを定義\ndimnames(mat1)[[1]] <- c(\"Variable 1\", \"Variable 2\", \"Variable 3\")\ndimnames(mat2)[[1]] <- c(\"Variable 1\", \"Variable 2\", \"Variable 3\")\n\n# リストに相関係数行列を結合\ndata <- list(mat1, mat2)\nnames(data) <- c(\"Study1\", \"Study2\")\n\n# 二つの研究のサンプルサイズを定義\nn <- c(205, # N of study 1\n       830) # N of study 2\n\n# 行列とサンプルサイズを結合\ncfa.data <- list(data, n)"},{"path":"sem.html","id":"モデル仕様-1","chapter":"11 構造方程式モデリングメタ分析","heading":"11.3.2 モデル仕様","text":"CFA モデルを指定するためには、先に述べた RAM 指定と２段階メタ分析 SEM 手順を使用する必要がある。{metaSEM} パッケージは、２段階のそれぞれについて、tssem1 と tssem2 という別々の関数を含んでいる。最初の関数は、すべての研究の相関行列をプールし、２番目の関数は、提案されたモデルをデータに適合させる。","code":""},{"path":"sem.html","id":"ステージ-1","chapter":"11 構造方程式モデリングメタ分析","heading":"11.3.2.1 ステージ 1","text":"最初の段階では、tssem1 関数を用いて相関行列をプールする。この関数では、4つの重要な引数を指定する必要がある。Cov. プールしたい相関行列の list を指定する。リスト内のすべての相関行列は、同一の構造を持っている必要があることに注意。Cov. プールしたい相関行列の list を指定する。リスト内のすべての相関行列は、同一の構造を持っている必要があることに注意。n. 各研究のサンプルサイズを含む数値ベクトルで、Cov に含まれる行列と同じ順序で並べられる。n. 各研究のサンプルサイズを含む数値ベクトルで、Cov に含まれる行列と同じ順序で並べられる。method. 固定効果モデル (\"FEM\") またはランダム効果モデル (\"REM\") を使用するかどうかを指定。method. 固定効果モデル (\"FEM\") またはランダム効果モデル (\"REM\") を使用するかどうかを指定。RE.type. ランダム効果モデルを利用する場合、ランダム効果の推定方法を指定する。デフォルトは \"Symm\" で、2つの変数間の共分散を含む、すべての \\(\\tau^2\\) の値を推定する。\"Diag\" に設定すると、ランダム効果行列の対角要素のみが推定される。これは、ランダム効果が独立であると仮定していることを意味する。\"Diag\" を設定すると、モデルは非常に単純化されるが、推定しなければならないパラメータが少なくなるため、多くの場合、この方法が望ましい。これは変数の数が多い場合や研究の数が少ない場合に特に意味がある。RE.type. ランダム効果モデルを利用する場合、ランダム効果の推定方法を指定する。デフォルトは \"Symm\" で、2つの変数間の共分散を含む、すべての \\(\\tau^2\\) の値を推定する。\"Diag\" に設定すると、ランダム効果行列の対角要素のみが推定される。これは、ランダム効果が独立であると仮定していることを意味する。\"Diag\" を設定すると、モデルは非常に単純化されるが、推定しなければならないパラメータが少なくなるため、多くの場合、この方法が望ましい。これは変数の数が多い場合や研究の数が少ない場合に特に意味がある。この例では、ランダム効果モデルを仮定し、RE.type = \"Diag\" を使用する。モデルを cfa1 として保存し、出力を取得するために summary 関数を呼び出す。OpenMx status を見ると、モデルの推定値が信頼できるものであることが確認可能である。結果をより消化しやすくするために、coef 関数を用いて固定効果 (私たちの推定したプール相関) を抽出することが可能である。次に、vec2symMat を用いて係数から対称行列を作成し、解釈を容易にするために次元名を追加する。これで、変数のプールされた相関行列を見ることが可能である。モデルの出力を見てみると、すべての相関係数が有意であることがわかる ( \\(p<\\) 0.05) ただし、1つだけ、睡眠の質と日中機能不全の相関は有意ではなかった。私たちの想定したモデルの観点からは、これらの変数が異なる因子に負荷されると予想されるので、これは理にかなっている。また、異なる推定値の \\(^2\\) 値が非常に大きい (65-93%) ことがわかる。","code":"\ncfa1 <- tssem1(SleepProblems$data, \n               SleepProblems$n, \n               method=\"REM\",\n               RE.type = \"Diag\")\n\nsummary(cfa1)## \n## Call:\n## meta(y = ES, v = acovR, RE.constraints = Diag(paste0(RE.startvalues, \n##     \"*Tau2_\", 1:no.es, \"_\", 1:no.es)), RE.lbound = RE.lbound, \n##     I2 = I2, model.name = model.name, suppressWarnings = TRUE, \n##     silent = silent, run = run)\n## \n## 95% confidence intervals: z statistic approximation (robust=FALSE)\n## Coefficients:\n##                 Estimate    Std.Error       lbound       ubound z value\n## Intercept1   0.444432236  0.057467775  0.331797465  0.557067006  7.7336\n## Intercept2   0.478173063  0.042506058  0.394862720  0.561483407 11.2495\n## Intercept3   0.032786305  0.071282427 -0.106924685  0.172497295  0.4599\n## Intercept4   0.132711876  0.048151188  0.038337281  0.227086471  2.7561\n## Intercept5   0.509594150  0.036490787  0.438073522  0.581114778 13.9650\n## Intercept6   0.120881305  0.040915599  0.040688204  0.201074406  2.9544\n## Intercept7   0.192545120  0.060739565  0.073497760  0.311592481  3.1700\n## Intercept8   0.221265205  0.039608121  0.143634715  0.298895695  5.5864\n## Intercept9   0.189786602  0.045589099  0.100433611  0.279139594  4.1630\n## Intercept10  0.509204468  0.023983697  0.462197284  0.556211651 21.2313\n## Tau2_1_1     0.032324879  0.015012416  0.002901083  0.061748674  2.1532\n## Tau2_2_2     0.016349084  0.008326703  0.000029047  0.032669121  1.9635\n## Tau2_3_3     0.049769970  0.023797989  0.003126768  0.096413171  2.0914\n## Tau2_4_4     0.019828043  0.010038215  0.000153503  0.039502583  1.9753\n## Tau2_5_5     0.010963532  0.006133040 -0.001057005  0.022984070  1.7876\n## Tau2_6_6     0.012511016  0.007794974 -0.002766852  0.027788883  1.6050\n## Tau2_7_7     0.034863896  0.016839497  0.001859088  0.067868704  2.0704\n## Tau2_8_8     0.012156429  0.006571848 -0.000724157  0.025037015  1.8498\n## Tau2_9_9     0.017532003  0.009481599 -0.001051590  0.036115595  1.8491\n## Tau2_10_10   0.003543432  0.002549068 -0.001452649  0.008539512  1.3901\n##                          Pr(>|z|)    \n## Intercept1    0.00000000000001044 ***\n## Intercept2  < 0.00000000000000022 ***\n## Intercept3               0.645553    \n## Intercept4               0.005849 ** \n## Intercept5  < 0.00000000000000022 ***\n## Intercept6               0.003133 ** \n## Intercept7               0.001524 ** \n## Intercept8    0.00000002318788406 ***\n## Intercept9    0.00003141179890975 ***\n## Intercept10 < 0.00000000000000022 ***\n## Tau2_1_1                 0.031302 *  \n## Tau2_2_2                 0.049594 *  \n## Tau2_3_3                 0.036497 *  \n## Tau2_4_4                 0.048239 *  \n## Tau2_5_5                 0.073838 .  \n## Tau2_6_6                 0.108491    \n## Tau2_7_7                 0.038418 *  \n## Tau2_8_8                 0.064346 .  \n## Tau2_9_9                 0.064450 .  \n## Tau2_10_10               0.164502    \n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## Q statistic on the homogeneity of effect sizes: 908.1438\n## Degrees of freedom of the Q statistic: 100\n## P value of the Q statistic: 0\n## \n## Heterogeneity indices (based on the estimated Tau2):\n##                               Estimate\n## Intercept1: I2 (Q statistic)    0.9316\n## Intercept2: I2 (Q statistic)    0.8837\n## Intercept3: I2 (Q statistic)    0.9336\n## Intercept4: I2 (Q statistic)    0.8547\n## Intercept5: I2 (Q statistic)    0.8315\n## Intercept6: I2 (Q statistic)    0.7800\n## Intercept7: I2 (Q statistic)    0.9093\n## Intercept8: I2 (Q statistic)    0.7958\n## Intercept9: I2 (Q statistic)    0.8366\n## Intercept10: I2 (Q statistic)   0.6486\n## \n## Number of studies (or clusters): 11\n## Number of observed statistics: 110\n## Number of estimated parameters: 20\n## Degrees of freedom: 90\n## -2 log likelihood: -100.688 \n## OpenMx status1: 0 (\"0\" or \"1\": The optimization is considered fine.\n## Other values may indicate problems.)[...]\nCoefficients:\n           Estimate Std.Error lbound  ubound z value Pr(>|z|)    \nIntercept1    0.444     0.057  0.331   0.557   7.733  < 0.001 ***\nIntercept2    0.478     0.042  0.394   0.561  11.249  < 0.001 ***\nIntercept3    0.032     0.071 -0.106   0.172   0.459    0.645    \nIntercept4    0.132     0.048  0.038   0.227   2.756    0.005 ** \nIntercept5    0.509     0.036  0.438   0.581  13.965  < 0.001 ***\nIntercept6    0.120     0.040  0.040   0.201   2.954    0.003 ** \nIntercept7    0.192     0.060  0.073   0.311   3.170    0.001 ** \nIntercept8    0.221     0.039  0.143   0.298   5.586  < 0.001 ***\nIntercept9    0.189     0.045  0.100   0.279   4.163  < 0.001 ***\nIntercept10   0.509     0.023  0.462   0.556  21.231  < 0.001 ***\nTau2_1_1      0.032     0.015  0.002   0.061   2.153    0.031 *  \nTau2_2_2      0.016     0.008  0.000   0.032   1.963    0.049 *  \nTau2_3_3      0.049     0.023  0.003   0.096   2.091    0.036 *  \nTau2_4_4      0.019     0.010  0.000   0.039   1.975    0.048 *  \nTau2_5_5      0.010     0.006 -0.001   0.022   1.787    0.073 .  \nTau2_6_6      0.012     0.007 -0.002   0.027   1.605    0.108    \nTau2_7_7      0.034     0.016  0.001   0.067   2.070    0.038 *  \nTau2_8_8      0.012     0.006 -0.000   0.025   1.849    0.064 .  \nTau2_9_9      0.017     0.009 -0.001   0.036   1.849    0.064 .  \nTau2_10_10    0.003     0.002 -0.001   0.008   1.390    0.164    \n---\nSignif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n[...]\n\nHeterogeneity indices (based on the estimated Tau2):\n                              Estimate\nIntercept1: I2 (Q statistic)    0.9316\nIntercept2: I2 (Q statistic)    0.8837\nIntercept3: I2 (Q statistic)    0.9336\nIntercept4: I2 (Q statistic)    0.8547\nIntercept5: I2 (Q statistic)    0.8315\nIntercept6: I2 (Q statistic)    0.7800\nIntercept7: I2 (Q statistic)    0.9093\nIntercept8: I2 (Q statistic)    0.7958\nIntercept9: I2 (Q statistic)    0.8366\nIntercept10: I2 (Q statistic)   0.6486\n\n[...]\nOpenMx status1: 0 (\"0\" or \"1\": The optimization is considered fine.\nOther values may indicate problems.)\n# 固定係数 (相関) を抽出\nfixed.coefs <- coef(cfa1, \"fixed\")\n\n# 対称行列を作成\nfc.mat <- vec2symMat(fixed.coefs, diag = FALSE)\n\n# 列名と行名をつける\ndimnames(fc.mat)[[1]] <- c(\"Quality\", \"Latency\", \n                           \"Efficiency\", \"DTDysf\", \"HypSomnia\")\ndimnames(fc.mat)[[2]] <- c(\"Quality\", \"Latency\", \n                           \"Efficiency\", \"DTDysf\", \"HypSomnia\")\n\n# 相関行列を表示 (３桁) \nround(fc.mat, 3)##            Quality Latency Efficiency DTDysf HypSomnia\n## Quality      1.000   0.444      0.478  0.033     0.133\n## Latency      0.444   1.000      0.510  0.121     0.193\n## Efficiency   0.478   0.510      1.000  0.221     0.190\n## DTDysf       0.033   0.121      0.221  1.000     0.509\n## HypSomnia    0.133   0.193      0.190  0.509     1.000"},{"path":"sem.html","id":"ステージ-2","chapter":"11 構造方程式モデリングメタ分析","heading":"11.3.2.2 ステージ 2","text":"相関行列をプールした後、提案した因子モデルがデータにうまく適合しているかどうかを判断することになる。モデルを指定するために、今回は RAM 式を使用し、\\(\\boldsymbol{}\\), \\(\\boldsymbol{S}\\), \\(\\boldsymbol{F}\\) という行列を指定する必要がある。これら行列の各フィールドを埋めるために、最初に空行列を構築することが最善であることがよくある。構造的には、私たちが定義したすべて行列は、観測変数だけでなく、仮定した潜在変数である f_Insomnia と f_Lassitude も含んでいる。ここでは、出発点としてゼロ行列を作成する方法を示した。\\(\\boldsymbol{}\\) 行列\\(\\boldsymbol{}\\) 行列では、モデルにおける非対称 (つまり単一) 矢印を指定する。各単一矢印は列変数から始まり、列が行変数のエントリと交差するところで終わる。矢印を表さない他のフィールドはすべて 0 で埋められる。\\(\\boldsymbol{}\\) 行列に文字列を追加することで、矢印を「推定」しなければならないことを指定する。この文字列は、最適化手順の開始値 (通常は 0.1 から 0.3 の間のどこか) で始まり、その後に * が続く。記号の後に、その値のラベルを指定する。\\(\\boldsymbol{}\\) 行列の2つのフィールドが同じラベルを持つ場合、これはそのフィールドが同じ値を持つと仮定することを意味する。この例では、すべての推定矢印の開始値を 0.3 とし、先に示した経路図に従ってフィールドにラベル付けを行う。最後のステップは、\\(\\boldsymbol{}\\) 行列を .mxMatrix 関数に入れて、ステージ2モデルで使用できるようにすることである。\\(\\boldsymbol{S}\\) 行列\\(\\boldsymbol{S}\\) 行列では、推定したい分散を指定する。この例では、これらはすべての観測変数の分散と、2つの潜在要因の間の相関である。まず、潜在要因の自分自身との相関を1に設定した。さらに、観測された変数の分散は 0.2、相関は 0.3 という開始値を使用する。これらはすべてこのコードで指定することができる。そして、再び、.mxMatrix を用いて行列に変換する。\\(\\boldsymbol{F}\\) 行列最後に、\\(\\boldsymbol{F}\\) 行列を指定するのは簡単である。観測された変数の対角要素には 1 を記入し、それ以外は 0 を使用する。さらに、行列の少なくとも 1 つの要素が 0 でない行だけを選択する (つまり、最後の 2 行は 0 しか含まれていないので削除する)。","code":"\n# 行と列の名称のベクトルを作成\ndims <- c(\"Quality\", \"Latency\", \"Efficiency\", \n          \"DTDysf\", \"HypSomnia\", \"f_Insomnia\", \"f_Lassitude\")\n\n# 7x7 のゼロ行列を作成\nmat <- matrix(rep(0, 7*7), nrow = 7, ncol = 7)\n\n# 列名と行名をつける\ndimnames(mat)[[1]] <- dimnames(mat)[[2]] <- dims\nmat##             Qlty Ltncy Effcncy DTDysf HypSmn f_Insmn f_Lsstd\n## Quality        0     0       0      0      0       0       0\n## Latency        0     0       0      0      0       0       0\n## Efficiency     0     0       0      0      0       0       0\n## DTDysf         0     0       0      0      0       0       0\n## HypSomnia      0     0       0      0      0       0       0\n## f_Insomnia     0     0       0      0      0       0       0\n## f_Lassitude    0     0       0      0      0       0       0\nA <- matrix(c(0, 0, 0, 0, 0, \"0.3*Ins_Q\", 0          ,\n              0, 0, 0, 0, 0, \"0.3*Ins_L\", 0          ,\n              0, 0, 0, 0, 0, \"0.3*Ins_E\", 0          ,\n              0, 0, 0, 0, 0, 0          , \"0.3*Las_D\",\n              0, 0, 0, 0, 0, 0          , \"0.3*Las_H\",\n              0, 0, 0, 0, 0, 0          , 0          ,\n              0, 0, 0, 0, 0, 0          , 0\n              ), nrow = 7, ncol = 7, byrow=TRUE)\n\n# 列名と行名をつける\ndimnames(A)[[1]] <- dimnames(A)[[2]] <- dims\nA <- as.mxMatrix(A)\n# 分散を表す対角行列を作る\nVars <- Diag(c(\"0.2*var_Q\", \"0.2*var_L\", \n               \"0.2*var_E\", \"0.2*var_D\", \"0.2*var_H\"))\n\n# 潜在変数に対する行列を作成する\nCors <- matrix(c(1, \"0.3*cor_InsLas\",\n                 \"0.3*cor_InsLas\", 1),\n               nrow=2, ncol=2)\n\n# 結合する\nS <- bdiagMat(list(Vars, Cors))\n\n# 列名と行名をつける\ndimnames(S)[[1]] <- dimnames(S)[[2]] <- dims\nS <- as.mxMatrix(S)\n# 対角行列を作成\nF1 <- Diag(c(1, 1, 1, 1, 1, 0, 0))\n\n# ヌルでない行だけを選択\nF1 <- F1[1:5,]\n\n# 行ラベルと列ラベルの指定\ndimnames(F1)[[1]] <- dims[1:5]\ndimnames(F1)[[2]] <- dims\n\nF1 <- as.mxMatrix(F1)"},{"path":"sem.html","id":"モデル適合","chapter":"11 構造方程式モデリングメタ分析","heading":"11.3.3 モデル適合","text":"さて、いよいよ提案したモデルをプールされたデータに適合させる。これを行うには、 tsem2 関数を使用する。ステージ1のモデル cfa1、3つ行列、そして diag.constraints=FALSE を指定するだけである (mediation モデルを適用しているわけではないため)。結果として得られるオブジェクトを cfa2 として保存し、summary を用いてアクセスする。OpenMxの状態 が 0 であり、最適化がうまくいったことがわかる。出力では、Lassitude \\(\\rightarrow\\) Daytime Dysfunction (Las_D) の 0.69 のように、2つの潜在因子と観察された症状の間のパスの推定値が提供される。私たちはまた、モデルによると、2つの潜在的な要因の間に有意な相関があることがわかる。\\(r_{\\text{Ins,Las}}\\) = 0.33.しかし、最も重要なことは、想定したモデルがどの程度データに適合しているかをチェックすることである。これは Goodness--fit indices を見ることによって達成可能である。適合度検定は、\\(\\chi^2_4=\\) 5.26、\\(p=\\) 0.26 で、有意でないことがわかる。他の統計検定とは異なり、このアウトカムは、私たちのモデルがデータによく適合するという帰無仮説を受け入れることを意味するので、望ましい結果である。さらに、近似値の二乗平均平方根誤差 (Root Mean Square Error Approximation, RMSEA) の値は 0.0098 であることがわかる。経験則では、RSMEA の値が 0.05 以下であれば、モデルはデータによく適合していると考えることができ、値が小さいほど適合度が高いことを示している (Browne Cudeck 1993)。したがって、この適合度指数も、モデルが私たちのデータによく適合していることを示している。\n代替モデル\n\nSEM\n研究によくある問題は、研究者が自分の提唱するモデルにのみ注目し、それがデータにうまく適合するかどうかに注目しがちなことである。もし、想定したモデルがデータに近い適合を示すことがわかれば、多くの研究者は、データが自分の理論を証明したと直接結論づけることが多い。\n\nしかし、同じデータに対して複数のモデルがうまく適合する可能性があるため、これは問題である。したがって、代替モデルの仮説や構造も確認する必要がある。もし、代替モデルもデータにうまくフィットすれば、我々の提案した構造が本当に「正しい」ものなのかどうかがわからなくなる。\n","code":"\ncfa2 <- tssem2(cfa1, \n               Amatrix = A, \n               Smatrix = S, \n               Fmatrix = F1, \n               diag.constraints = FALSE)\nsummary(cfa2)## \n## Call:\n## wls(Cov = pooledS, aCov = aCov, n = tssem1.obj$total.n, RAM = RAM, \n##     Amatrix = Amatrix, Smatrix = Smatrix, Fmatrix = Fmatrix, \n##     diag.constraints = diag.constraints, cor.analysis = cor.analysis, \n##     intervals.type = intervals.type, mx.algebras = mx.algebras, \n##     mxModel.Args = mxModel.Args, subset.variables = subset.variables, \n##     model.name = model.name, suppressWarnings = suppressWarnings, \n##     silent = silent, run = run)\n## \n## 95% confidence intervals: z statistic approximation\n## Coefficients:\n##            Estimate Std.Error   lbound   ubound z value              Pr(>|z|)\n## Las_D      0.688251  0.081845 0.527838 0.848665  8.4092 < 0.00000000000000022\n## Ins_E      0.789438  0.060605 0.670654 0.908221 13.0260 < 0.00000000000000022\n## Las_H      0.741372  0.088425 0.568063 0.914681  8.3842 < 0.00000000000000022\n## Ins_L      0.658587  0.053650 0.553435 0.763739 12.2756 < 0.00000000000000022\n## Ins_Q      0.613591  0.051384 0.512879 0.714303 11.9412 < 0.00000000000000022\n## cor_InsLas 0.330274  0.045607 0.240886 0.419662  7.2418    0.0000000000004428\n##               \n## Las_D      ***\n## Ins_E      ***\n## Las_H      ***\n## Ins_L      ***\n## Ins_Q      ***\n## cor_InsLas ***\n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## Goodness-of-fit indices:\n##                                                Value\n## Sample size                                3272.0000\n## Chi-square of target model                    5.2640\n## DF of target model                            4.0000\n## p value of target model                       0.2613\n## Number of constraints imposed on \"Smatrix\"    0.0000\n## DF manually adjusted                          0.0000\n## Chi-square of independence model            809.5366\n## DF of independence model                     10.0000\n## RMSEA                                         0.0098\n## RMSEA lower 95% CI                            0.0000\n## RMSEA upper 95% CI                            0.0297\n## SRMR                                          0.0413\n## TLI                                           0.9960\n## CFI                                           0.9984\n## AIC                                          -2.7360\n## BIC                                         -27.1086\n## OpenMx status1: 0 (\"0\" or \"1\": The optimization is considered fine.\n## Other values indicate problems.)## [...]\n## Coefficients:\n##            Estimate Std.Error lbound ubound z value Pr(>|z|)    \n## Las_D         0.688     0.081  0.527  0.848   8.409  < 0.001 ***\n## Ins_E         0.789     0.060  0.670  0.908  13.026  < 0.001 ***\n## Las_H         0.741     0.088  0.568  0.914   8.384  < 0.001 ***\n## Ins_L         0.658     0.053  0.553  0.763  12.275  < 0.001 ***\n## Ins_Q         0.613     0.051  0.512  0.714  11.941  < 0.001 ***\n## cor_InsLas    0.330     0.045  0.240  0.419   7.241  < 0.001 ***\n## ---\n## Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n## \n## Goodness-of-fit indices:\n##                                                Value\n## Sample size                                3272.0000\n## Chi-square of target model                    5.2640\n## DF of target model                            4.0000\n## p value of target model                       0.2613\n## [...]\n## RMSEA                                         0.0098\n## RMSEA lower 95% CI                            0.0000\n## RMSEA upper 95% CI                            0.0297\n## [...]\n## OpenMx status1: 0 (\"0\" or \"1\": The optimization is considered fine.\n## Other values indicate problems.)"},{"path":"sem.html","id":"パス図-1","chapter":"11 構造方程式モデリングメタ分析","heading":"11.3.4 パス図","text":"\nモデルの適合後、{metaSEM} はそれをグラフィカルに可視化することを非常に簡単にしてくれる。パス図を描くためには、まず、{semPlot} パッケージ (Epskamp 2019) をインストールし、ロードする必要がある。モデルをプロットするために、{semPlot} が使用できる形式に変換する必要があるので、meta2semPlot 関数を使用して行っておこう。そして、グラフを生成するために、{semPlot} の semPaths 関数を使ってみよう。この関数は多くのパラメータを持っており、コンソールに ?semPaths と入力し、Enter キーを押すことでアクセスすることが可能である。以下がコードと結果のプロットである。\n更なる学習\n\nこの章で取り上げたことは、メタアナリシス SEM\nの初歩的な入門として捉えていただきたい。より詳細なメタアナリシス SEM\nの議論は、Mike Cheung の決定的な本である Meta-Analysis: \nStructural Equation Modeling Approach (2015a)\nに記載されている。この本は、ここでカバーしていない他のさまざまな種類のメタ分析構造方程式モデルについても記述しており、\nR を使用してどのように実装できるかを説明されている。\n\n短めの (そして、オープンにアクセスできる)\nリソースを探すのであれば、{metaSEM} パッケージの\nvignette をお読みいただきたい。この vignette\nには、メタアナリシスSEMの理論について簡単に説明し、 R\nを使ったいくつかの図解を掲載している。{metaSEM}\nをロードした後、コンソールで vignette(“metaSEM”)\nを実行することにより、インターネットからヴィネットをダウンロードすることができる。\n\\[\\tag*{$\\blacksquare$}\\]","code":"\nlibrary(semPlot)\ncfa.plot <- meta2semPlot(cfa2)\n# macOS 用文字化け対策\npar(family= \"HiraKakuProN-W3\")\n\n# プロットラベルを作成 (左から右、下から上) \nlabels <- c(\"睡眠\\nの質\",\n            \"睡眠\\n潜時\",\n            \"睡眠\\n効率\",\n            \"日中機\\n能障害\",\n            \"過眠症\",\"不眠\", \n            \"倦怠感\")\n\n# プロット\nsemPaths(cfa.plot, \n         whatLabels = \"est\", \n         edge.color = \"black\", \n         nodeLabels = labels,\n         sizeMan = 10, \n         sizeLat = 10, \n         edge.label.cex = 1)"},{"path":"sem.html","id":"演習問題-10","chapter":"11 構造方程式モデリングメタ分析","heading":"11.4 演習問題","text":"\n知識を試そう！\n\n構造方程式モデリングとは何か、何のために使うのか。\n\nSEM の表現方法として、どのようなものがあるか？\n\nランダム効果メタ分析を SEM の観点から説明しなさい。\n\n多変量メタ分析とは何か、どのような場合に有用か。\n\n提案したメタ分析 SEM\nがデータによく適合することがわかったとき、このモデルが自動的に「正しい」モデルであることを意味するのだろうか。\n\n問題の解答は、本書の巻末 Appendix\nにある。\n","code":""},{"path":"sem.html","id":"要約-7","chapter":"11 構造方程式モデリングメタ分析","heading":"11.5 要約","text":"構造方程式モデリング (SEM) は、観測される (＝顕在) 変数と観測されない (＝潜在) 変数の間の複雑な関係を検証するために使用できる統計手法である。構造方程式モデリング (SEM) は、観測される (＝顕在) 変数と観測されない (＝潜在) 変数の間の複雑な関係を検証するために使用できる統計手法である。メタ分析はマルチレベルモデルに基づいているため、SEM の観点からも定式化することが可能である。これは、ランダム効果メタ分析を構造方程式モデルとして「複製」するために使用することが可能である。しかし、より重要なことは、観測された効果量間のより複雑な関係をモデル化したメタ分析を行うことができることである。メタ分析はマルチレベルモデルに基づいているため、SEM の観点からも定式化することが可能である。これは、ランダム効果メタ分析を構造方程式モデルとして「複製」するために使用することが可能である。しかし、より重要なことは、観測された効果量間のより複雑な関係をモデル化したメタ分析を行うことができることである。メタ分析 SEM は、例えば、多変量メタ分析を行うために適用することができる。多変量メタ分析では、2つ以上のアウトカムを、両アウトカム間の相関を考慮しながら、共同で推定する。メタ分析 SEM は、例えば、多変量メタ分析を行うために適用することができる。多変量メタ分析では、2つ以上のアウトカムを、両アウトカム間の相関を考慮しながら、共同で推定する。メタ分析的 SEM のもう一つの応用は、確証的因子分析である。含まれるすべての研究にわたって提案された因子モデルの適合性をテストするために、2段階の手順を使用しなければならない。第一段階では、個々の研究の相関行列がプールされる。そして、このプールされた相関行列は、想定された SEM を適合させるために使用される。メタ分析的 SEM のもう一つの応用は、確証的因子分析である。含まれるすべての研究にわたって提案された因子モデルの適合性をテストするために、2段階の手順を使用しなければならない。第一段階では、個々の研究の相関行列がプールされる。そして、このプールされた相関行列は、想定された SEM を適合させるために使用される。","code":""},{"path":"netwma.html","id":"netwma","chapter":"12 ネットワークメタ分析","heading":"12 ネットワークメタ分析","text":"臨\n床試験や他の種類の介入研究のメタ分析を行う場合、通常、1個の特定の治療の真の効果の大きさを推定する。我々は、同じ種類の介入を同様の対照群、例えばプラセボと比較した研究を含める。他の条件がすべて同じであれば、これは特定の種類の治療が効果的かどうかを評価することを可能にする。しかし、多くの研究分野では、「決定的な」治療法は一つだけではなく、いくつもあるのである。例えば、片頭痛はいろいろな薬物療法があるし、非薬物療法の選択肢もある。特に「成熟した」研究分野では、ある種の治療が有効であることを示すことは、あまり意味がないことが多いのである。むしろ、ある特定の適応症に対して、どの治療法が最も効果的であるかを調べたいのである。これは新たな問題を引き起こす。従来のメタ分析で複数の治療の比較有効性を評価するためには、2つの治療間の直接比較が十分存在していることが必要である。しかし、残念なことに、そうではないこともよくある。多くの研究分野では、「弱い」対照群の代わりに、2つの治療の効果を直接比較した臨床試験は、一般にあったとしても少ない。このことは、従来のメタ分析では、複数の治療法の相対的な有効性に関する確かな証拠を確立できないことを意味することが多い。しかし、2つ以上の治療法を直接比較することはできなくとも、間接的な証拠は通常利用可能である。異なる治療法が別々の試験で評価されたとしても、これらの試験はすべて同じ対照群を用いている可能性がある。例えば、直接比較されたことはない2種類の薬があるとしても、それぞれの効果がプラセボと比較して研究されている可能性がある。ネットワークメタ分析 (network meta-analysis) では、このような間接的な比較を取り入れ、複数の介入の効果を同時に比較することがが可能である (Dias et al. 2013)。ネットワークメタ分析は、混合治療比較メタ分析 (mixed-treatment comparison meta-analysis) としても知られている (Valkenhoef et al. 2012)。これは、複数の直接的・間接的な治療比較を1つのモデルに統合し、比較の「ネットワーク」として形式化することができるからである。ネットワークメタ分析は「ホット」な研究トピックである。この10年間で、バイオ分野・メディカル分野やその他の分野の応用研究者によって取り上げられることが増えてきた。しかし、この方法には、異質性やいわゆるネットワークの非一貫性 (network inconsistency) に関する、通常のメタ分析以上に課題や落とし穴もある (Salanti et al. 2014)。したがって、まずネットワークメタ分析モデルの中核的な構成要素と前提について議論することが重要である。ネットワークメタ分析の基礎は、少し抽象的になることがある。そこで、この手法の理解を深めるために、本質的な内容を少しずつ見ていこう。","code":""},{"path":"netwma.html","id":"what-is-net-ma","chapter":"12 ネットワークメタ分析","heading":"12.1 ネットワークメタ分析とは何か?","text":"","code":""},{"path":"netwma.html","id":"direct-indirect-evidence","chapter":"12 ネットワークメタ分析","heading":"12.1.1 直接証拠と間接証拠","text":"まず、治療の「ネットワーク」とは何を意味するのかを理解する必要がある。ある無作為化比較試験 \\(\\) からデータを抽出し、治療Aの効果を他の条件B (例えば、待機リスト対照群) と比較したとする。この比較を図式化することができる。このように治療法の比較を視覚的に表現したものをグラフと呼ぶ。グラフは、異なるオブジェクトが互いにどのように関連しているかをモデル化するために使用される構造であり、このトピックに関する数学の分野として、グラフ理論が存在する。このグラフには２つの主要な構成要素がある。まず、試行 \\(\\) における二つの条件AとBを表す二つの円(いわゆるノード)である。次に、この2つのノードを結ぶ線である。この線はエッジと呼ばれる。エッジは、と B がどのように関係するかを表す。ここでは、この線は非常に簡単に解釈できる。と B を比較したときに観測される効果の大きさ \\(\\theta_{\\text{,,B}}\\) で と B の関係を表すことができる。この効果の大きさは、例えば、結果の指標によって標準化平均差 (SMD) やオッズ比などで表現することが可能である。さて、別の試験 \\(j\\) からもデータを得たとする。この試験でも対照条件Bを用いたが、Aを投与する代わりに別の治療法Cを用いた。これで最初の小さなネットワークができあがる。グラフに2つの効果量推定値が含まれていることがよくわかる。と B を比較した \\(\\hat\\theta_{\\text{,,B}}\\) と、C と B を比較した \\(\\hat\\theta_{j\\text{,C,B}}\\) である。これらの効果量は両方とも「実際の」試験で直接観察されているので、我々はその情報を直接的証拠と呼んでいる。したがって、これらの効果量を \\(\\hat\\theta^{\\text{direct}}_{\\text{B,}}\\) と \\(\\hat\\theta^{\\text{direct}}_{\\text{B,C}}\\) で表記する。この表記で条件 B が最初に来るのは、基準グループと決めたからである。B を参照条件としたのは、両試験で対照群として用いられていたからである。新しいグラフでは、すべてのノード (条件) は、直接的か、間接的に接続されている。B 条件 (対照群) は、他のすべてのノードに直接接続されている。B から他の2つのノード 、C に行くには、グラフ上で1つの「ステップ」しか必要ない: B \\(\\rightarrow\\) , B \\(\\rightarrow\\) C。一方、と C は1つの直接接続しかなく、両方とも B に接続する: \\(\\rightarrow\\) B と C \\(\\rightarrow\\) B。しかし、と C の間には間接的なつながりがある。このつながりは、B が2つの条件 \\(\\rightarrow\\) B と C \\(\\rightarrow\\) B の間のリンク、すなわちブリッジとして機能するために存在する。その結果、ネットワークの構造から導き出される と C の関係の間接的な証拠が存在する。直接観測されたエッジの情報を使って、間接的に観測されたAとCの比較の効果を計算することが可能である。この非観測、間接効果量を \\(\\hat\\theta^{\\text{indirect}}_{\\text{,C}}\\) と表記する。効果推定値は、次の式を用いて導出できる。 (Dias et al. 2018, chap. 1):\\[\\begin{equation}\n\\hat\\theta_{\\text{,C}}^{\\text{indirect}} = \\hat\\theta_{\\text{B,}}^{\\text{direct}} - \\hat\\theta_{\\text{B,C}}^{\\text{direct}}\n\\tag{12.1}\n\\end{equation}\\]このステップは、ネットワークメタ分析の重要な要素である。上記の式は、たとえそれが試験で直接評価されなかったとしても、比較の効果量を推定することが可能である。ネットワークメタ分析では、1つのモデルで直接および間接的なエビデンスを組み合わせる。この情報に基づいて、含まれる各治療の (相対) 効果を推定することが可能である。間接的な証拠を追加することで、その特定の比較に直接的な証拠がある場合でも、効果量推定の精度を上げることが可能である。全体として、ネットワークメタ分析にはいくつかの利点がある。関連する一連の研究から入手可能なすべての情報を1つの分析にプールすることができる。従来のメタ分析で、例えばプラセボと異なる治療法を比較する試験をどのように扱うかを考えてみてみよう。それぞれの比較 (例えば、治療Aとプラセボの比較、治療Bとプラセボの比較、治療Aと治療Bの比較など) を別々のメタ分析でプールしなければならないだろう。関連する一連の研究から入手可能なすべての情報を1つの分析にプールすることができる。従来のメタ分析で、例えばプラセボと異なる治療法を比較する試験をどのように扱うかを考えてみてみよう。それぞれの比較 (例えば、治療Aとプラセボの比較、治療Bとプラセボの比較、治療Aと治療Bの比較など) を別々のメタ分析でプールしなければならないだろう。ネットワークメタ分析では、従来のメタ分析では不可能であった間接的なエビデンスをネットワークに取り込むことが可能である。ペアワイズメタ分析では、実際に試験に含まれた比較のうち、直接的な証拠のみをプールすることができる。ネットワークメタ分析では、従来のメタ分析では不可能であった間接的なエビデンスをネットワークに取り込むことが可能である。ペアワイズメタ分析では、実際に試験に含まれた比較のうち、直接的な証拠のみをプールすることができる。すべての仮定が満たされ、結果が十分に決定的であれば、ネットワークメタ分析によって、研究対象集団に対してどのタイプの治療が望ましいかを推論することができる。すべての仮定が満たされ、結果が十分に決定的であれば、ネットワークメタ分析によって、研究対象集団に対してどのタイプの治療が望ましいかを推論することができる。これらはすべて興味深いものであるが、考慮すべき重要な限界がいくつかある。まず、間接効果量の推定値の分散がどのように計算されるかを見てみよう。\\[\\begin{equation}\n\\text{Var} \\left(\\hat\\theta_{\\text{,C}}^{\\text{indirect}} \\right) = \\text{Var} \\left(\\hat\\theta_{\\text{B,}}^{\\text{direct}} \\right) + \\text{Var} \\left(\\hat\\theta_{\\text{B,C}}^{\\text{direct}} \\right)\n\\tag{12.2}\n\\end{equation}\\]間接比較の分散を計算するために、直接比較の分散を 足し算 した。つまり、間接的な証拠から推定される効果量は、直接的な証拠に基づくものよりも常に大きな分散を持ち、したがって精度も低くなる (Dias et al. 2018, chap. 1)。これは極めて論理的である。数学的に推測しなければならない結果に比べ、観測データから推定された効果量には、はるかに高い信頼性を持つことができるのである。\nさらにもう1つの問題がある。直接比較から間接的な証拠を推定することができる先ほどの式 (12.1) は、重要な前提条件である推移性 (transitivity) の仮定が満たされた場合にのみ成立する (船尾と黒田は transitivity の訳に「類似性」をあてている)。統計学的な観点からは、この仮定はネットワークの一貫性 (consistency) と訳される (訳注: Minds では「一貫性」、神田と船尾と黒田は「一致性」と訳している。このほか「整合性」と訳されることもある) (Efthimiou et al. 2016)。以下では、この2つの用語の意味と、それらがなぜ重要であるかを説明する。","code":""},{"path":"netwma.html","id":"transitivity-consistency","chapter":"12 ネットワークメタ分析","heading":"12.1.2 推移性と一貫性","text":"ネットワークメタ分析は、標準的なメタ分析手法の延長線上にある貴重な手法であるのは間違いない。しかし、その有効性には疑問が残る。ネットワークメタ分析に対する批判の多くは、推察される通り、間接的な証拠の利用を中心に展開されている (Edwards et al. 2009; Ioannidis 2006)。これは特に、比較のために直接証拠が実際に利用可能である場合を含んでいる。(ランダム化) 試験の参加者は治療条件 (例えば と B) のいずれかに偶然割り当てられるが、私たちのネットワークでは試験条件そのものはランダムに選択されていないという点は重要である。もちろん、これはすべて論理的なことである。通常、被験者をいくつかの試験条件のうちの1つにランダムに割り当てることは問題ない。しかし、研究者がサイコロを振って治験の治療条件を決めてから研究を展開することは考えにくい。ネットワークメタ分析では、選択された試験条件の構成がランダムなパターンになることはほとんどない。これはネットワークメタ分析モデル自体の問題ではない (Dias et al. 2018, chap. 1)。ネットワークメタ分析モデルが偏るのは、試験内の特定の比較の選択、または非選択が、その比較の真の効果に依存する場合のみである (Dias et al. 2013)。この表現はかなり抽象的なので、少し詳しく説明しよう。\n今述べた要件は、ネットワークメタ分析の推移性 (transitivity) という仮定から導かれたものである。これがネットワークメタ分析に特有の仮定なのか、それとも従来の pairwise メタ分析の仮定を単に拡張したものなのかについては、文献上でも意見が分かれているようである。また、この意見の相違は、文献における用語の一貫性のない使い方にも一部起因している可能性がある (Dias et al. 2018; Efthimiou et al. 2016; Song et al. 2009; Lu Ades 2009)。推移性の仮定の核となる考え方は、以前、式 (12.1) (Efthimiou et al. 2016) を用いて行ったように、(例えば比較 \\(-\\) B と C \\(-\\) Bから) 直接証拠を組み合わせて、関連する比較 (例えば \\(-\\) C) について間接証拠を作り出せることである。推移性の仮定は交換性 (exchangeability) の概念と関係している。この前提条件については、ランダム効果モデルについて説明した Chapter 4.1.2 で既に述べた。交換可能性の仮定は、ある比較 \\(\\) のそれぞれの真の効果量 \\(\\theta_i\\) は、真の効果量の「包括的」分布からランダムに、独立に引き出された結果であることを言う。この仮定を私たちのシナリオに置き換えると、ネットワークメタ分析は、\\(K\\) 件の臨床試験のセットと考える。ここで、このモデルの各試験は、\\(M\\) で示されるネットワークでのすべての治療比較を含むと仮定する (たとえば、\\(-\\) B、\\(-\\) C、B \\(-\\) C など)。しかし、いくつかの臨床試験では、治療比較が「削除」され、「欠落」しているものがある。その理由は、実際には、研究はすべての可能な治療法の選択肢を評価することはできないからである (Dias et al. 2013)。重要な前提としては、ある比較、例えば \\(-\\) B の効果は、試験間で交換可能であり、ある試験が実際にこの比較を評価したか、それが 「欠落」しているかは関係ない、ということである。ネットワークメタ分析では、ある比較 \\(\\) の効果 \\(\\hat\\theta_i\\) が、効果量が直接または間接的な証拠によって得られたとしても、真の効果の包括的な分布からのランダムで独立した抽選に基づくとき、交換性が満たされる。共変量や他の効果修飾因子 (調査集団の年齢層や治療強度など) が、例えば、条件 対 B、C 対 B を評価する試験間で均等に分布していない場合、推移性の仮定が破られる可能性がある (Song et al. 2009)。推移性を統計的に検証することはできないが、母集団、方法論、対象条件ができるだけ類似している試験のみを含めることで、この仮定に違反するリスクを軽減することがが可能である (Salanti et al. 2014)。統計的な推移性の現れ方を一貫 (consistency) と言い、その欠如を非一貫 (inconsistency) と言う (Efthimiou et al. 2016; Cipriani et al. 2013)。一貫とは、直接証拠に基づく比較 (例: \\(-\\) B) と間接証拠に基づく比較の相対的効果が異ならないことを意味する (Schwarzer, Carpenter, Rücker 2015, chap. 8)。\\[\\begin{equation}\n\\theta_{\\text{,B}}^{\\text{indirect}} = \\theta_{\\text{,B}}^{\\text{direct}}\n\\tag{12.3}\n\\end{equation}\\]ネットワークメタ分析モデルの非一貫を診断する方法として、net heat plots (Krahn, Binder, König 2013) や node splitting method (Dias et al. 2010) など、いくつかの方法が提案されている。これらの方法については、以下のセクションで詳しく説明する。","code":""},{"path":"netwma.html","id":"netw-which-model","chapter":"12 ネットワークメタ分析","heading":"12.1.3 ネットワークメタ分析のモデル","text":"以上で、ネットワークメタ分析モデルの基本的な理論と前提条件についての説明を終える。以前は、3つのノードとエッジを持つ単純なネットワークを説明として使用していた。しかし、実際には、ネットワークメタ分析に含まれる治療法の数は、通常、はるかに多くなる。そのため、すぐにかなり複雑なネットワークになり、例えば次のようなネットワークになる。しかし、ネットワーク内の治療法 \\(S\\) の数が増えれば、推定しなければならない (直接・間接) 一対比較 \\(C\\) の数は急増する。\nしたがって、効率的かつ内部的に一貫性のある方法で、利用可能なすべてのネットワークデータをプールできる計算モデルが必要である。ネットワークメタ分析のために、いくつかの統計的アプローチが開発されている (Efthimiou et al. 2016)。以下の章では、頻度論的階層モデル (frequentist hierarchical model) とベイズ階層モデル (Bayesian hierarchical model) について説明し、それらがどのように R に実装され得るかを説明する。\nどのモデル手法を使うべきか？\n\n複数のネットワークメタ分析モデルがある場合、それぞれの統計手法が異なることもありうる。良いことにサンプルサイズが十分であれば、どれも同じ結果を出すはずである\n(Shim et al. 2019)。一般的に、ネットワークメタ分析の方法は、他の方法よりも有効であるとか、有効でなかったりすることはない。そのため、直感的に選ぶか、またはそれを実装している\nR\nパッケージの機能に基づいて、どちらかの方法を安全に選択することがが可能である\n(Efthimiou et al. 2016)。\n\nほとんどの分野では、ベイズ的アプローチよりも頻度論的推論に基づく手法の方が\n(今でも)\nずっと一般的である。これは、人によっては、頻度論的モデルが生み出す結果をより簡単に理解することができるためかもしれない。頻度論的モデルのデメリットとしては、\nR における頻度論的ネットワークメタ分析の実装 (次に取り上げる)\nでは、ベイズモデルで可能なメタ回帰がまだサポートされていないことが挙げられる。\n\n実際には、メインの分析に1つのアプローチを選択し、感度分析でもう1つのアプローチを採用するのが有効な戦略である。2つの手法が同じ結論に至れば、その知見が信頼に足るものであるという確信が得られる。\n","code":""},{"path":"netwma.html","id":"frequentist-ma","chapter":"12 ネットワークメタ分析","heading":"12.2 頻度論的ネットワークメタ分析","text":"\n以下では、{netmeta} パッケージ (Rücker et al. 2020) を用いたネットワークメタ分析の実行方法を説明する。このパッケージは、頻度論的 (frequentist) 枠組みでネットワークメタ分析モデルを推定することが可能である。{netmeta} で使用されている手法は、もともと電気ネットワーク用に開発されたグラフ理論的手法から派生したものである (Rücker 2012)。\n確率の頻度論的解釈\n\n頻度論的とは、ある事象 \\(E\\)\nの確率を解釈するための一般的な理論的アプローチである。頻出論的アプローチは、あるプロセス\n(例えば実験) を何度も何度も繰り返した場合に\\(E\\) が発生すると予想される頻度で \\(E\\) の確率を定義する (Aronow Miller 2019, chap. 1.1.1)。\n\n頻度論的な考え方は、定量的な研究者が日常的に使う多くの統計処理、例えば有意性検定、信頼区間の計算、\\(p\\)\n値の計算などの核心となるものである。\n","code":""},{"path":"netwma.html","id":"グラフ理論モデル","chapter":"12 ネットワークメタ分析","heading":"12.2.1 グラフ理論モデル","text":"ここで、{netmeta} パッケージで実装されているネットワークメタ分析モデルがどのように定式化されるかを説明しよう。いくつかの臨床試験から効果量のデータを集めたとする。そして、\\(K\\) 件すべての試験を調べて、試験に含まれる治療比較の総数を数える。この対の比較の数を \\(M\\) 件とする。そして、各比較 \\(m\\) に対する効果量 \\(\\hat\\theta_m\\) を計算し、全ての効果量をベクトル \\(\\boldsymbol{\\hat\\theta} = (\\hat\\theta_1, \\hat\\theta_2, \\dots, \\hat\\theta_M)\\) に集める。ネットワークメタ分析を行うには、この観測された効果量のベクトル \\(\\boldsymbol{\\hat\\theta}\\) がどのように生成されたかを記述するモデルが必要である。{netmeta}では、以下のようなモデルを用いる (Schwarzer, Carpenter, Rücker 2015, chap. 8)。\\[\\begin{equation}\n\\boldsymbol{\\hat\\theta} =\\boldsymbol{X} \\boldsymbol{\\theta}_{\\text{treat}} + \\boldsymbol{\\epsilon}\n\\tag{12.4}\n\\end{equation}\\]観測された効果の大きさのベクトル \\(\\boldsymbol{\\hat\\theta}\\) は、式の右辺 (私たちのモデル) によって生成されたと仮定する。前段の \\(\\boldsymbol{X}\\) は \\(m \\times n\\) デザイン行列で、列は異なる治療法 \\(n\\)、行は治療比較 \\(m\\) を表している。この行列では、治療比較は同じ行の1と-1で定義され、列の位置は比較される治療と対応する。式の最も重要な部分は、ベクトル \\(\\boldsymbol{\\theta}_{\\text{treat}}\\) である。このベクトルは、ネットワーク内の \\(n\\) 個のユニークな治療の真の 効果を含みる。このベクトルは、ネットワークメタ分析モデルが推定する必要があるもので、ネットワーク内のどの治療が最も効果的であるかを決定することを可能にするからである。パラメータ \\(\\boldsymbol{\\epsilon}\\) は、すべての比較のサンプリング誤差\\(\\epsilon_m\\)を含むベクトルである。各比較のサンプリング誤差は、平均0、分散\\(\\sigma^2_m\\)のガウス正規分布から無作為抽出であると仮定する。\\[\\begin{equation}\n\\epsilon_m \\sim \\mathcal{N}(0,\\sigma_m^2)\n\\tag{12.4}\n\\end{equation}\\]モデル式を説明するために (Schwarzer, Carpenter, Rücker 2015, 189参照)、私たちのネットワークメタ分析が \\(K=\\) 5 件の研究から構成されていると想像する。各研究は、ユニークな治療比較を含む (すなわち、\\(K=M\\))。これらの比較は、\\(-\\) B, \\(-\\) C, \\(-\\) D, B \\(-\\) C, および B \\(-\\) Dである。この結果、(観測された) 比較のベクトルは \\(\\boldsymbol{\\hat\\theta} = (\\hat\\theta_{1\\text{,,B}}, \\hat\\theta_{2\\text{,,C}}, \\hat\\theta_{4\\text{,,D}}, \\hat\\theta_{4\\text{,B,C}}, \\hat\\theta_{5\\text{,B,D}})^\\top\\)。 私たちの目的は、ネットワークに含まれる4つの条件全ての真の効果量、\\(\\boldsymbol{\\theta}_{\\text{treat}} = (\\theta_{\\text{}}, \\theta_{\\text{B}}, \\theta_{\\text{C}}, \\theta_{\\text{D}})^\\top\\) を推定することである。これらのパラメータをモデルの式に代入すると、次のような式が得られる。\\[\\begin{align}\n  \\boldsymbol{\\hat\\theta} &= \\boldsymbol{X} \\boldsymbol{\\theta}_{\\text{treat}} + \\boldsymbol{\\epsilon} \\notag \\\\\n\\begin{bmatrix}\n\\hat\\theta_{1\\text{,,B}} \\\\\n\\hat\\theta_{2\\text{,,C}} \\\\\n\\hat\\theta_{3\\text{,,D}} \\\\\n\\hat\\theta_{4\\text{,B,C}} \\\\\n\\hat\\theta_{5\\text{,B,D}} \\\\\n\\end{bmatrix}\n&=\n\\begin{bmatrix}\n1 & -1 & 0 & 0 \\\\\n1 & 0 & -1 & 0 \\\\\n1 & 0 & 0 & -1 \\\\\n0 & 1 & -1 & 0 \\\\\n0 & 1 & 0 & -1 \\\\\n\\end{bmatrix}\n\\begin{bmatrix}\n\\theta_{\\text{}} \\\\\n\\theta_{\\text{B}} \\\\\n\\theta_{\\text{C}} \\\\\n\\theta_{\\text{D}} \\\\\n\\end{bmatrix}\n+\n\\begin{bmatrix}\n\\epsilon_{1} \\\\\n\\epsilon_{2} \\\\\n\\epsilon_{3} \\\\\n\\epsilon_{4} \\\\\n\\epsilon_{5} \\\\\n\\end{bmatrix}\n\\tag{12.5}\n\\end{align}\\]なお、このモデル式は、現在のままでは数学的な観点から問題がある。今のところ、このモデルはoverparameterizedである。手元の情報に基づいて推定するには、私たちのモデルにはあまりにも多くのパラメータ \\(\\boldsymbol{\\theta}_{\\text{treat}}\\) が存在する。これは、デザイン行列 \\(\\boldsymbol{X}\\) がフルランクでないことと関係がある。ここでは、行列は、その列がすべて独立でないとき、フルランクを持たない。または、別の言い方をすると、独立列の数が列の総数 \\(n\\) より小さいとき、フルランクを持たない 61 。治療のネットワークを扱っているので、治療の組み合わせが互いに完全に独立でないことは明らかである。例えば、治療Dの列 (4列目) は、最初の3列の線形結合として記述することができる 62 。全体として、たかだか \\(n-1\\) 個の独立した治療比較が存在することになるが、ここでのモデルは常に \\(\\boldsymbol{\\theta}_{\\text{treat}}\\) の \\(n\\) 個の治療の真の効果を推定しなければならない。したがって、この行列はフルランクではない。このように \\(\\boldsymbol{X}\\) がフルランクを持たないということは、invertibleではないということである。したがって、\\(\\boldsymbol{\\theta}_{\\text{treat}}\\) は (加重) 最小二乗法を使って直接推定することができないのである。そこで、{netmeta} に実装されているグラフ理論のアプローチが解決策を提供する。このアプローチの背後にある退屈な数学的詳細については、{netmeta} パッケージが作業してくれるので、ここでは割愛する。この方法は、いわゆる Moore-Penrose 擬似逆行列を構築し、重み付き最小二乗法を用いてネットワークモデルの適合値を計算することができる、ということだけを述べておく。この手順では、2つ以上のペアワイズ比較 (つまり、2つ以上の条件が比較された研究) を行うマルチアーム (訳注: arm は群と同じ意味) 研究についても考慮する。マルチアーム比較は、少なくとも1つの条件が2回以上比較されるため、相関がある (Chapter 3.5.2)。このことは、このモデルで説明しない限り、マルチアーム試験の比較の精度が人為的に高くなることを意味する。また、このモデルでは、試験間の異質性 (heterogeneity) の推定値を組み込むことができる。「従来の」ランダム効果モデル (Chapter 4.1.2) と同様に、比較 \\(m\\) の分散に推定異質性分散 \\(\\hat\\tau^2\\) を追加することで実現する。すなわち \\(s^2_m + \\hat\\tau^2\\) である。{netmeta}パッケージでは、DerSimonian-Laird estimator 法 (Jackson, White, Riley 2013, Chapter 4.1.2.1 も参照) を適応して\\(\\tau^2\\)値を推定している。\\(^2\\) に相当するものも計算でき、これでネットワーク内の非一貫 (inconsistency) の量を表すことができる。この \\(^2\\) は、Higgins Thompson の式と同様に、\\(Q\\) から導かれる。ただし、ネットワークメタ分析では、\\(Q\\) はネットワークの総異質性に変換される (\\(Q_{\\text{total}}\\)とも表記される)。したがって、以下の式が使われる。\\[\\begin{equation}\n^2 = \\text{max} \\left(\\frac{Q_{\\text{total}}-\\text{d.f.}} {Q_{\\text{total}}}, 0 \\right)\n\\tag{12.6}\n\\end{equation}\\]ここで、ネットワークの自由度は:\\[\\begin{equation}\n\\text{d.f.} = \\left( \\sum^K_{k=1}p_k-1 \\right)- (n-1)\n\\tag{12.7}\n\\end{equation}\\]とし、\\(K\\) を研究の総数、\\(p\\) をある研究 \\(k\\) における条件の数、\\(n\\) をネットワークモデルにおける治療の総数とする。","code":""},{"path":"netwma.html","id":"r-での頻度論的ネットワークメタ分析","chapter":"12 ネットワークメタ分析","heading":"12.2.2 R での頻度論的ネットワークメタ分析","text":"ここまでインプットしたら、いよいよ実践的な例題である。以下では、{netmeta} を使って、独自のネットワークメタ分析を行う。いつものように、まずパッケージをインストールし、それからライブラリからロードする。","code":"\nlibrary(netmeta)"},{"path":"netwma.html","id":"データを準備","chapter":"12 ネットワークメタ分析","heading":"12.2.2.1 データを準備","text":"この図では、TherapyFormats データを使用している。このデータセットは、うつ病に対する認知行動療法の異なる提供形式の有効性を評価する実際のネットワークメタ分析 (P. Cuijpers, Noma, et al. 2019) をモデルとしている。含まれるすべての研究は、うつ病の症状に対する効果がテスト後に測定されたランダム化比較試験である。含まれる比較の効果量は、分析された2つの条件間の標準化平均差 (SMD) として表現されている。\n“TherapyFormats” データセット\n\nTherapyFormats データセットは {dmetar}\nパッケージに含まれている。{dmetar}\nをインストールし、ライブラリからロードした後、\ndata(TherapyFormats) を実行すると、自動的に R\n環境にデータセットが保存される。これでデータセットが使用できるようになる。\n\n{dmetar} がインストールされていない場合は、インターネット\nから .rda\nファイルとしてデータセットをダウンロードし、作業ディレクトリに保存してから、R\nStudio ウィンドウでクリックしてインポートすることが可能である。\nデータを見てみよう。2列目の TE には、すべての比較の効果量、そして seTE にはそれぞれの標準誤差が格納される。{netmeta} を使用するには、データセット内の全ての効果量が既に計算されている必要がある。効果量の計算方法については、Chapter 3 で説明したが、Chapter 17 の章では、さらに詳しい計算方法を紹介している。2列目の TE には、すべての比較の効果量、そして seTE にはそれぞれの標準誤差が格納される。{netmeta} を使用するには、データセット内の全ての効果量が既に計算されている必要がある。効果量の計算方法については、Chapter 3 で説明したが、Chapter 17 の章では、さらに詳しい計算方法を紹介している。このデータセットには、さらに2つの列がある。このデータセットには、さらに2つの列が含まれているが、ここでは示していない。これらの列には、単純に条件のフルネームが格納されている。このデータセットには、さらに2つの列がある。このデータセットには、さらに2つの列が含まれているが、ここでは示していない。これらの列には、単純に条件のフルネームが格納されている。studlab 列は、特定の治療比較がどの研究から抽出されたかを示す、ユニークな研究ラベルを含んでいる。この列は、マルチアーム研究 (すなわち、複数の比較対象がある研究) をチェックするのに便利である。これは、 table と .matrix 関数を使用して行うことが可能である。studlab 列は、特定の治療比較がどの研究から抽出されたかを示す、ユニークな研究ラベルを含んでいる。この列は、マルチアーム研究 (すなわち、複数の比較対象がある研究) をチェックするのに便利である。これは、 table と .matrix 関数を使用して行うことが可能である。TherapyFormatsのデータセットには、Breiman によるマルチアーム研究1件しか含まれていない。この研究には3つの比較が含まれているが、他の研究は1つしか含まれていない。ネットワークメタ分析のデータを作成する際には、(1) データセットに研究ラベルの列を含めること、(2) その列で個々の研究に固有の名前を付けること、(3) 2つ以上の比較に貢献する研究には正確に同じ名前を付けることが不可欠となる。","code":"\nlibrary(dmetar)\ndata(TherapyFormats)\n\nhead(TherapyFormats[1:5])##          author     TE  seTE treat1 treat2\n## 1  Ausbun, 1997  0.092 0.195    ind    grp\n## 2  Crable, 1986 -0.675 0.350    ind    grp\n## 3  Thiede, 2011 -0.107 0.198    ind    grp\n## 4 Bonertz, 2015 -0.090 0.324    ind    grp\n## 5     Joy, 2002 -0.135 0.453    ind    grp\n## 6   Jones, 2013 -0.217 0.289    ind    grp\nas.matrix(table(TherapyFormats$author))## [...]\n## Bengston, 2004              1\n## Blevins, 2003               1\n## Bond, 1988                  1\n## Bonertz, 2015               1\n## Breiman, 2001               3\n## [...]"},{"path":"netwma.html","id":"モデルを適合","chapter":"12 ネットワークメタ分析","heading":"12.2.2.2 モデルを適合","text":"netmeta 関数を使って、最初のネットワークメタ分析モデルを適合させることが可能である。最も重要な引数は以下の通りである。TE. 各比較の効果量を含むデータセットの列の名前である。TE. 各比較の効果量を含むデータセットの列の名前である。seTE. 各比較の標準誤差を格納する列の名前。seTE. 各比較の標準誤差を格納する列の名前。treat1. データセット中の 最初の 処置の名前を格納する列。treat1. データセット中の 最初の 処置の名前を格納する列。treat2. データセット中の treat2 の列には、2番目の 処置の名前が含まれている。treat2. データセット中の treat2 の列には、2番目の 処置の名前が含まれている。studlab. 比較対象が抽出された研究。この引数はオプションであるが、常に指定することを勧める。この引数は任意であるが、常に指定することを推奨する。これは、私たちのネットワークにマルチアーム試験がある場合に、この関数に知らせる唯一の方法である。studlab. 比較対象が抽出された研究。この引数はオプションであるが、常に指定することを勧める。この引数は任意であるが、常に指定することを推奨する。これは、私たちのネットワークにマルチアーム試験がある場合に、この関数に知らせる唯一の方法である。data. データセットの名前である。data. データセットの名前である。sm. 使用する効果量の種類。\"RD\" (リスク差)、\"RR\" (リスク比)、\"\" (オッズ比)、\"HR\" (ハザード比)、\"MD\" (平均差)、 \"SMD\" (標準化平均差) などとすることができる。その他の利用可能な指標については、関数ドキュメント (?netmeta) を参照。sm. 使用する効果量の種類。\"RD\" (リスク差)、\"RR\" (リスク比)、\"\" (オッズ比)、\"HR\" (ハザード比)、\"MD\" (平均差)、 \"SMD\" (標準化平均差) などとすることができる。その他の利用可能な指標については、関数ドキュメント (?netmeta) を参照。fixed. 固定効果ネットワークメタ分析を行うかどうか？TRUE または FALSE を指定する必要がある。fixed. 固定効果ネットワークメタ分析を行うかどうか？TRUE または FALSE を指定する必要がある。random. ランダム効果モデルを用いるか？TRUE または FALSE。random. ランダム効果モデルを用いるか？TRUE または FALSE。reference.group. 他の全ての治療に対して、どの治療を参照治療とするか (例: reference.group = \"grp\" ) を指定することが可能である。reference.group. 他の全ての治療に対して、どの治療を参照治療とするか (例: reference.group = \"grp\" ) を指定することが可能である。tol.multiarm. マルチアーム研究の比較の効果量は、デザイン上、一貫している。しかし、原著論文では、各比較でわずかにずれた結果が報告されていることがあり、その結果、一貫性が損なわれていることがある。この引数で、効果量とその標準誤差の非一貫性に対する許容閾値 (数値) を指定することで、モデルで許容される。tol.multiarm. マルチアーム研究の比較の効果量は、デザイン上、一貫している。しかし、原著論文では、各比較でわずかにずれた結果が報告されていることがあり、その結果、一貫性が損なわれていることがある。この引数で、効果量とその標準誤差の非一貫性に対する許容閾値 (数値) を指定することで、モデルで許容される。details.chkmultiarm. 効果量の不一致があるマルチアーム比較の推定値を表示するかどうか (TRUE または FALSE).details.chkmultiarm. 効果量の不一致があるマルチアーム比較の推定値を表示するかどうか (TRUE または FALSE).sep.trts. 比較ラベルのセパレーターとして使用する文字 (例: \" vs. \")。sep.trts. 比較ラベルのセパレーターとして使用する文字 (例: \" vs. \")。最初のネットワークメタ分析の結果は、m.netmetaという名前で保存される。参照グループとして、“care usual” (\"cau\") 条件を使用する。今は、固定効果モデルが適切であると仮定しよう。この場合、次のようなコードになる。この出力には見るべきものがたくさんあるので、順を追って見ていこう。最初に見るのは、各比較の計算された効果量である。アスタリスク記号 (*) は、標準誤差が (効果量の依存性を考慮し) 修正された私たちのマルチアーム研究を示している。その下には、各研究の治療群の数の概要が示されている。次の表は、私たちの (固定効果) ネットワーク・メタ分析モデルにおける各比較の適合値を示している。この表の \\(Q\\) 列は、どの比較がネットワーク全体の非一貫性に大きく寄与しているかを示しており、とても興味深い。例えば、Crable, 1986 の \\(Q\\) 値は \\(Q=\\) 3.05 で、かなり高いことがわかる。そして、ネットワークメタ分析の核心である「治療推定値」にたどり着く。指定されたように、すべての治療の効果は、通常通りのケアとの比較で表示されているが、それが cau の効果が表示されていない理由である。その下に、このネットワークモデルにおける異質性/非一貫性が非常に高く、\\(^2=\\) 89.6%であることを見ることができる。これは、固定効果モデルの選択がおそらく適切ではなかったことを示している (この点については後ほど触れる)。\n出力の最後の部分 (Tests heterogeneity) は、ネットワークにおける総異質性を、2つのコンポーネントに分解している。すなわち、デザイン内の異質性、およびデザイン間の不一致である。「デザイン」とは、例えばA \\(-\\) B、\\(-\\) B \\(-\\) Cのように、1つの試験に含まれる条件の選択と定義される。全く同じ条件を含む試験間で真の効果量の差がある場合、デザイン内異質性と呼ぶことができる。一方、デザイン間のばらつきは、このネットワークの非一貫性を反映している。デザイン内異質性、デザイン間非一貫性ともに非常に有意である (\\(p\\)s < 0.001)。これは、ランダム効果モデルが指示されている可能性を示すもう一つの兆候である。これをさらに裏付けるために、full design--treatment interaction random-effects model (J. Higgins et al. 2012) に基づく全体の非一貫性 (total inconsistency) を算出しよう。これを行うには、m.netmeta オブジェクトを decomp.design 関数に当てはめればよい。出力では、まず、このモデルにおけるデザイン内およびデザイン間の異質性/非一貫性に対する各デザインの個々の寄与を示す \\(Q\\) 値が示される。出力の重要な部分は、最後の部分 (Q statistic assess consistency assumption full design--treatment interaction random effects model) である。完全な design--treatment のランダム効果モデルを仮定すると、\\(Q\\) の値がかなり減少し (以前は \\(Q=\\) 101.83、今は \\(Q=\\) 3.83)、デザイン間の非一貫性が有意でなくなったことがわかる (\\(p=\\) 0.9865)。このことは、私たちのネットワークモデルにおける非一貫性や異質性を説明するために、少なくとも部分的にランダム効果モデルが示される可能性をも示唆している。","code":"\nm.netmeta <- netmeta(TE = TE,\n                     seTE = seTE,\n                     treat1 = treat1,\n                     treat2 = treat2,\n                     studlab = author,\n                     data = TherapyFormats,\n                     sm = \"SMD\",\n                     fixed = TRUE,\n                     random = FALSE,\n                     reference.group = \"cau\",\n                     details.chkmultiarm = TRUE,\n                     sep.trts = \" vs \")\nsummary(m.netmeta)## Original data (with adjusted standard errors for multi-arm studies):\n## \n##                    treat1 treat2    TE seTE seTE.adj narms multiarm\n## [...]\n## Burgan, 2012          ind    tel -0.31 0.13   0.1390     2         \n## Belk, 1986            ind    tel -0.17 0.08   0.0830     2         \n## Ledbetter, 1984       ind    tel -0.00 0.23   0.2310     2         \n## Narum, 1986           ind    tel  0.03 0.33   0.3380     2         \n## Breiman, 2001         ind    wlc -0.75 0.51   0.6267     3        *\n## [...]\n## \n## Number of treatment arms (by study):\n##                          narms\n## Ausbun, 1997                 2\n## Crable, 1986                 2\n## Thiede, 2011                 2\n## Bonertz, 2015                2\n## Joy, 2002                    2\n## [...]\n## \n## Results (fixed effects model):\n## \n##                treat1 treat2   SMD         95%-CI      Q leverage\n## Ausbun, 1997      grp    ind  0.06 [ 0.00;  0.12]   0.64     0.03\n## Crable, 1986      grp    ind  0.06 [ 0.00;  0.12]   3.05     0.01\n## Thiede, 2011      grp    ind  0.06 [ 0.00;  0.12]   0.05     0.03\n## Bonertz, 2015     grp    ind  0.06 [ 0.00;  0.12]   0.01     0.01\n## Joy, 2002         grp    ind  0.06 [ 0.00;  0.12]   0.02     0.00\n## [....]\n## \n## Number of studies: k = 182\n## Number of treatments: n = 7\n## Number of pairwise comparisons: m = 184\n## Number of designs: d = 17\n## \n## Fixed effects model\n## \n## Treatment estimate (sm = 'SMD', comparison: other treatments vs 'cau'):\n##         SMD             95%-CI      z  p-value\n## cau       .                  .      .        .\n## grp -0.5767 [-0.6310; -0.5224] -20.81 < 0.0001\n## gsh -0.3940 [-0.4588; -0.3292] -11.92 < 0.0001\n## ind -0.6403 [-0.6890; -0.5915] -25.74 < 0.0001\n## tel -0.5134 [-0.6078; -0.4190] -10.65 < 0.0001\n## ush -0.1294 [-0.2149; -0.0439]  -2.97   0.0030\n## wlc  0.2584 [ 0.2011;  0.3157]   8.84 < 0.0001\n##\n## \n## Quantifying heterogeneity / inconsistency:\n## tau^2 = 0.26; tau = 0.51; I^2 = 89.6% [88.3%; 90.7%]\n## \n## Tests of heterogeneity (within designs) and inconsistency (between designs):\n##                       Q d.f.  p-value\n## Total           1696.84  177 < 0.0001\n## Within designs  1595.02  165 < 0.0001\n## Between designs  101.83   12 < 0.0001\ndecomp.design(m.netmeta)## Q statistics to assess homogeneity / consistency\n##  [...]\n## Design-specific decomposition of within-designs Q statistic\n## \n##      Design      Q df  p-value\n##  cau vs grp   82.5 20 < 0.0001\n##  cau vs gsh    0.7  7   0.9982\n##  cau vs ind  100.0 29 < 0.0001\n##  cau vs tel   11.4  5   0.0440\n##  [...]\n## \n## Between-designs Q statistic after detaching of single designs\n## \n##    Detached design      Q df  p-value\n##  [...]\n##         ind vs wlc  77.23 11 < 0.0001\n##         tel vs wlc  95.45 11 < 0.0001\n##         ush vs wlc  95.81 11 < 0.0001\n##  gsh vs ind vs wlc 101.78 10 < 0.0001\n##\n## Q statistic to assess consistency under the assumption of\n## a full design-by-treatment interaction random effects model\n## \n##                    Q df p-value tau.within tau2.within\n## Between designs 3.82 12  0.9865     0.5403      0.2919"},{"path":"netwma.html","id":"ネットワークモデルのさらなる検証","chapter":"12 ネットワークメタ分析","heading":"12.2.2.3 ネットワークモデルのさらなる検証","text":"","code":""},{"path":"netwma.html","id":"ネットワークグラフ","chapter":"12 ネットワークメタ分析","heading":"12.2.2.3.1 ネットワークグラフ","text":"netmeta を使ってネットワークメタ分析モデルをフィットさせた後、ネットワークグラフ を作成することができる。これは netgraph 関数を用いて行うことが可能である。netgraph 関数には多くの引数があり、コンソールで ?netgraph を実行すれば調べることができる。しかし、これらの引数のほとんどは、非常に賢明なデフォルト値を持っているので、あまり多くのことを指定する必要はない。最初のステップとして、フィットしたモデル m.netmeta を関数に与えてみる。モデルでは短縮ラベルを使用しているので、プロットでは長いラベル (treat1.long と treat2.long に格納) に置き換える必要がある。これは、 labels 引数を用いて行うことができ、すべての治療法の完全な名前を指定する必要がある。治療ラベルは、 m.netmeta$trts に格納されているものと同じ順序である必要がある。このネットワークグラフはいくつかの種類の情報を提示している。まず、ネットワークにおける比較の全体的な構造を見ることが可能である。これは、元のデータでどの治療が互いに比較されたかをよりよく理解することが可能である。さらに、プロット中のエッジが異なる幅を持っていることがわかる。幅の大きさは、ネットワークで特定の比較を見つける頻度を表している。例えば、ガイド付きセルフヘルプのフォーマットは、多くの試験で待機リストと比較されていることがわかる。また、網掛けされた三角形で表現されたマルチアーム試験も見られる。これはBreimanによる研究で、ガイド付き自己啓発、個人セラピー、待機者リストの3つを比較したものである。netgraph関数は、3Dグラフを描くこともでき、複雑なネットワーク構造をよりよく把握するのに便利である。この関数は、{rgl} パッケージがインストールされ、ロードされていることが必要である。3Dグラフを作成するためには、dim 引数を \"3d\" に設定するだけである。","code":"\n# 治療順序を表示 (短いラベル) \nm.netmeta$trts## [1] \"cau\" \"grp\" \"gsh\" \"ind\" \"tel\" \"ush\" \"wlc\"\n# フルネームを置き換え (see treat1.long と treat2.long を参照) \nlong.labels <- c(\"Care As Usual\", \"Group\", \n                 \"Guided Self-Help\", \n                 \"Individual\", \"Telephone\", \n                 \"Unguided Self-Help\", \n                 \"Waitlist\")\n\nnetgraph(m.netmeta, \n         labels = long.labels)\nlibrary(rgl)\nnetgraph(m.netmeta, dim = \"3d\")"},{"path":"netwma.html","id":"直接証拠と間接証拠の可視化","chapter":"12 ネットワークメタ分析","heading":"12.2.2.3.2 直接証拠と間接証拠の可視化","text":"次のステップでは、各比較を推定するために使用されるdirectとindirectの証拠の比率を見よう。{dmetar} の direct.evidence.plot 関数は、この目的のために開発された関数である。\n“direct.evidence.plot” 関数\n\ndirect.evidence.plot 関数は、{dmetar}\nパッケージに含まれている。{dmetar}\nがインストールされ、コンピュータに読み込まれると、この関数を使用できるようになる。もし、{dmetar}\nをインストールしていない場合は、以下の手順でインストールできる。\n\n関数のソースコードにアクセスする オンライン.\n\nソースコード全体をコンソール (R Studio の左下ペイン)\nにコピー＆ペーストし、Enterキーを押して、 R\nに関数を「学習」させる。\n\n{ggplot2} と {gridExtra}\nパッケージがインストールされ、ロードされていることを確認する。\nこの関数は、各推定比較に使用された直接証拠と間接証拠のパーセンテージを示すプロットを提供する。direct.evidence.plot関数が入力として必要とするのは、フィットしたネットワークメタ分析モデル m.netmetaのみである。\n見てわかるように、このネットワークモデルには、間接的な証拠だけで推論しなければならない推定値がいくつかあることがわかる。また、このプロットでは、各推定比較の最小並列度 (Minimal Parallelism) と平均パス長 (Mean Path Length) という2つの追加指標を得ることが可能である。König, Krahn, Binder (2013) によると、平均パス長 > 2 であるとは、比較推定が特に注意して解釈されるべきことを意味する。","code":"\nlibrary(dmetar)\n\nd.evidence <- direct.evidence.plot(m.netmeta)\nplot(d.evidence)"},{"path":"netwma.html","id":"効果推計表","chapter":"12 ネットワークメタ分析","heading":"12.2.2.3.3 効果推計表","text":"次に、すべての可能な治療比較について、このネットワークの推定値を見ることができる。これを行うには、 m.netmeta$TE.fixed (固定効果モデルを使用した場合) または m.netmeta$TE.random (ランダム効果モデルを使用した場合) に保存された行列を使用することで可能である。行列を読みやすくするために、いくつかの前処理をしておこう。まず、m.netmetaオブジェクトからデータを抽出し、行列の数値を小数点以下２桁に丸める。行列の1つの「三角形」が冗長な情報を持つことを考慮して、このコードを使って下の三角形を空の値に置き換える。これにより、次のような結果が得られる。これらの結果を研究論文で報告する場合、各効果量の推定値の信頼区間を含める方がよいだろう。これは、 m.netmeta の lower.fixed と upper.fixed (または lower.random と upper.random ) 行列を使用して、以前と同じ方法で取得することが可能である。さらに便利な方法は、netleague 関数を使用して、すべての推定効果量をエクスポートすることである。この関数は、上で作成したものと同じような表を作成する。しかし、netleague によって生成された行列では、上部の三角形は、このネットワークで利用可能な直接比較のプール効果量のみを表示し、我々がそれぞれの比較について従来のメタ分析を行った場合のようなものを達成することが可能である。我々はすべての比較について直接の証拠を持っているわけではないので、上側の三角形のいくつかのフィールドは空のままである。netleague が生成する行列の下側の三角形には、それぞれ比較の推定効果量が含まれる (間接的な証拠しか得られないものも含まれる)。netleague の出力は、簡単に.csv ファイルにエクスポートすることができる。これは、ネットワークメタ分析の包括的な結果を1つの表で報告するために使用することが可能になる。この関数を使用するもう一つの大きな利点は、効果量推定値と信頼区間が各セルに一緒に表示されることである。このような治療推定表を作成して、“netleague.csv” という名前の .csv ファイルとして保存したい。これは、以下のコードを用いて実現しよう。","code":"\nresult.matrix <- m.netmeta$TE.fixed\nresult.matrix <- round(result.matrix, 2)\nresult.matrix[lower.tri(result.matrix, diag = FALSE)] <- NA\nresult.matrix##     cau  grp   gsh  ind   tel   ush   wlc\n## cau   0 0.58  0.39 0.64  0.51  0.13 -0.26\n## grp  NA 0.00 -0.18 0.06 -0.06 -0.45 -0.84\n## gsh  NA   NA  0.00 0.25  0.12 -0.26 -0.65\n## ind  NA   NA    NA 0.00 -0.13 -0.51 -0.90\n## tel  NA   NA    NA   NA  0.00 -0.38 -0.77\n## ush  NA   NA    NA   NA    NA  0.00 -0.39\n## wlc  NA   NA    NA   NA    NA    NA  0.00\n# 効果量テーブルを生成\nnetleague <- netleague(m.netmeta, \n                       bracket = \"(\", # use round brackets\n                       digits=2)      # round to two digits\n\n# 結果を保存 (ここでは固定効果モデル) \nwrite.csv(netleague$fixed, \"netleague.csv\")"},{"path":"netwma.html","id":"治療法のランキング","chapter":"12 ネットワークメタ分析","heading":"12.2.2.3.4 治療法のランキング","text":"\nネットワークメタ分析で答えられる最も興味深い問題は、どの治療が最も高い効果を持つかということである。{netmeta} に実装された netrank 関数は、この点で役に立つ。これは、治療のランキングを生成することができ、どの治療が最大の効果をもたらす可能性が高いか低いかを示す。netrank 関数は、netmeta 自体で使われているモデルと同様に、頻度論的アプローチに基づいている。この頻度論的手法は、治療の順位付けに P-score を使用している。これは、ある治療が他の治療よりも優れているという確実性を、すべての競合する治療に対して平均して測定するものである。P-スコアは、ベイズネットワークメタ分析の章で説明する SUCRA スコア(Rücker Schwarzer 2015)と同等であることが示されている。netrank 関数は入力として m.netmeta というモデルを必要とする。さらに、small.values パラメータを指定する必要がある。これは、比較において小さい (つまり、負の) 効果量が有益 (\"good\") または有害 (\"bad\") の効果を示しているかを定義するものである。ここでは、small.values = \"good\"を使用する。つまり、効果量が負であるとき、ある治療法がうつ病を減少させるのに有効であることを意味する。個人セラピー (ind) のPスコアが最も高く、この治療形式が特に有用であることを示している。逆に、待機者リスト (wlc) のPスコアはゼロである。これは、単に治療を待たせることは最良の選択肢ではないという直感と一致しているようである。とはいえ、ランキンで最高スコアだからといって、ある治療法が「最善」であると自動的に結論づけるべきでは決してないだろう グ(Mbuagbaw et al. 2017)。このネットワークにおける不確実性をよりよく可視化する方法は、ある条件を比較群として使用したフォレストプロットを作成することである。{netmeta} では、forest 関数を使用してこれを実現することができる。{netmeta}の forest 関数の動作は、Chapter 6 で説明した {meta} パッケージの forest 関数と非常によく似ている。主な違いは、forestプロットで参照グループを reference.group 引数で指定する必要があることである。また、care us usual (\"cau\") を使用する。フォレストプロットでは、個人療法以外にも高いパフォーマンスを示す治療形式があることがわかる。また、信頼区間の一部が重なっていることもわかる。このため、明確な判断は容易ではない。個別治療が最も良い結果を出しているように見えるが、いくつかの治療法も通常のケアと比較して大きな効果を上げている。","code":"\nnetrank(m.netmeta, small.values = \"good\")##     P-score\n## ind  0.9958\n## grp  0.8184\n## tel  0.6837\n## gsh  0.5022\n## ush  0.3331\n## cau  0.1669\n## wlc  0.0000\nforest(m.netmeta, \n       reference.group = \"cau\",\n       sortvar = TE,\n       xlim = c(-1.3, 0.5),\n       smlab = paste(\"Therapy Formats vs. Care As Usual \\n\",\n                     \"(Depressive Symptoms)\"),\n       drop.reference.group = TRUE,\n       label.left = \"Favors Intervention\",\n       label.right = \"Favors Care As Usual\",\n       labels = long.labels)"},{"path":"netwma.html","id":"結果の妥当性を評価","chapter":"12 ネットワークメタ分析","heading":"12.2.2.4 結果の妥当性を評価","text":"","code":""},{"path":"netwma.html","id":"net-heat-plot","chapter":"12 ネットワークメタ分析","heading":"12.2.2.4.1 ネットヒートプロット","text":"{netmeta} パッケージは netheat という関数を内蔵しており、これにより ネットヒートプロット を作成することが可能である。ネットヒートプロットは、ネットワークモデルの非一貫性や、どのようなデザインが非一貫性に寄与しているかを評価するのに非常に有効である。netheat 関数は、フィットしたネットワークメタ分析オブジェクトを必要とするだけで、プロットを生成する。この関数は、行の各デザインが他のデザイン (列) と比較される2次ヒートマップを生成する。重要な点は、行と列が、このネットワークにおける個々の治療比較ではなく、特定のデザインを意味することである。したがって、このプロットは、マルチアーム研究で使用されたデザイン (ガイド付き自助、個人療法、待機者リストの比較) の行と列も特徴としている。ネットヒートプロットには2つの重要な特徴がある(Schwarzer, Carpenter, Rücker 2015, chap. 8)。灰色のボックス。灰色のボックスは、ある治療比較が他の治療比較の推定にどれだけ重要であるかを示すものである。ボックスが大きければ大きいほど、その比較はより重要である。これを分析する簡単な方法は、プロットの行を次々に見ていき、各行でどのボックスが最も大きいかをチェックすることである。よくある発見は、ヒートマップの対角線上にあるボックスが大きいことである。これは、直接証拠が使われたことを意味するからである。例えば、特に大きなボックスは、 “cau vs grp” 行と “cau vs grp” 列の交点で見ることが可能である。灰色のボックス。灰色のボックスは、ある治療比較が他の治療比較の推定にどれだけ重要であるかを示すものである。ボックスが大きければ大きいほど、その比較はより重要である。これを分析する簡単な方法は、プロットの行を次々に見ていき、各行でどのボックスが最も大きいかをチェックすることである。よくある発見は、ヒートマップの対角線上にあるボックスが大きいことである。これは、直接証拠が使われたことを意味するからである。例えば、特に大きなボックスは、 “cau vs grp” 行と “cau vs grp” 列の交点で見ることが可能である。色のついた背景。色のついた背景は、行のデザインが列のデザインに起因する非一貫性の量を意味する。フィールドの色は、深い赤 (強い非一貫性を示す) から青 (このデザインからの証拠が行の証拠をサポートすることを示す) までの範囲となる。netheat 関数は、アルゴリズムを使用して、行と列を非一貫性が大きいクラスタと小さいクラスタにソートする。このプロットでは、いくつかの非一貫なフィールドが左上隅に表示されている。例えば、“ind vs wlc” の行では、“cau vs grp” の列のエントリーが赤く表示されていることが分かる。これは、“ind vs wlc” の推定に対して “cau vs grp” が寄与しているエビデンスが非一貫であることを意味する。一方、“gsh vs wlc” 列のフィールドは濃い青色で表示されており、これはこのデザインの証拠が行デザイン “ind vs wlc” の証拠を支持していることを表している。色のついた背景。色のついた背景は、行のデザインが列のデザインに起因する非一貫性の量を意味する。フィールドの色は、深い赤 (強い非一貫性を示す) から青 (このデザインからの証拠が行の証拠をサポートすることを示す) までの範囲となる。netheat 関数は、アルゴリズムを使用して、行と列を非一貫性が大きいクラスタと小さいクラスタにソートする。このプロットでは、いくつかの非一貫なフィールドが左上隅に表示されている。例えば、“ind vs wlc” の行では、“cau vs grp” の列のエントリーが赤く表示されていることが分かる。これは、“ind vs wlc” の推定に対して “cau vs grp” が寄与しているエビデンスが非一貫であることを意味する。一方、“gsh vs wlc” 列のフィールドは濃い青色で表示されており、これはこのデザインの証拠が行デザイン “ind vs wlc” の証拠を支持していることを表している。この結果は、固定効果モデルを用いてネットワークメタ分析モデルを適合させたため、固定効果モデルに基づいていることを再認識する必要がある。しかし、これまでの研究から、固定効果モデルの使用は適切ではないことが次第に明らかになってきた–異質性とデザインの非一貫性が多すぎるのである。そこで、ランダム効果モデルを仮定したときに、ネットヒートプロットがどのように変化するかを確認してみよう。netheat の random 引数を TRUE に設定することにより、これを行うことが可能である。この結果、ネットワーク内の非一貫性が大幅に減少していることがわかる。暗赤色の背景を持つフィールドはなくなった。これは、ランダム効果モデルが使用されると、このモデルの全体的な一貫性がかなり改善されることを示している。したがって、このデータには、ランダム効果モデルが望ましいと結論づけることが可能である。実際には、netmetaを使用して comb.random を TRUE に設定しながら (そして comb.fixed を FALSE に設定して) モデルを再実行し、ランダム効果モデルに基づく分析結果のみを報告することになる。また、ランダム効果モデルに基づく分析結果のみを報告する。","code":"\nnetheat(m.netmeta)\nnetheat(m.netmeta, random = TRUE)"},{"path":"netwma.html","id":"net-splitting","chapter":"12 ネットワークメタ分析","heading":"12.2.2.4.2 ネットワークの分割","text":"ネットワークの一貫性をチェックするもう1つの方法は、ネットワークの分割である。この方法は、このネットワーク推定を直接証拠と間接証拠に分割し、このネットワーク内の個々の比較の推定における非一貫性をコントロールすることを可能にするものである。ネットワーク分割手法を適用するには、適合したモデルを netsplit 関数に提供するだけでよい。出力で示される最も重要な情報は、直接的証拠と間接的証拠に基づく効果推定値の差 (Diff) と、この差が有意であるかどうか (p-value列で示される) である。差が \\(p<\\) 0.05のとき、直接推定と間接推定の間に有意な不一致 (非一貫性) があることになる。出力では、(固定効果モデルを使用した場合) 直接証拠と間接証拠の間に有意な不一致を示す比較が確かにたくさんあることがわかる。正味の分割結果を可視化する良い方法は、フォレストプロットである。","code":"\nnetsplit(m.netmeta)## Separate indirect from direct evidence using back-calculation method\n## \n## Fixed effects model: \n## \n##  comparison  k prop     nma  direct  indir.    Diff     z  p-value\n##  grp vs cau 21 0.58 -0.5767 -0.3727 -0.8628  0.4901  8.72 < 0.0001\n##  gsh vs cau  8 0.22 -0.3940 -0.5684 -0.3442 -0.2243 -2.82   0.0048\n##  ind vs cau 30 0.71 -0.6403 -0.7037 -0.4863 -0.2174 -3.97 < 0.0001\n##  tel vs cau  6 0.35 -0.5134 -0.7471 -0.3867 -0.3604 -3.57   0.0004\n##  ush vs cau  9 0.35 -0.1294 -0.1919 -0.0953 -0.0966 -1.06   0.2903\n##  [...]\n## \n## Legend:\n##  [...]\n##  Diff       - Difference between direct and indirect estimates\n##  z          - z-value of test for disagreement (direct vs. indirect)\n##  p-value    - p-value of test for disagreement (direct vs. indirect)\nnetsplit(m.netmeta) %>% forest()"},{"path":"netwma.html","id":"比較調整済みファネルプロット","chapter":"12 ネットワークメタ分析","heading":"12.2.2.4.3 比較調整済みファネルプロット","text":"ネットワークメタ分析モデルで出版バイアスを評価することは困難である。Chapter 9 で紹介した手法の多くは、従来のメタ分析からネットワークメタ分析へ移行すると、そのまま適用することはできない。しかし、ネットワークメタ分析における出版バイアスのリスクを評価するために、比較調整ファンネルプロットが提案されており、特定の条件下では使用することがが可能である (Salanti et al. 2014)。このファンネルプロットは、出版バイアスがネットワークモデルにどのような影響を与えたかに関する特定の仮説がある場合に適用される。例えば、サンプルサイズが小さくても、「新規」の知見を持つ研究は出版される可能性が高いので、出版バイアスが生じる可能性がある。科学には、「画期的な」結果を出そうとする自然な動機がある。例えば、新しいタイプの治療法が現在の技術水準よりも優れていることを示すためである。ということは、今回のデータには small-study effect (Chapter 9.2.1 参照) のようなものが存在することになる。新しい治療法と古い治療法を比較した場合の効果は、ファネルプロットにおいて非対称に分布していることが予想される。これは、「期待はずれ」の結果 (つまり、新しい治療法が古い治療法より優れていない) が、ファイルの引き出しに入るからである。サンプルサイズが小さくなるにつれて、新しい治療法の有益性は、有意になるためにますます大きくなり、したがって、出版に値するようになる必要がある。理論的には、これは標準的なメタ分析で見られる特徴的な非対称のファンネルプロットを作成することになる。もちろん、このようなパターンは、プロット内の効果量がある方法でコード化されている場合にのみ現れる。例えば、「新旧仮説」を検証するためには、プロットで使用される各効果量が同じように解釈できることを確認する必要がある。例えば、正の効果量は常に「新しい」治療が優れていたことを示し、負の符号はその反対を意味することを確認する必要がある。これは、古い治療法から新しい治療法への「ランキング」を定義し、このランキングを使用して各効果の符号を定義することで実現が可能である。{netmeta}の funnel 関数は、このような比較調整されたファネルプロットを生成するために使用することが可能である。以下は最も重要な引数である。order. この引数は、仮説とされる出版バイアスメカニズムの順序を指定する。単純に、ネットワーク内のすべての治療名を提供し、仮説に従ってそれらをソートする必要がある。たとえば、出版バイアスが「新しい」治療を好むかどうかを検証したい場合、すべての治療名を挿入し、最も古い治療から始めて、最も新しいタイプの介入で終了する。order. この引数は、仮説とされる出版バイアスメカニズムの順序を指定する。単純に、ネットワーク内のすべての治療名を提供し、仮説に従ってそれらをソートする必要がある。たとえば、出版バイアスが「新しい」治療を好むかどうかを検証したい場合、すべての治療名を挿入し、最も古い治療から始めて、最も新しいタイプの介入で終了する。pch. これは、ファネルプロットで使用する研究のシンボルを指定するものである。19に設定すると、例えば単純なドットが表示される。pch. これは、ファネルプロットで使用する研究のシンボルを指定するものである。19に設定すると、例えば単純なドットが表示される。col. この引数を使用すると、異なる比較を区別するために使用する色を指定することが可能である。ここで指定する色の数は、ファネルプロットにおける ユニーク な比較の数と同じでなければならない。実際には、これは多くの異なる色が必要であることを意味する。 R がプロットに使用できる色の完全なリストは、オンラインで見ることが可能である。col. この引数を使用すると、異なる比較を区別するために使用する色を指定することが可能である。ここで指定する色の数は、ファネルプロットにおける ユニーク な比較の数と同じでなければならない。実際には、これは多くの異なる色が必要であることを意味する。 R がプロットに使用できる色の完全なリストは、オンラインで見ることが可能である。linreg. TRUE` に設定すると、ファネルプロットの非対称性に対する Egger の検定 (Chapter 9.2.1.2) が行われ、その \\(p\\) 値がプロット内に表示される。linreg. TRUE` に設定すると、ファネルプロットの非対称性に対する Egger の検定 (Chapter 9.2.1.2) が行われ、その \\(p\\) 値がプロット内に表示される。引数は {meta} の funnel 関数に定義されているものを追加で使用することも可能である。もし仮説が正しければ、サンプルサイズが小さい (つまり標準誤差が大きい) 研究は、プロットのゼロ線付近に非対称に分布すると予想される。これは、新しい治療法と古い治療法を比較し、新しい治療法が優れていないことを発見した小規模の研究は、出版される可能性が低いからである。したがって、これらの研究は漏斗の片側で系統的に欠落しているのである。しかし、このプロットは極めて対称的に見える。これは Egger の検定で確認したが、有意ではなかった (\\(p=\\) 0.402)。全体として、これはこのネットワークに小規模研究の効果があることを示すものではない。少なくとも、優れた効果を持つ「革新的な」治療法は、発表された文献の中に見つかる可能性が高いからである。\n{netmeta} を使ったネットワークメタ分析:\n最後の要点\n\nこの章は長い章となり、新しいトピックを大量にカバーしてきた。{netmeta}\nで使われている統計モデルの背後にあるコアなアイデアを示し、このアプローチでネットワークメタ分析モデルを適合させる方法、結果を可視化し解釈する方法、そして発見の妥当性を評価する方法について説明した。ネットワークメタ分析における\n(臨床)\n意思決定は、1つのテストやメトリックに基づくべきでないことは、どれほど強調しても十分とはいえない。\n\nその代わりに、私たちは素直な目でモデルとその結果を探求し、見つけたパターンの一貫性をチェックし、推定値に関連する大きな不確実性を考慮に入れなければならないのである。\n\n次章では、ベイズの観点からネットワークメタ分析を (再び)\n考えてみる。このアプローチの背後にある哲学は、ここで説明したものとかなり異なるが、どちらの手法も本質的に同じことを達成しようとするものである。実際、解析の「パイプライン」も驚くほど似ている。さあ、ベイズ解析の時間だ。\n","code":"\nfunnel(m.netmeta, \n      order = c(\"wlc\", \"cau\", \"ind\", \"grp\", # from old to new\n                \"tel\", \"ush\", \"gsh\"), \n      pch = c(1:4, 5, 6, 8, 15:19, 21:24), \n      col = c(\"blue\", \"red\", \"purple\", \"forestgreen\", \"grey\", \n              \"green\", \"black\", \"brown\", \"orange\", \"pink\", \n              \"khaki\", \"plum\", \"aquamarine\", \"sandybrown\", \n              \"coral\", \"gold4\"), \n      linreg = TRUE)"},{"path":"netwma.html","id":"bayesian-net-ma","chapter":"12 ネットワークメタ分析","heading":"12.3 ベイズ的ネットワークメタ分析","text":"以下では、ベイズ型階層構造フレームワークに基づくネットワークメタ分析の実行方法を説明する。このために使用する R パッケージは、{gemtc} (Valkenhoef et al. 2012) と呼ばれるものである。しかし、その前に、一般的なベイズ推論の考え方と、ネットワークメタ分析に使用できるベイズモデルの種類を考えてみよう。","code":""},{"path":"netwma.html","id":"bayesian-inference","chapter":"12 ネットワークメタ分析","heading":"12.3.1 ベイズ推論","text":"\nベイズ推定は、頻度論的 (frequentist) 統計学とは別に、重要な統計学である。頻度論的統計学は、ほとんどの研究分野でより頻繁に使用されていると言ってよいでしょう。しかし、ベイズアプローチの方が実は古く、近年は研究者に取り上げられることが多くなっており (Marsman et al. 2017)、決して「無くなった」わけではない (McGrayne 2011)。ベイズ統計学の基礎となるのは、トーマス・ベイズ牧師 (1701-1761、 Bellhouse et al. 2004) が最初に定式化したベイズの定理である。ベイズ統計学が頻出主義と異なるのは、「主観的」な事前知識も取り入れて推論を行う点である。ベイズの定理は、ある事象Aが発生する確率を、別の事象Bが発生したことを既に知っていると仮定して推定することを可能にする。これは、条件付き確率と呼ばれ、\\(P(\\text{}|\\text{B})\\) のように表現される。この定理は、この条件付き確率の計算方法を説明する公式に基づいている。\\[\\begin{equation}\nP(\\text{}|\\text{B})=\\frac{P(\\text{B}|\\text{})\\times\nP(\\text{})}{P(\\text{B})}\n\\tag{12.8}\n\\end{equation}\\]\nこの式では、分数の分子にある2つの確率にそれぞれ名前がついている。\\(P(\\text{B}|\\text{})\\) の部分は、尤度 (ゆうど) と呼ばれる。Aがある場合に事象Bが発生する確率である (Etz 2018)。\\(P(\\text{})\\) は、\\(\\) が発生する先行確率である。\\(P(\\text{}|\\text{B})\\) は、posterior 確率で、B が与えられたときの の確率である。\\[\\begin{equation}\nP(\\text{}|\\text{B}) \\propto P(\\text{B}|\\text{})\\times P(\\text{})\n\\tag{12.9}\n\\end{equation}\\]ここで、\\(\\propto\\) という記号は、分数の分母を捨てたので、値が変化しても、左側の確率は右側の部分と少なくとも比例していることを意味している。ベイズの定理は、上の式の右辺から順に考えていくと理解しやすい。Aの確率に関する事前情報と、Aが起こる場合のBの可能性を組み合わせて、Aの事後確率 (適応確率) \\(P(\\text{}|\\text{B})\\) を出すだけなのである。ここで重要なのは、前の知識を考慮すると、Aの確率の「より良い」 (事後) 推定値が得られるということである。この知識は、Aの確率を仮定したもの (事前確率) である。ベイズの定理は、や B を特定の事象に見立てて、先ほどの方法で説明されることが多いようである。しかし、や B を2つの変数の確率分布と考えることもが可能である。を正規分布に従う確率変数とする。この分布は、パラメータの集合で特徴付けることができ、それを \\(\\boldsymbol{\\theta}\\) で表す。は正規分布なので、 \\(\\boldsymbol{\\theta}\\) には の真の平均 \\(\\mu\\) と分散 \\(\\sigma^2\\) の2つの要素が含まれている。さらに、B について、\\(\\boldsymbol{\\theta}\\) の推定に使いたい実測データを集めたとする。観測されたデータをベクトル \\(\\boldsymbol{Y}\\) に格納する。また、観測データは正規分布に従うので、\\(P({Y})\\) で表される。このことから、次のような式が成り立つ。\\[\\begin{equation}\nP(\\boldsymbol{\\theta} | {\\boldsymbol{Y}} ) \\propto P( {\\boldsymbol{Y}} | \\boldsymbol{\\theta} )\\times P( \\boldsymbol{\\theta})\n\\tag{12.10}\n\\end{equation}\\]この式には、\\(P(\\boldsymbol{\\theta})\\) という \\(\\boldsymbol{\\theta}\\) の事前分布を仮定している。この事前分布は、これまでの知識に基づいて、あるいは直感的に \\(\\boldsymbol{\\theta}\\) がどのようなものであるかを、 priori に定義することが可能である。尤度分布 \\(P({\\boldsymbol{Y}}|\\boldsymbol{\\theta})\\) と、パラメータ \\(\\boldsymbol{\\theta}\\) が与えられたときのデータの確率 \\(P(\\boldsymbol{\\theta}|{\\boldsymbol{Y}})\\) から、事後分布を推定することができる。この事後分布は、観測データと事前知識の両方を考慮した場合の \\(\\boldsymbol{\\theta}\\) の推定値を表している。重要なのは、事後分布はあくまでも分布であって、1つの推定「真」値ではないことである。つまり、ベイズ推論の結果であっても確率的であることに変わりはない。また、実際のパラメータ値に対する私たちの信念を表すという意味で、主観的なものでもある。したがって、ベイズ統計学では、推定値の信頼区間を計算するのではなく、信用 (確信) 区間 (Credible Interval, CrI) を計算するのである。ここで、先ほど説明した3つの分布が、具体的な例ではどのように見えるかを可視化してみよう。\nベイズアプローチのもう一つの利点は、パラメータが可視化されたようなベルカーブ分布に従う必要がないことである。他の種類の (より複雑な) 分布もモデル化することができる。しかし、ベイズ推定の欠点は、収集したデータから (結合) 分布を生成するのに、非常に計算コストがかかることである。事後分布を生成するために、Gibbs サンプリング法などの特殊なマルコフ連鎖モンテカルロシミュレーション手法が開発された。マルコフ連鎖モンテカルロは、ベイジアンネットワークメタ分析モデルを実行するための {gemtc} パッケージでも使用されている (Valkenhoef et al. 2012)。","code":""},{"path":"netwma.html","id":"bayesian-net-ma-model","chapter":"12 ネットワークメタ分析","heading":"12.3.2 ベイズ的ネットワークメタ分析モデル","text":"","code":""},{"path":"netwma.html","id":"ペアワイズメタ分析","chapter":"12 ネットワークメタ分析","heading":"12.3.2.1 ペアワイズメタ分析","text":"ここでは、{gemtc} がネットワークメタ分析に用いるベイズ型階層モデルを定式化する。まず、従来のペアワイズメタ分析のモデルを最初に定義することから始めましょう。この定義は、「標準的な」ランダム効果モデルについて説明した Chapter 4.1.2 の定義と同等である。以下に述べるのは、メタ分析を概念化するための「ベイズ的な方法」に過ぎない。一方、このベイズ的なペアワイズメタ分析の定義は、これ以上拡張しなくても、ネットワークメタ分析に直接適用できるので、すでに非常に有益なものとなっている (Dias et al. 2013)。このモデルをベイズ型階層モデルと呼んでいる (Efthimiou et al. 2016、より詳細な議論は Chapter 13.1 を参照)。ここで言う「階層的」というのは、何も不思議なことではない。実際、メタ分析・モデルは階層構造、つまり「多階層」を前提としていることは、既に Chapter 10 で説明した。例えば、従来のメタ分析を実施するとしよう。\\(K\\) 件の研究が含まれ、各研究の観測された効果量 \\(\\hat\\theta_k\\) を計算する。そして、固定効果モデルを次のように定義する。\\[\\begin{equation}\n\\hat\\theta_k \\sim \\mathcal{N}(\\theta,\\sigma_k^2)\n\\tag{12.11}\n\\end{equation}\\]この式は、効果量が正規分布に従うと仮定して、効果量の尤度式中の \\(P(\\boldsymbol{Y}|\\boldsymbol{\\theta})\\) 部分を表現したものである。各効果量は同じ分布からの抽選であり、その平均が真の効果量 \\(\\theta\\)、分散が \\(\\sigma^2_k\\) であると仮定する。固定効果モデルでは、真の効果量は全ての研究で同一であると仮定するので、異なる研究 \\(k\\) とその観測された効果量 \\(\\hat\\theta_k\\) に対して、\\(\\theta\\) は変わらない。\nベイズモデルの面白いところは、本当の効果 \\(\\theta\\) が未知でも、その事前分布を定義できることである。この事前分布は、\\(\\theta\\) がどのように見えると考えるかを近似する。例えば、平均が0の正規分布に基づく事前分布を \\(\\theta \\sim \\mathcal{N}(0, \\sigma^2)\\) (ここで \\(\\sigma^2\\) を指定)と仮定することが可能である。{gemtc} パッケージでは、デフォルトで uninformative priors と呼ばれる、分散が非常に大きな事前分布を使用する。これは、事前の「信念」が事後結果に大きな影響を与えないようにするためで、主に実際に観測されたデータに「語らせる」ようにする。この式は、ランダム効果モデルに簡単に拡張することができる。\\[\\begin{equation}\n\\hat\\theta_k \\sim \\mathcal{N}(\\theta_k,\\sigma_k^2)\n\\tag{12.12}\n\\end{equation}\\]この式は、各研究が同じ真の効果量 \\(\\theta\\) の推定量であると仮定しないことを除けば、あまり変わらない。その代わりに、各観測効果量 \\(\\hat\\theta_k\\) によって推定される “試験固有”の真の効果量 \\(\\theta_k\\) が存在すると仮定する。さらに、これらの研究固有の真の効果は、真の効果量の包括的な分布の一部である。この真の効果量分布は、その平均値 \\(\\mu\\) と分散 \\(\\tau^2\\) (ここでの研究間異質性) によって定義される。\\[\\begin{equation}\n\\theta_k \\sim \\mathcal{N}(\\mu,\\tau^2)\n\\tag{12.13}\n\\end{equation}\\]また、ベイズモデルでは、\\(\\mu\\) と \\(\\tau^2\\) の両方に (非情報的な) 事前分布を与える。","code":""},{"path":"netwma.html","id":"ネットワークメタ分析への拡張","chapter":"12 ネットワークメタ分析","heading":"12.3.2.2 ネットワークメタ分析への拡張","text":"さて、ベイズメタ分析モデルが1対比較のためにどのように定式化されるかをカバーしたので、それをネットワークメタ分析に拡張することを始めましょう。前のランダム効果モデルの2つの公式は、このために再利用することが可能である。我々は、モデル・パラメータを少し違った形で概念化するだけである。ネットワークメタ分析では、比較対象が様々な治療法からなることがあるので、ある研究 \\(k\\) で見つかった効果量を \\(\\hat\\theta_{k \\text{,,B}}\\) で表す。これは、治療Aと治療Bを比較した研究 \\(k\\) における効果量を意味する。この新しい表記法を適用すると、以下の式が得られる。\\[\\begin{align}\n\\hat\\theta_{k \\text{,,B}} &\\sim \\mathcal{N}(\\theta_{k \\text{,,B}},\\sigma_k^2) \\notag \\\\\n\\theta_{k \\text{,,B}} &\\sim \\mathcal{N}(\\theta_{\\text{,B}},\\tau^2) \\tag{12.14}\n\\end{align}\\]式で表される一般的な考え方は変わらないことがわかる。ここで、\\(-\\) B比較の (研究固有の) 真の効果、\\(\\theta_{k \\text{,,B}}\\) は、平均 \\(\\theta_{text{,B}}\\) を持つ真の効果の包括的分布の一部であると仮定する。この平均真の効果量 \\(\\theta_{1\\text{,,B}}\\) は、\\(\\theta_{1\\text{,B}}\\) から \\(\\theta_{1\\text{,}}\\) を減算した結果であり、\\(\\theta_{1\\text{,}}\\) はある定義済みの参照治療 \\(1\\) と比べた治療Aの効果である。同様に、\\(\\theta_{1\\text{,B}}\\)は、同じ参照治療と比較した治療Bの効果として定義されている。ベイズモデルでは、参照群と比較したこれらの効果も事前分布を与えられる。前章の頻度論的ネットワークメタ分析ですでに述べたように、マルチアーム研究をネットワークモデルに含めることは、効果量が相関してしまうので問題がある。ベイズネットワークメタ分析では、この問題は、マルチアーム研究の効果が多変量 (正規) 分布に由来すると仮定することによって解決することが可能である。マルチアーム試験 \\(k\\) が、合計 \\(n=\\) 5 の治療法を調べたとする。E を参照治療とすると、\\(n\\) - 1 = 4 の治療効果があることになる。ベイズ階層モデルを用いて、これらの観測された治療効果が次の形式の多変量正規分布からのドローであると仮定する63。\\[\\begin{align}\n\\begin{bmatrix}\n\\hat\\theta_{k\\text{,,E}} \\\\\n\\hat\\theta_{k\\text{,B,E}} \\\\\n\\hat\\theta_{k\\text{,C,E}} \\\\\n\\hat\\theta_{k\\text{,D,E}}\n\\end{bmatrix}\n&=\n\\mathcal{N}\\left(\n\\begin{bmatrix}\n\\theta_{\\text{,E}} \\\\\n\\theta_{\\text{B,E}} \\\\\n\\theta_{\\text{C,E}} \\\\\n\\theta_{\\text{D,E}}\n\\end{bmatrix}\n,\n\\begin{bmatrix}\n\\tau^2 & \\tau^2/2 & \\tau^2/2 & \\tau^2/2 \\\\\n\\tau^2/2 & \\tau^2 & \\tau^2/2 & \\tau^2/2 \\\\\n\\tau^2/2 & \\tau^2/2 & \\tau^2 & \\tau^2/2 \\\\\n\\tau^2/2 & \\tau^2/2 & \\tau^2/2 & \\tau^2\n\\end{bmatrix}\n\\right).\n\\tag{12.15}\n\\end{align}\\]","code":""},{"path":"netwma.html","id":"r-におけるベイズ的ネットワークメタ分析","chapter":"12 ネットワークメタ分析","heading":"12.3.3 R におけるベイズ的ネットワークメタ分析","text":"それでは、最初のベイジアンネットワークメタ分析を行うために、{gemtc} パッケージを使用してみよう。いつものように、まずパッケージをインストールし、ライブラリからロードする必要がある。\n{gemtc} パッケージは、以前説明した Gibbs サンプリング手順で使用する {rjags} (Plummer 2019) に依存している (Chapter 12.3.1 参照)。ただし、このパッケージをインストールして読み込む前に、まず JAGS (Just Another Gibbs Sampler の略) という別のソフトをインストールする必要がある。このソフトは Windows と Mac の両方に対応しており、インターネットから無料でダウンロード可能。これが完了したら、{rjags} パッケージをインストールして読み込むことができる64。","code":"\nlibrary(gemtc)\ninstall.packages(\"rjags\")\nlibrary(rjags)"},{"path":"netwma.html","id":"データを準備-1","chapter":"12 ネットワークメタ分析","heading":"12.3.3.1 データを準備","text":"この例では、すでに頻出ネットワークメタ分析に使用した TherapyFormats データセットを再び使用する。しかし、{gemtc} で使用できるように、データの構造を少し調整する必要がある。元の TherapyFormats データセットには TE と seTE という列があり、各行が1つの比較を表す標準化平均値と標準誤差が格納されている。このような相対効果データを {gemtc} で使用したい場合、各行が1つの治療群を表すようにデータフレームの形を変更する必要がある。さらに、効果量の列にNAを記入して、比較でどの治療が参照群として使われたかを指定する必要がある。このように整形したデータセットを “TherapyFormatsGeMTC” という名前で保存している65。\n“TherapyFormatsGeMTC” データセット\n\nTherapyFormatsGeMTC データセットは\n{dmetar}\nパッケージに含まれている。{dmetar}\nをインストールし、ライブラリからロードした後、\ndata(TherapyFormatsGeMTC)\nを実行すると、自動的にデータセットが R\n環境にセーブされる。これでデータセットが利用できるようになる。もし、{dmetar}\nがインストールされていない場合は、インターネット\nから .rda\nファイルとしてダウンロードし、作業ディレクトリに保存した後、R Studio\nのウィンドウでクリックするとインポートすることが可能である。\nTherapyFormatsGeMTC データセットは、2つの要素を持つリストで、そのうちの1つは data と呼ばれるものである。この要素は、モデルを適合させるために必要なデータフレームである。それでは、見ていこう。{gemtc} パッケージを使う際は、データフレームの列名を{gemtc} が指定する列名にする必要がある。連続的な結果 (平均差や標準化平均差など) に基づく効果量を使用する場合、以下の列名が必要である。study. この列には、ネットワークに含まれる各研究の (ユニークな) ラベルが含まれ、{netmeta}で使用されている studlab 列と同じである。study. この列には、ネットワークに含まれる各研究の (ユニークな) ラベルが含まれ、{netmeta}で使用されている studlab 列と同じである。treatment. この列は治療法のラベルまたは短縮コードを含む。treatment. この列は治療法のラベルまたは短縮コードを含む。diff. この列には、比較のために計算された効果量 (例えば、標準化された平均差) が含まれる。diff 列には、比較で使用された参照治療の行はNA (欠損) とする必要がある。そして、参照治療が比較された治療の行には、この比較のために計算された実際の効果量が格納される。また、参照カテゴリは、比較単位ではなく、試験単位で定義されていることに留意されたい。これは、多群間試験において、他のすべての治療が比較される参照治療は1つしかないことを意味する。例えば、3群間研究では、2つの効果量を含める必要がある。1つは参照グループと比較した第一治療、もう1つは参照グループと比較した第二治療の効果量である。diff. この列には、比較のために計算された効果量 (例えば、標準化された平均差) が含まれる。diff 列には、比較で使用された参照治療の行はNA (欠損) とする必要がある。そして、参照治療が比較された治療の行には、この比較のために計算された実際の効果量が格納される。また、参照カテゴリは、比較単位ではなく、試験単位で定義されていることに留意されたい。これは、多群間試験において、他のすべての治療が比較される参照治療は1つしかないことを意味する。例えば、3群間研究では、2つの効果量を含める必要がある。1つは参照グループと比較した第一治療、もう1つは参照グループと比較した第二治療の効果量である。std.err. この列は、効果量の標準誤差を含む。参照群ではNAに設定され、参照群と比較された治療法の行でのみ定義される。std.err. この列は、効果量の標準誤差を含む。参照群ではNAに設定され、参照群と比較された治療法の行でのみ定義される。２値アウトカムのデータなど、他のデータ入力フォーマットも可能である。効果量データの種類によって、データセットがどのように構成される必要があるかは、{gemtc} のドキュメントで詳しく説明されている。コンソールで ?mtc.model を実行し、“Details” セクションにスクロールすることでアクセスが可能である。","code":"\nlibrary(dmetar)\ndata(TherapyFormatsGeMTC)\n\nhead(TherapyFormatsGeMTC$data)##          study   diff std.err treatment\n## 1 Ausbun, 1997  0.092   0.195       ind\n## 2 Ausbun, 1997     NA      NA       grp\n## 3 Crable, 1986 -0.675   0.350       ind\n## 4 Crable, 1986     NA      NA       grp\n## 5 Thiede, 2011 -0.107   0.198       ind\n## 6 Thiede, 2011     NA      NA       grp"},{"path":"netwma.html","id":"ネットワークグラフ-1","chapter":"12 ネットワークメタ分析","heading":"12.3.3.2 ネットワークグラフ","text":"さて、データの準備ができたので、これを mtc.network 関数に渡す。これにより、mtc.network クラスのオブジェクトが生成され、後のモデル作成段階で使用することが可能である。あらかじめ計算された効果量データを使用するため、mtc.network の data.re 引数でデータセットを指定する必要がある。生の効果量データ (例: 平均、標準偏差、サンプルサイズ) を使用する場合は、data.ab 引数を使用することになる。オプションの treatments 引数を使用すると、ネットワークに含まれるすべての治療の実際の名前を {gemtc} に提供することが可能である。この際、データフレームの列名は id と description でなければならない。ここでは事前にデータフレームを作成し、TherapyFormatsGeMTCに treat.codes として保存してある。このデータフレームと TherapyFormatsGeMTC の効果量データを使って、 mtc.network オブジェクトを作成する。それを network という名前で保存する。作成されたオブジェクトを summary 関数に代入すると、すでにネットワークに関する興味深い情報を得ることが可能である。また、plot関数を使用してネットワークプロットを生成することもが可能である。{netmeta} パッケージで生成されたネットワークと同様に、エッジの太さはその比較に含めた研究数に対応している。別の方法として、Fruchterman-Reingold アルゴリズムを用いて、ネットワークのより良い視覚化を作成できるかどうかを確認することもが可能である。このアルゴリズムには固有のランダム性があるため、結果を再現できるように seed を設定する必要がある。ネットワークプロットは {igraph} パッケージ (Csardi Nepusz 2006) を使って作成される。このパッケージがインストールされ、ロードされたとき、プロットの外観を変えるために他の引数も使うことが可能である。異なるスタイルオプションの詳細な説明はオンラインの {igraph} manual にある。","code":"\nTherapyFormatsGeMTC$treat.codes##    id        description\n## 1 ind         Individual\n## 2 grp              Group\n## 3 gsh   Guided Self-Help\n## 4 tel          Telephone\n## 5 wlc           Waitlist\n## 6 cau      Care As Usual\n## 7 ush Unguided Self-Help\nnetwork <- mtc.network(data.re  = TherapyFormatsGeMTC$data,\n                       treatments = TherapyFormatsGeMTC$treat.codes)\nsummary(network)## $Description\n## [1] \"MTC dataset: Network\"\n## \n## $`Studies per treatment`\n## ind grp gsh tel wlc cau ush \n##  62  52  57  11  83  74  26  \n## \n## $`Number of n-arm studies`\n## 2-arm 3-arm \n##   181     1 \n## \n## $`Studies per treatment comparison`\n##     t1  t2 nr\n## 1  ind tel  4\n## 2  ind wlc 18\n## 3  grp ind  7\n## [...]\nplot(network, \n     use.description = TRUE) # 完全な治療名を使用\nlibrary(igraph)\nset.seed(12345) # 再現性のため seed を設定\n\nplot(network, \n     use.description = TRUE,            # 完全な治療名を使用\n     vertex.color = \"white\",            # ノードの色\n     vertex.label.color = \"gray10\",     # treatment ラベルの色\n     vertex.shape = \"sphere\",           # ノードの形\n     vertex.label.family = \"Helvetica\", # ラベルのフォント\n     vertex.size = 20,                  # ノードの大きさ\n     vertex.label.dist = 2,             # ラベルとノード中心の距離\n     vertex.label.cex = 1.5,            # ノードラベルの大きさ\n     edge.curved = 0.2,                 # エッジのカーブ\n     layout = layout.fruchterman.reingold)"},{"path":"netwma.html","id":"モデルのコンパイル","chapter":"12 ネットワークメタ分析","heading":"12.3.3.3 モデルのコンパイル","text":"mtc.network オブジェクトを使用して、モデルの指定とコンパイルを開始することが可能である。{gemtc} パッケージの素晴らしいところは、ベイズ推定プロセスのほとんどの部分を自動化できることである。例えば、モデル中のすべてのパラメータに対して適切な事前分布を選択することが可能である。このように、mtc.model 関数を用いてモデルをコンパイルする際に指定しなければならない引数はごくわずかである。まず、前に作成した mtc.network オブジェクトを指定する。さらに、linearModel 引数を用いて、ランダム効果モデルか固定効果モデルのどちらを使用するかを決定しなければならない。頻度論的分析では、かなりの異質性と非一貫性が見られたため (Chapter 12.2.2.4.1 参照)、linearModel = \"random\" を使用する。また、使用するマルコフ連鎖の数を指定する必要がある。ここでは、3から4の間の値が賢明で、n.chain = 4 とする。さらに、オプションで likelihood と link という2つの引数を指定することが可能である。この2つの引数は、使用している効果量データの種類によって異なり、明示的に指定しない限りは {gemtc} によって自動的に推測される。我々は連続的な結果データ (SMD など) に基づく効果量を扱っているので、「正規」 (normal) の尤度と 「同一」 (indetity) のリンクを仮定している。２値アウトカム (対数オッズ比など) を使用していた場合、適切な尤度 (likelyhood) とリンク (link) はそれぞれ \"binom\" (二項) と \"logit\" である。これに関する詳細は mtc.model のドキュメントに記載されている。しかし、前のステップでデータが正しく準備されている場合には、通常 mtc.model は自動的に正しい設定を選択する。","code":"\n# コンパイル済みモデルを \"model\" と命名\nmodel <- mtc.model(network,\n                   likelihood = \"normal\",\n                   link = \"identity\",\n                   linearModel = \"random\",\n                   n.chain = 4)"},{"path":"netwma.html","id":"マルコフ連鎖モンテカルロ法サンプリング","chapter":"12 ネットワークメタ分析","heading":"12.3.3.4 マルコフ連鎖モンテカルロ法サンプリング","text":"さて、いよいよ分析の重要な部分であるマルコフ連鎖モンテカルロ法 (MCMC) サンプリングに入る。MCMCシミュレーションは、パラメータの事後分布を推定し、ネットワークメタ分析の結果を生成することが可能である。この手順で達成したい重要な望みが2つある。マルコフ連鎖モンテカルロ法の最初の数回の実行が、シミュレーションの結果に大きな影響を与えないようにしたい。マルコフ連鎖モンテカルロ法の最初の数回の実行が、シミュレーションの結果に大きな影響を与えないようにしたい。マルコフ連鎖モンテカルロ法は、モデルパラメータの正確な推定値を得るために十分な時間実行する必要がある (すなわち、収束する必要がある)。マルコフ連鎖モンテカルロ法は、モデルパラメータの正確な推定値を得るために十分な時間実行する必要がある (すなわち、収束する必要がある)。これらの点を解決するために、マルコフ連鎖モンテカルロ法のアルゴリズムがモデル結果を推論するために反復する回数を2つのフェーズに分割した: まず、burn-in反復回数 (n.adapt) を定義し、その結果は破棄される。次のフェーズでは、モデルパラメータの推定に実際に使用するシミュレーションの反復回数 (n.iter) を指定する。通常、多くの反復計算を行うため、thin引数を指定することで、\\(\\)番目の反復計算の値のみを抽出することもできる。これにより、必要なコンピュータのメモリを削減することが可能である。シミュレーションは mtc.run 関数を用いて行うことができる。この例では、異なる設定で2回実行し、どちらがより効果的かを比較する。コンパイルした model オブジェクトを関数に与え、先ほど説明したパラメータを指定する必要がある。まず、数回の繰り返しのシミュレーションをおこない、次に、大きな繰り返しのシミュレーションをおこなう。両方のオブジェクトをそれぞれ mcmc1 と mcmc2 という名前で保存する。ネットワークの大きさによっては、シミュレーションが終了するまでに時間がかかることがある。","code":"\nmcmc1 <- mtc.run(model, n.adapt = 50, n.iter = 1000, thin = 10)\nmcmc2 <- mtc.run(model, n.adapt = 5000, n.iter = 1e5, thin = 10)"},{"path":"netwma.html","id":"bayesian-model-convergence","chapter":"12 ネットワークメタ分析","heading":"12.3.3.5 モデルの収束を評価","text":"シミュレーションの結果、アルゴリズムが収束したかどうか、また、どの設定が好ましいかを確認するために、mcmc1 と mcmc2 オブジェクトの出力をいくつか評価することが可能である。 plot 関数を使用することは、良いスタートである。これは、すべての反復における各治療比較について、一般的にtrace plotと呼ばれる一種の 「時系列」を提供する。この例では、個人セラピー (ind) と待機者コントロール (wlc) の比較の推定値にのみ焦点を当てる。mcmc1 の前半と後半の繰り返しを比較すると、時系列全体のトレンドに若干の不連続性があることがわかる。4種類の連鎖の推定値 (4本の線) は、プロットの前半から後半に移るときに、そのコースがわずかに異なっている。一方、mcmc2 のプロットでは、上下の変動はより急激であるが、長期的なトレンドは見られない。これは、mcmc2 の設定がより適切であることを示す最初の兆候である66。事後効果量推定値の密度プロットを見ることで、収束の評価を続けることが可能である。mcmc1 の分布はまだ滑らかな正規分布から多少乖離しているが、mcmc2 の結果は古典的なベルカーブに近づいていることがわかる。収束を評価するのに非常に有用なもう一つの方法は、Gelman-Rubin プロットである。このプロットは、いわゆる潜在的スケール削減係数 (Potential Scale Reduction Factor, PSRF) (訳注 PSRF の訳語はまだ定まっていない。) を示し、各チェーン内のばらつきとチェーン間のばらつきを比較し、両者が時間とともにどのように発展していくかを示している。収束した場合、PRSF は反復回数の増加とともに徐々にゼロまで縮小し、最終的には少なくとも 1.05 以下になるはずである。このプロットを作成するには、mtc.run オブジェクトを gelman.plot 関数に代入するだけでよい。両方のシミュレーションの結果を示す (ここでも ind と wlc の比較のみ)。また、このコードを使って、モデルの全体的な PSRF に直接アクセスすることが可能である。両方のシミュレーションで PRSF は閾値を下回っているが、mcmc2 の値はずっと低く、1に非常に近いことがわかる。これは、2番目のモデルを使用すべきことを示している。","code":"\nplot(mcmc1)\nplot(mcmc2)\ngelman.plot(mcmc1)\ngelman.plot(mcmc2)\ngelman.diag(mcmc1)$mpsrf## [1] 1.034131\ngelman.diag(mcmc2)$mpsrf## [1] 1.000351"},{"path":"netwma.html","id":"非一貫性の評価-ノード分割法","chapter":"12 ネットワークメタ分析","heading":"12.3.3.6 非一貫性の評価: ノード分割法","text":"{netmeta} パッケージと同様に、{gemtc} パッケージもネットワークモデルの一貫性を評価する方法を提供している。すなわち、ノード分割 (nodesplit) 法である (Dias et al., 2010)。この手順の考え方は、以前説明した net splitting 法のものと似ている (Chapter 12.2.2.4.2)。ノード分割分析を行うには、mtc.nodesplit 関数を使用し、mcmc2 と同じ設定を使用する。解析結果は nodesplit という名前で保存しよう。nodesplit モデルの計算には、ネットワークの複雑さによっては数時間かかることがある。\nsummary 関数を使用すると、結果を表示することができる。この関数の出力は、直接証拠のみ、間接証拠のみ、利用可能なすべての証拠を用いた場合の、異なる比較の効果についての結果を示している。直接証拠と間接証拠を用いた異なる推定値は、非一貫性の存在を示唆する。ベイズの p.value 列を見ることによって、これをコントロールすることが可能である。\\(p<\\) 0.05の1つ以上の比較は、このネットワークに非一貫性があることを示すので、問題がある。出力から、この (ランダム効果モデルの) 例では非一貫ではないことがわかる。ノード分割法によって複数の推定値に非一貫性を示す場合、デザイン間の潜在的な差異について、含まれるすべてのエビデンスを再度確認することが重要である。例えば、AとBを比較した研究では、Aを評価した他の研究とは系統的に異なる母集団が含まれている可能性がある。もう一つのアプローチは、研究の賢明な部分集合のみがネットワークに含まれる場合に、非一貫性が持続するかどうかを確認することである。最後に、後述するネットワークメタ回帰を実行することによって、非一貫性の理由を評価することも可能である。ノードスプリットモデルに対して、plot 関数を用いてフォレストプロットを生成することも可能である。しかし、先に nodesplit オブジェクトを summary に代入後、フォレストプロットが生成される。","code":"\nnodesplit <- mtc.nodesplit(network, \n                           linearModel = \"random\", \n                           likelihood = \"normal\",\n                           link = \"identity\",\n                           n.adapt = 5000, \n                           n.iter = 1e5, \n                           thin = 10)\nsummary(nodesplit)## Node-splitting analysis of inconsistency\n## ========================================\n## \n##    comparison  p.value CrI                  \n## 1  d.ind.tel   0.62785                      \n## 2  -> direct           0.13 (-0.39, 0.64)   \n## 3  -> indirect         -0.037 (-0.46, 0.38) \n## 4  -> network          0.034 (-0.30, 0.36)  \n## 5  d.ind.wlc   0.87530                      \n## 6  -> direct           1.0 (0.74, 1.3)      \n## 7  -> indirect         0.97 (0.71, 1.2)     \n## 8  -> network          0.98 (0.80, 1.2)     \n## 9  d.ind.grp   0.61380                      \n## 10 -> direct           0.14 (-0.29, 0.57)   \n## 11 -> indirect         0.26 (0.044, 0.48)   \n## 12 -> network          0.24 (0.041, 0.43)   \n## [...]\nplot(summary(nodesplit)) "},{"path":"netwma.html","id":"ネットワークメタ解析結果の生成","chapter":"12 ネットワークメタ分析","heading":"12.3.3.7 ネットワークメタ解析結果の生成","text":"さて、ネットワークメタ分析モデルを適合させ、それが信頼できるものであると確信したところで、いよいよ結果を出すときが来た。前に述べたように、ネットワークメタ分析で答えたい主な疑問は、どの治療が一番よく効くかということである。この質問に答えるために、まず rank.probability 関数を実行することが可能である。この関数は、ある治療法が最も良い選択である確率、2番目に良い選択である確率、3番目に良い選択である確率、などを計算する。この関数は入力として mcmc2 オブジェクトを必要とし、さらに preferredDirection という引数を指定する。もし、より小さい (つまり、負の) 効果量がより良い結果を示すのであれば、この引数を -1 に設定する。それ以外の場合は 1 を使用する。結果は rank という名前で保存され、いわゆる rankogram を用いて可視化される。このプロットでは、個人セラピー (ind) はおそらくこのネットワークで最良の治療オプションであることがわかる。なぜなら、ind の最初の棒 (1位を意味する) が最も大きいからである。この発見は、同じパターンを発見した頻度論的分析の結果と一致する。さらに、forest 関数を用いて、結果のフォレストプロットを作成することもできる。これを行うには、まず results オブジェクトを relative.effect 関数に入れ、参照治療である t1 を指定する必要がある。ここでも参照群として care usual (\"cau\") を使用する。そして、結果に対して forest 関数を呼び出し、プロットを生成する。頻度論的ネットワークメタ分析の章では、ネットワーク内のどの治療が最も効果的であるかを評価するメトリックとして P-score をすでに取り上げた。P-スコアに相当するのは、Surface Cumulative Ranking (SUCRA)スコアで、これは次のように計算が可能である (Salanti, Ades, Ioannidis 2011)。\\[\\begin{equation}\n\\text{SUCRA}_j = \\frac{\\sum_{b=1}^{-1}\\text{cum}_{jb}}{-1}\n\\tag{12.16}\n\\end{equation}\\]ここで、\\(j\\) は何らかの治療法、\\(\\) は全ての競合する治療法、\\(b\\) は \\(b = 1, 2, \\dots, -1\\) の最良治療法、\\(\\text{cum}\\) はある治療法が \\(b\\) 個の最良治療法の中にある累積確率 を表す。 R で SUCRA スコアを計算するには、sucra 関数を使用する。\n“sucra” 関数\n\nsucra 関数は {dmetar}\nパッケージに含まれている。{dmetar}\nがインストールされ、コンピュータに読み込まれると、この関数を使用できるようになる。もし、{dmetar}\nをインストールしていない場合は、以下の手順でインストールできる。\n\n関数の online\nのソースコードにアクセスする。\n\nソースコード全体をコンソール(R\nStudioの左下ペイン)にコピー＆ペーストし、「Enter」キーを押して、\nR に関数を「学習」させる。\n\n{ggplot2}\nパッケージがインストールされ、ロードされていることを確認する。\nsucra 関数は入力として rank.probability オブジェクトだけを必要とするが、ここでは値が小さいほど良い結果を示すかことを指定する必要がある。これは lower..better という引数を用いて行うことが可能である。どのような結果が得られるか見てみよう。各治療の SUCRA 値を見ると、やはり個別治療 (ind) が最も良い選択肢と思われ、次いで電話による治療 (tel)、ガイド付きセルフヘルプ (gsh) が続く。通常は、モデルに基づく各治療比較の効果量推定値を報告したい。治療効果表は、 relative.effect.table 関数を用いてエクスポートする。この関数の結果は result というオブジェクトに保存され、.csv ファイルとしてエクスポートすることも可能である。relative.effect.table 関数は、推定効果と各比較の信頼区間を含む治療比較行列を自動的に作成する。","code":"\nrank <- rank.probability(mcmc2, preferredDirection = -1)\nplot(rank, beside=TRUE)\nforest(relative.effect(mcmc2, t1 = \"cau\"), \n       use.description = TRUE, # 完全な治療名を使用\n       xlim = c(-1.5, 0.5))\nlibrary(dmetar)\nrank.probability <- rank.probability(mcmc2)\nsucra <- dmetar::sucra(rank.probability, lower.is.better = TRUE)\n\nsucra##         SUCRA\n## ind 0.9225292\n## tel 0.8516583\n## gsh 0.6451292\n## [...]\nplot(sucra)\nresults <- relative.effect.table(mcmc2)\nsave(results, file = \"results.csv\")"},{"path":"netwma.html","id":"ネットワークメタ回帰","chapter":"12 ネットワークメタ分析","heading":"12.3.4 ネットワークメタ回帰","text":"\n{gemtc} パッケージの大きな特徴は、ネットワークメタ回帰を行うことができる点である。従来のメタ回帰と同様に、この機能を使って、特定の研究特性がネットワークで発見された効果量の大きさに影響を与えるかどうかを判断することが可能である。また、非一貫性を説明する可能性のある変数をチェックするのに便利なツールである。研究のバイアスのリスクが、ネットワークメタ分析における効果に影響を与えるかどうかを評価したいとする。たとえば、バイアス・リスクの高い研究は、一般に、対照群または代替治療と比較して、より高い効果を報告することが考えられる。モデルに予測因子として偏りのリスクを含めることで、そのような関連をコントロールし、結果への影響を評価することが可能である。{gemtc} でネットワークメタ回帰を実行するには、共変量なしのベイズネットワークメタ分析モデルを適合させたときと同様のステップを踏む必要がある。まず、mtc.network を使用してネットワークを設定する必要がある。しかし、今回は studies という追加の引数を指定する。この引数には、各研究の予測変数の情報を格納したデータフレームを指定する。TherapyFormatsGeMTC データセットには、study.info という要素があり、各研究のバイアスリスクが格納されている。それでは、データを簡単に見てみよう。このデータセットには2つの列が含まれている。study はネットワークに含まれる研究の名前、rob はそのバイアスリスクである。study のラベルは、実際の効果量データセットで使用されているものと完全に同一である必要があることに注意する必要がある。rob 変数はダミーコードの予測変数で、0 は低バイアスリスク、1 は高バイアスリスクを示す。study.info データフレームを使用して、mtc.network でメタ回帰ネットワークを作成することが可能である。ここで、ネットワークメタ分析モデルに含めたい回帰因子を定義する必要がある。これは、3つの要素を持つリストオブジェクトを生成することで行うことが可能である。coefficient: この要素は、ネットワークメタ分析に含まれるすべての治療にわたる (高) バイアスリスクの効果について、1つの共有係数を推定したいので、\"shared\" に設定する。coefficient: この要素は、ネットワークメタ分析に含まれるすべての治療にわたる (高) バイアスリスクの効果について、1つの共有係数を推定したいので、\"shared\" に設定する。variable: 予測変数として使用したい変数の名前を指定する (ここでは \"rob\")。variable: 予測変数として使用したい変数の名前を指定する (ここでは \"rob\")。control: 参照グループとして使用する治療法も指定しなければならない。この例では、\"cau\" (care usual) を使用する。control: 参照グループとして使用する治療法も指定しなければならない。この例では、\"cau\" (care usual) を使用する。次に、モデルをコンパイルする。先ほど生成したネットワークを mtc.model 関数に与え、モデルのタイプを \"regression\" に設定し、先ほど生成した regressor オブジェクトを関数の引数に与える。出力結果は model.mr という名前で保存される。このステップの後、mtc.run関数を用いてモデルを実行することが可能である。mcmc2 モデルのフィッティングに使用したのと同じ仕様を使用する。結果は mcmc3 として保存される。では、summary 関数を使って結果を解析してみよう。予測変数の結果は、Bの隣に報告されている。予測変数はダミー・コード化されているので、 B の値は、バイアスの高いリスクを持つ研究の効果を表す。推定値は \\(b=\\) -0.33 で、2番目の表 (Quantiles variable) を見ると、\\(b\\) の95% 信頼区間が -0.59 から -0.08 までであることがわかる。信頼区間には0が含まれないので、バイアスのリスクは確かに結果に影響すると結論づけられるであろう。バイアスのリスクが高いとき (rob = 1)、より高い全体効果を予測が可能である (この例では、負の効果量は「より良い」結果を示している)。2つのフォレストプロットを生成することにより、予測変数の効果をさらに調査することができる。1つは、バイアスリスクが高いときの推定治療効果で、もう1つは、それが低いときのものである。これは relative.effect 関数を用いて行うことができ、ここで covariate 値を指定する。covariate = 0 はバイアスリスクの低い研究を表し、covariate = 1 はバイアスリスクの高い研究を表す。フォレストプロットを比較すると、あるパターンが見えてくる。すなわち、バイアスリスクの高い研究に基づく治療効果は、一般に高い (よりマイナスである)。これは、予測変数の推定値と一致している。最後に、先ほど生成したネットワークメタ回帰モデルが、先ほどの「通常の」ネットワークメタ分析モデルよりもデータにフィットしているかどうかを調べることもが可能である。これを行うには、逸脱度情報量規準 (Deviance Information Criteria, DIC) を比較する。これは、頻度論統計学における AIC および BIC 値に相当する。以下のコードを用いて、mcmc3 と mcmc2 の両方の DIC にアクセスすることが可能である。メタ回帰モデルの DIC 値 (261.19) は、バイアスリスクをコントロールしなかった以前のモデル (DIC = 323.6) より低いことが出力からわかる。DIC 値が低いほど、適合度が高いことを示している。この知見に基づき、このネットワークメタ回帰モデルは、共変量なしのモデルよりもデータによく適合していると結論づけることが可能である。\n更なる学習\n\n以上、 R\nを使ったネットワークメタ分析の簡単な紹介をした。ネットワークメタ分析の背後にある一般的な考え方、それに関連する仮定といくつかの注意点、ネットワークメタ分析を行うことができる2つの異なる統計的アプローチ、およびそれらが\nR でどのように実装されているかを説明した。\n\nここで取り上げたことは、あくまで大まかな概要として捉えていただきたい。主な落とし穴をいくつか取り上げたが、実際にネットワークメタ分析を始めると、やはり行き詰まる可能性がある。\n\nネットワークメタ分析について、またそれをどのように実際に適用できるかを知るための優れたリソースが、Dias\net al. によって書かれた Network Meta-Analysis \nDecision-Making である (2018)。この本では、いくつかの実践例も紹介されており、オープンソースのソフトウェア\nWinBUGS\nを使用してネットワークメタ分析モデルを実行する方法が紹介されている。ネットワークメタ分析の「最先端」の短い\n(そしてかなり技術的な) 概要は、Efthimiou et\nal. によるオープンアクセス論文(2016)で見ることが可能である。\n\\[\\tag*{$\\blacksquare$}\\]","code":"\nTherapyFormatsGeMTC$study.info##                        study rob\n## 1             Campbell, 2000   1\n## 2             Reynolds, 1989   1\n## 3            Carpenter, 1994   0\n## 4             Shrednik, 2000   1\n## [...]\nnetwork.mr <- mtc.network(data.re = TherapyFormatsGeMTC$data,\n                          studies = TherapyFormatsGeMTC$study.info,\n                          treatments = TherapyFormatsGeMTC$treat.codes)\nregressor <- list(coefficient = \"shared\",\n                  variable = \"rob\",\n                  control = \"cau\")\nmodel.mr <- mtc.model(network.mr,\n                      likelihood = \"normal\",\n                      link = \"identity\",\n                      type = \"regression\",\n                      regressor = regressor)\nmcmc3 <- mtc.run(model.mr,\n                 n.adapt = 5000,\n                 n.iter = 1e5,\n                 thin = 10)\nsummary(mcmc3)## Results on the Mean Difference scale\n## [...]\n## \n## 1. Empirical mean and standard deviation for each variable,\n##    plus standard error of the mean:\n## \n##              Mean      SD  Naive SE Time-series SE\n## d.ind.cau  0.6992 0.07970 0.0003985      0.0004201\n## d.ind.grp  0.1933 0.10009 0.0005005      0.0005321\n## [...]\n## B         -0.3297 0.13047 0.0006523      0.0010379\n## \n## 2. Quantiles for each variable:\n## \n##                2.5%      25%      50%     75%    97.5%\n## d.ind.cau  0.542044  0.64602  0.69967  0.7529  0.85571\n## d.ind.grp -0.002622  0.12599  0.19353  0.2608  0.38962\n## [...]\n## B         -0.586266 -0.41790 -0.32957 -0.2417 -0.07455\n## \n## [...]\n## -- Regression settings:\n## \n## Regression on \"rob\", shared coefficients, \"cau\" as control\n## Input standardized: x' = (rob - 0.4340659) / 1\n## Estimates at the centering value: rob = 0.4340659\nforest(relative.effect(mcmc3, t1 = \"cau\", covariate = 1),\n       use.description = TRUE, xlim = c(-1.5, 1))\ntitle(\"High Risk of Bias\")\n\nforest(relative.effect(mcmc3, t1 = \"cau\", covariate = 0),\n       use.description = TRUE, xlim = c(-1.5, 1))\ntitle(\"Low Risk of Bias\")\nsummary(mcmc3)$DIC##        Dbar          pD         DIC data points \n##   185.82124    75.36609   261.18733   183.00000\nsummary(mcmc2)$DIC##        Dbar          pD         DIC data points \n##    185.5705    138.0150    323.5854    183.0000"},{"path":"netwma.html","id":"演習問題-11","chapter":"12 ネットワークメタ分析","heading":"12.4 演習問題","text":"\n知識を試そう！\n\nネットワークメタ分析はどのような場合に有用か？標準的なメタ分析と比較して、どのような利点があるか？\n\n治療ネットワークにおける直接エビデンスと間接エビデンスの違いは何か？間接エビデンスの生成に直接エビデンスをどのように利用できるのか？\n\nネットワークメタ分析における推移性 (transitivity)\nの仮定の主な考え方は何か？\n\n推移性 (transitivity) と一貫性 (consistency) の関係は？\n\nネットワークメタ分析に使用できる2つのモデリングアプローチを挙げなさい。どちらか一方が優れているか？\n\n1つの試験から複数の比較を含める場合\n(マルチアーム試験など)、どのような問題が発生するか？\n\n異なる治療法の P-スコアまたは SUCRA\nスコアを解釈する際、どのような点に注意しなければならないか？\n\n問題の解答は、本書の巻末 Appendix\nにある。\n","code":""},{"path":"netwma.html","id":"要約-8","chapter":"12 ネットワークメタ分析","heading":"12.5 要約","text":"ネットワークメタ分析は、様々な治療や介入の相対的効果を共同で推定するのに有用なツールである。ネットワークメタ分析は、様々な治療や介入の相対的効果を共同で推定するのに有用なツールである。治療効果を推定するために、ネットワークメタ分析は、直接 (すなわち観察) 証拠と間接証拠の両方を結合する。ただし、これには「推移性 (交差性) 」という前提がある。推移性は、2つの比較の直接証拠を組み合わせて、3つ目の比較についての有効な間接証拠を導き出すことができるときに満たされる。治療効果を推定するために、ネットワークメタ分析は、直接 (すなわち観察) 証拠と間接証拠の両方を結合する。ただし、これには「推移性 (交差性) 」という前提がある。推移性は、2つの比較の直接証拠を組み合わせて、3つ目の比較についての有効な間接証拠を導き出すことができるときに満たされる。推移性の統計的な現れは一貫性 (consistency) であり、その反対は斐伊川 (inconsistency) である。非一貫性は、直接証拠に基づく比較の真の効果が、間接証拠に基づくものと一致しないときに生じるものである。推移性の統計的な現れは一貫性 (consistency) であり、その反対は斐伊川 (inconsistency) である。非一貫性は、直接証拠に基づく比較の真の効果が、間接証拠に基づくものと一致しないときに生じるものである。ノードスプリッティングやネットヒートプロットなどの手法により、ネットワーク内の非一貫性を特定することができる。非一貫性が見つかると、結果全体の妥当性が脅かされることになる。このような場合、研究／デザイン間の系統的な差異を引き起こした可能性のある特性をネットワーク全体でチェックする必要がある。ノードスプリッティングやネットヒートプロットなどの手法により、ネットワーク内の非一貫性を特定することができる。非一貫性が見つかると、結果全体の妥当性が脅かされることになる。このような場合、研究／デザイン間の系統的な差異を引き起こした可能性のある特性をネットワーク全体でチェックする必要がある。ネットワークメタ分析は、頻度論的またはベイズ的アプローチのいずれかを使用して可能である。実際には、これらの方法にはそれぞれ長所があるが、通常、全体的な結果は非常に似ている。ネットワークメタ分析は、頻度論的またはベイズ的アプローチのいずれかを使用して可能である。実際には、これらの方法にはそれぞれ長所があるが、通常、全体的な結果は非常に似ている。ベイズ型階層モデルに基づくネットワークメタ分析では、効果量の差を予測する研究共変量を加えることもが可能である。この結果、ネットワークメタ回帰モデルになる。ベイズ型階層モデルに基づくネットワークメタ分析では、効果量の差を予測する研究共変量を加えることもが可能である。この結果、ネットワークメタ回帰モデルになる。SUCRA や P-score などの指標は、このネットワークにおいて、どのタイプの治療が最も効果的であるかを調べるために使用することが可能である。しかし、意思決定プロセスに不確実性を組み込むことも重要である。異なる治療法の信頼区間は重なり合うこともよくあるので、1つの形式が他のすべての形式より本当に優れているかどうかは、あまり明確ではない。SUCRA や P-score などの指標は、このネットワークにおいて、どのタイプの治療が最も効果的であるかを調べるために使用することが可能である。しかし、意思決定プロセスに不確実性を組み込むことも重要である。異なる治療法の信頼区間は重なり合うこともよくあるので、1つの形式が他のすべての形式より本当に優れているかどうかは、あまり明確ではない。","code":""},{"path":"bayesian-ma.html","id":"bayesian-ma","chapter":"13 ベイズメタ分析","heading":"13 ベイズメタ分析","text":"こ\nれまでの章では、「マルチレベル」モデル (Chapter 10)、メタ分析的構造方程式モデリング (Chapter 11)、ネットワークメタ分析 (Chapter 12) など、メタ分析のやや高度な拡張を掘り下げてきた。さて、一歩下がって、もう一度「従来の」メタ分析を見直そう。ただし、今回はこれまでとは異なる角度でベイズメタ分析を扱う。\nすでに一つ前のネットワークメタ分析に関する章でベイズモデルを取り上げた。そこでは、ベイズの定理や事前分布の考え方など、ベイズ統計の背後にある主要な考え方について議論してきた (Chapter 12.3.1 参照)。本章では、この知識をもとに、メタ分析を行うための「ベイズ的な方法」をより深く理解したい。例えば、ベイジアンネットワークのメタ分析モデルを設定するとき、{gemtc} パッケージは自動的に優先順位を指定したが、ここでは、これを自分たちで行っていきたい。背景は少し複雑であるが、ベイズメタ分析も本質的に「従来の」メタ分析と同じことをしていることがわかる。しかし、ベイズモデルを使用することは、頻度論的アプローチと比較して、いくつかの実用的な利点もある。そのため、 R を使用して利点のあるモデルを実装する方法を学ぶことは価値がある。","code":""},{"path":"bayesian-ma.html","id":"bayes-hierarchical-model","chapter":"13 ベイズメタ分析","heading":"13.1 ベイズ型階層モデル","text":"ベイズメタ分析を行うために、いわゆるベイズ階層モデル (Röver 2017; Julian Higgins, Thompson, Spiegelhalter 2009) を採用する。このタイプのモデルについては、すでにネットワークメタ分析の章 (Chapter 12.3.2) で簡単に取り上げた。Chapter 10 では、すべてのメタ分析モデルには固有の「マルチレベル」、つまり階層的な構造があることを学んだ。最初のレベルには、個々の参加者がいる。このレベルのデータは、通常、各研究 \\(k\\) の計算された効果量 \\(\\hat\\theta_k\\) という形で届く。参加者が第２レベルにネストされると、それぞれの研究の真の効果量 \\(\\theta_k\\) は、独自の分布に従うと仮定する。この真の効果の分布は、平均 \\(\\mu\\) (推定したい「真の」効果のプール値) と分散 \\(\\tau^2\\) (研究間の異質性を表す) を持っている。これを定式化してみよう。最初のレベルでは、研究 \\(k\\) で報告された観察された効果量 \\(\\hat\\theta_k\\) が、この研究での「真の」効果 \\(\\theta_k\\) の推定値であると仮定した。観察された効果 \\(\\hat\\theta_k\\) は、サンプル誤差 \\(\\epsilon_k\\) のために \\(\\theta_k\\) から乖離している。これは、\\(\\hat\\theta_k\\) が \\(k\\) の基礎となる母集団から抽出 (サンプル) されたと仮定している。この母集団は、平均 \\(\\theta_k\\)、研究の「真の」効果、および分散 \\(\\sigma^2\\) を持つ分布と見なすことが可能である。第2ステップでは、真の効果量 \\(\\theta_k\\) 自身は、真の効果量の包括的な分布のサンプルに過ぎないと仮定する。この分布の平均 \\(\\mu\\) は、推定したい効果量のプール値である。包括的な分布は分散 \\(\\tau^2\\) も持っているので、研究別の真の効果 \\(\\theta_k\\) は、\\(\\mu\\) から乖離している。この分散は、研究間の異質性を表す。まとめると、この2つの方程式が得られる。\\[\\begin{align}\n\\hat\\theta_k &\\sim \\mathcal{N}(\\theta_k,\\sigma_k^2) \\notag \\\\\n\\theta_k &\\sim \\mathcal{N}(\\mu,\\tau^2) \\tag{13.1}\n\\end{align}\\]ここでは、\\(\\mathcal{N}\\) を使って、左側のパラメータが正規分布からサンプルされたことを示す。これは2番目の式に対して不必要に厳しい仮定であるという意見もあるが (Julian Higgins, Thompson, Spiegelhalter 2009)、ここで示したような定式化は、ほとんどの場合に使用されているものである。前にも述べたように、固定効果モデルはこのモデルの特殊なケースで、\\(\\tau^2 = 0\\) 、つまり研究間の異質性がなく、すべての研究が1つの真の効果量を共有していると仮定している (すなわち、すべての研究 \\(k\\) に対して、\\(\\theta_k = \\mu\\))。また、この式を簡略化するために、合わせた形式を用いることができる。\\[\\begin{equation}\n\\hat\\theta_k  \\sim \\mathcal{N}(\\mu,\\sigma_k^2 + \\tau^2)\n\\tag{13.2}\n\\end{equation}\\]これらの公式は、ランダム効果 (Chapter 4.1.2) や３レベルメタ分析 (Chapter 10.1) モデルを議論したときに定義したものとよく似ていることに、すでに気づいただろう。実際、この定式化には特に「ベイズ的」なものはない。しかし、次の式 (Williams, Rast, Bürkner 2018) を追加すると、この点は変わる。\\[\\begin{align}\n(\\mu, \\tau^2) &\\sim p(.) \\notag \\\\\n\\tau^2 &> 0 \\tag{13.3}\n\\end{align}\\]最初の行が特に重要で、パラメータ \\(\\mu\\) と \\(\\tau^2\\) の事前分布 (prior distributions) を定義している。これにより、真のプール効果量 \\(\\mu\\) と研究間異質性 \\(\\tau^2\\) がどのように見えるか、またそれについてどの程度確信が持てるかを priori に指定することが可能である。2番目の式は、研究間異質性分散が0より大きくなければならないという制約を加えている。しかし、この式は、\\(\\mu\\) と \\(\\tau^2\\) で使用される事前分布の正確な種類 を指定していない。それは、何らかの事前分布が仮定されていることを教えてくれるだけである。ベイズメタ分析モデルのための合理的で特別な事前分布については、後で詳しく説明する。\nネットワークメタ分析の章では、ベイズアプローチがモデルパラメータを推定する方法について説明した。要約すると、マルコフ連鎖モンテカルロに基づくサンプリング手続き、例えば Gibbs サンプリングを使用することである。本章で使用する {brms} パッケージでは、いわゆる -U-Turn サンプリング (NUTS, Hoffman Gelman 2014) を使用する67。\nこれまでの章では、主に {meta} と {metafor} パッケージを使用してきた。この二つのパッケージは、非ベイズ的、つまり頻度論的なフレームワークに基づいてメタ分析を行うことが可能である。したがって、「従来の」アプローチですでにこのような強力なツールに頼ることができるのに、なぜベイズ法を使い始めなければならないのかと疑問に思うだろう。その理由は、以下のようなベイズメタ分析には明確な利点があるからである (Williams, Rast, Bürkner 2018; McNeish 2016; Chung et al. 2013)。ベイズ法は、\\(\\tau^2\\) の推定値における不確実性を直接モデル化することが可能である。また、特に対象研究の数が少ない場合 (実際には非常に多い)、効果のプール推定に優れている場合がある。ベイズ法は、\\(\\tau^2\\) の推定値における不確実性を直接モデル化することが可能である。また、特に対象研究の数が少ない場合 (実際には非常に多い)、効果のプール推定に優れている場合がある。ベイズ法は、\\(\\mu\\) と \\(\\tau^2\\) の両方について、完全な事後分布 (posterior distribution) を生成する。これにより、\\(\\mu\\) または \\(\\tau^2\\) がある指定された値より小さいまたは大きい正確な確率を計算することが可能である。これは、信頼区間だけを計算する頻度論的方法とは対照的である。しかし、(95％) 信頼区間は、データサンプリングが何度も繰り返された場合、母集団のパラメータ (例えば、\\(\\mu\\) や \\(\\tau^2\\)) の真の値が、サンプルの95％において信頼区間の範囲に収まることを述べているに過ぎないのである。真のパラメータが2つの指定された値の間にある確率は教えてくれない。ベイズ法は、\\(\\mu\\) と \\(\\tau^2\\) の両方について、完全な事後分布 (posterior distribution) を生成する。これにより、\\(\\mu\\) または \\(\\tau^2\\) がある指定された値より小さいまたは大きい正確な確率を計算することが可能である。これは、信頼区間だけを計算する頻度論的方法とは対照的である。しかし、(95％) 信頼区間は、データサンプリングが何度も繰り返された場合、母集団のパラメータ (例えば、\\(\\mu\\) や \\(\\tau^2\\)) の真の値が、サンプルの95％において信頼区間の範囲に収まることを述べているに過ぎないのである。真のパラメータが2つの指定された値の間にある確率は教えてくれない。ベイズ法は、メタ分析を計算する際に、事前知識と仮定を統合することができる。ベイズ法は、メタ分析を計算する際に、事前知識と仮定を統合することができる。","code":""},{"path":"bayesian-ma.html","id":"priors","chapter":"13 ベイズメタ分析","heading":"13.2 事前分布の設定","text":"これまで、ベイズメタ分析で効果をプールするために使用できる階層モデルを定式化した。しかし、このようなモデルを実行するためには、\\(\\mu\\) と \\(\\tau^2\\) の事前分布を指定しなければならない。特に、研究数が少ない場合、事前分布は結果にかなりの影響を与えるので、賢く選択する必要がある。\n一般的に、良いアプローチは、弱情報事前 (weakly informative prior) を使用することである (Williams, Rast, Bürkner 2018)。弱情報事前分布は、無情報事前 (non-informative priors) 分布と対比することが可能である。無情報的事前分布は、事前分布の最も単純な形式である。これは通常、一様分布に基づいており、すべての値が等しく信頼できることを表現する時に使用される。一方、弱情報事前分布は、もう少し洗練されたものである。これは、ある値が他の値よりも信頼できるという弱い確信を持っていることを表す分布に依存する。しかし、データから推定されるパラメータの値については、まだ具体的な記述はしていない。直感的には、これは非常に理にかなっている。たとえば、多くのメタ分析では、真の効果がSMD = -2.0 と 2.0 の間のどこかにあると仮定することは妥当であるが、SMD = 50 になることはまずないだろう。この理論的根拠に基づいて、ここでの \\(\\mu\\) 事前分布は、平均 0、分散 1の正規分布から出発すると良いだろう。これは、真のプールされた効果量 \\(\\mu\\) が -2.0 と 2.0 の間にあることを、約95%の事前確率で認めることを意味する。\\[\\begin{equation}\n\\mu \\sim \\mathcal{N}(0,1)\n\\tag{13.4}\n\\end{equation}\\]次に指定しなければならない事前分布は、\\(\\tau^2\\) の事前分布である。\\(\\tau^2\\) は常に非負であるが、0 (またはゼロに近い値) であってもよいことがわかっているので、これは少し難しい。この場合に推奨される分布で、\\(\\tau^2\\) のような分散によく使われるものは、Half-Cauchy 事前分布である。Half-Cauchy 分布は、Cauchy 分布の特殊なケースで、分布の「半分」 (もちろん、正の側) に対してのみ定義されている68。Half-Cauchy 分布は2つのパラメータで制御される。最初のものは、分布のピークを指定する位置パラメータ \\(x_0\\) である。もう1つは、スケーリングパラメータ \\(s\\) である。これは、分布がどの程度裾が重い (heavy-tailed) か (すなわち、どの程度高い値まで「広がる」か) を制御する。Half-Cauchy 分布は \\(\\mathcal{HC}(x_0,s)\\) と表記される。以下のグラフは、\\(x_0\\) の値を 0 に固定し、\\(s\\) の値を変化させた場合の Half-Cauchy 分布を可視化したものである。Half-Cauchy 分布は通常、かなり重い裾を持つので、\\(\\tau\\) の事前分布として特に有用である。この重い尾は、\\(\\tau\\) の非常に高い値を何らかの確率で与えることを保証すると同時に、低い値の方がより可能性が高いと想定している。多くのメタ分析では、\\(\\tau\\) (\\(\\tau^2\\) の平方根) は 0.3 近辺にあるか、少なくとも同じような範囲にある。したがって、Half-Cauchy 事前分布を指定するために、\\(s =\\) 0.3 を使用することが可能である。これにより、\\(\\tau =\\) 0.3 より小さい値は50%の確率で存在することが保証される (Williams, Rast, Bürkner 2018)。このことは、{extraDistr} パッケージの phcauchy 関数で実装されている Half-Cauchy 分布関数を用いて確認することが可能である (Wołodźko 2020)。しかし、これはすでに \\(\\tau\\) の真の値に関するかなり具体的な仮定である。より保守的なアプローチとして、この実践例では、\\(s\\) を0.5に設定する。これは、分布をよりフラットにできる。一般的に、常に異なる事前分布を用いた感度分析を行い、それが結果に大きな影響を与えるかどうかを確認することを勧める。 \\(s =\\) 0.5 を Half-Cauchy 分布のパラメータとして使用し、\\(\\tau\\) の事前分布を次のように書くことが可能である。\\[\\begin{equation}\n\\tau \\sim \\mathcal{HC}(0,0.5)\n\\tag{13.5}\n\\end{equation}\\]これで、階層モデルの式と事前指定をまとめることが可能である。これは、ベイズ・メタ分析に使用できる完全なモデルにつながる。\\[\\begin{align}\n\\hat\\theta_k &\\sim \\mathcal{N}(\\theta_k,\\sigma_k^2) \\notag \\\\\n\\theta_k &\\sim \\mathcal{N}(\\mu,\\tau^2) \\notag \\\\\n\\mu &\\sim \\mathcal{N}(0,1) \\notag \\\\\n\\tau &\\sim \\mathcal{HC}(0,0.5) \\tag{13.5}\n\\end{align}\\]","code":"\nlibrary(extraDistr)\nphcauchy(0.3, sigma = 0.3)## [1] 0.5"},{"path":"bayesian-ma.html","id":"bayes-ma-R","chapter":"13 ベイズメタ分析","heading":"13.3 R でのベイズメタ分析","text":"\nメタ分析のためのベイズモデルを定義したので、いよいよ R で実装してみよう。ここでは、{brms} パッケージ (Bürkner 2017b, 2017a) を使ってモデルの適合を行う。{brms} パッケージは、ベイズ回帰モデルを適合させるための非常に多機能で強力なツールである。マルチレベル (混合効果) モデル、一般化線形モデル、多変量モデル、一般化加法モデルなど、幅広い用途に使用することが可能である。モデルの多くは人レベルのデータを必要とするが、{brms} は (重み付けされた) 研究レベルデータを扱うメタ分析にも使用可能である69。モデルの適合を始める前に、まず {brms} パッケージをインストールし、ロードする必要がある。","code":"\nlibrary(brms)"},{"path":"bayesian-ma.html","id":"モデルの適合-1","chapter":"13 ベイズメタ分析","heading":"13.3.1 モデルの適合","text":"このデータセットには、大学生における「第3の波」心理療法の効果を調査したメタ分析からの情報が含まれている (Chapter 4.2.1)。モデルを適合させる前に、まず、全体の効果量 \\(\\mu\\) と研究間の異質性 \\(\\tau\\) の事前分布を指定しよう。前に、\\(\\mu \\sim \\mathcal{N}(0,1)\\) と \\(\\tau \\sim \\mathcal{HC}(0,0.5)\\) と定義した。分布を指定するには、prior 関数を使用する。この関数は2つの引数を取る。最初の引数では、分布パラメータを含む、事前分布として想定される分布を指定する。2番目の引数では、事前分布の class を定義する必要がある。\\(\\mu\\) の場合、母集団レベルの固定効果であるため、適切なクラスは Intercept である。\\(\\tau\\) の場合は、分散 (より正確には、標準偏差) なので、クラスは sd である。両方の prior を prior 関数で定義し、それらを連結したものを priors という名前で保存する。さて、次にモデルの適合を行う。これを行うには、{brms} の brm 関数を使用する。この関数には多くの引数があるが、私たちに関係するのはごく一部である。引数 formula には、モデルの数式が指定される。{brms} パッケージは回帰式の表記法を用いており、アウトカム (ここでは観測された効果量) y が一つ以上の予測変数 x によって予測されることを表している。チルダ ( ~ ) は、y ~ x という予測関係があることを指定するために使用される。メタ分析はやや特殊で、効果量を予測する変数を持っていない (メタ回帰を実行する場合を除く)。つまり、切片のみのモデルであることを示すために、x を 1 に置き換える必要がある。さらに、単純に各研究の効果量をそのまま y に使うことはできないので、y|se(se_y) を使う。また、精度の高い研究 (すなわち、サンプルサイズ) にはより大きな重みを与える必要がある。ここで、se(se_y) の部分は、データセット中の各効果量 y の標準誤差を表している。ランダム効果モデルを使用したい場合、最後のステップは、式の右側にランダム効果項 (1|study) を追加することである。これは、y の効果量が研究内で入れ子になっていると仮定し、その真の効果量は、真の効果量の包括的な母集団からランダムに抽出されたものであることを指定するものである。固定効果モデルを使用したい場合は、この項を省略すればよい。したがって、ランダム効果モデルの一般的な完全式は、次のようになる。y|se(se_y) ~ 1 + (1|random)。モデルの計算式の詳細については、コンソールで ?brmsformula と入力すると、ドキュメントが表示される。他の引数はかなり単純である。prior には、モデルに定義したい prior を指定する。この例では、以前に作成した priors オブジェクトを代入することが可能である。iter 引数は、MCMC アルゴリズムの反復回数を指定する。モデルが複雑であればあるほど、この数値は大きくなるはずである。しかし、反復回数が多ければ多いほど、関数が終了するまでに時間がかかるということでもある。最後に、data を指定する。ここでは、データセットの名前を指定する。適合したベイズメタ分析モデルを m.brm という名前で保存する。コードは以下のようになる。ベイズ法は、以前取り上げた標準的なメタ分析手法に比べ、計算量が非常に多いことに注意。そのため、サンプリングが完了するまで数分かかる場合がある。","code":"\npriors <- c(prior(normal(0,1), class = Intercept),\n            prior(cauchy(0,0.5), class = sd))\nm.brm <- brm(TE|se(seTE) ~ 1 + (1|Author),\n             data = ThirdWave,\n             prior = priors,\n             iter = 4000)"},{"path":"bayesian-ma.html","id":"収束性とモデルの妥当性の評価","chapter":"13 ベイズメタ分析","heading":"13.3.2 収束性とモデルの妥当性の評価","text":"結果の解析を始める前に、モデルが収束すること (つまり、MCMC アルゴリズムが最適解を見つること) を確認する必要がある。もし収束しなければ、パラメータは信頼できないので、解釈すべきではない。収束しないことはベイズモデルで頻繁に起こり、反復回数 (iter) を大きくしモデルを再実行することで解決することが多い。モデルの収束と全体的な妥当性を評価するために、常に2つのことを行うべきである。まず、パラメータ推定値の \\(\\hat{R}\\) (「R ハット」と読む) 値をチェックし、次に、事後予測チェック (posterior predictive checks) を行う。\\(\\hat{R}\\) の値は、ベイジアンネットワークメタ分析 (Chapter 12.3.3.5 ) を議論する際にすでに取り上げた Potential Scale Reduction Factor (PSRF) を表している。推定 \\(\\hat{R}\\) 値は 1.01 より小さいはずである。これを確認するために、m.brm オブジェクトの summary を生成しよう。見ての通り、両パラメータの Rhat 値は 1 であり、収束した。つまり、結果を解釈できることを意味する。一方、事後予測チェックでは、事後予測分布からランダムに抽出してデータをシミュレートし、観測データと比較する。モデルが収束してデータをよく捉えていれば、再現分布の密度は観測データの密度とほぼ同じになると予想される。これは、関数 pp_check の出力で簡単に確認することが可能である。","code":"\nsummary(m.brm)## Family: gaussian \n##   Links: mu = identity; sigma = identity \n## Formula: TE | se(seTE) ~ 1 + (1 | Author) \n##    Data: ThirdWave (Number of observations: 18) \n## Samples: 4 chains, each with iter = 4000; warmup = 2000; thin = 1;\n##          total post-warmup samples = 8000\n## \n## Group-Level Effects: \n## ~Author (Number of levels: 18) \n##               Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS \n## sd(Intercept)     0.29      0.10     0.11     0.51 1.00     2086   \n## \n## Population-Level Effects: \n##           Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS \n## Intercept     0.57      0.09     0.39     0.76 1.00     3660    \n## \n##\n## [...]\n## \n## Samples were drawn using sampling(NUTS). For each parameter, \n## Bulk_ESS and Tail_ESS are effective sample size measures, \n## and Rhat is the potential scale reduction factor on split \n## chains (at convergence, Rhat = 1).\npp_check(m.brm)"},{"path":"bayesian-ma.html","id":"結果の解釈","chapter":"13 ベイズメタ分析","heading":"13.3.3 結果の解釈","text":"まず、要約出力の Group-Level Effects を見ることによって、結果の解釈を始めていこう。このセクションは、数式で定義したランダム効果のために予約されている。ランダム効果のメタ分析モデルを適用したので、個々の研究を意味する変数 ~Author は、ランダム切片でモデル化された。前に説明したように、これはレベル２において、各研究がそれ自身の「真の」効果量を持ち、それは真の効果量の包括的な分布からサンプルされた、というの仮定を表している。また、グループレベルの効果は 18 あり、これは結果のデータ中の \\(K =\\) 18 件の研究に対応している。研究間異質性の推定値 sd(Intercept) である \\(\\tau =\\) 0.29 である、したがって、prior を設定する際の最初の「最良の推測」に近いものである。ranef 関数を使用すると、プール効果から各研究の「真の」効果量の推定偏差を抽出することも可能である。次に解釈できるのは、Population-Level Effects である。このセクションは、モデル化した「固定」母集団パラメータを表す。ここでは \\(\\mu\\) のことで、メタ分析の全体的な効果量である。出力では、推定値は (バイアス補正された) SMD が 0.57 であり、95％信用 (確信) 区間は95％CrI: 0.39-0.76であることがわかる。これは、このメタ分析で研究された介入は、中程度の大きさの全体的な効果を有することを示している。これはベイズモデルなので、\\(p\\) -値は見当たらない。しかし、この例は、古典的な有意性検定に頼ることなく、合理的な推論を行うことができることを強調するものである。頻度論的なメタ分析になりベイズモデルの利点として、推定したいパラメータを確率的にモデル化することができる。ベイズモデルで、興味のあるパラメータを推定するだけでなく、\\(\\tau^2\\) と \\(\\mu\\) の事後分布全体を推定するには、posterior_samples 関数を使用するだけでよい。この結果、データフレームには2つの列が含まれる。b_Intercept はプール効果量 \\(\\tau\\) の事後サンプルデータ、sd_Author_Intercept は研究間異質性データである。列の名前をより分かりやすくするために、smd と tau に改名しよう。post.samples のデータを用いて、事後分布の密度プロットを作成してみよう。プロットには、{ggplot2} パッケージを使用する。事後分布はほぼ、一峰性の正規分布に従い、\\(\\mu\\) と \\(\\tau\\) の推定値付近でピークを示すことがわかる。ベイズ法は、関心のあるパラメータの実際のサンプル分布を作成するということは、\\(\\mu\\) または \\(\\tau\\) がある特定の値より大きいか小さいかという正確な確率を計算することができるということである。以前の文献で、介入の効果が SMD = 0.30 以下であれば、もう意味がないことがわかったとする。そこで、このメタ分析における真の全体効果が SMD = 0.30 より小さい確率を、このモデルに基づいて計算してみよう。これは、経験的累積分布関数 (Empirical Cumulative Distribution Function, ECDF) を見ることによって行うことが可能である。ECDF は、ある特定の値 \\(X\\) を選択することができ、提供されたデータに基づいて、ある値 \\(x\\) が \\(X\\) より小さい確率を返す。この例での \\(\\mu\\) の事後分布の ECDF は、以下のようになる。ECDF 関数を使って、 R で ECDF を定義し、プールした効果が 0.30 より小さい確率を調べることができる。コードは以下のようになる。0.21% ということは、プール効果が 0.30 より小さい確率は非常に低いことがわかる。このカットオフが有効であると仮定すると、このメタ分析で見出された介入の全体的な効果は、意味のあるものである可能性が非常に高いということになる。","code":"\nranef(m.brm)## $Author\n## , , Intercept\n##                           Estimate Est.Error         Q2.5       Q97.5\n## Call et al.             0.06836636 0.1991649 -0.327463365  0.47663987\n## Cavanagh et al.        -0.14151644 0.1767123 -0.510165576  0.18799272\n## DanitzOrsillo           0.48091338 0.2829719 -0.003425284  1.08636421\n## de Vibe et al.         -0.31923470 0.1454819 -0.612269461 -0.03795683\n## Frazier et al.         -0.11388029 0.1497128 -0.417029387  0.17085917\n## [...]\npost.samples <- posterior_samples(m.brm, c(\"^b\", \"^sd\"))\nnames(post.samples)## [1] \"b_Intercept\"          \"sd_Author__Intercept\"\nnames(post.samples) <- c(\"smd\", \"tau\")\nggplot(aes(x = smd), data = post.samples) +\n  geom_density(fill = \"lightblue\",                # 色を指定\n               color = \"lightblue\", alpha = 0.7) +  \n  geom_point(y = 0,                               # 平均に点を追加\n             x = mean(post.samples$smd)) +\n  labs(x = expression(italic(SMD)),\n       y = element_blank()) +\n  theme_minimal()\n\nggplot(aes(x = tau), data = post.samples) +\n  geom_density(fill = \"lightgreen\",               # 色を指定\n               color = \"lightgreen\", alpha = 0.7) +  \n  geom_point(y = 0, \n             x = mean(post.samples$tau)) +        # 平均に点を追加\n    labs(x = expression(tau),\n       y = element_blank()) +\n  theme_minimal()\nsmd.ecdf <- ecdf(post.samples$smd)\nsmd.ecdf(0.3)## [1] 0.002125"},{"path":"bayesian-ma.html","id":"フォレストプロットの生成","chapter":"13 ベイズメタ分析","heading":"13.3.4 フォレストプロットの生成","text":"\nこれまで見てきたように、ベイズモデルによって、そのサンプル事後分布を抽出することが可能である。これは、モデルが与えられたときの特定の値の確率を直接評価するのに非常に役立つ。また、この機能を利用して、非常に有益で見栄えのする拡張フォレストプロット (Chapter 6) を作成することも可能である70。残念ながら、現在のところ、{brms} モデルから直接フォレストプロットを作成するパッケージは整備されていない。しかし、{tidybayes} パッケージ (Kay 2020) の関数を使用することにより、自分で作成することが可能である。そこで、まずパッケージを読み込んでから先に進もう。プロットを作成する前に、データを準備する必要がある。特に、各研究の事後分布を個別に抽出する必要がある (フォレストプロットは各研究の特定の効果量も描写しているため)。これを実現するために、{tidybayes} パッケージの spread_draws 関数を使用することが可能である。この関数は3つの引数を入力として必要とする。適合 {brms} モデル、結果をインデックス化するランダム効果因子、そして抽出したいパラメータ (ここでは固定項: 効果量を抽出したいので b_Intercept) である。パイプ演算子を使うことで、出力を直接操作することが可能である。{dplyr} の mutate 関数を用いて、各研究の推定偏差にプール効果量 b_Intercept を加算して、各研究の実際の効果量を計算する。その結果を study.draws として保存する。次に、同様の方法でプール効果の分布を生成したい (フォレストプロットでは、効果の要約は通常最後の行に表示されるため)。そこで、先ほどのコードを少しアレンジして、プール効果だけを得るために第2引数を削除する。mutate の呼び出しは、\"Author\" という追加の列を追加するだけである。その結果を pooled.effect.draws という名前で保存する。次に、study.draws と pooled.effect.draws を一つのデータフレームにバインドしている。そして、パイプを再び立ち上げ、まず ungroup を呼び出し、次に mutate を用いて、(1) 研究ラベルをきれいにし (ドットをスペースに置き換えるなど)、(2) 研究因子レベルを効果量 (高から低) で並べ替える。その結果、プロットに必要なデータができあがり、forest.data として保存する。最後に、フォレストプロットは各研究の効果量 (SMD と信用 (確信) 区間) も表示する必要がある。そのために、新しく作成した forest.data データセットを使用し、Author でグループ化し、mean_qi 関数を使用してこれらの値を計算する。出力は forest.data.summary という名前で保存する。これで、{ggplot2} パッケージでフォレストプロットを生成する準備が整った。プロットを生成するコードは次のようなものである。観測に基づく効果量とモデルに基づく効果量ここで一つ、非常に重要なことを述べておこう。フォレストプロットに表示されている効果量は、元の研究の観測された効果量ではなく、ベイズモデルに基づいた研究の効果量 (\\(\\theta_k\\)) の推定値である。フォレストプロットで示された点は、ranef を用いてランダム効果を抽出した際に見た研究ごとの推定値と同等である (ただし、これらの値はプールされた効果を中心にしたもの)。さらに、効果量が非常に大きい研究 (例えば、“DanitzOrsillo” や “Shapiro et al.” などの外れ値) の値を見ると、モデルベースの効果量は、最初の観測値よりも全体効果 \\(\\hat\\mu\\) に 近いことがわかる71。この平均への縮小は、メタ分析的ランダム効果モデルのような共通の包括的分布を持つ階層的モデルに典型的なものである。推定プロセスにおいて、ベイズモデルは、メタ分析におけるすべての効果量 \\(k\\) によって共同推定される真の効果量の全体的分布に関する情報で、ある研究 \\(k\\) の効果に関する情報を「補完」する。このような「強さの借用」は、極端な効果を持つ研究の値が平均値に向かって引っ張られることを意味する (Lunn et al. 2012, chap. 10.1)。この挙動は、比較的少ない情報を提供する研究 (つまり、大きな標準誤差を持つ研究) においてより顕著になる。\\[\\tag*{$\\blacksquare$}\\]","code":"\nlibrary(tidybayes)\nlibrary(dplyr)\nlibrary(ggplot2)\nlibrary(ggridges)\nlibrary(glue)\nlibrary(stringr)\nlibrary(forcats)\nstudy.draws <- spread_draws(m.brm, r_Author[Author,], b_Intercept) %>% \n  mutate(b_Intercept = r_Author + b_Intercept)\npooled.effect.draws <- spread_draws(m.brm, b_Intercept) %>% \n  mutate(Author = \"Pooled Effect\")\nforest.data <- bind_rows(study.draws, \n                         pooled.effect.draws) %>% \n   ungroup() %>%\n   mutate(Author = str_replace_all(Author, \"[.]\", \" \")) %>% \n   mutate(Author = reorder(Author, b_Intercept))\nforest.data.summary <- group_by(forest.data, Author) %>% \n  mean_qi(b_Intercept)\nggplot(aes(b_Intercept, \n           relevel(Author, \"Pooled Effect\", \n                   after = Inf)), \n       data = forest.data) +\n  \n  # プール効果と信頼区間に縦線を追加\n  geom_vline(xintercept = fixef(m.brm)[1, 1], \n             color = \"grey\", size = 1) +\n  geom_vline(xintercept = fixef(m.brm)[1, 3:4], \n             color = \"grey\", linetype = 2) +\n  geom_vline(xintercept = 0, color = \"black\", \n             size = 1) +\n  \n  # 密度を追加\n  geom_density_ridges(fill = \"blue\", \n                      rel_min_height = 0.01, \n                      col = NA, scale = 1,\n                      alpha = 0.8) +\n  geom_pointintervalh(data = forest.data.summary, \n                      size = 1) +\n  \n  # テキストとラベルを追加\n  geom_text(data = mutate_if(forest.data.summary, \n                             is.numeric, round, 2),\n    aes(label = glue(\"{b_Intercept} [{.lower}, {.upper}]\"), \n        x = Inf), hjust = \"inward\") +\n  labs(x = \"Standardized Mean Difference\", # 要約\n       y = element_blank()) +\n  theme_minimal()"},{"path":"bayesian-ma.html","id":"演習問題-12","chapter":"13 ベイズメタ分析","heading":"13.4 演習問題","text":"\n知識を試そう！\n\n「従来の」ランダム効果モデルとベイズ型階層モデルの相違点と類似点は何か？\n\nベイズメタ分析の頻度論的な利点と比較した場合の利点を3つ挙げよ。\n\n弱情報的事前分布と非情報的事前分布の違いを説明しなさい。\n\nHalf-Cauchy 分布とは何か、なぜベイズメタ分析に有用なのか。\n\nECDF とは何か、ベイズメタ分析にどう使えるか？\n\n問題の解答は、本書の巻末 Appendix\nにある。\n","code":""},{"path":"bayesian-ma.html","id":"要約-9","chapter":"13 ベイズメタ分析","heading":"13.5 要約","text":"メタ分析は頻度論的な統計で行われることが多いが、ベイズメタ分析も可能である。メタ分析は頻度論的な統計で行われることが多いが、ベイズメタ分析も可能である。ベイズメタ分析は、ベイズ階層モデルに基づいている。このモデルの核となる考え方は、「従来の」ランダム効果モデルと同じである。ただし、\\(\\mu\\) と \\(\\tau^2\\) 、(情報量が多い、情報量が少ない、または情報量が少ない) 事前分布を仮定している点が異なる。ベイズメタ分析は、ベイズ階層モデルに基づいている。このモデルの核となる考え方は、「従来の」ランダム効果モデルと同じである。ただし、\\(\\mu\\) と \\(\\tau^2\\) 、(情報量が多い、情報量が少ない、または情報量が少ない) 事前分布を仮定している点が異なる。ベイズメタ分析モデルでは、通常、弱情報事前を仮定するのがよいだろう。弱情報的事前は、ある値が他の値よりも信頼性が高いという弱い信念を表すために使用される。ベイズメタ分析モデルでは、通常、弱情報事前を仮定するのがよいだろう。弱情報的事前は、ある値が他の値よりも信頼性が高いという弱い信念を表すために使用される。研究間異質性分散 \\(\\tau^2\\) の事前分布を指定するために、Half-Cauchy 分布を使用することができる。Half-Cauchy 分布は、正の値に対してのみ定義され、より重いテールを持つので、このタスクに特に適している。これは、\\(\\tau^2\\) の非常に高い値の可能性は低いけれども、まだ非常に可能性があることを表現するために使うことが可能である。研究間異質性分散 \\(\\tau^2\\) の事前分布を指定するために、Half-Cauchy 分布を使用することができる。Half-Cauchy 分布は、正の値に対してのみ定義され、より重いテールを持つので、このタスクに特に適している。これは、\\(\\tau^2\\) の非常に高い値の可能性は低いけれども、まだ非常に可能性があることを表現するために使うことが可能である。ベイズメタ分析モデルを当てはめる際には、(1) モデルが収束するのに十分な反復回数を含んでいるかどうかを常に確認すること (例えば、\\(\\hat{R}\\) の値を確認するなど)、(2) 異なる事前仕様を用いた感度分析を行って結果に対する影響を評価することが重要である。ベイズメタ分析モデルを当てはめる際には、(1) モデルが収束するのに十分な反復回数を含んでいるかどうかを常に確認すること (例えば、\\(\\hat{R}\\) の値を確認するなど)、(2) 異なる事前仕様を用いた感度分析を行って結果に対する影響を評価することが重要である。","code":""},{"path":"power.html","id":"power","chapter":"14 検出力分析","heading":"14 検出力分析","text":"メ\nタ分析が有用な理由の一つは、不正確な知見を複数組み合わせて、より正確な知見を得ることができるためである。ほとんどの場合、メタ分析は、含まれるどの研究よりも狭い信頼区間を持つ推定値を生成する。これは、真の効果が小さい場合に特に有効である。一次研究では小さな効果の有意性を確認できないだろうが、メタ分析による推定値は、そのような小さな効果が存在することを確認するために必要な統計的検出力を提供できることが多いのである。\nしかし、統計的検出力の不足は、メタ分析においてさえも重要な役割を果たすことがある。多くのメタ分析で含まれる研究の数は少なく、\\(K=\\) 10 件以下であることが多い。例えば、コクランのシステマティックレビューにおける研究の数の中央値は6である (Borenstein et al. 2011)。メタ分析にはサブグループ分析やメタ回帰が含まれることが多く、その場合はさらに検出力が必要となることを考慮すると、この問題はさらに深刻になる。さらに、多くのメタ分析では、研究間の異質性が高い。これもまた全体的な精度を低下させ、結果として統計的検出力を低下させる。統計的検出力の概念については、Chapter 9.2.2.2 ですでに触れ、p-曲線法について学んだ。統計的検出力の背後にある考え方は、古典的な仮説検定に由来している。これは仮説検定で起こりうる2種類のエラーに直接関係している。最初のエラーは、帰無仮説 (\\(\\mu_1 = \\mu_2\\)) が真であるのに、対立仮説 (\\(\\mu_1 \\neq \\mu_2\\) ) を受け入れることである。これは、タイプ または \\(\\alpha\\) エラーとしても知られている。逆に、対立仮説が真であるのに、帰無仮説を受け入れることもある。これは、タイプ II または \\(\\beta\\) エラーとして知られている偽陰性 (false negative) を発生させる。検定の検出力は、\\(\\beta\\) に直接依存し、検出力 = \\(1 - \\beta\\) と定義される。帰無仮説では、2群の平均の間に差がないと仮定し、対立仮説では差 (すなわち「効果」) が存在すると仮定する。統計的検出力は、効果 (つまり、平均値の差) が存在する場合に、検定がそれを検出する確率として定義できる。\\[\\begin{equation}\n\\text{Power} = P(\\text{reject H}_0~|~\\mu_1 \\neq \\mu_2) = 1 - \\beta\n\\tag{14.1}\n\\end{equation}\\]タイプ の誤りはタイプ II の誤りよりも重大であると考えるのが一般的である。したがって、\\(\\alpha\\) レベルは慣習的に 0.05 に設定され、\\(\\beta\\) レベルは0.2に設定されている。つまり、\\(1-\\beta\\) = 1 - 0.2 = 80% という閾値をもたらし、通常、検定の統計的検出力が適切かどうかを決定するのに使われる。研究者が新しい研究を計画するとき、通常、80% の検出力が保証されるサンプルサイズを選択する。真の効果が大きければ、統計的に有意な結果を得ることは容易である。したがって、検出力が 80% に固定されている場合、必要なサンプルサイズは真の効果の大きさにのみ依存する。想定される効果が小さいほど、80% の検出力を確保するために必要なサンプルサイズは大きくなる。一次研究を行う研究者は、発見されると予想される効果量に基づいて、priori に、サンプルのサイズを計画することができる。メタ分析では公表されたものしか扱えないため、状況は異なる。しかし、メタ分析に含める研究の数や種類については、ある程度コントロールすることができる (例えば、より緩やかな、あるいは厳しい包含基準を定義する)。こうすることで、全体の検出力を調整することもできる。メタ分析における統計的検出力に影響を与える要因はいくつかある。対象研究の総数とそのサンプルサイズ。どれくらいの数の研究を見込んでいるのか、またその数は少ないのか多いのか。対象研究の総数とそのサンプルサイズ。どれくらいの数の研究を見込んでいるのか、またその数は少ないのか多いのか。見つけたい効果量。これは特に重要で、効果量がどの程度大きければ意味があるのかを仮定しなければならないことがある。例えば、あるうつ病の介入研究では、SMD = 0.24 という小さい効果でも患者にとって意味がある可能性があると計算されている (Pim Cuijpers et al. 2014)。介入の負の効果 (例えば、死亡や症状の悪化) を研究したい場合、非常に小さな効果量であっても極めて重要であり、検出されるべきものである。見つけたい効果量。これは特に重要で、効果量がどの程度大きければ意味があるのかを仮定しなければならないことがある。例えば、あるうつ病の介入研究では、SMD = 0.24 という小さい効果でも患者にとって意味がある可能性があると計算されている (Pim Cuijpers et al. 2014)。介入の負の効果 (例えば、死亡や症状の悪化) を研究したい場合、非常に小さな効果量であっても極めて重要であり、検出されるべきものである。予想される研究間の異質性。異質性が大きいとメタ分析による推定値の精度と、その結果、有意な効果を見出す可能性にも影響する。予想される研究間の異質性。異質性が大きいとメタ分析による推定値の精度と、その結果、有意な効果を見出す可能性にも影響する。上記以外にも、サブグループ分析など、実施したい分析について考えることも重要である。各サブグループにはどれくらいの研究があるのか？各グループでどのような効果を見出したいのか？\nPost-Hoc 検出力検定: 「検出力の乱用」\n\n検出力分析は、必ず \npriori、つまりメタ分析を実行する前に行わなければならない。\n\n分析の後に行われる検出力分析 (「post hoc 分析」)\nは、深い欠陥のある論理に基づいている (Hoenig Heisey 2001) 。まず、post hoc\nの検出力分析は、一様であり、まだ知らないことは何も教えてくれない。収集したサンプルに基づいて効果が有意でないことがわかったとき、計算された\npost hoc 検出力は、定義上、不十分 (すなわち、50% 以下)\nである。あるテストの post hoc に検出力を計算するとき、単に結果の \\(p\\)\n値に直接リンクしている検出力関数で「遊んで」いるにすぎない。\n\npost-hoc の検出力の推定値には、\\(p\\)\n値がまだ教えてくれていないことはない。すなわち、検定の効果とサンプルサイズに基づいて、検出力が統計的有意性を確認するのに不十分であることを示している。\n\npost hoc に検出力を解釈すると、power approach\nparadox (PAP)\nにもつながる。このパラドックスは、有意な効果をもたらさない分析では、p値が小さいと、帰無仮説が真であるというより多くの証拠を示すと考えられ、真の効果を検出する力が高くなるために生じる。\n","code":""},{"path":"power.html","id":"固定効果モデル","chapter":"14 検出力分析","heading":"14.1 固定効果モデル","text":"固定効果モデルの下でのメタ分析の検出力を決定するために、対立仮説が正しいことを表す分布を指定しなければならない。しかし、これを行うには、単に \\(\\theta \\neq 0\\) (すなわち、何らかの効果が存在する) というだけでは不十分である。十分な検出力 (80%) で検出したい特定の真の効果を仮定しなければならない。例えば、SMD = 0.29 である。効果量をその標準誤差で割ると \\(z\\) スコアになることは、以前すでに取り上げた (Chapter 8.1.2 を参照)。\\(z\\) スコアは、標準正規分布に従う。ここで、\\(|z| \\geq\\) 1.96 という値は、効果がゼロとは有意に異なることを意味する (\\(p<\\) 0.05)。これはまさにメタ分析で達成したいことである。つまり、結果の正確な効果量と標準誤差がどんなに大きくても、\\(|z|\\) の値は少なくとも 1.96 でなければならず、したがって統計的に有意でなければならない。\\[\\begin{equation}\nz  = \\frac{\\theta}{\\sigma_{\\theta}}~~~\\text{}~~~|z| \\geq 1.96.\n\\tag{14.2}\n\\end{equation}\\]プール効果量の標準誤差である \\(\\sigma_{\\theta}\\) (「シグマ・シータ」と読む) の値は、以下の式を用いて計算することができる。\\[\\begin{equation}\n\\sigma_{\\theta}=\\sqrt{\\frac{\\left(\\frac{n_1+n_2}{n_1n_2}\\right)+\\left(\\frac{\\theta^2}{2(n_1+n_2)}\\right)}{K}}\n\\tag{14.3}\n\\end{equation}\\]ここで、\\(n_1\\) と \\(n_2\\) は、ある研究のグループ1とグループ2のサンプルサイズを表し、\\(\\theta\\)は、想定される効果量 (標準化平均差を表している)、\\(K\\) は、メタ分析における研究の総数である。重要なのは、簡略化のため、この式は、両群のサンプルサイズが、含まれるすべての研究において同一であると仮定していることである。この式は、標準化平均差の標準誤差を計算するのに使われる式と非常によく似ているが、1つだけ例外がある。ここで、標準誤差を \\(K\\) で割る。これは、プール効果標準誤差が、メタ分析における研究の総数を表す係数 \\(K\\) によって減少することを意味する。言い換えれば、固定効果モデルを仮定した場合、研究をプールすると、全体効果の精度が \\(K\\)-倍になる72。\\(\\theta\\) を定義し、\\(K\\) を計算した結果、\\(z\\) という値になる。この \\(z\\) スコアは、群サイズ \\(n_1\\) と \\(n_2\\) を持つ \\(K\\) 件の研究がある場合、メタ分析の検出力を得るために使用することができる。\\[\\begin{align}\n\\text{Power} &= 1-\\beta \\notag \\\\\n             &= 1-\\Phi(c_{\\alpha}-z)+\\Phi(-c_{\\alpha}-z) \\notag \\\\\n             &= 1-\\Phi(1.96-z)+\\Phi(-1.96-z). \\tag{14.4}\n\\end{align}\\]ここで、\\(c_{\\alpha}\\) は、指定された \\(\\alpha\\) レベルが与えられたときの、標準正規分布の臨界値である。記号 \\(\\Phi\\) (「ファイ」と読む) は、標準正規分布の累積分布関数 (cumulative distribution function, CDF) である \\(\\Phi(z)\\) を表す。 R では、標準正規分布の CDF は pnorm 関数で実装されている。この公式は、固定効果メタ分析の検出力を計算するために使用できる。\\(K=\\) 10 件の研究があり、両群がそれぞれ約25人の参加者を持つと仮定しよう。SMD = 0.2 の効果を検出できるようにしたい。このようなメタ分析にはどのような検出力があるか？このメタ分析には 10 件の研究が含まれているにもかかわらず、60.6%と検出力不足であることがわかる。固定効果メタ分析の検出力を計算するには、power.analysis 関数を使用する方が便利である。\n“power.analysis” 関数\n\npower.analysis 関数は、{dmetar}\nパッケージに含まれている。{dmetar}\nがインストールされ、コンピュータに読み込まれると、この関数を使用できるようになる。もし、{dmetar}\nをインストールしていない場合は、以下の手順でインストールできる。\n\n関数のソースコードにアクセスする オンライン.\n\nソースコード全体をコンソール (R Studio の左下ペイン)\nにコピー＆ペーストし、Enterキーを押して、 R\nに関数を「学習」させる。\n\n{ggplot2}\nパッケージがインストールされ、ロードされていることを確認する。\npower.analyze 関数は、以下の引数を含む。d. 標準化平均差 (SMD) で表される仮説的な、または妥当な総合効果量。効果量は正の数値でなければならない。d. 標準化平均差 (SMD) で表される仮説的な、または妥当な総合効果量。効果量は正の数値でなければならない。. 治療や介入の効果をコントロールと比較して想定したもので、オッズ比 () で表される。d と の両方が指定された場合、結果は d の値に対してのみ計算される。. 治療や介入の効果をコントロールと比較して想定したもので、オッズ比 () で表される。d と の両方が指定された場合、結果は d の値に対してのみ計算される。k. メタ分析に含まれると予測される研究数。k. メタ分析に含まれると予測される研究数。n1, n2. 対象研究の第1群、第2群における平均サンプルサイズの予測値。n1, n2. 対象研究の第1群、第2群における平均サンプルサイズの予測値。p. 使用するアルファ値。デフォルトは \\(\\alpha\\) =0.05。p. 使用するアルファ値。デフォルトは \\(\\alpha\\) =0.05。heterogeneity. 研究間の異質性のレベル。固定効果モデルで異質性がない場合は \"fixed\"、異質性が低い場合は \"low\"、異質性が中程度の場合は \"moderate\"、異質性が高い場合は \"high\" を指定することができる。デフォルトは \"fixed\"。heterogeneity. 研究間の異質性のレベル。固定効果モデルで異質性がない場合は \"fixed\"、異質性が低い場合は \"low\"、異質性が中程度の場合は \"moderate\"、異質性が高い場合は \"high\" を指定することができる。デフォルトは \"fixed\"。先ほどの例と同じ入力で、この関数を試してみよう。","code":"\n# 仮定条件を定義\ntheta <- 0.2\nK <- 10\nn1 <- 25\nn2 <- 25\n\n# プール効果の標準誤差を計算\nsigma <- sqrt(((n1+n2)/(n1*n2)+(theta^2/(2*n1+n2)))/K)\n\n# z を計算\nz = theta/sigma\n\n# 検出力を計算\n1 - pnorm(1.96-z) + pnorm(-1.96-z)## [1] 0.6059151\nlibrary(dmetar)\npower.analysis(d = 0.2, \n               k = 10, \n               n1 = 25, \n               n2 = 25, \n               p = 0.05)## Fixed-effect model used.## Power: 60.66%"},{"path":"power.html","id":"ランダム効果モデル","chapter":"14 検出力分析","heading":"14.2 ランダム効果モデル","text":"ランダム効果モデルを仮定した検出力分析の場合、研究間の異質性分散 \\(\\tau^2\\) を考慮する必要がある。したがって、標準誤差の適合版、\\(\\sigma^*_{\\theta}\\) を計算する必要がある。\\[\\begin{equation}\n\\sigma^*_{\\theta}=\\sqrt{\\frac{\\left(\\frac{n_1+n_2}{n_1n_2}\\right)+\\left(\\frac{\\theta^2}{2(n_1+n_2)}\\right)+\\tau^2}{K}}\n\\tag{14.5}\n\\end{equation}\\]問題は、\\(\\tau^2\\) の値は、通常、データを見る前にはわからないということである。しかし、Hedges Pigott (2001) は、研究間異質性が低い、中程度、高い場合にモデル化するために使用することができるガイドラインを提供している。低い異質性:\\[\\begin{equation}\n\\sigma^*_{\\theta} = \\sqrt{1.33\\times\\dfrac{\\sigma^2_{\\theta}}{K}}\n\\tag{14.6}\n\\end{equation}\\]中程度の異質性:\\[\\begin{equation}\n\\sigma^*_{\\theta} = \\sqrt{1.67\\times\\dfrac{\\sigma^2_{\\theta}}{K}}\n\\tag{14.7}\n\\end{equation}\\]高い異質性:\\[\\begin{equation}\n\\sigma^*_{\\theta} = \\sqrt{2\\times\\dfrac{\\sigma^2_{\\theta}}{K}}\n\\tag{14.8}\n\\end{equation}\\]また、power.analyze 関数はランダム効果メタ分析に使用することができる。異質性引数 heterogeneity を用いて、想定される研究間の異質性の大きさを制御することができる。設定可能な値は \"low\"、\"moderate\"、\"high\" である。前の例と同じ値を用いて、研究間の異質性が中程度の場合の期待検出力を計算してみよう。推定された検出力は 40.76% であることがわかる。これは、標準的な 80% の閾値よりも低い値である。また、固定効果モデルを仮定した場合の 60.66% よりも低くなっている。これは、研究間の異質性がプール効果の推定値の精度を低下させ、その結果、統計的検出力が低下するためである。Figure 14.1 は、 真の効果量、研究数、研究間の異質性の量がメタ分析の検出力に及ぼす影響を可視化している73。\nFigure 14.1: ランダム効果メタアナリシスの検出力 (各研究 \\(n\\)=50)。色が濃いほど、研究間の異質性が高い。\n","code":"\npower.analysis(d = 0.2, \n               k = 10, \n               n1 = 25, \n               n2 = 25, \n               p = 0.05,\n               heterogeneity = \"moderate\")## Random-effects model used (moderate heterogeneity assumed). \n## Power: 40.76%"},{"path":"power.html","id":"power-subgroup","chapter":"14 検出力分析","heading":"14.3 サブグループ解析","text":"サブグループ分析を計画する際、自由に使える研究数がある場合、2群間の差がどの程度大きければ検出できるかを知ることが重要になることがある。これは、サブグループの差のための検出力分析を適用できる条件である。 R では、Hedges Pigott (2004) のアプローチを実装した power.analysis.subgroup 関数を用いてサブグループの検出力分析を行うことができる。\npower.analysis.subgroup 関数\n\npower.analysis.subgroup\n関数は、{dmetar}\nパッケージに含まれている。{dmetar}\nがインストールされ、コンピュータに読み込まれると、この関数を使用できるようになる。もし、{dmetar}\nをインストールしていない場合は、以下の手順でインストールできる。\n\n関数のソースコードにアクセスする オンライン.\n\nソースコード全体をコンソール (R Studio の左下ペイン)\nにコピー＆ペーストし、Enterキーを押して、 R\nに関数を「学習」させる。\n\n{ggplot2}\nパッケージがインストールされ、ロードされていることを確認する。\nグループ１の効果は SMD = 0.3、標準誤差は 0.13 であり、グループ２の効果は SMD = 0.66、標準誤差は 0.14 であると仮定しよう。これらの仮定条件を関数の呼び出しの入力として使用することができる。この出力では、想像上のサブグループ検定の検出力 (47%) が十分でないことがわかる。出力は、他のすべてが同じで、十分な検出力に達するには、効果量の差が少なくとも 0.54 である必要があることも教えてくれる。\\[\\tag*{$\\blacksquare$}\\]","code":"\npower.analysis.subgroup(TE1 = 0.30, TE2 = 0.66, \n                        seTE1 = 0.13, seTE2 = 0.14)## Minimum effect size difference needed for sufficient power: 0.536 (input: 0.36)\n## Power for subgroup difference test (two-tailed): 46.99%"},{"path":"risk-of-bias-plots.html","id":"risk-of-bias-plots","chapter":"15 バイアスリスクのプロット","heading":"15 バイアスリスクのプロット","text":"Luke . McGuinness によるこの章を引用する場合はこ\nの章では、 {robvis} パッケージを使用して、 R でRisk Bias プロットを作成する方法について説明する。","code":""},{"path":"risk-of-bias-plots.html","id":"イントロダクション","chapter":"15 バイアスリスクのプロット","heading":"15.1 イントロダクション","text":"システマティックレビューやメタ分析の一環として、関連する領域別バイアスリスク評価ツールを用いて、含まれる研究の内部妥当性 (バイアスリスク、Risk Bias) を調べ、この評価結果をグラフで提示すとよいだろう。コクランハンドブックでは、2種類の図を推奨している。各ドメイン内で所定のバイアスリスク判定を受けた研究の割合を示す要約棒グラフと、各研究のドメインレベルの判定を提示す交通信号プロット (Traffic Light Plot、今のところ定着した日本語訳はない) である。しかし、これらの図を作成する際に、研究者が利用できる選択肢は限られている。RevMan にはプロットを作成する機能があるが、多くの研究者はシステマティックレビューを行うために RevMan を使用していないため、関連データをシステムにコピーする解決方法は非効率的である。同様に、MS PowerPoint などのソフトウェアを使用して手作業でグラフを作成するのは時間がかかり、変更が必要な場合は手作業で図を更新しなければならない。さらに、ジャーナルは通常、出版品質 (300-400 dpi 以上) の図を要求するが、RevMan からバイアスリスクの図をエクスポートしたり、手作業で作成したりする場合、品質を維持するのが難しい場合がある。\nFigure 15.1: Example RevMan output.\nこのようなことを避けるために、バイアスリスク評価の要約表を要約プロットまたは交通信号プロットに変換する関数を提供する {robvis} パッケージ (McGuinness Higgins 2020; McGuinness 2019) を使用して、R Studio 内でバイアスリスク数値を自分で簡単にプロットできるようになる。","code":""},{"path":"risk-of-bias-plots.html","id":"robvis-を読み込む","chapter":"15 バイアスリスクのプロット","heading":"15.1.1 {robvis} を読み込む","text":"すでに {dmetar} パッケージがインストールされていると仮定して (Chapter 2.3 参照)、{robvis} パッケージを使用しロードする。","code":"\nlibrary(robvis)"},{"path":"risk-of-bias-plots.html","id":"バイアスリスクの要約表データをインポート","chapter":"15 バイアスリスクのプロット","heading":"15.1.2 バイアスリスクの要約表データをインポート","text":"プロットを作成するために、まず、Excel から R にバイアスリスク評価の結果をインポートする必要がある。なお、{robvis} はデータ作成方法について指定があり、Excel で表を設定する際には以下のガイダンスに必ず従わなければならない。最初の列名は “Study” とし、研究識別子を記述する (例: Anthony et al, 2019)。最後から2番目の列名は “Overall” とする。全体のリスクオブバイアス判定を記載する。最後の列名は “Weight” とし、研究の精度の指標 (例えば、メタ分析で各研究に割り当てられた重み、またはメタ分析が行われなかった場合は、各研究のサンプルサイズ) を記述する。詳しくは、Chapter 4.1.1 を参照。その他の列は、特定のドメインのバイアスリスク評価結果を含む。上記のガイダンスを詳しく説明するために、5つのドメインを持つ ROB2 ツールを例として考えてみよう。このツールで {robvis} が期待する結果のデータセットは8列である。列 1. 試験の識別子列 2-6. 1列につき1つの RoB2 ドメイン列 7. 総合的なリスクオブバイアス判定列 8. 重みExcel では、このバイアスリスクの要約表は次のようになる。\n列の名前\n\n４種類あるうちの３種類のテンプレート (ROB2, ROBINS-, QUADAS-2)\nでは、ドメインレベル判定を含む列の名前は重要ではない。robvis\n内のテンプレートが各ドメインを正しく修正する。\nExcel で作成した表をカンマ区切りファイル (例: “robdata.csv”) として作業ディレクトリに保存し、以下のコマンドを使用してプログラム的にそのファイルを R に読み込むか、Chapter 2.4 で説明したインポート機能を使用して読み込むことができる。","code":"\nmy_rob_data <- read.csv(\"robdata.csv\", header = TRUE)"},{"path":"risk-of-bias-plots.html","id":"テンプレート","chapter":"15 バイアスリスクのプロット","heading":"15.1.3 テンプレート","text":"{robvis} は、使用したバイアスリスク評価ツールに固有のテンプレート図を入力するために、提供されたデータを使用してバイアスリスク図を作成する。現在、{robvis} には、以下の3つのツールのテンプレートが含まれている。ROB2 は、ランダム化比較試験のための新しい Cochrane の Risk Bias ツール。ROBINS-は、Risk Bias Non-randomized Studies Interventions (ランダム化されていない介入研究におけるバイアスのリスク) ツール。QUADAS-2 は、Quality Applicability Diagnostic Accuracy Studies, Version 2。{robvis} には、ROB1 とラベル付けされた特別な汎用テンプレートも含まれている。ランダム化対照試験用の Cochrane risk bias ツールで使用するために設計されているが、上記のリストに含まれていない他のドメインベースのツールで実行された評価結果を可視化するために使用することも可能である。このテンプレートを使用する際に必要な追加ステップの詳細については、Chapter 15.4 を参照。","code":""},{"path":"risk-of-bias-plots.html","id":"データセット例","chapter":"15 バイアスリスクのプロット","heading":"15.1.4 データセット例","text":"{robvis} パッケージには、上記の各テンプレートに対応したデータセット例が格納されている。これらは以下のオブジェクトに格納されている。data_rob2 :ROB2 ツールのデータ例data_robins :ROBINS-ツールのデータ例data_quadas :QUADAS-2 ツール用のサンプルデータdata_rob1 :RoB-1 ツール用のサンプルデータデータセットは glimpse 関数を用いて探索することができる (Chapter 2.5.1 参照)。例えば、library(robvis) を用いてパッケージをロードしたら、以下のコマンドを実行して ROBINS-のサンプルデータセットを閲覧してみよう。このサンプルデータセットを、このガイドの残りの部分で提示されるプロットを作成するために使用する。","code":"\nglimpse(data_robins)## Rows: 12\n## Columns: 10\n## $ Study   <fct> Study 1, Study 2, Study 3, Study 4, Study 5, Study 6, Study 7,…\n## $ D1      <fct> Critical, Moderate, Moderate, Low, Serious, Critical, Critical…\n## $ D2      <fct> Low, Low, Low, Low, Serious, Serious, Moderate, Moderate, Low,…\n## $ D3      <fct> Critical, Low, Moderate, Serious, Low, Moderate, Moderate, Low…\n## $ D4      <fct> Critical, Critical, Critical, Critical, Low, Critical, Serious…\n## $ D5      <fct> Low, Low, Critical, Moderate, Moderate, Critical, Critical, Lo…\n## $ D6      <fct> Low, Moderate, Low, Low, Low, Moderate, Serious, Low, Serious,…\n## $ D7      <fct> Serious, Low, Serious, Critical, Moderate, Serious, Serious, C…\n## $ Overall <fct> Critical, Low, Serious, Low, Serious, Serious, Moderate, Moder…\n## $ Weight  <dbl> 33.3333333, 33.3333333, 0.1428571, 9.0909091, 12.5000000, 25.0…"},{"path":"risk-of-bias-plots.html","id":"要約プロット","chapter":"15 バイアスリスクのプロット","heading":"15.2 要約プロット","text":"","code":""},{"path":"risk-of-bias-plots.html","id":"基本情報","chapter":"15 バイアスリスクのプロット","heading":"15.2.1 基本情報","text":"R にバイアスリスク要約表をインポートしたら、バイアスリスク図の作成は非常に簡単である。まず始めに、ROB2 サンプルデータセット (data_rob2) を用いた単純な重み付き要約棒グラフを、以下のコードを実行して作成する。","code":"\nrob_summary(data = data_rob2, \n            tool = \"ROB2\")"},{"path":"risk-of-bias-plots.html","id":"プロットを修正","chapter":"15 バイアスリスクのプロット","heading":"15.2.2 プロットを修正","text":"rob_summary 関数には以下のパラメータがある。data. 要約 (ドメイン) レベルの risk--bias 評価を含むデータフレーム。最初の列は研究の詳細、2 番目の列は評価の最初のドメイン、最後の列は各研究に割り当てる重み付けを含む。この関数は、データに全体的なリスクオブバイアスの列が含まれていることを想定している。例えば、ROB2.0 のデータセットでは、8列 (研究の詳細1、ドメインレベルの判定5、総合判定1、重み付け1の順) となる。tool. 使用したバイアスリスク評価ツール。現在、RoB2.0 (\"ROB2\")、\"ROBINS-\"、\"QUADAS-2\" がサポートされている。overall. 図に全体の Risk Bias を示す追加のバーを含めるかどうかのオプション。デフォルトは FALSE である。weighted. 棒グラフに重みをつけるかどうかを指定するオプション。デフォルトは TRUE で、現在の Cochrane Collaboration のガイダンスに沿ったものである。colour. プロットの配色を指定するための引数である。デフォルトは \"cochrane\" で、普遍的なコクランカラーを使用する。また、色覚異常者に優しいパレットのプリセットオプションも利用できる (colour = \"colourblind\")。quiet. プロットを表示せず、静かに生成するための論理オプション。デフォルトは FALSE。各引数の機能例を以下に示す。","code":""},{"path":"risk-of-bias-plots.html","id":"tool","chapter":"15 バイアスリスクのプロット","heading":"15.2.2.1 tool","text":"tool は、使用するツールテンプレートを定義するための引数である。上の例では、ROB2 テンプレートが使用されている。他の2つの主要なテンプレート、ROBINS-と QUADAS-2 テンプレートは、以下に示されている。","code":"\nrob_summary(data = data_robins, \n            tool = \"ROBINS-I\")\nrob_summary(data = data_quadas, \n            tool = \"QUADAS-2\")"},{"path":"risk-of-bias-plots.html","id":"overall","chapter":"15 バイアスリスクのプロット","heading":"15.2.2.2 overall","text":"デフォルトでは、全体の Risk Bias 判定を表す追加のバーはプロットに含まれない。これを含めたい場合は、overall = TRUE と設定する。例えば","code":"\nrob_summary(data = data_rob2, \n            tool = \"ROB2\", \n            overall = TRUE)"},{"path":"risk-of-bias-plots.html","id":"重み付けのある棒グラフとない棒グラフ","chapter":"15 バイアスリスクのプロット","heading":"15.2.2.3 重み付けのある棒グラフとない棒グラフ","text":"デフォルトでは、棒グラフは研究の精度の指標で重み付けされ、特定のバイアスのリスクがある研究の割合ではなく、情報の割合を示すようになる。このアプローチは、Cochrane Handbookに沿っている。このオプションをオフにするには、weighted = FALSE と設定し、重み付けしない棒グラフを作成する。例えば、次の2つのプロットを比較してみてみよう。","code":"\nrob_summary(data = data_rob2, \n            tool = \"ROB2\")\nrob_summary(data = data_rob2, \n            tool = \"ROB2\",\n            weighted = FALSE)"},{"path":"risk-of-bias-plots.html","id":"カラースキーム","chapter":"15 バイアスリスクのプロット","heading":"15.2.2.4 カラースキーム","text":"イギリス英語両プロット関数の colour 引数は、2つの定義済みカラースキーム、\"cochrane\" (デフォルト) または \"colourblind\" から選択するか、あるいは hex code のベクトルを与えて自分自身のパレットを定義することが可能である。例えば、定義済みの \"colourblind\" パレットを使用するため、以下のようにする。自分だけのカラースキームを決めることもできる。独自のカラースキームを定義する場合、離散判定 (例: 「低」、「中」、「高」、「重要」) の数と指定する色の数が同じであることを確認する必要がある。さらに、色はバイアスのリスクの昇順 (例: 「Low」～「Critical」) で指定する必要があり、最初の16進数はバイアスのリスクが “Low” に対応する。","code":"\nrob_summary(data = data_rob2, \n            tool = \"ROB2\", \n            colour = \"colourblind\")\nrob_summary(data = data_rob2, \n            tool = \"ROB2\", \n            colour = c(\"#f442c8\",\"#bef441\",\"#000000\"))"},{"path":"risk-of-bias-plots.html","id":"交通信号プロット","chapter":"15 バイアスリスクのプロット","heading":"15.3 交通信号プロット","text":"研究者は、評価した各研究の各領域におけるバイアスのリスクを提示したいと思うことがよくある。このプロットは一般的に交通信号プロットと呼ばれ、{robvis} の rob_traffic_light 関数で作成することができる。","code":""},{"path":"risk-of-bias-plots.html","id":"基本情報-1","chapter":"15 バイアスリスクのプロット","heading":"15.3.1 基本情報","text":"まず、ROB2 サンプルデータセット( data_rob2 )を用いた交通信号プロットを、以下のコードを実行して作成した。","code":"\nrob_traffic_light(data = data_rob2, \n                  tool = \"ROB2\")"},{"path":"risk-of-bias-plots.html","id":"プロットを修正-1","chapter":"15 バイアスリスクのプロット","heading":"15.3.2 プロットを修正","text":"rob_summary 関数には以下のパラメータがある。data. 要約 (ドメイン) レベルの risk--bias 評価を含むデータフレーム。最初の列は研究の詳細、2 番目の列は評価の最初のドメイン、最後の列は各研究に割り当てる重み付けを含む。この関数は、データに全体的なリスク・オブ・バイアスの列が含まれていることを想定している。例えば、ROB2.0のデータセットでは、8列 (研究の詳細1、ドメインレベルの判断5、総合判断1、重み1、この順) となる。tool. 使用したバイアスリスク評価ツール。現在、RoB2.0 (\"ROB2\")、\"ROBINS-\"、\"QUADAS-2\" がサポートされている。colour. プロットの配色を指定するための引数である。デフォルトは \"cochrane\" で、どこにでもあるコクランカラーを使用する。また、色覚異常者に優しいパレット (\"colourblind\")のプリセットオプションも利用できる。psize.「交通信号」ポイントの大きさを変更するためのオプション。デフォルトは 20。quiet. プロットを表示せず、静かに生成するための論理オプション。デフォルトは FALSE。","code":""},{"path":"risk-of-bias-plots.html","id":"ツール","chapter":"15 バイアスリスクのプロット","heading":"15.3.2.1 ツール","text":"使用するツールテンプレートを定義するための引数である。ROB2 テンプレートのデモと、他の2つの主要テンプレートである ROBINS-と QUADAS-2 テンプレートを以下に表示する。","code":"\nrob_traffic_light(data = data_robins, \n                  tool = \"ROBINS-I\")\nrob_traffic_light(data = data_quadas, \n                  tool = \"QUADAS-2\")"},{"path":"risk-of-bias-plots.html","id":"カラースキーム-1","chapter":"15 バイアスリスクのプロット","heading":"15.3.2.2 カラースキーム","text":"イギリス英語両プロット関数の colour 引数は、2つの定義済み配色 \"cochrane\" (デフォルト) と \"colourblind\" から選択することができる。例えば、定義済みの \"colourblind\" パレットを使用する場合。自分だけのカラースキームを決めることもできる。独自のカラースキームを定義する場合、離散判定 (例: “Low”、“Moderate”、“High”、“Critical”) の数と指定する色の数が同じであることを確認する必要がある。さらに、色はバイアスのリスクの昇順 (例: “Low”～“Critical”) で指定する必要があり、最初の16進数はバイアスのリスクが “Low” の色に対応する。","code":"\nrob_traffic_light(data = data_rob2, \n                  tool = \"ROB2\", \n                  colour = \"colourblind\")\nrob_traffic_light(data = data_rob2, \n                  tool = \"ROB2\", \n                  colour = c(\"#f442c8\",\"#bef441\",\"#000000\"))"},{"path":"risk-of-bias-plots.html","id":"ポイントサイズ","chapter":"15 バイアスリスクのプロット","heading":"15.3.2.3 ポイントサイズ","text":"多数のバイアスリスク評価を実施した場合、結果の交通信号プロットが長すぎて役に立たないこともある。このような場合には、rob_traffic_light 関数の psize 引数を小さくすることで対応できる (デフォルトは 20)。例えば","code":"\n# Create bigger dataset (18 studies)\nnew_rob2_data <- rbind(data_rob2, data_rob2)\nnew_rob2_data$Study <- paste(\"Study\", seq(1:length(new_rob2_data$Study))) \n\n# Plot bigger dataset, reducing the psize argument from 20 to 8\nrob_traffic_light(data = new_rob2_data, \n                  tool = \"ROB2\", \n                  psize = 8)"},{"path":"risk-of-bias-plots.html","id":"rob1-template","chapter":"15 バイアスリスクのプロット","heading":"15.4 “ROB1” ジェネリックテンプレート","text":"","code":""},{"path":"risk-of-bias-plots.html","id":"モチベーション","chapter":"15 バイアスリスクのプロット","heading":"15.4.1 モチベーション","text":"このテンプレートは、プロットに含まれるドメインの柔軟性を高めている。任意の数のドメインを扱うことができ (ドメインの数が設定されている他のツールテンプレートを参照)、結果の図ではユーザー定義の列見出しをドメインのタイトルとして使用する。","code":""},{"path":"risk-of-bias-plots.html","id":"ドメイン数の違い","chapter":"15 バイアスリスクのプロット","heading":"15.4.2 ドメイン数の違い","text":"“ROB1” テンプレート ( tool = \"ROB1\" ) は、さまざまな数の列を扱うことができる。これはもともとROB1アセスメントツールで使用するために設計されたが、頻繁にドメインが追加または削除されるようになった。このテンプレートは他のツール (ROB2、QUADAS-2、ROBINS-) の調整版を使用して行われた評価の結果を提示すために使用できるが、これは勧めない。他の公表されているツールを使用する著者は、ガイダンスに適合することを確実にするために、前の章で示されたより厳格なテンプレートを使用する必要がある。","code":""},{"path":"risk-of-bias-plots.html","id":"ドメイン名","chapter":"15 バイアスリスクのプロット","heading":"15.4.3 ドメイン名","text":"前のセクションで挙げた他のツールでは、ドメインレベルのバイアスリスク判定を含む列の名称は重要ではない。例えば、 D1 、 D2 、 D3 などの名前が一般的である。しかし、\"ROB1\" テンプレートを使用する場合は、この限りではない。data_rob2 と data_rob1 の列見出しを比較する (ここでは比較しやすいように横向きで表示している)。\nTable 15.1: データセット data_rob2 (左) data_rob1 (右) における列名の比較。\nROB2 サンプルデータセットのドメイン列 (列 2-6) には、 D1 ～ D5 という任意の名前が付けられているが、これは ROB2 ガイダンスで与えられた正しいドメインタイトルに対応するようにツールで上書きされるためである。一方、ROB1 サンプルデータセットのドメイン列 (列 2-8) は、rob_summary と rob_traffic_light が生成する図に使用されるため、正しくラベル付けされていることがわかる。例として、“Random.sequence.generation” 列の名前を “これはテスト” に変更してみよう。rob_summary 図では、最初のバーのタイトルが変更され、rob_traffic_light 図では、この変更を反映してキャプションが更新されている。","code":"\n# data_rob1 データセットのコピーを作成\nnew_rob1_data <- data_rob1\n\n# 最初のドメインの列名を変更\ncolnames(new_rob1_data)[2] <- \"これはテスト\"\n\n# 要約棒グラフを作成; macOS では文字化けするためフォント (ただし y 軸が追加されてしまう) \nrob_summary(data = new_rob1_data, tool = \"ROB1\") +\n  theme_classic(base_family = \"Hiragino Kaku Gothic Pro W3\")\n# 交通信号プロットを作成\nrob_traffic_light(data = new_rob1_data, \n                  tool = \"ROB1\")"},{"path":"risk-of-bias-plots.html","id":"カスタマイズと保存","chapter":"15 バイアスリスクのプロット","heading":"15.5 カスタマイズと保存","text":"","code":""},{"path":"risk-of-bias-plots.html","id":"ggplot2-パッケージ","chapter":"15 バイアスリスクのプロット","heading":"15.5.1 {ggplot2} パッケージ","text":"{robvis} 関数 (rob_summary と rob_traffic_light) は共に ggplot オブジェクトを生成するので、{ggplot2} パッケージの関数を使用してカスタマイズしたり保存したりすることができる。このパッケージを読み込むには、次のコードを使用する。","code":"\nlibrary(ggplot2)"},{"path":"risk-of-bias-plots.html","id":"プロットの修正","chapter":"15 バイアスリスクのプロット","heading":"15.5.2 プロットの修正","text":"プロットには、{ggplot2} 関数を使ってポストプロダクションで行うことができる様々な修正がある。便利な例は、プロットにタイトルを追加することである。","code":"\n# 事前に ggplot2 がインストールされ、ロードされていること\nrob_summary(data_rob2, \"ROB2\") +\n  ggtitle(\"Your custom title\")"},{"path":"risk-of-bias-plots.html","id":"プロットの保存","chapter":"15 バイアスリスクのプロット","heading":"15.5.3 プロットの保存","text":"バイアスのリスクのプロットを保存するために、まず <- 演算子を用いてオブジェクトに割り当て、次に {ggplot2} パッケージの ggsave 関数を用いて保存する。要約棒グラフを保存する際は、高さと幅をデフォルト値にして、以下のコードを使用することを勧める。交通信号プロットも、保存する方法は同じである。しかし、width と height パラメータの最適な値は、含まれる研究の数や名前が変わると、プロットごとに異なるため、推奨値はない。","code":"\n# プロットを作成し、オブジェクトに格納\nrob_barplot <- rob_summary(data_rob2, \"ROB2\")\n\n# プロットを保存\nggsave(plot = rob_barplot,        # 保存するオブジェクト\n       filename = \"robplot2.png\", # 保存先\n       width = 8,                 # 画像の幅 (推奨値) \n       height = 2.41,             # 画像の高さ (推奨値) \n       dpi = 1000)                # 画像の解像度"},{"path":"risk-of-bias-plots.html","id":"異なるフォーマットで保存","chapter":"15 バイアスリスクのプロット","heading":"15.5.4 異なるフォーマットで保存","text":"プロットは、ファイル名の拡張子を変えるだけで (例えば “.png” から “.pdf” に)、上記の関数を使って様々なフォーマットで保存することが可能である。使用可能なフォーマットは .png、.pdf、.tiff、.svg74 である。例えば、上で作成した棒グラフ (rob_barplot) を PDF として保存するには、以下のようにする。","code":"\n# プロットを保存\nggsave(plot = rob_barplot,                  \n       filename = \"robplot2.pdf\", # 拡張子を \".pdf\"\n       width = 8,                           \n       height = 2.41,                       \n       dpi = 1000)"},{"path":"risk-of-bias-plots.html","id":"ウェブアプリ","chapter":"15 バイアスリスクのプロット","heading":"15.6 ウェブアプリ","text":"robvis の機能を手軽に体験してもらうために、{robvis} パッケージのグラフィカルなインターフェースを提供する Web アプリケーションを作成した。ウェブアプリはこちらで公開されている。以下に、簡単なガイド付きウォークスルーを紹介する。","code":""},{"path":"risk-of-bias-plots.html","id":"ランディングページ","chapter":"15 バイアスリスクのプロット","heading":"15.6.1 ランディングページ","text":"このページでは、前の章で紹介したガイダンスの簡潔版、特にデータセットのセットアップについて紹介した。さらに重要なのは、各ツールのサンプルデータセットを CSV ファイルとしてダウンロードし、アプリとの対話や機能探索に利用できることである。","code":""},{"path":"risk-of-bias-plots.html","id":"交通信号プロットページ","chapter":"15 バイアスリスクのプロット","heading":"15.6.2 交通信号プロットページ","text":"2番目のタブをクリックすると、以下の画面が表示される。このメニューは rob_traffic_light 関数のグラフィカルインターフェイスとして機能する。“Browse…” をクリックし、CSV ファイルを保存した場所に移動して、バイアスリスクの要約表をアップロードした。ドロップダウン・ボックスを使用して、バイアス・リスクの評価を行うために使用するツールを選択する。基本的な交通信号のプロットがウィンドウの右側に表示されるはずである。以下のオプションを使ってプロットをカスタマイズすることができる。使用する配色を選択してみよう (“Cochrane” または “Colour-blind friendly” のいずれか)ポイントサイズの変更 (1つの交通信号プロット上に多数の研究をプロットしたい場合に有効)文字サイズの変更プロットが完成したら、必要な形式 (.png, .jpg, .tiff, .eps) を選んで “Download plot” ボタンをクリックすれば、プロットをダウンロードすることができる。最初に形式を選択しないと、ダウンロードエラーになる。","code":""},{"path":"risk-of-bias-plots.html","id":"要約プロットページ","chapter":"15 バイアスリスクのプロット","heading":"15.6.3 要約プロットページ","text":"3番目のタブをクリックすると、以下の画面が表示される。このメニューは rob_summary 関数のグラフィカルインターフェイスとして機能する。“Browse…” をクリックし、CSV ファイルを保存した場所に移動して、バイアスリスクの要約表をアップロードする。ドロップダウン・ボックスを使用して、バイアス・リスクの評価を行うために使用するツールを選択する。基本的な加重要約棒グラフがウィンドウの右側に表示されるはずである。以下のオプションを使用して、プロットをカスタマイズすることができる。図形の作成時にウェイトを使用するかどうかを選択することができる。バイアス判定全体のリスク分布を表す棒グラフを追加してみよう。使用する配色を選択してみよう (“Cochrane” または “Colour-blind friendly” のいずれか)交通信号プロットタブと同様に、必要なフォーマットを選択し、“Download plot” ボタンをクリックすると、プロットをダウンロードすることができる。\\[\\tag*{$\\blacksquare$}\\]","code":""},{"path":"reporting-reproducibility.html","id":"reporting-reproducibility","chapter":"16 報告と再現性","heading":"16 報告と再現性","text":"こ\nれまでの章では、 R でメタ分析を行うために使用できる様々なテクニック、アプローチ、戦略について説明してきた。しかし、統計解析の実行は、実際にはメタ分析「プロセス」全体のごく一部の割合を占めるに過ぎない。「現場」では、以下のような「事件」が発生する。R のコードにエラーが見つかったため、解析の一部を変更してやり直さなければならない。R のコードにエラーが見つかったため、解析の一部を変更してやり直さなければならない。共同研究者や査読者は、別のアプローチやモデルの使用、あるいは追加の感度分析を行うことを提案している。共同研究者や査読者は、別のアプローチやモデルの使用、あるいは追加の感度分析を行うことを提案している。分析作業の一部を共同研究者の一人に委任する必要があり、現在の作業状況を送らなければならない。分析作業の一部を共同研究者の一人に委任する必要があり、現在の作業状況を送らなければならない。プロジェクトをしばらく中断していたため、再開するころにはいろいろなことを忘れてしまっている。プロジェクトをしばらく中断していたため、再開するころにはいろいろなことを忘れてしまっている。解析結果をプロジェクトの共同研究者と共有したいが、共同研究者は R を知らず、R Studio はインストールすらされていない。解析結果をプロジェクトの共同研究者と共有したいが、共同研究者は R を知らず、R Studio はインストールすらされていない。これらはほんの一部のシナリオであるが、 R でメタ分析を行う際の再現可能なワークフローが、あなたや一緒に働く人々にとって有益であることを説明している。また、再現性を目指すことは、オープンサイエンスの実践の基礎でもある。完全に再現可能なメタ分析は、私たちがどのように結果に至ったかを他の人に可能な限り明らかにするものである。\nR Studio は、再現性のあるワークフローを作成し、協力を得るために最適なツールである。本章では、分析の再現、報告、普及のための3つのツールを紹介する R Projects、R Markdown および Open Science Framework である。","code":""},{"path":"reporting-reproducibility.html","id":"r-project-の利用","chapter":"16 報告と再現性","heading":"16.1 R Project の利用","text":"解析を始めるには、まずR Studioで R Project を立ち上げるのがよいだろう R Projectは、コンピュータ上のフォルダーに新しい環境を作成する。このフォルダには、分析に必要なすべてのデータと R コードが保存される R Project で分析を行うということは、作成したすべてのオブジェクトが Project 環境に一時的に保存され、次に開いたときにアクセスできるようになることを意味する。新しい R Project を作成するには、R Studio ウィンドウの右上にある R Project フィールドをクリックし、ドロップダウンメニューから New Project… を選択する。次に、コンピュータ上に新しいフォルダである New Directory を作成する。これがプロジェクトの作業ディレクトリとなる。そして、New Project をクリックする。新しいプロジェクトに「Meta-Anallysis Project」という名前をつける。プロジェクトフォルダは、~Documents/R に格納される。プロジェクトの作成をクリックすると、 R Project が設定される。 R Project の大きな特徴は、参照したいファイルへの絶対パスを使用する必要がないことである。ファイル名、またはファイルが (サブ) フォルダーにある場合は、フォルダー名とファイル名だけを使用する。例えば、データセット data.xlsx をサブフォルダー “data” に格納する。{openxlsx} パッケージ (Chapter 2.4) を使用すると、相対パスでデータセットをインポートすることができる。","code":"\nread_excel(\"data/data.xlsx\")"},{"path":"reporting-reproducibility.html","id":"r-markdown-で再現性のあるレポートを作成","chapter":"16 報告と再現性","heading":"16.2 R Markdown で再現性のあるレポートを作成","text":"Markdown はテキストフォーマットのためのシンプルなマークアップ言語である。R Markdown (Xie, Allaire, Grolemund 2018)は Markdown の拡張機能で、プレーンテキスト、 R コード、 R 出力を1つのドキュメントに簡単にまとめることができるようになっている。このため、R Markdown は非常に便利なレポート作成ツールとなっている。R Markdown を使用すると、分析で使用したすべてのコード、コードによって生成された出力を含む HTML または PDF ファイルを作成でき、各分析ステップで行ったことに関する詳細な情報を追加することが可能にある。R Markdown ファイルを R Studio で構築するのはとても簡単である。R Studio ウィンドウの左上隅にある、緑色の「プラス」記号のついた白いシンボルをクリックすればよいのである。そして、ドロップダウンメニューから、R Markdown… をクリックする。新しい R Markdown ドキュメントの名前を定義すると、R Studio ウィンドウの左上隅にポップアップ表示されるはずである。このファイルには、すでにいくつかの例示的な内容が含まれているが、最初の6行を除いて削除することが可能である。この部分はいわゆる YAML ヘッダーである。これは、ドキュメントのタイトル、著者、日付、エクスポート形式を記述する。出力形式は html_document を選択した。これはドキュメントがレンダリングされると HTML ページとしてエクスポートされることを意味している。R Markdown　ドキュメント はすべて、2つの部分から構成されている。 普通の Markdown テキスト、そして、グレーで示されたいわゆる R チャンクである。R Markdown ドキュメントのテキスト部分がどのようにフォーマットされるかについては詳しく説明しない。オンラインの cheat sheet は、Markdown 構文を学び始める素晴らしいリソースである (20分程度で読むことができる)。一方、 R コードのチャンクは、通常コンソールに入力するコードを含んでいるだけである。ドキュメントの右上にある Insert フィールドをクリックすることで、新しいコードチャンクを追加することができる。各チャンクの上にある小さな緑の三角形をクリックし、コードを実行することができる。文書を書き終えたら、左上の編み目のマークをクリックして、HTML、PDF、MS Word 文書として書き出すことができる。これにより、すべてのテキスト、コード、出力を含む文書がレンダリングされ、定義されたフォーマットでエクスポートされる。最終的な文書は、自動的にプロジェクトフォルダに保存される。","code":"---\ntitle: \"Analysis\"\nauthor: \"Author Name\"\ndate: \"10/16/2020\"\noutput: html_document\n---"},{"path":"reporting-reproducibility.html","id":"osf","chapter":"16 報告と再現性","heading":"16.3 OSF レポジトリ","text":"オープンサイエンス・フレームワーク (Open Science Framework, OSF) は、研究におけるコラボレーションと再現性を促進するためのオープンソースのオンラインプラットフォームである。OSF にはオンラインリポジトリがあり、研究者が研究資料を預けて共同研究を行い、研究プロセスのすべてのステップを (より) 透明化することが可能である。OSF は、過去10年間に大きな勢いを得たオープンサイエンス運動の急先鋒である。すべてのメタ分析者は、収集したデータと分析に使用した R コードにオープンアクセスすることで、研究と分析プロセスを一般に公開することが推奨される。OSFはこれを行うための素晴らしいツールである。自分で作成したすべてのリポジトリは、デフォルトで非公開になっており、いつ、何を公開するかは、あなた次第なのである。以下では、 R で OSF リポジトリを設定する方法、ファイルのアップロードとダウンロード、共同研究者を追加する方法を紹介する。","code":""},{"path":"reporting-reproducibility.html","id":"アクセストークン","chapter":"16 報告と再現性","heading":"16.3.1 アクセス・トークン","text":"OSF を使い始めるには、まずウェブサイトで個人アカウントを作成する必要がある。アカウントが作成されたら、 R を使って直接リポジトリを操作できるように、アクセストークンを生成する必要がある。アクセストークンを取得するには、Profile > Settings > Personal access tokens に移動する必要がある。そこで、Create token をクリックする。次に、Scopes の下にあるすべてのボックスにチェックを入れ、Create token を再度クリックする。すると、個人用のアクセストークンが表示されるはずである。このトークンをコピーして保存しておく。","code":""},{"path":"reporting-reproducibility.html","id":"パッケージと認証について","chapter":"16 報告と再現性","heading":"16.3.2 パッケージと認証について","text":"{OSF} リポジトリに R 経由で直接アクセスするには、{osfr} パッケージ (Wolen et al. 2020) を使用する。このパッケージの機能を使う前に、まずアクセストークンを使って認証する必要がある。これを行うには、osf_auth 関数を使用して、受け取ったばかりのアクセストークンを渡す (以下に表示されるトークンはデタラメ)。","code":"\nlibrary(osfr)\nosf_auth(\"AtmuMZ3pSuS7tceSMz2NNSAmVDNTzpm2Ud87\")"},{"path":"reporting-reproducibility.html","id":"レポジトリの設定","chapter":"16 報告と再現性","heading":"16.3.3 レポジトリの設定","text":"{osfr} を使うと、 R を使った OSF リポジトリを初期化することが可能である。新しいメタ分析プロジェクトに取り組んでいて、データとR Markdown スクリプトを OSF リポジトリにアップロードしたいと想像してみよう。リポジトリの名前は “Meta-Analysis Project” とする。新しいリポジトリを作成するには、osf_create_project 関数を使用する。新しい OSF リポジトリを R に meta_analysis_project という名前で保存する。osf_open 関数を使用すると、新しく作成したリポジトリにオンラインでアクセスできるようになる。リポジトリが作成されたので、次に コンポーネントを追加していく。OSF では、コンポーネントはコンピュータのフォルダのように動作した。例えば、データセット用のコンポーネントと R Markdown スクリプト用のコンポーネントの2つを作成したいとする。これを行うには、 osf_create_component 関数を使用することが可能である。この関数に R のリポジトリオブジェクト ( meta_analysis_project ) を渡し、新しいコンポーネントのタイトルを設定しなければならない。リポジトリのオンラインページに行くと、2つのコンポーネントが追加されていることがわかる。","code":"\nmeta_analysis_project <- osf_create_project(\"Meta-Analysis Project\")\nosf_open(meta_analysis_project)\nscripts <- osf_create_component(meta_analysis_project, \n                                title = \"Analysis Scripts\")\ndatasets <- osf_create_component(meta_analysis_project, \n                                 title = \"Datasets\")"},{"path":"reporting-reproducibility.html","id":"アップロードとダウンロード","chapter":"16 報告と再現性","heading":"16.3.4 アップロードとダウンロード","text":"OSF リポジトリにデータをアップロードするには、 osf_upload 関数を使用する。この関数では、ファイルを追加するコンポーネントと、アップロードするファイルのパスを指定する必要がある。例えば、“Analysis.rmd” というR Markdownスクリプトをアップロードしたい場合、現在 R プロジェクトのサブフォルダ “scripts” に保存されているものとする。アップロードするには、次のコードを使用する。ファイルが正常にアップロードされたかどうかを確認するには、 osf_ls_files 関数を使用してコンポーネントのコンテンツにアクセスする。アップロードが成功したことが出力で確認可能である。ファイルをダウンロードするには、 osf_ls_files 関数の出力から行を選択し、osf_download 関数でそれを使用して、ファイルをコンピュータのプロジェクトフォルダにダウンロードしなおせばよい。","code":"\nosf_upload(scripts, \"scripts/Analysis.rmd\")\nosf_ls_files(scripts)## # A tibble: 2 x 3\n##   name            id                       meta            \n##   <chr>           <chr>                    <list>          \n## 1 Analysis.rmd    1db74s7bfcf91f0012567572l <named list [3]>\nosf_download(osf_ls_files(scripts)[1,])"},{"path":"reporting-reproducibility.html","id":"pre-registration","chapter":"16 報告と再現性","heading":"16.3.5 コラボレーション、オープンアクセス、事前登録","text":"OSF のリポジトリサイトでは、Contributorsという項目で共同研究者を追加することも可能である。ウェブサイト右上の Make Public ボタンをクリックすることで、いつでもリポジトリを public にすることが可能である。Chapter 1.4.2 で、解析計画と事前登録が高品質なメタ分析に不可欠な部分であることを説明してきた。OSFでは、私たちのプロジェクトのために、オープンにアクセスできる事前登録を作成することができ、とても便利である。上部にある登録ボタンをクリックし、新規登録を作成するだけでよいのである。これにより、OSF Registries のウェブサイトが表示され、分析計画など、計画中の研究についての詳細情報を提供することが可能である。必要な情報をすべて指定した後、試験を登録することが可能である。これにより、一意のID (例: osf.io/q2jp7) でアクセス可能な登録項目が作成される。登録が完了した後は、検索計画、仮説、分析戦略を変更することはできない。\\[\\tag*{$\\blacksquare$}\\]","code":""},{"path":"es-calc.html","id":"es-calc","chapter":"17 効果量の計算と換算","heading":"17 効果量の計算と換算","text":"メタ分析が頻繁に直面する問題は、適切な「生の」効果量データが、含まれるすべての研究から抽出できるとは限らないことである。metacont (Chapter 4.2.2) や metabin (Chapter 4.2.3.1) などの {meta} パッケージのほとんどの関数は、生の効果量データが完全に利用可能な場合にのみ使用することができる。実際には、これは困難につながることも多い。出版された論文の中には、特に古いものでは、必要な (生の) 効果量データを抽出できるような方法で結果を報告していないものがある。\\(t\\)-検定、one-way ANOVA、\\(\\chi^2\\)-検定 の結果は報告されていても、メタ分析に必要なグループごとの平均や標準偏差、研究条件におけるイベント数が報告されていないことはよくあることである。幸いなことに、報告された情報を望ましい効果量フォーマットに変換できる場合がある。これにより、metagen を用いた事前計算データ (Chapter 4.2.1) によるメタ分析で、影響を受けた研究を含めることができるようになる。例えば、2標本の \\(t\\)-検定 の結果を標準化平均差 (SMD) とその標準誤差に変換し、metagen を用いて事前に計算された SMD のメタ分析を行うことができる。{esc} パッケージ (Lüdecke 2019) には、このような変換を R 内で直接行うことができる便利な関数がいくつか用意されている。","code":""},{"path":"es-calc.html","id":"平均値および標準誤差","chapter":"17 効果量の計算と換算","heading":"17.1 平均値および標準誤差","text":"\n平均と標準誤差から SMD や Hedges’ \\(g\\) を計算するとき、平均の標準偏差はサンプルサイズの平方根を「割り算」して標準誤差として定義されることを利用することができる (Thalheimer Cook 2002)。\\[\\begin{equation}\n\\text{SD} =\\text{SE}\\sqrt{n}\n\\tag{17.1}\n\\end{equation}\\]SMD や Hedges’ \\(g\\) は esc_mean_se関数を使って計算することができる。以下はその例である。","code":"\nlibrary(esc)\n\nesc_mean_se(grp1m = 8.5,   # group 1 の平均\n            grp1se = 1.5,  # group 1 の標準誤差\n            grp1n = 50,    # group 1 のサンプル\n            grp2m = 11,    # group 2 の平均\n            grp2se = 1.8,  # group 2 の標準誤差\n            grp2n = 60,    # group 2 のサンプル\n            es.type = \"d\") # SMD に変換; Hedges' g を使う場合は \"g\"## \n## Effect Size Calculation for Meta Analysis\n## \n##      Conversion: mean and se to effect size d\n##     Effect Size:  -0.2012\n##  Standard Error:   0.1920\n##        Variance:   0.0369\n##        Lower CI:  -0.5774\n##        Upper CI:   0.1751\n##          Weight:  27.1366"},{"path":"es-calc.html","id":"回帰係数","chapter":"17 効果量の計算と換算","heading":"17.2 回帰係数","text":"標準化または非標準化回帰係数から SMD、Hedges’ \\(g\\) または相関 \\(r\\) を計算することができる (Lipsey Wilson 2001、Appendix B)。標準化されていない係数に対しては、{esc} の esc_B 関数を使用することができる。以下はその例である。標準化された回帰係数は esc_beta を用いて変換することができる。メタ分析で回帰係数を用いることは、すべての研究で同じモデルを仮定するため注意が必要である。特に、複数の回帰モデルから係数が抽出された場合には、各モデルで異なる共分散に対して調整されているかもしれず、この場合 \\(b\\) 値が直接比較できないため問題となる。","code":"\nlibrary(esc)\n\nesc_B(b = 3.3,       # 標準化されていない回帰係数\n      sdy = 5,       # 予測変数 y の標準偏差\n      grp1n = 100,   # group 1 のサンプルサイズ\n      grp2n = 150,   # group 2 のサンプルサイズ\n      es.type = \"d\") # SMD に変換; Hedges' g を使う場合は \"g\"## \n## Effect Size Calculation for Meta Analysis\n## \n##      Conversion: unstandardized regression coefficient to effect size d\n##     Effect Size:   0.6962\n##  Standard Error:   0.1328\n##        Variance:   0.0176\n##        Lower CI:   0.4359\n##        Upper CI:   0.9565\n##          Weight:  56.7018\nesc_B(b = 2.9,       # 標準化されていない回帰係数\n      sdy = 4,       # 予測変数 y の標準偏差\n      grp1n = 50,    # group 1 のサンプルサイズ\n      grp2n = 50,    # group 2 のサンプルサイズ\n      es.type = \"r\") # 相関係数に変換## Effect Size Calculation for Meta Analysis\n## \n##      Conversion: unstandardized regression coefficient \n##                  to effect size correlation\n##     Effect Size:   0.3611\n##  Standard Error:   0.1031\n##        Variance:   0.0106\n##        Lower CI:   0.1743\n##        Upper CI:   0.5229\n##          Weight:  94.0238\n##      Fisher's z:   0.3782\n##       Lower CIz:   0.1761\n##       Upper CIz:   0.5803\nesc_beta(beta = 0.32,   # 標準化されていない回帰係数\n         sdy = 5,       # 予測変数 y の標準偏差\n         grp1n = 100,   # group 1 のサンプルサイズ\n         grp2n = 150,   # group 2 のサンプルサイズ\n         es.type = \"d\") # SMD に変換; Hedges' g を使う場合は \"g\"## \n## Effect Size Calculation for Meta Analysis\n## \n##      Conversion: standardized regression coefficient to effect size d\n##     Effect Size:   0.6867\n##  Standard Error:   0.1327\n##        Variance:   0.0176\n##        Lower CI:   0.4266\n##        Upper CI:   0.9468\n##          Weight:  56.7867\nesc_beta(beta = 0.37,   # 標準化されていない回帰係数\n         sdy = 4,       # 予測変数 y の標準偏差\n         grp1n = 50,    # group 1 のサンプルサイズ\n         grp2n = 50,    # group 2 のサンプルサイズ\n         es.type = \"r\") # 相関係数に変換## Effect Size Calculation for Meta Analysis\n## \n##      Conversion: standardized regression coefficient \n##                  to effect size correlation\n##     Effect Size:   0.3668\n##  Standard Error:   0.1033\n##        Variance:   0.0107\n##        Lower CI:   0.1803\n##        Upper CI:   0.5278\n##          Weight:  93.7884\n##      Fisher's z:   0.3847\n##       Lower CIz:   0.1823\n##       Upper CIz:   0.5871"},{"path":"es-calc.html","id":"convert-corr","chapter":"17 効果量の計算と換算","heading":"17.3 相関関係","text":"\n同じ大きさの群 (\\(n_1=n_2\\)) の場合、以下の式で点-双列相関から SMD を導き出すことができる (Lipsey Wilson 2001, chap. 3)。\\[\\begin{equation}\nr_{pb} = \\frac{\\text{SMD}}{\\sqrt{\\text{SMD}^2+4}} ~~~~~~~~\n\\text{SMD}=\\frac{2r_{pb}}{\\sqrt{1-r^2_{pb}}} \\tag{17.2}\n\\end{equation}\\]不均等な大きさの群には、別の数式を使用する必要がある (Aaron, Kromrey, Ferron 1998)。\\[\\begin{align}\nr_{pb} &= \\frac{\\text{SMD}}{\\sqrt{\\text{SMD}^2+\\dfrac{(N^2-2N)}{n_1n_2}}} \\notag \\\\\n\\text{SMD} &= \\dfrac{r_{pb}}{\\sqrt{(1-r^2)\\left(\\frac{n_1}{N}\\times\\left(1-\\frac{n_1}{N}\\right)\\right)}} \\tag{17.3}\n\\end{align}\\]\\(r_{pb}\\) を SMD や Hedges’ \\(g\\) に変換するには、esc_rpb 関数を使用する。","code":"\nlibrary(esc)\n\nesc_rpb(r = 0.25,      # 点-双列相関\n        grp1n = 99,    # group 1 のサンプルサイズ\n        grp2n = 120,   # group 2 のサンプルサイズ\n        es.type = \"d\") # SMD に変換; Hedges' g を使う場合は \"g\"## \n## Effect Size Calculation for Meta Analysis\n## \n##      Conversion: point-biserial r to effect size d\n##     Effect Size:   0.5188\n##  Standard Error:   0.1380\n##        Variance:   0.0190\n##        Lower CI:   0.2483\n##        Upper CI:   0.7893\n##          Weight:  52.4967"},{"path":"es-calc.html","id":"一元配置分散分析","chapter":"17 効果量の計算と換算","heading":"17.4 一元配置分散分析","text":"また、2群の一元配置 ANOVA の \\(F\\)-値から SMD を導き出すこともできる。そのような ANOVA は、自由度を見ることで識別できる。2群の一元配置ANOVAでは、自由度は常に1から始まるはずである (例: \\(F_{\\text{1,147}}\\) =5.31)。変換に使う式は次のようなものである (Rosnow Rosenthal 1996; Rosnow, Rosenthal, Rubin 2000; Thalheimer Cook 2002 を参照)。\\[\\begin{equation}\n\\text{SMD} = \\sqrt{  F\\left(\\frac{n_1+n_2}{n_1 n_2}\\right)\\left(\\frac{n_1+n_2}{n_1+n_2-2}\\right)}\n\\tag{17.4}\n\\end{equation}\\]\\(F\\)-値 から SMD や Hedges’ \\(g\\) を計算するには、esc_f 関数を使用する。以下はその例である。","code":"\nesc_f(f = 5.04,      # one-way anova の F-値\n      grp1n = 519,   # group 1 のサンプルサイズ \n      grp2n = 528,   # group 2 のサンプルサイズ\n      es.type = \"g\") # Hedges' g　に変換; SMD の場合は \"d\"## \n## Effect Size Calculation for Meta Analysis\n## \n##      Conversion: F-value (one-way-Anova) to effect size Hedges' g\n##     Effect Size:   0.1387\n##  Standard Error:   0.0619\n##        Variance:   0.0038\n##        Lower CI:   0.0174\n##        Upper CI:   0.2600\n##          Weight: 261.1022"},{"path":"es-calc.html","id":"標本の-t-検定","chapter":"17 効果量の計算と換算","heading":"17.5 2標本の \\(t\\) 検定","text":"標準化平均差として表現される効果量は、以下の式 (Rosnow, Rosenthal, Rubin 2000; Thalheimer Cook 2002) を用いて、独立2標本 \\(t\\) -検定値からも導き出すことができる。\\[\\begin{equation}\n\\text{SMD} = \\frac {t(n_1+n_2)}{\\sqrt{(n_1+n_2-2)(n_1n_2)}}\n\\tag{17.5}\n\\end{equation}\\]R では、esc_t 関数を使って \\(t\\)-値から SMD や Hedges’ g を計算することができる。以下はその例である。","code":"\nesc_t(t = 3.3,     # t-値\n      grp1n = 100, # group 1 のサンプルサイズ\n      grp2n = 150, # group 2 のサンプルサイズ\n      es.type=\"d\") # SMD に変換; Hedges' g を使う場合は \"g\"## \n## Effect Size Calculation for Meta Analysis\n## \n##      Conversion: t-value to effect size d\n##     Effect Size:   0.4260\n##  Standard Error:   0.1305\n##        Variance:   0.0170\n##        Lower CI:   0.1703\n##        Upper CI:   0.6818\n##          Weight:  58.7211"},{"path":"es-calc.html","id":"p-値","chapter":"17 効果量の計算と換算","heading":"17.6 \\(p\\) 値","text":"研究では、効果の大きさ (例えば、Cohen’s \\(d\\) 値)、その効果の \\(p\\) -値のみを報告し、それ以上のことは報告しないことがある。しかし、メタ分析で結果をプールするためには、効果量の精度の指標、できれば標準誤差が必要である。そのような場合、効果量の \\(p\\) -値から標準誤差を推定しなければならない。これは、Altman Bland (2011) による公式を用いれば、差分 (すなわち SMD) または比 (すなわちリスク比またはオッズ比) に基づく効果量に対して可能である。これらの公式は、 R の se..p 関数で実装されている。\n“se..p” 関数\n\nse..p 関数は、{dmetar}\nパッケージに含まれている。{dmetar}\nがインストールされ、コンピュータに読み込まれると、この関数を使用できるようになる。もし、{dmetar}\nをインストールしていない場合は、以下の手順でインストールできる。\n\n関数のソースコードに オンライン\nでアクセスする。\n\nソースコード全体をコンソール (R Studio の左下ペイン)\nにコピー＆ペーストし、Enterキーを押して、 R\nに関数を「学習」させる。\n\\(N=\\) 71人の参加者を持つ研究で、\\(d=\\) 0.71 の効果量を報告していると仮定すると、\\(p=\\) 0.013 のように標準誤差を計算することができる。\\(N=\\) 200人の参加者が、=0.91、\\(p=\\) 0.38の効果量を報告した研究については、標準誤差はこのように計算される。また、 effect.size.type = \"ratio\" の場合、自動的に 対数変換効果量と標準誤差も計算する。これは、metagen 関数 (Chapter 4.2.1) を使う際に必要なものである。","code":"\nlibrary(dmetar)\n\nse.from.p(0.71,\n          p = 0.013,\n          N = 71,\n          effect.size.type = \"difference\")##   EffectSize StandardError StandardDeviation  LLCI  ULCI\n## 1       0.71         0.286             2.410 0.149 1.270\nlibrary(magrittr) # pipe を使う\n\nse.from.p(0.91, p = 0.38, N = 200,\n          effect.size.type = \"ratio\") %>% t()##                        [,1]\n## logEffectSize        -0.094\n## logStandardError      0.105\n## logStandardDeviation  1.498\n## logLLCI              -0.302\n## logULCI               0.113\n## EffectSize            0.910\n## LLCI                  0.739\n## ULCI                  1.120"},{"path":"es-calc.html","id":"chi2-検定","chapter":"17 効果量の計算と換算","heading":"17.7 \\(\\chi^2\\) 検定","text":"統計量 \\(\\chi^2\\) をオッズ比に変換するには、esc_chisq 関数を使用する (d.f. = 1と仮定する；例: \\(\\chi^2_1\\) = 8.7)。以下はその例である。","code":"\nesc_chisq(chisq = 7.9,        # カイ二乗値\n          totaln = 100,       # 全体のサンプルサイズ\n          es.type = \"cox.or\") # オッズ比へ変換## \n## Effect Size Calculation for Meta Analysis\n## \n##      Conversion: chi-squared-value to effect size Cox odds ratios\n##     Effect Size:   2.6287\n##  Standard Error:   0.3440\n##        Variance:   0.1183\n##        Lower CI:   1.3394\n##        Upper CI:   5.1589\n##          Weight:   8.4502"},{"path":"es-calc.html","id":"nnt","chapter":"17 効果量の計算と換算","heading":"17.8 治療必要例数","text":"Cohen’s \\(d\\) や Hedges’ \\(g\\) のような効果量は、実用的な観点からは解釈が難しいことが多い。メタ分析で介入効果が \\(g=\\) 0.35 であることを発見したとする。このような効果が何を意味するのか、患者、公務員、医療関係者、その他の利害関係者にどのように伝えればよいのだろうか。また、他の人が結果を理解しやすいように、メタ分析ではしばしば治療必要例数 (Number Needed Treat, NNT) を報告している。この指標は、医学研究において最も一般的に使用されている。これは、1つのネガティブな事象 (例: 再発) を予防するため、あるいは1つのポジティブな事象 (例: 症状の寛解、反応) を達成するために、研究対象の治療を何人の患者が追加で受けなければならないかを意味する。例えば、NNT = 3 の場合、研究課題に応じて、追加で1件の再発を回避するために3人が治療を受けなければならない、あるいは、確実に1件の症状寛解を達成するために3人の患者が治療を受けなければならないと言うことができる。二値効果量データを扱う場合、NNT の算出は比較的容易である。式は次のようになる。\\[\\begin{equation}\n\\text{NNT} = (p_{e_{\\text{treat}}}-p_{e_{\\text{control}}})^{-1}\n\\tag{17.6}\n\\end{equation}\\]この式で、\\(p_{e_{\\text{treat}}}\\) と \\(p_{e_{\\text{control}}}\\) は、それぞれ治療群と対照群でイベントを経験した参加者の割合である。これらの割合は、リスク比 (Chapter 3.3.2.1 ) を計算するのに使われる「リスク」と同じで、実験群イベント率 (experimental group event rate, EER) および対照群イベント率 (control group event rate, CER) としても知られている。この式から、NTT は (絶対) リスク差の逆数と表現することもできる。標準化平均差または Hedges’ \\(g\\) を NNT に変換するのはより複雑である。よく使われる方法は2つある。治療群の患者が対照群の患者より好ましいアウトカムを得る確率として定義される曲線下面積 (area curve, AUC) から NNT を計算する Kraemer Kupfer (2006) による方法である。この方法は、余分な情報がなくても SMD または \\(g\\) から直接 NNT を計算することができる。治療群の患者が対照群の患者より好ましいアウトカムを得る確率として定義される曲線下面積 (area curve, AUC) から NNT を計算する Kraemer Kupfer (2006) による方法である。この方法は、余分な情報がなくても SMD または \\(g\\) から直接 NNT を計算することができる。Furukawa Leucht の方法は、CER またはその合理的な推定値を用いて SMD から NNT 値を計算するものである。Furukawa 法は、Kraemer & Kupfer 法 (Furukawa Leucht 2011) と比較して、真の NNT 値を推定するのに優れていることが示されている。したがって、CER を合理的に推定できるのであれば、常に Furukawa 式が優先されるべきである。Furukawa Leucht の方法は、CER またはその合理的な推定値を用いて SMD から NNT 値を計算するものである。Furukawa 法は、Kraemer & Kupfer 法 (Furukawa Leucht 2011) と比較して、真の NNT 値を推定するのに優れていることが示されている。したがって、CER を合理的に推定できるのであれば、常に Furukawa 式が優先されるべきである。効果量としてリスク比やオッズ比を使用する場合、NNT は nnt 関数を使用して {meta} オブジェクトから直接計算することができる。metabin (Chapter 4.2.3.1) を使ってメタ分析を行った後、その結果を nnt 関数に代入するだけである。以下はその例である。nnt 関数は、異なる CER を仮定した場合の治療に必要な数を提供する。結果の3行は、このデータセットにおける最小、平均、最大の CER の結果を示している。CER の平均値が、通常報告される「典型的な」NNT である。また、要約指標 sm が \"RR\" または \"\" であれば、nnt を metagen モデルで使用することも可能である。このようなモデルでは、nnt の p.c 引数で想定される CER を指定する必要がある。以下は、Chapter 4.2.3.1.5 で作成した m.gen_bin メタ分析オブジェクトを使用した例である。標準化平均差または Hedges’ \\(g\\) は、{dmetar} の NNT 関数を使用して NNT に変換することができる。\n“NNT” 関数\n\nもし、{dmetar}\nをインストールしていない場合は、以下の手順でインストールできる。\n\n関数のソースコードに オンライン\nでアクセスする。\n\nソースコード全体をコンソール (R Studio の左下ペイン)\nにコピー＆ペーストし、Enterキーを押して、 R\nに関数を「学習」させる。\nKraemer & Kupfer 法を使うには、NNT 関数に効果量 (SMD または \\(g\\)) を与えるだけでよい。Furukawa 法は、CER の値が与えられるとすぐに自動的に使用される。\n注意して扱うべき数字: NNT への批判\n\nNNT の使用は一般的ではあるが、臨床試験の結果を伝えるために NNT\nを使用することは議論の余地がないわけではない。批判としては、一般人がしばしば誤解すること\n(他の効果量の指標に代わる「直感的な」指標とされているにもかかわらず\nChristensen Kristiansen (2006))、研究者がよく NNT\nを不正確に計算することが挙げられる (Mendes, Alves, Batel-Marques 2017)。\n\nさらに、NNT の信頼できる標準誤差 (および信頼区間)\nを計算することはできないので、メタアナリシスでは使用できないことになる\n(Hutton 2010)。別の効果量指標を用いてプールを行った後に初めて、結果を\nNNT に変換することが可能である。\n","code":"\nlibrary(meta)\ndata(Olkin1995)\n\n# 二値効果量データを使ってメタ分析を実行\nm.b <- metabin(ev.exp, n.exp, ev.cont, n.cont, \n               data = Olkin1995,\n               sm = \"RR\")\nnnt(m.b)## Number needed to treat (common effect model): \n## \n##      RR    p.c    NNTB             95%-CI\n##  0.7728 0.1440 30.5677 [26.1222; 37.2386]\n##  0.7728 0.3750 11.7383 [10.0312; 14.3001]\n## \n## Number needed to treat (random effects model): \n## \n##      RR    p.c    NNTB             95%-CI\n##  0.7694 0.1440 30.1139 [24.0662; 41.3519]\n##  0.7694 0.3750 11.5641 [ 9.2417; 15.8796]\n# 固定効果モデルの結果も示す\nm.gen_bin <- update.meta(m.gen_bin, \n                         fixed = TRUE)\n\nnnt(m.gen_bin, \n    p.c = 0.1) # CER 0.1 を使用## Number needed to treat (common effect model): \n## \n##      RR    p.c   NNTH            95%-CI\n##  2.0319 0.1000 9.6906 [8.2116; 11.6058]\n## \n## Number needed to treat (random effects model): \n## \n##      RR    p.c   NNTH            95%-CI\n##  2.0218 0.1000 9.7870 [6.4761; 16.4843]\nNNT(d = 0.245)## Kraemer & Kupfer method used. \n## [1] 7.270711\nNNT(d = 0.245, CER = 0.35)## Furukawa & Leucht method used. \n## [1] 10.61533"},{"path":"es-calc.html","id":"pool-groups","chapter":"17 効果量の計算と換算","heading":"17.9 マルチアーム研究","text":"解析単位誤差 (Chapter 3.5.2) を避けるために、(標準化) 平均差を計算する前に、2つ以上の試験群の平均と標準偏差をプールする必要がある場合がある。2群の連続効果量データをプールするには、以下の式を用いることができる。\\[\\begin{align}\nn_{\\text{pooled}} &= n_1 + n_2  \\\\\nm_{\\text{pooled}} &= \\frac{n_1m_1+n_2m_2}{n_1+n_2} \\\\\nSD_{\\text{pooled}} &= \\sqrt{\\frac{(n_1-1)SD^{2}_{1}+ (n_2-1)SD^{2}_{2}+\\frac{n_1n_2}{n_1+n_2}(m^{2}_1+m^{2}_2-2m_1m_2)} {n_1+n_2-1}}\n\\end{align}\\]この式を R で適用するには、pool.groups 関数を使用する。\n“pool.groups” 関数\n\npool.groups 関数は、{dmetar}\nパッケージに含まれている。{dmetar}\nがインストールされ、コンピュータに読み込まれると、この関数を使用できるようになる。もし、{dmetar}\nをインストールしていない場合は、以下の手順でインストールできる。\n\n関数のソースコードに オンライン\nでアクセスする。\n\nソースコード全体をコンソール (R Studio の左下ペイン)\nにコピー＆ペーストし、Enterキーを押して、 R\nに関数を「学習」させる。\n以下はその一例である。","code":"\nlibrary(dmetar)\n\npool.groups(n1 = 50,   # group 1 サンプルサイズ\n            n2 = 50,   # group 2 サンプルサイズ\n            m1 = 3.5,  # group 1 平均\n            m2 = 4,    # group 2 平均\n            sd1 = 3,   # group 1 標準偏差\n            sd2 = 3.8) # group 2 標準偏差##   Mpooled SDpooled Npooled\n## 1    3.75 3.415369     100"},{"path":"es-calc.html","id":"aggregate-es","chapter":"17 効果量の計算と換算","heading":"17.10 効果量の集約","text":"{metafor} の aggregate 関数を使うと、例えば、同じ研究やクラスターの一部であるという理由で、いくつかの従属する 事前に計算された効果量 を一つの推定値に集約することが可能である。これは、解析単位エラー (Chapter 3.5.2 参照) を回避する方法であるが、研究内相関の値を仮定する必要があり、これは通常未知である。効果量依存性を扱うもう一つの (そしてしばしば望ましい) 方法は、(相関) 階層モデルで、これは Chapter 10 で説明されている。この例では、Chernobyl データセット (Chapter 10.2 参照) の効果量を集約し、各研究が1つの効果量のみを提供するようにする。なお、aggregate は集約された効果量 yi とその分散 (variance) vi (標準誤差の平方根) を返す。\\[\\tag*{$\\blacksquare$}\\]","code":"\nlibrary(metafor)\nlibrary(dmetar)\ndata(\"Chernobyl\")\n\n# 'Chernobyl' データを 'escalc' オブジェクトに変換\nChernobyl <- escalc(yi = z,           # 効果量\n                    sei = se.z,       # 標準誤差\n                    data = Chernobyl)\n\n# 研究レベルで効果量を集約\n# 相関 rho=0.6 を仮定\nChernobyl.agg <- aggregate(Chernobyl, \n                           cluster = author,\n                           rho = 0.6)\n\n# 集約結果を表示\nChernobyl.agg[,c(\"author\", \"yi\", \"vi\")]##                       author     yi     vi \n## 1 Aghajanyan & Suskov (2009) 0.2415 0.0079 \n## 2     Alexanin et al. (2010) 1.3659 0.0012 \n## 3             Bochkov (1993) 0.2081 0.0014 \n## 4      Dubrova et al. (1996) 0.3068 0.0132 \n## 5      Dubrova et al. (1997) 0.4453 0.0110\n## [...]"},{"path":"qanda.html","id":"qanda","chapter":"A Q&A","heading":"A Q&A","text":"","code":""},{"path":"qanda.html","id":"qanda1","chapter":"A Q&A","heading":"A.1 Chapter 1: はじめに","text":"1. メタ分析はどのように定義することができるか？メタ分析と他の文献レビューの違いは何か？メタ分析は、分析の分析と定義することができる (Glassによる定義)。他のタイプの (システマティック) レビューとは対照的に、メタ分析は、定量的な方法でエビデンスを統合することを目的としている。通常、その目的は、明確に区分された研究分野全体を記述する数値的な推定値を導き出すことである。2. メタ分析の生みの親、生みの親を一人挙げることができるか？その人物はどのような功績を残したか？Karl Pearson: 大英帝国全体の腸チフス接種データの組み合わせ; Ronald Fisher: 農業調査研究のデータを統合するアプローチ; Mary Smith Gene Glass: 「メタ分析」という言葉を作り、心理療法試験の最初のメタ分析; John Hunter Frank Schmidt: 測定アーチファクトを補正したメタ分析 (心理測定メタ分析) ; Rebecca DerSimonian Nan Laird: ランダム効果モデルのメタ分析計算法; Peter Elwood Archie Cochrane: 医学におけるメタ分析のパイオニア的存在である。3. メタ分析のよくある問題点を3つ挙げ、1～2文で説明しなさい。“リンゴとオレンジ”: 研究が違いすぎて合成できない、“Garbage , Garbage ”: 無効なエビデンスがメタ分析で再現されるだけ、“ファイルの引き出し”: ネガティブな結果は公表されず、メタ分析に偏った結果が出る、“研究者のアジェンダ”: 研究者は証明したいことを証明するためにメタ分析をいじることができる、などである。4. メタ分析のための良いリサーチクエスチョンを定義する資質を挙げなさい。FINER: 実現可能、興味深い、新規、倫理的、関連性；PICO: 明確に定義された集団、介入／曝露、対照群／比較、分析されたアウトカム。5. 大学生の睡眠介入に関するメタ分析の適格基準をもう一度見てみよう (Chapter 1.4.1 の終わり)。この研究の適格基準、除外基準から PICO を抽出できるか。対象: 高等教育機関学生；介入: 睡眠焦点型心理学的介入；比較: 受動的対照条件；アウトカム: 睡眠障害、標準化症状測定による。6. 研究を検索するために使用できるいくつかの重要なソースを挙げなさい。総説、研究中の参考文献、「フォワードサーチ」 (関連論文を引用した研究の検索)、関連雑誌の検索、書誌データベース検索。7. 「研究の質」と「バイアスのリスク」の違いを1～2文で説明しなさい。研究分野において重要とされる研究品質基準をすべて満たしていても、バイアスのリスクが高い場合がある (この種の研究または研究テーマではバイアスの回避が困難なためなど)。","code":""},{"path":"qanda.html","id":"qanda2","chapter":"A Q&A","heading":"A.2 Chapter 2: Rの発見","text":"1. 変数 Author を表示しなさい。2. subgroup を因子型 (factor) に変換しなさい。3. “Jones” と “Martin” の研究のデータをすべて選択しなさい。4. 研究名 “Rose” を “Bloom” に変更しなさい。5. TE から seTE を引いて、新しい変数 TE_seTE_diff を作成し、結果を data に保存しなさい。6. パイプを使用して、(1) subgroup が”one” または “two” に属するすべての研究をフィルタし、(2) 変数 TE_seTE_diff を選択し、(3) その変数の平均をとり、それに exp 関数を適用しなさい。","code":"\ndata$Author\ndata$subgroup <- as.factor(data$subgroup)\nlibrary(tidyverse)\ndata %>%\n    filter(Author %in% c(\"Jones\", \"Martin\"))\ndata[5,1] <- \"Bloom\"\nTE_seTE_diff <- data$TE - data$seTE\ndata %>%\n    deplyr::filter(subgroup %in% c(\"one\", \"two\")) %>%\n    pull(TE_seTE_diff) %>%\n    mean() %>%\n    exp()"},{"path":"qanda.html","id":"qanda3","chapter":"A Q&A","heading":"A.3 Chapter 3: 効果の大きさ","text":"1. 効果量という言葉に明確な定義はあるか？人々は、効果量という言葉で何を指すか？いいえ、普遍的に受け入れられる定義はない。ある人は、介入群と対照群の間の差に対して「効果量」という言葉を留保している。また、より自由な定義を使用し、「1変数」の測定値 (例えば、平均値や割合) のみを除外する者もいる。2. 観測された効果量が母集団の真の効果量から乖離する主な理由を挙げなさい。それはどのように定量化できるのか。観察された効果量は、サンプル誤差のために真の効果量から乖離することが想定されている。研究のサンプル・エラーの予想サイズは、その標準誤差で表すことができる。3. なぜ大規模な研究は小規模な研究よりも真の効果の推定に優れているのか？なぜなら、サンプリング誤差が小さく、より正確な効果推定ができると想定されることがあるからである。4. 効果量の指標は、どのような基準を満たせばメタ分析に使えるのか？比較可能で、計算可能で、信頼性があり、解釈可能である必要がある。5. 標準化平均差 (Standardized Mean Difference, SMD) が1であることは何を表しているのか？2群の平均値がプール標準偏差の1倍だけ異なることを表している。6. 比 (オッズ比など) に基づく効果量をプールするためには、どのような変換が必要か。効果量は対数変換する必要がある (逆変量プール法を使用するため)。7. 効果量補正の種類を3つ挙げよ。標準化平均差のスモールサンプルバイアス補正 (Hedges’ \\(g\\))、信頼性の低さに関する補正、範囲制限に関する補正。8. 分析単位の問題はどのような場合に発生するか？どうすれば回避できるか？データセット内の効果量に相関がある場合 (例えば、同じ研究の一部であるため)。分析単位の問題は、(1)共有グループのサンプルサイズを分割する、(2)比較を取り除く、(3)グループを組み合わせる、(4)効果量の依存性を考慮したモデル (例: ３レベルモデル) を使用する、などによって (一部または全部) 回避することができる。","code":""},{"path":"qanda.html","id":"qanda4","chapter":"A Q&A","heading":"A.4 Chapter 4: 効果量のプール","text":"1. 固定効果モデルとランダム効果モデルの違いは何か？固定効果モデルは、すべての研究が同じ真の効果量の推定者であると仮定している。ランダム効果モデルは、研究間の異質性 (分散 \\(\\tau^2\\)) によって、研究の真の効果量が変化すると仮定し、それを推定する必要がある。2. 固定効果モデルとランダム効果モデルの結果が同じになるケースは考えられるか。研究間異質性分散 \\(\\tau^2\\) がゼロの場合。3. \\(\\tau^2\\) とは何か？どのように推定するのか？研究間の異質性分散。制限付き最尤法 (REML)、Paule-Mandel 推定量、DerSimonian-Laird 推定量など、さまざまな方法を用いて推定することができる。4. Knapp-Hartung の調整はどの分布に基づいているか？どのような効果があるか？この調整は \\(t\\)-分布に基づくものである。Knapp-Hartung の調整は、通常、より保守的な (すなわち、より広い) 信頼区間をもたらす。5. 「逆分散」 (inverse-variance) プーリングとはどういう意味か？この方法が最適解でないのはどのような場合か？この方法は、研究の分散の逆数をプーリングの重みとして使用するため、逆分散プーリングと呼ばれる。一般的な逆分散法は、二値アウトカム・データ (例えば、リスクやオッズ比) のメタ分析には好まれない。6. 二値アウトカムデータをメタ分析したい。試験群の観察数はほぼ同じで、観察された事象は非常にまれで、治療効果が大きくなることは期待できない。どのようなプール方法を使用するか？このような場合、Peto 法がうまく機能する可能性がある。7. GLMM はどのようなアウトカム指標に使用できるのか。割合(Proportions)。他の二値アウトカム指標に使用することも可能であるが、一般的には推奨されていない。","code":""},{"path":"qanda.html","id":"qanda5","chapter":"A Q&A","heading":"A.5 Chapter 5: 研究間異質性","text":"1. なぜメタ分析の研究間異質性を調べることが重要なのか。研究間の異質性が大きい場合、真の効果の大きさはかなり異なることが想定される。この場合、平均的な真の効果の点推定値は、データを全体的によく表していない可能性がある。また、研究間の異質性は、例えば、少数の外れた研究が全体の結果を歪めてしまうため、効果推定値が頑健でなくなる可能性がある。2. 異質性の2つのタイプを挙げられるか？メタ分析の計算にはどちらが関係するか？ベースライン/デザインに関連した異質性と統計的異質性。メタ分析では統計的異質性のみが定量的に評価される。3. Cochran’s \\(Q\\) の有意性が、研究間異質性の十分な指標とならないのはなぜか。\\(Q\\) 検定の有意性は、メタ分析に含まれる研究数とその規模に大きく依存することがある。4. メタ分析で異質性の大きさを表現するために予測区間を使うメリットは何か。予測区間は、要約尺度と同じ尺度で、研究間の異質性が将来の研究に与える影響を表現することができる。5. 統計的外れ値と影響力のある研究の違いは何か？統計的外れ値とは、効果量が極端な研究のことである。研究は、全体の結果に対する影響が大きい場合、影響力がある。ある研究があまり影響力がなくても統計的外れ値として定義されることがあり、またその逆もありえる。例えば、大規模な研究は、その効果量が特に小さくもなく大きくもないのに、プール結果に大きな影響を与えることがある。6. GOSH のプロットは何に使えるのか。GOSH プロットは、データにおける異質性のパターンや、どの研究がそれに寄与しているかを調べるために使用することができる。","code":""},{"path":"qanda.html","id":"qanda6","chapter":"A Q&A","heading":"A.6 Chapter 6: フォレストプロット","text":"1. フォレストプロットの主要な構成要素は何か？各研究の観察された効果量と信頼区間、観察された効果量を囲む四角の大きさで表される各研究の重み、各研究の観察された効果量と重みの数値、菱形で表されるプール効果、通常は効果なしを表す参照線などのグラフィカル表示。**2. メタ分析でフォレストプロットを提示するメリットは何か？これにより、含まれるすべての研究の数、効果量、精度、および観察された効果がどのようにプールされた効果に「加算」されるかを迅速に調べることができる。3. フォレストプロットの限界は何か、Drapery プロットはこの限界をどのように克服しているのか。フォレストプロットは、固定された有意閾値 (通常、\\(\\alpha\\) = 0.05) を仮定した効果の信頼区間を示すことができるだけである。Drapery プロットは、\\(p\\) -値を変化させた場合の効果量の信頼区間 (したがって有意性) を表示すために使用できる。","code":""},{"path":"qanda.html","id":"qanda7","chapter":"A Q&A","heading":"A.7 Chapter 7: サブグループ解析","text":"1. 影響度分析や異常値分析ではわからないことのうち、何がサブグループ解析ではわかることがあるか？サブグループ解析は、データにある異質性のパターンが存在することを教えてくれるだけでなく、なぜ存在するのかを説明できる可能性がある。2. サブグループ解析の背景にあるモデルが、なぜ固定効果 (複数) モデルと呼ばれるのか。なぜなら、サブグループ内の研究はランダム効果モデルに従うが、サブグループのレベル自体は固定されていると仮定しているからである。固定サブグループ効果はいくつかある。3. メタ分析の一環として、ある教育研修プログラムの効果が、実施された学区によって異なるかどうかを調べたいと考えている。この問いに答えるために、固定効果 (複数) モデルを用いたサブグループ解析は適切か？おそらく、そうではないだろう。学区は、すべての学区ではなく、より多くの学区から選ばれたものであると考える方が理にかなっている。4. あなたの友人が、合計9つの研究を含むメタ分析を行った。これらの研究のうち5つが1つのサブグループに分類され、4つが他のサブグループに分類されている。彼女は、サブグループ解析を行うことに意味があるかどうかをあなたに尋ねている。あなたならどうするか？研究数の合計が10より少ないので、サブグループ解析を行うのは得策ではないだろう。5. メタ分析で、分析した治療法が男性よりも女性でより効果的であると著者が主張しているものがあった。この知見は、研究対象者に含まれる女性の割合に基づいて研究をサブグループに分けたサブグループ解析に基づいている。この知見は信頼できるか、またその理由は？この所見は、集計された研究データを用いて作成されたサブグループ変数に基づくものである。これは生態学的なバイアスをもたらす可能性があり、その結果には疑問が残る。","code":""},{"path":"qanda.html","id":"qanda8","chapter":"A Q&A","heading":"A.8 Chapter 8: メタ回帰","text":"1. 一次研究で用いられる従来の回帰分析と、メタ回帰の違いは何か？分析の単位は (人ではなく) 研究であり、その効果量はだいたい正確である。メタ回帰では、ある研究が他の研究よりも大きなウェイトを持つという事実を考慮した回帰モデルを構築しなければならない。2. サブグループ解析とメタ回帰は密接な関係がある。メタ回帰の公式をどのようにサブグループデータに適応させることができるか。ダミー／カテゴリー予測変数の使用による。3. メタ回帰において、個々の研究に異なる重みを与えるためにどのような方法が用いられるか？メタ回帰では、加重最小二乗法を用いて、精度の高い研究をより重要視している。4. データによく適合するメタ回帰モデルにはどのような特徴があるか？これを調べるには、どのような指標を用いればよいか？「良い」メタ回帰モデルは、説明されない研究間異質性分散の量を大きく減少させるはずである。この説明される分散の増加をカバーする指数が、\\(R^2\\) のアナログである。5. メタ分析の手法でサブグループ解析を計算する場合、\\(\\tau^2\\) の値をサブグループで別々にするか、共通にするか。サブグループで共通の推定値 \\(\\tau^2\\) を想定している。6. (多重) メタ回帰の限界と落とし穴は何か。メタ回帰の過剰適合は偽陽性の結果につながり、多重共線性はロバストでないパラメータ推定値につながる可能性がある。7. (複数の) メタ回帰モデルの頑健性を向上させるために利用できる方法を2つ挙げ、それが有用である理由を述べよ。並べ替え検定を行うか、マルチモデル推論を利用することができる。","code":""},{"path":"qanda.html","id":"qanda9","chapter":"A Q&A","heading":"A.9 Chapter 9: 出版バイアス","text":"1. 「出版バイアス」という言葉はどのように定義できるか？なぜメタ分析で問題になるのか？出版バイアスは、ある研究が出版される確率がその結果に依存する場合に存在した。これは、メタ分析において偏った結果を導き出す可能性があるため、問題となる。すべてのエビデンスが考慮されているわけではないので、メタ分析では、既存のすべての情報を考慮したときには現れなかったであろう結果が得られることがある。2. 他にどのような報告バイアスがあるか？少なくとも3つ挙げて説明しなさい。引用バイアス: ネガティブな知見を持つ研究は引用されにくい、タイムラグバイアス: ネガティブな知見を持つ研究は後に出版される、多重出版バイアス: ポジティブな知見を持つ研究は複数の論文で報告されやすい、言語バイアス: 英語で出版されていないため証拠が省略されることがある、結果報告バイアス: 研究結果がポジティブであればネガティブよりも多く報告される傾向がある。3. 疑わしい研究慣行 (QRP) を2つ挙げ、どのようにメタ分析の妥当性を脅かすかを説明しなさい。P-hacking、HARKing。どちらも、真の効果がないにもかかわらず、肯定的な知見を膨らませることにつながる。4. 小規模研究効果法の基本的な前提を説明しなさい。大規模な研究 (すなわち標準誤差が小さい研究) は、その結果がどうであれ、出版される可能性が非常に高い。小規模な研究は精度が小さいので、統計的有意性を得るためには非常に高い効果量が必要となる。したがって、非常に高い効果を持つ小規模な研究だけが出版され、それ以外は「ファイルの引き出し」に入ったままになってしまうのである。5. データが小規模研究の効果を示すことがわかったとき、自動的に出版バイアスがあることを意味するか？研究間の異質性、共変量の影響 (例えば、小規模な研究ほど治療の忠実度が高い)、偶然性など、小規模な研究の効果を見つける理由は他にもいくつかある。6. p-曲線は、メタ分析に含まれるすべての研究の真の効果を推定するのか、それとも「有意な」効果量を持つすべての研究の真の効果だけを推定するのか、どちらか？P曲線は、すべての有意な効果量の真の効果を推定するだけである。これは、研究間の異質性がある場合にうまく機能しない理由の一つである。7. どの出版バイアス法が一番性能が良いか。出版バイアス方法は、一貫して他のすべての方法より優れているものはない。したがって、いくつかの方法を適用して、その結果が一致するかどうかを確認することは有用である。","code":""},{"path":"qanda.html","id":"qanda10","chapter":"A Q&A","heading":"A.10 Chapter 10:「マルチレベルメタ分析","text":"1. なぜ「マルチレベル」モデルではなく「３レベル」モデルと言う方が正確なのか？なぜなら、「従来の」ランダム効果モデルは、すでにマルチレベルモデルであることがある。参加者が研究内にネストされており、研究自体が真の効果量の母集団から引き出されていることを仮定している。2. ３レベルメタ分析モデルはいつ有用か？相関のあるデータやネストされたデータを扱う場合。３レベルモデルは、研究が複数の効果量に寄与している場合や、研究自体がより大きなクラスターに分類されると信じるに足る理由がある場合に特に有用である。3. 効果量依存性の一般的な原因を2つ挙げなさい。一次研究に携わった研究者が引き起こした依存、メタ分析者自身が作り出した依存。4. マルチレベル \\(^2\\) の統計量はどのように解釈すればよいか。これは、サンプル誤差に起因しない分散の量を示し、クラスタ内の異質性分散とクラスタ間の異質性分散を区別するものである。5. モデレータ変数の効果を取り入れるために、どのように３レベルモデルを拡張することができるのか？モデル式に固定効果項を積算することで","code":""},{"path":"qanda.html","id":"qanda11","chapter":"A Q&A","heading":"A.11 Chapter 11: 構造方程式モデリングメタ分析","text":"1. 構造方程式モデリングとは何か、何のために使うのか。構造方程式モデリングは、顕在変数と潜在変数の間に想定される関係を検証するために用いることができる統計手法である。2. SEM の表現方法として、どのようなものがあるか？SEM はグラフやマトリックスで表現することができる。3. ランダム効果メタ分析を SEM の観点から説明しなさい。SEM の観点からは、ランダム効果メタ分析における真の全体効果量は、潜在変数と見なすことができる。それは、レベル1のサンプル誤差とレベル2の真の効果量の異質性分散という2つのアームによって “影響”される。4. 多変量メタ分析とは何か、どのような場合に有用か。多変量メタ分析では、2つ (またはそれ以上) の研究のアウトカムを同時にプールすることができる。2つのアウトカム変数を共同で推定することの利点は、アウトカム間の相関を考慮することができることである。5. 提案したメタ分析 SEM がデータによく適合することがわかったとき、このモデルが自動的に「正しい」モデルであることを意味するのだろうか。いいえ、データによく合うモデルは1つだけではないことが多い。","code":""},{"path":"qanda.html","id":"qanda12","chapter":"A Q&A","heading":"A.12 Chapter 12: ネットワークメタ分析","text":"1. ネットワークメタ分析はどんな時に有用か？標準的なメタ分析と比較して、どのような利点があるか？ネットワークメタ分析は、ある問題領域に対して複数の競合する治療法があり、どの治療法が最も効果が大きいかを推定したい場合に有効である。従来のメタ分析とは対照的に、ネットワーク・メタ分析モデルは、直接および間接のエビデンスを統合することができる。2. 治療ネットワークにおける直接エビデンスと間接エビデンスの違いは何か？間接エビデンスの生成に直接エビデンスをどのように利用できるのか？直接エビデンスとは、対象となる研究で実際に調査された比較によって提供される情報である。間接エビデンスは、ある (直接観察された) 比較の効果を、関連する比較 (例えば、同じ対照群を用いた比較) の効果から差し引くことによって、直接エビデンスから導き出されるものである。3. ネットワークメタ分析における推移性 (transitivity) の仮定の主な考え方は何か？推移性の仮定は、直接証拠が観察されない間接証拠を推論するために使用できること、および直接証拠と間接証拠は一致することを規定している。4. 推移性 (transivity) と一貫性 (consistency) の関係は？推移性は、ネットワークメタ分析を行うための前提条件であり、直接的に検証することはできない。推移性統計的な現れ方は一貫性であり、直接エビデンスに基づく効果量の推定値が間接エビデンスに基づく推定値と同一または類似している場合に満たされる。5. ネットワークメタ分析に使用できる2つのモデリングアプローチを挙げなさい。どちらか一方が優れているか？ネットワークメタ分析は、頻度論的モデルまたはベイズモデルを用いて実施することができる。どちらのモデルも同等で、サンプルサイズが大きくなるにつれて収束する結果が得られる。6. 1つの試験から複数の比較を含める場合 (マルチアーム試験など)、どのような問題が発生するか？つまり、効果推定値に相関があり、解析単位に誤差が生じる。7. 異なる治療法の P-スコアまたは SUCRA スコアを解釈する際、どのような点に注意しなければならないか？異なる治療法の効果推定値が重なることが多いこと。つまり、P-/SUCRAスコアは常に慎重に解釈されるべきものである。","code":""},{"path":"qanda.html","id":"qanda13","chapter":"A Q&A","heading":"A.13 Chapter 13: ベイズメタ分析","text":"1. 「従来の」ランダム効果モデルとベイズ型階層モデルの相違点と類似点は何か？頻度論的メタ分析の基礎となるランダム効果モデルは、概念的にはベイズ階層モデルと同じである。主な違いは、ベイズ型階層モデルは、全体の真の効果量 \\(\\mu\\) と研究間の異質性 \\(\\tau\\) に対する (弱い情報量の) 事前分布を含むということである。2. ベイズメタ分析の頻度論的な利点と比較した場合の利点を3つ挙げよ。\\(\\tau^2\\) の推定値の不確実性を直接モデル化する。\\(\\mu\\) の事後分布を作成し、\\(\\mu\\) がある値以下になる確率を計算するために使用できる。事前知識や信念をモデルに統合することができる。3. 弱情報的事前分布と非情報的事前分布の違いを説明しなさい。非情報的 prior は、すべて、あるいはある範囲の可能な値が等しくあり得ると仮定する。弱情報的 prior は、ある値が他の値よりも確率が高いという弱い信念を表している。4. Half-Cauchy 分布とは何か、なぜベイズメタ分析に有用なのか。Half-Cauchy 分布は、正の値に対してのみ定義される Cauchy 分布である。これは、位置とスケーリング・パラメータによって制御され、後者は分布の尾がどの程度重いかを決定する。Half-Cauchy 分布は、\\(\\tau\\) の事前分布として使うことができる。5. ECDF とは何か、ベイズメタ分析にどう使えるか？ECDF とは、経験的累積分布関数の略である。\\(\\mu\\) (または \\(\\tau\\)) の事後分布に基づく ECDF は、推定されたパラメータがある指定された閾値より下または上にある (累積) 確率を決定するために使用されることができる。","code":""},{"path":"formula.html","id":"formula","chapter":"B 効果量の計算式","heading":"B 効果量の計算式","text":"\\renewcommand{arraystretch}{1}","code":""},{"path":"symbollist.html","id":"symbollist","chapter":"C シンボルマーク一覧","heading":"C シンボルマーク一覧","text":"注記: ベクトルや行列は太字で表記される。例えば、メタ分析で観測された全ての効果量をベクトルで表すと \\(\\boldsymbol{\\hat\\theta} = (\\hat\\theta_1, \\hat\\theta_2, \\dots, \\hat\\theta_K)^\\top\\) となる。ここで \\(K\\) は総研究数である。\\(\\top\\) 記号はベクトルが transposed であることを表している。これは、ベクトルの要素が水平方向ではなく、垂直方向に配置されていることを意味する。これは、ベクトルと別の行列を掛け合わせるなどの操作を行う際に必要な場合がある。","code":""},{"path":"attr.html","id":"attr","chapter":"D R およびパッケージ情報","heading":"D R およびパッケージ情報","text":"本書は、macOS Catalina 10.15.4 (Apple Darwin 17.0 64-bit x86-64) で動作する R バージョン 4.0.3 (“Bunny-Wunnies Freak ”, 2020-10-10) を使ってコンパイルされている。本書では、以下のパッケージバージョンを使用している。(訳注: 翻訳は、macOS および Windows の R 3.6 から 4.3 で検証した。)付属のベースパッケージロケール: en_US.UTF-8 (訳注: 日本語は ja_JP.UTF-8)属性Figure 1.2 :Sirswindon 英語版ウィキペディア, CC -SA 3.0。Wikimedia Commons 経由。オリジナルから脱色している。","code":"brms 2.13.0                 clubSandwich 0.5.5\ndmetar 0.0.9000             dplyr 1.0.1                 \nesc 0.5.1                   extraDistr 1.9.1            \nforcats 0.5.0               gemtc 0.8-6                 \nggplot2 3.3.2               ggridges 0.5.2              \nglue 1.4.1                  igraph 1.2.5                \nmeta 5.0-0                  metafor 2.5-62              \nmetaSEM 1.2.5               metasens 0.5-0              \nnetmeta 2.0-0               openxlsx 4.1.5              \nosfr 0.2.8                  PerformanceAnalytics 2.0.4  \nrjags 4-10                  robvis 0.3.0                \nsemPlot 1.1.2               stringr 1.4.0               \ntidybayes 2.1.1             tidyverse 1.3.0\nwildmeta 0.1.0base 4.0.3        datasets 4.0.3    graphics 4.0.3      \ngrDevices 4.0.3   methods 4.0.3     stats 4.0.3\nutils 4.0.3"},{"path":"corrections.html","id":"corrections","chapter":"E 訂正・備考","heading":"E 訂正・備考","text":"最終更新日 25 November, 2023 である (訳注: 翻訳の更新日)。","code":""},{"path":"corrections.html","id":"chapter-4.2","chapter":"E 訂正・備考","heading":"Chapter 4.2","text":"最近、{meta} の新しいバージョン(バージョン5.0-0)がリリースされた。この章では、非推奨のメッセージを避けるために、それに応じてコードを適応させた。引数 comb.fixed と comb.random は、それぞれ fixed と random と呼ばれるようになった。引数 comb.fixed と comb.random は、それぞれ fixed と random と呼ばれるようになった。すべての研究を表示すには、 {meta} メタ分析オブジェクトの summary メソッドを使用する必要がある。すべての研究を表示すには、 {meta} メタ分析オブジェクトの summary メソッドを使用する必要がある。","code":""},{"path":"corrections.html","id":"chapter-7.3","chapter":"E 訂正・備考","heading":"Chapter 7.3","text":"最近、{meta} の新しいバージョン(バージョン5.0-0)がリリースされた。この章では、非推奨のメッセージを避けるために、それに応じてコードを適応させることとした。引数 byvar は subgroup と呼ばれるようになった。引数 byvar は subgroup と呼ばれるようになった。すべての研究を表示すには、{meta} メタ分析オブジェクトの summary メソッドを使用する必要がある。すべての研究を表示すには、{meta} メタ分析オブジェクトの summary メソッドを使用する必要がある。","code":""},{"path":"corrections.html","id":"chapter-12.2.1","chapter":"E 訂正・備考","heading":"Chapter 12.2.1","text":"印刷版には、非正方形 (長方形) 行列におけるフルランクの定義に関する事実誤認がある。行がすべて独立でない行列はフルランクではない」と記載されている。しかし、これは正方行列と、行数が列数より少ない (\\(m < n\\)) 非正方行列にのみ適用される。この例では、行数が列数よりも多いので、\\(\\boldsymbol{X}\\) はフルランクではない。これは、その列がすべて独立していないためである (\\(m > n\\) の行列では、行は常に線形従属)。この誤りはオンライン版で修正された。","code":""},{"path":"corrections.html","id":"chapter-12.2.2","chapter":"E 訂正・備考","heading":"Chapter 12.2.2","text":"最近、{netmeta} の新しいバージョン(バージョン2.0-0)がリリースされた。この章では、エラーメッセージを避けるために、それに応じてコードを適応させた。最新版の {netmeta} では、rma.mv に実装されている Fisher scoring algorithm が収束しない問題が発生していた。この問題は、2021年10月24日以前にインストールされたすべてのバージョンの {dmetar} に関連した。この問題を回避するには、最新バージョンの {dmetar} を再インストールしよう (https://dmetar.protectlab.org/#installation)。","code":""},{"path":"citing-this-guide-1.html","id":"citing-this-guide-1","chapter":"本書を引用","heading":"本書を引用","text":"本書を引用する際は、:\nHarrer, M., Cuijpers, P., Furukawa, T.., & Ebert,\nD.D. (2021). Meta-Analysis R: Hands-\nGuide. Boca Raton, FL London: Chapmann & Hall/CRC Press.\nISBN 978-0-367-61007-4.\nとしていただきたい。参照情報は、 BibTeX または .ris でダウンロード可能。","code":""},{"path":"references.html","id":"references","chapter":"References","heading":"References","text":"","code":""}]
